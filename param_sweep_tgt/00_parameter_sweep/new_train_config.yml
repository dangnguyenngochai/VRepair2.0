world_size: 1
gpu_ranks:
- 0
batch_size: 4
valid_batch_size: 1
src_vocab: /home/lgm/VRepair2.0/param_sweep_tgt/00_parameter_sweep/data.vocab.src
tgt_vocab: /home/lgm/VRepair2.0/param_sweep_tgt/00_parameter_sweep/data.vocab.tgt
src_vocab_size: 2000
tgt_vocab_size: 2000
src_seq_length: 1000
tgt_seq_length: 100
both_embeddings: /home/lgm/VRepair2.0/param_sweep_tgt/00_parameter_sweep/codebert_embeddings.txt
embeddings_type: "GloVe"
freeze_word_vecs_enc: True
freeze_word_vecs_dec: True
save_data: /home/lgm/VRepair2.0/param_sweep_tgt/00_parameter_sweep/finetuned_embeddings
data:
  github:
    path_src: /home/lgm/VRepair2.0/vul_data/random_fine_tune_train.src.txt
    path_tgt: /home/lgm/VRepair2.0/vul_data/random_fine_tune_train.tgt.txt
  valid:
    path_src: /home/lgm/VRepair2.0/vul_data/random_fine_tune_valid.src.txt
    path_tgt: /home/lgm/VRepair2.0/vul_data/random_fine_tune_valid.tgt.txt
save_model: /home/lgm/VRepair2.0/param_sweep_tgt/00_parameter_sweep/model/model
overwrite: false
train_steps: 100000
valid_steps: 20000
save_checkpoint_steps: 20000
early_stopping: 2
early_stopping_criteria: accuracy
keep_checkpoint: 10
optim: adam
learning_rate: 0.0005
learning_rate_decay: 0.9
label_smoothing: 0.1
param_init: 0
param_init_glorot: true
encoder_type: transformer
decoder_type: transformer
enc_layers: 3
dec_layers: 3
heads: 4
rnn_size: 768
word_vec_size: 768
transformer_ff: 1024
dropout:
- 0.1
attention_dropout:
- 0.1
copy_attn: true
position_encoding: true
accum_count: 8
bridge: true
tensorboard: true
tensorboard_log_dir: /home/lgm/VRepair2.0/param_sweep_tgt/00_parameter_sweep/tensorboard_log_dir
seed: 0
