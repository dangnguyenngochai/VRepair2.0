[2022-05-05 21:16:31,006 INFO] Missing transforms field for github data, set to default: [].
[2022-05-05 21:16:31,006 WARNING] Corpus github's weight should be given. We default it to 1 for you.
[2022-05-05 21:16:31,006 INFO] Missing transforms field for valid data, set to default: [].
[2022-05-05 21:16:31,006 INFO] Parsed 2 corpora from -data.
[2022-05-05 21:16:31,007 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-05-05 21:16:31,007 INFO] Loading vocab from text file...
[2022-05-05 21:16:31,007 INFO] Loading src vocabulary from /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/data.vocab.src
[2022-05-05 21:16:31,049 INFO] Loaded src vocab has 36352 tokens.
[2022-05-05 21:16:31,058 INFO] Loading tgt vocabulary from /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/data.vocab.tgt
[2022-05-05 21:16:31,064 INFO] Loaded tgt vocab has 5924 tokens.
[2022-05-05 21:16:31,066 INFO] Building fields with vocab in counters...
[2022-05-05 21:16:31,068 INFO]  * tgt vocab size: 2004.
[2022-05-05 21:16:31,099 INFO]  * src vocab size: 2002.
[2022-05-05 21:16:31,099 INFO]  * src vocab size = 2002
[2022-05-05 21:16:31,100 INFO]  * tgt vocab size = 2004
[2022-05-05 21:16:31,103 INFO] Building model...
[2022-05-05 21:16:33,068 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2002, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2004, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=2004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2022-05-05 21:16:33,068 INFO] encoder: 2882304
[2022-05-05 21:16:33,068 INFO] decoder: 4189141
[2022-05-05 21:16:33,068 INFO] * number of parameters: 7071445
[2022-05-05 21:16:33,119 INFO] Starting training on GPU: [0]
[2022-05-05 21:16:33,119 INFO] Start training loop and validate every 20000 steps...
[2022-05-05 21:16:33,119 INFO] github's transforms: TransformPipe()
[2022-05-05 21:16:33,119 INFO] Weighted corpora loaded so far:
			* github: 1
/home/lgm/miniconda3/lib/python3.8/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  var = torch.tensor(arr, dtype=self.dtype, device=device)
[2022-05-05 21:16:41,778 INFO] Step 50/100000; acc:  11.79; ppl: 77.82; xent: 4.35; lr: 0.00050; 53573/5302 tok/s;      9 sec
[2022-05-05 21:16:44,102 INFO] Weighted corpora loaded so far:
			* github: 2
[2022-05-05 21:16:50,474 INFO] Step 100/100000; acc:  20.43; ppl: 30.87; xent: 3.43; lr: 0.00050; 53155/5270 tok/s;     17 sec
[2022-05-05 21:17:32,005 INFO] Missing transforms field for github data, set to default: [].
[2022-05-05 21:17:32,005 WARNING] Corpus github's weight should be given. We default it to 1 for you.
[2022-05-05 21:17:32,005 INFO] Missing transforms field for valid data, set to default: [].
[2022-05-05 21:17:32,005 INFO] Parsed 2 corpora from -data.
[2022-05-05 21:17:32,005 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-05-05 21:17:32,005 INFO] Loading vocab from text file...
[2022-05-05 21:17:32,005 INFO] Loading src vocabulary from /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/data.vocab.src
[2022-05-05 21:17:32,048 INFO] Loaded src vocab has 36367 tokens.
[2022-05-05 21:17:32,057 INFO] Loading tgt vocabulary from /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/data.vocab.tgt
[2022-05-05 21:17:32,063 INFO] Loaded tgt vocab has 5924 tokens.
[2022-05-05 21:17:32,064 INFO] Building fields with vocab in counters...
[2022-05-05 21:17:32,067 INFO]  * tgt vocab size: 2004.
[2022-05-05 21:17:32,098 INFO]  * src vocab size: 2002.
[2022-05-05 21:17:32,098 INFO]  * src vocab size = 2002
[2022-05-05 21:17:32,099 INFO]  * tgt vocab size = 2004
[2022-05-05 21:17:32,099 INFO] Building model...
[2022-05-05 21:17:33,649 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2002, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2004, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=2004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2022-05-05 21:17:33,650 INFO] encoder: 2882304
[2022-05-05 21:17:33,650 INFO] decoder: 4189141
[2022-05-05 21:17:33,650 INFO] * number of parameters: 7071445
[2022-05-05 21:17:33,678 INFO] Starting training on GPU: [0]
[2022-05-05 21:17:33,678 INFO] Start training loop and validate every 20000 steps...
[2022-05-05 21:17:33,678 INFO] github's transforms: TransformPipe()
[2022-05-05 21:17:33,678 INFO] Weighted corpora loaded so far:
			* github: 1
[2022-05-05 21:18:40,739 INFO] Missing transforms field for github data, set to default: [].
[2022-05-05 21:18:40,739 WARNING] Corpus github's weight should be given. We default it to 1 for you.
[2022-05-05 21:18:40,740 INFO] Missing transforms field for valid data, set to default: [].
[2022-05-05 21:18:40,740 INFO] Parsed 2 corpora from -data.
[2022-05-05 21:18:40,740 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-05-05 21:18:40,740 INFO] Loading vocab from text file...
[2022-05-05 21:18:40,740 INFO] Loading src vocabulary from /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/data.vocab.src
[2022-05-05 21:18:40,783 INFO] Loaded src vocab has 36382 tokens.
[2022-05-05 21:18:40,791 INFO] Loading tgt vocabulary from /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/data.vocab.tgt
[2022-05-05 21:18:40,797 INFO] Loaded tgt vocab has 5924 tokens.
[2022-05-05 21:18:40,799 INFO] Building fields with vocab in counters...
[2022-05-05 21:18:40,802 INFO]  * tgt vocab size: 2004.
[2022-05-05 21:18:40,833 INFO]  * src vocab size: 2002.
[2022-05-05 21:18:40,833 INFO]  * src vocab size = 2002
[2022-05-05 21:18:40,833 INFO]  * tgt vocab size = 2004
[2022-05-05 21:18:40,834 INFO] Building model...
[2022-05-05 21:18:42,381 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2002, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2004, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=2004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2022-05-05 21:18:42,382 INFO] encoder: 2882304
[2022-05-05 21:18:42,382 INFO] decoder: 4189141
[2022-05-05 21:18:42,382 INFO] * number of parameters: 7071445
[2022-05-05 21:18:42,409 INFO] Starting training on GPU: [0]
[2022-05-05 21:18:42,409 INFO] Start training loop and validate every 20000 steps...
[2022-05-05 21:18:42,409 INFO] github's transforms: TransformPipe()
[2022-05-05 21:18:42,409 INFO] Weighted corpora loaded so far:
			* github: 1
/home/lgm/miniconda3/lib/python3.8/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  var = torch.tensor(arr, dtype=self.dtype, device=device)
[2022-05-05 21:18:51,077 INFO] Step 50/100000; acc:  11.51; ppl: 77.48; xent: 4.35; lr: 0.00050; 54651/5268 tok/s;      9 sec
[2022-05-05 21:18:53,342 INFO] Weighted corpora loaded so far:
			* github: 2
[2022-05-05 21:18:59,757 INFO] Step 100/100000; acc:  20.82; ppl: 31.51; xent: 3.45; lr: 0.00050; 52252/5283 tok/s;     17 sec
[2022-05-05 21:19:04,497 INFO] Weighted corpora loaded so far:
			* github: 3
[2022-05-05 21:19:08,567 INFO] Step 150/100000; acc:  27.68; ppl: 20.03; xent: 3.00; lr: 0.00050; 52549/5242 tok/s;     26 sec
[2022-05-05 21:19:15,707 INFO] Weighted corpora loaded so far:
			* github: 4
[2022-05-05 21:19:17,357 INFO] Step 200/100000; acc:  32.84; ppl: 15.12; xent: 2.72; lr: 0.00050; 53060/5261 tok/s;     35 sec
[2022-05-05 21:19:25,808 INFO] Step 250/100000; acc:  37.96; ppl: 11.98; xent: 2.48; lr: 0.00050; 54045/5366 tok/s;     43 sec
[2022-05-05 21:19:26,856 INFO] Weighted corpora loaded so far:
			* github: 5
[2022-05-05 21:19:34,773 INFO] Step 300/100000; acc:  40.81; ppl: 10.35; xent: 2.34; lr: 0.00050; 53234/5053 tok/s;     52 sec
[2022-05-05 21:19:38,095 INFO] Weighted corpora loaded so far:
			* github: 6
[2022-05-05 21:19:43,476 INFO] Step 350/100000; acc:  44.07; ppl:  8.82; xent: 2.18; lr: 0.00050; 51254/5317 tok/s;     61 sec
[2022-05-05 21:19:49,307 INFO] Weighted corpora loaded so far:
			* github: 7
[2022-05-05 21:19:52,304 INFO] Step 400/100000; acc:  46.16; ppl:  7.94; xent: 2.07; lr: 0.00050; 51682/5235 tok/s;     70 sec
[2022-05-05 21:20:00,513 INFO] Weighted corpora loaded so far:
			* github: 8
[2022-05-05 21:20:01,153 INFO] Step 450/100000; acc:  48.69; ppl:  7.08; xent: 1.96; lr: 0.00050; 52540/5160 tok/s;     79 sec
[2022-05-05 21:20:09,749 INFO] Step 500/100000; acc:  51.49; ppl:  6.19; xent: 1.82; lr: 0.00050; 54917/5326 tok/s;     87 sec
[2022-05-05 21:20:11,741 INFO] Weighted corpora loaded so far:
			* github: 9
[2022-05-05 21:20:18,555 INFO] Step 550/100000; acc:  53.35; ppl:  5.63; xent: 1.73; lr: 0.00050; 51443/5243 tok/s;     96 sec
[2022-05-05 21:20:23,000 INFO] Weighted corpora loaded so far:
			* github: 10
[2022-05-05 21:20:27,407 INFO] Step 600/100000; acc:  55.38; ppl:  5.20; xent: 1.65; lr: 0.00050; 52740/5253 tok/s;    105 sec
[2022-05-05 21:20:34,245 INFO] Weighted corpora loaded so far:
			* github: 11
[2022-05-05 21:20:36,291 INFO] Step 650/100000; acc:  57.09; ppl:  4.83; xent: 1.57; lr: 0.00050; 51782/5200 tok/s;    114 sec
[2022-05-05 21:20:44,837 INFO] Step 700/100000; acc:  59.34; ppl:  4.34; xent: 1.47; lr: 0.00050; 53633/5322 tok/s;    122 sec
[2022-05-05 21:20:45,535 INFO] Weighted corpora loaded so far:
			* github: 12
[2022-05-05 21:20:53,822 INFO] Step 750/100000; acc:  61.11; ppl:  4.05; xent: 1.40; lr: 0.00050; 52504/5122 tok/s;    131 sec
[2022-05-05 21:20:56,886 INFO] Weighted corpora loaded so far:
			* github: 13
[2022-05-05 21:21:02,579 INFO] Step 800/100000; acc:  62.83; ppl:  3.72; xent: 1.31; lr: 0.00050; 50780/5161 tok/s;    140 sec
[2022-05-05 21:21:11,388 INFO] Step 850/100000; acc:  63.95; ppl:  3.51; xent: 1.26; lr: 0.00050; 51977/5292 tok/s;    149 sec
[2022-05-05 21:21:19,206 INFO] Weighted corpora loaded so far:
			* github: 14
[2022-05-05 21:21:20,276 INFO] Step 900/100000; acc:  65.55; ppl:  3.34; xent: 1.21; lr: 0.00050; 52889/5171 tok/s;    158 sec
[2022-05-05 21:21:28,770 INFO] Step 950/100000; acc:  67.50; ppl:  3.07; xent: 1.12; lr: 0.00050; 55022/5333 tok/s;    166 sec
[2022-05-05 21:21:30,403 INFO] Weighted corpora loaded so far:
			* github: 15
[2022-05-05 21:21:37,603 INFO] Step 1000/100000; acc:  68.80; ppl:  2.91; xent: 1.07; lr: 0.00050; 52178/5196 tok/s;    175 sec
[2022-05-05 21:21:41,617 INFO] Weighted corpora loaded so far:
			* github: 16
[2022-05-05 21:21:46,342 INFO] Step 1050/100000; acc:  70.07; ppl:  2.77; xent: 1.02; lr: 0.00050; 52251/5302 tok/s;    184 sec
[2022-05-05 21:21:52,897 INFO] Weighted corpora loaded so far:
			* github: 17
[2022-05-05 21:21:55,252 INFO] Step 1100/100000; acc:  70.67; ppl:  2.68; xent: 0.98; lr: 0.00050; 51709/5212 tok/s;    193 sec
[2022-05-05 21:22:03,852 INFO] Step 1150/100000; acc:  72.06; ppl:  2.53; xent: 0.93; lr: 0.00050; 54692/5284 tok/s;    201 sec
[2022-05-05 21:22:04,176 INFO] Weighted corpora loaded so far:
			* github: 18
[2022-05-05 21:22:13,040 INFO] Step 1200/100000; acc:  73.39; ppl:  2.40; xent: 0.88; lr: 0.00050; 51027/4975 tok/s;    211 sec
[2022-05-05 21:22:15,677 INFO] Weighted corpora loaded so far:
			* github: 19
[2022-05-05 21:22:21,765 INFO] Step 1250/100000; acc:  75.22; ppl:  2.26; xent: 0.82; lr: 0.00050; 51295/5244 tok/s;    219 sec
[2022-05-05 21:22:26,924 INFO] Weighted corpora loaded so far:
			* github: 20
[2022-05-05 21:22:30,612 INFO] Step 1300/100000; acc:  75.60; ppl:  2.23; xent: 0.80; lr: 0.00050; 51843/5225 tok/s;    228 sec
[2022-05-05 21:22:38,124 INFO] Weighted corpora loaded so far:
			* github: 21
[2022-05-05 21:22:39,488 INFO] Step 1350/100000; acc:  76.50; ppl:  2.14; xent: 0.76; lr: 0.00050; 52672/5133 tok/s;    237 sec
[2022-05-05 21:22:48,178 INFO] Step 1400/100000; acc:  78.33; ppl:  2.02; xent: 0.70; lr: 0.00050; 52971/5230 tok/s;    246 sec
[2022-05-05 21:22:49,548 INFO] Weighted corpora loaded so far:
			* github: 22
[2022-05-05 21:22:57,072 INFO] Step 1450/100000; acc:  78.74; ppl:  1.97; xent: 0.68; lr: 0.00050; 52916/5202 tok/s;    255 sec
[2022-05-05 21:23:00,785 INFO] Weighted corpora loaded so far:
			* github: 23
[2022-05-05 21:23:05,738 INFO] Step 1500/100000; acc:  79.20; ppl:  1.93; xent: 0.66; lr: 0.00050; 51628/5351 tok/s;    263 sec
[2022-05-05 21:23:11,896 INFO] Weighted corpora loaded so far:
			* github: 24
[2022-05-05 21:23:14,514 INFO] Step 1550/100000; acc:  80.25; ppl:  1.87; xent: 0.63; lr: 0.00050; 51897/5226 tok/s;    272 sec
[2022-05-05 21:23:23,103 INFO] Step 1600/100000; acc:  80.88; ppl:  1.83; xent: 0.61; lr: 0.00050; 54571/5382 tok/s;    281 sec
[2022-05-05 21:23:23,133 INFO] Weighted corpora loaded so far:
			* github: 25
[2022-05-05 21:23:32,040 INFO] Step 1650/100000; acc:  81.87; ppl:  1.77; xent: 0.57; lr: 0.00050; 52698/5074 tok/s;    290 sec
[2022-05-05 21:23:34,402 INFO] Weighted corpora loaded so far:
			* github: 26
[2022-05-05 21:23:40,856 INFO] Step 1700/100000; acc:  82.43; ppl:  1.73; xent: 0.55; lr: 0.00050; 51039/5211 tok/s;    298 sec
[2022-05-05 21:23:49,968 INFO] Step 1750/100000; acc:  83.24; ppl:  1.69; xent: 0.52; lr: 0.00050; 50543/5079 tok/s;    308 sec
[2022-05-05 21:23:57,074 INFO] Weighted corpora loaded so far:
			* github: 27
[2022-05-05 21:23:58,784 INFO] Step 1800/100000; acc:  83.85; ppl:  1.66; xent: 0.51; lr: 0.00050; 52860/5134 tok/s;    316 sec
[2022-05-05 21:24:07,256 INFO] Step 1850/100000; acc:  84.53; ppl:  1.62; xent: 0.48; lr: 0.00050; 53973/5444 tok/s;    325 sec
[2022-05-05 21:24:08,297 INFO] Weighted corpora loaded so far:
			* github: 28
[2022-05-05 21:24:16,270 INFO] Step 1900/100000; acc:  84.66; ppl:  1.61; xent: 0.48; lr: 0.00050; 52903/5148 tok/s;    334 sec
[2022-05-05 21:24:19,558 INFO] Weighted corpora loaded so far:
			* github: 29
[2022-05-05 21:24:24,948 INFO] Step 1950/100000; acc:  85.39; ppl:  1.58; xent: 0.46; lr: 0.00050; 51828/5303 tok/s;    343 sec
[2022-05-05 21:24:30,744 INFO] Weighted corpora loaded so far:
			* github: 30
[2022-05-05 21:24:33,737 INFO] Step 2000/100000; acc:  86.06; ppl:  1.55; xent: 0.44; lr: 0.00050; 52473/5128 tok/s;    351 sec
[2022-05-05 21:24:41,971 INFO] Weighted corpora loaded so far:
			* github: 31
[2022-05-05 21:24:42,628 INFO] Step 2050/100000; acc:  86.16; ppl:  1.53; xent: 0.43; lr: 0.00050; 52465/5204 tok/s;    360 sec
[2022-05-05 21:24:51,219 INFO] Step 2100/100000; acc:  86.75; ppl:  1.50; xent: 0.41; lr: 0.00050; 54495/5273 tok/s;    369 sec
[2022-05-05 21:24:53,234 INFO] Weighted corpora loaded so far:
			* github: 32
[2022-05-05 21:24:59,971 INFO] Step 2150/100000; acc:  87.31; ppl:  1.48; xent: 0.39; lr: 0.00050; 51289/5265 tok/s;    378 sec
[2022-05-05 21:25:04,417 INFO] Weighted corpora loaded so far:
			* github: 33
[2022-05-05 21:25:08,839 INFO] Step 2200/100000; acc:  87.79; ppl:  1.47; xent: 0.38; lr: 0.00050; 52583/5231 tok/s;    386 sec
[2022-05-05 21:25:15,634 INFO] Weighted corpora loaded so far:
			* github: 34
[2022-05-05 21:25:17,691 INFO] Step 2250/100000; acc:  87.89; ppl:  1.45; xent: 0.37; lr: 0.00050; 52354/5206 tok/s;    395 sec
[2022-05-05 21:25:26,177 INFO] Step 2300/100000; acc:  88.30; ppl:  1.44; xent: 0.36; lr: 0.00050; 54286/5324 tok/s;    404 sec
[2022-05-05 21:25:26,870 INFO] Weighted corpora loaded so far:
			* github: 35
[2022-05-05 21:25:35,196 INFO] Step 2350/100000; acc:  88.81; ppl:  1.41; xent: 0.35; lr: 0.00050; 52542/5180 tok/s;    413 sec
[2022-05-05 21:25:38,203 INFO] Weighted corpora loaded so far:
			* github: 36
[2022-05-05 21:25:43,924 INFO] Step 2400/100000; acc:  89.08; ppl:  1.40; xent: 0.34; lr: 0.00050; 51106/5210 tok/s;    422 sec
[2022-05-05 21:25:49,431 INFO] Weighted corpora loaded so far:
			* github: 37
[2022-05-05 21:25:52,756 INFO] Step 2450/100000; acc:  89.61; ppl:  1.38; xent: 0.32; lr: 0.00050; 51743/5271 tok/s;    430 sec
[2022-05-05 21:26:00,624 INFO] Weighted corpora loaded so far:
			* github: 38
[2022-05-05 21:26:01,677 INFO] Step 2500/100000; acc:  89.40; ppl:  1.38; xent: 0.33; lr: 0.00050; 52329/5221 tok/s;    439 sec
[2022-05-05 21:26:10,205 INFO] Step 2550/100000; acc:  90.15; ppl:  1.36; xent: 0.31; lr: 0.00050; 54510/5266 tok/s;    448 sec
[2022-05-05 21:26:11,937 INFO] Weighted corpora loaded so far:
			* github: 39
[2022-05-05 21:26:19,086 INFO] Step 2600/100000; acc:  90.40; ppl:  1.35; xent: 0.30; lr: 0.00050; 51622/5148 tok/s;    457 sec
[2022-05-05 21:26:27,818 INFO] Step 2650/100000; acc:  90.81; ppl:  1.33; xent: 0.28; lr: 0.00050; 52104/5192 tok/s;    465 sec
[2022-05-05 21:26:34,332 INFO] Weighted corpora loaded so far:
			* github: 40
[2022-05-05 21:26:36,681 INFO] Step 2700/100000; acc:  90.80; ppl:  1.33; xent: 0.29; lr: 0.00050; 51862/5269 tok/s;    474 sec
[2022-05-05 21:26:45,220 INFO] Step 2750/100000; acc:  90.91; ppl:  1.32; xent: 0.28; lr: 0.00050; 54767/5345 tok/s;    483 sec
[2022-05-05 21:26:45,546 INFO] Weighted corpora loaded so far:
			* github: 41
[2022-05-05 21:26:54,168 INFO] Step 2800/100000; acc:  91.49; ppl:  1.31; xent: 0.27; lr: 0.00050; 52836/5142 tok/s;    492 sec
[2022-05-05 21:26:56,827 INFO] Weighted corpora loaded so far:
			* github: 42
[2022-05-05 21:27:02,948 INFO] Step 2850/100000; acc:  91.52; ppl:  1.30; xent: 0.26; lr: 0.00050; 51468/5201 tok/s;    501 sec
[2022-05-05 21:27:08,070 INFO] Weighted corpora loaded so far:
			* github: 43
[2022-05-05 21:27:11,760 INFO] Step 2900/100000; acc:  91.85; ppl:  1.29; xent: 0.25; lr: 0.00050; 52504/5195 tok/s;    509 sec
[2022-05-05 21:27:19,318 INFO] Weighted corpora loaded so far:
			* github: 44
[2022-05-05 21:27:20,713 INFO] Step 2950/100000; acc:  91.52; ppl:  1.30; xent: 0.26; lr: 0.00050; 52460/5276 tok/s;    518 sec
[2022-05-05 21:27:29,141 INFO] Step 3000/100000; acc:  92.16; ppl:  1.28; xent: 0.25; lr: 0.00050; 53704/5358 tok/s;    527 sec
[2022-05-05 21:27:30,479 INFO] Weighted corpora loaded so far:
			* github: 45
[2022-05-05 21:27:38,070 INFO] Step 3050/100000; acc:  92.39; ppl:  1.27; xent: 0.24; lr: 0.00050; 52365/5087 tok/s;    536 sec
[2022-05-05 21:27:41,737 INFO] Weighted corpora loaded so far:
			* github: 46
[2022-05-05 21:27:46,811 INFO] Step 3100/100000; acc:  92.46; ppl:  1.26; xent: 0.23; lr: 0.00050; 51560/5311 tok/s;    544 sec
[2022-05-05 21:27:53,010 INFO] Weighted corpora loaded so far:
			* github: 47
[2022-05-05 21:27:55,677 INFO] Step 3150/100000; acc:  92.66; ppl:  1.26; xent: 0.23; lr: 0.00050; 52055/5198 tok/s;    553 sec
[2022-05-05 21:28:04,237 INFO] Step 3200/100000; acc:  92.50; ppl:  1.26; xent: 0.23; lr: 0.00050; 54846/5328 tok/s;    562 sec
[2022-05-05 21:28:04,261 INFO] Weighted corpora loaded so far:
			* github: 48
[2022-05-05 21:28:13,233 INFO] Step 3250/100000; acc:  93.26; ppl:  1.23; xent: 0.21; lr: 0.00050; 52317/5138 tok/s;    571 sec
[2022-05-05 21:28:15,551 INFO] Weighted corpora loaded so far:
			* github: 49
[2022-05-05 21:28:21,998 INFO] Step 3300/100000; acc:  92.81; ppl:  1.25; xent: 0.22; lr: 0.00050; 51474/5180 tok/s;    580 sec
[2022-05-05 21:28:26,814 INFO] Weighted corpora loaded so far:
			* github: 50
[2022-05-05 21:28:30,917 INFO] Step 3350/100000; acc:  93.21; ppl:  1.23; xent: 0.21; lr: 0.00050; 51557/5227 tok/s;    589 sec
[2022-05-05 21:28:38,115 INFO] Weighted corpora loaded so far:
			* github: 51
[2022-05-05 21:28:39,875 INFO] Step 3400/100000; acc:  93.33; ppl:  1.23; xent: 0.21; lr: 0.00050; 51582/5190 tok/s;    597 sec
[2022-05-05 21:28:48,394 INFO] Step 3450/100000; acc:  93.62; ppl:  1.23; xent: 0.20; lr: 0.00050; 53287/5311 tok/s;    606 sec
[2022-05-05 21:28:57,266 INFO] Step 3500/100000; acc:  93.49; ppl:  1.22; xent: 0.20; lr: 0.00050; 53433/5136 tok/s;    615 sec
[2022-05-05 21:29:00,545 INFO] Weighted corpora loaded so far:
			* github: 52
[2022-05-05 21:29:05,991 INFO] Step 3550/100000; acc:  93.79; ppl:  1.21; xent: 0.19; lr: 0.00050; 51562/5261 tok/s;    624 sec
[2022-05-05 21:29:11,834 INFO] Weighted corpora loaded so far:
			* github: 53
[2022-05-05 21:29:15,107 INFO] Step 3600/100000; acc:  93.78; ppl:  1.21; xent: 0.19; lr: 0.00050; 50681/5041 tok/s;    633 sec
[2022-05-05 21:29:24,202 INFO] Weighted corpora loaded so far:
			* github: 54
[2022-05-05 21:29:24,858 INFO] Step 3650/100000; acc:  93.64; ppl:  1.22; xent: 0.19; lr: 0.00050; 47738/4751 tok/s;    642 sec
[2022-05-05 21:29:33,723 INFO] Step 3700/100000; acc:  93.91; ppl:  1.21; xent: 0.19; lr: 0.00050; 53287/5100 tok/s;    651 sec
[2022-05-05 21:29:35,669 INFO] Weighted corpora loaded so far:
			* github: 55
[2022-05-05 21:29:42,443 INFO] Step 3750/100000; acc:  94.22; ppl:  1.20; xent: 0.18; lr: 0.00050; 51873/5296 tok/s;    660 sec
[2022-05-05 21:29:46,888 INFO] Weighted corpora loaded so far:
			* github: 56
[2022-05-05 21:29:51,314 INFO] Step 3800/100000; acc:  94.21; ppl:  1.20; xent: 0.18; lr: 0.00050; 52632/5181 tok/s;    669 sec
[2022-05-05 21:29:58,174 INFO] Weighted corpora loaded so far:
			* github: 57
[2022-05-05 21:30:00,147 INFO] Step 3850/100000; acc:  94.36; ppl:  1.19; xent: 0.17; lr: 0.00050; 52213/5187 tok/s;    678 sec
[2022-05-05 21:30:08,988 INFO] Step 3900/100000; acc:  94.55; ppl:  1.18; xent: 0.17; lr: 0.00050; 51793/5158 tok/s;    687 sec
[2022-05-05 21:30:09,668 INFO] Weighted corpora loaded so far:
			* github: 58
[2022-05-05 21:30:17,908 INFO] Step 3950/100000; acc:  94.45; ppl:  1.19; xent: 0.17; lr: 0.00050; 52927/5163 tok/s;    695 sec
[2022-05-05 21:30:20,886 INFO] Weighted corpora loaded so far:
			* github: 59
[2022-05-05 21:30:26,642 INFO] Step 4000/100000; acc:  94.53; ppl:  1.18; xent: 0.17; lr: 0.00050; 51314/5221 tok/s;    704 sec
[2022-05-05 21:30:32,157 INFO] Weighted corpora loaded so far:
			* github: 60
[2022-05-05 21:30:35,510 INFO] Step 4050/100000; acc:  94.89; ppl:  1.17; xent: 0.16; lr: 0.00050; 52100/5210 tok/s;    713 sec
[2022-05-05 21:30:43,406 INFO] Weighted corpora loaded so far:
			* github: 61
[2022-05-05 21:30:44,456 INFO] Step 4100/100000; acc:  94.75; ppl:  1.18; xent: 0.16; lr: 0.00050; 52756/5195 tok/s;    722 sec
[2022-05-05 21:30:52,947 INFO] Step 4150/100000; acc:  94.85; ppl:  1.17; xent: 0.16; lr: 0.00050; 54282/5330 tok/s;    731 sec
[2022-05-05 21:30:54,611 INFO] Weighted corpora loaded so far:
			* github: 62
[2022-05-05 21:31:01,851 INFO] Step 4200/100000; acc:  94.97; ppl:  1.17; xent: 0.16; lr: 0.00050; 51434/5197 tok/s;    739 sec
[2022-05-05 21:31:05,907 INFO] Weighted corpora loaded so far:
			* github: 63
[2022-05-05 21:31:10,840 INFO] Step 4250/100000; acc:  94.84; ppl:  1.17; xent: 0.16; lr: 0.00050; 50434/5143 tok/s;    748 sec
[2022-05-05 21:31:17,413 INFO] Weighted corpora loaded so far:
			* github: 64
[2022-05-05 21:31:19,748 INFO] Step 4300/100000; acc:  95.13; ppl:  1.16; xent: 0.15; lr: 0.00050; 51291/5173 tok/s;    757 sec
[2022-05-05 21:31:28,351 INFO] Step 4350/100000; acc:  94.94; ppl:  1.17; xent: 0.16; lr: 0.00050; 54220/5327 tok/s;    766 sec
[2022-05-05 21:31:37,348 INFO] Step 4400/100000; acc:  95.53; ppl:  1.15; xent: 0.14; lr: 0.00050; 52221/5051 tok/s;    775 sec
[2022-05-05 21:31:40,111 INFO] Weighted corpora loaded so far:
			* github: 65
[2022-05-05 21:31:46,847 INFO] Step 4450/100000; acc:  95.39; ppl:  1.16; xent: 0.15; lr: 0.00050; 47462/4845 tok/s;    784 sec
[2022-05-05 21:31:52,283 INFO] Weighted corpora loaded so far:
			* github: 66
[2022-05-05 21:31:56,010 INFO] Step 4500/100000; acc:  95.21; ppl:  1.16; xent: 0.15; lr: 0.00050; 50450/5047 tok/s;    794 sec
[2022-05-05 21:32:03,534 INFO] Weighted corpora loaded so far:
			* github: 67
[2022-05-05 21:32:04,935 INFO] Step 4550/100000; acc:  95.35; ppl:  1.16; xent: 0.15; lr: 0.00050; 52671/5136 tok/s;    803 sec
[2022-05-05 21:32:13,463 INFO] Step 4600/100000; acc:  95.54; ppl:  1.15; xent: 0.14; lr: 0.00050; 54140/5304 tok/s;    811 sec
[2022-05-05 21:32:14,821 INFO] Weighted corpora loaded so far:
			* github: 68
[2022-05-05 21:32:22,384 INFO] Step 4650/100000; acc:  95.57; ppl:  1.15; xent: 0.14; lr: 0.00050; 52732/5222 tok/s;    820 sec
[2022-05-05 21:32:26,051 INFO] Weighted corpora loaded so far:
			* github: 69
[2022-05-05 21:32:31,108 INFO] Step 4700/100000; acc:  95.79; ppl:  1.14; xent: 0.13; lr: 0.00050; 51390/5244 tok/s;    829 sec
[2022-05-05 21:32:37,252 INFO] Weighted corpora loaded so far:
			* github: 70
[2022-05-05 21:32:39,887 INFO] Step 4750/100000; acc:  95.72; ppl:  1.14; xent: 0.13; lr: 0.00050; 52009/5176 tok/s;    837 sec
[2022-05-05 21:32:49,016 INFO] Step 4800/100000; acc:  95.77; ppl:  1.14; xent: 0.13; lr: 0.00050; 51144/5055 tok/s;    847 sec
[2022-05-05 21:32:49,032 INFO] Weighted corpora loaded so far:
			* github: 71
[2022-05-05 21:32:57,942 INFO] Step 4850/100000; acc:  95.82; ppl:  1.14; xent: 0.13; lr: 0.00050; 52799/5168 tok/s;    856 sec
[2022-05-05 21:33:00,251 INFO] Weighted corpora loaded so far:
			* github: 72
[2022-05-05 21:33:06,734 INFO] Step 4900/100000; acc:  96.00; ppl:  1.14; xent: 0.13; lr: 0.00050; 51619/5076 tok/s;    864 sec
[2022-05-05 21:33:11,543 INFO] Weighted corpora loaded so far:
			* github: 73
[2022-05-05 21:33:15,638 INFO] Step 4950/100000; acc:  95.78; ppl:  1.14; xent: 0.13; lr: 0.00050; 52043/5234 tok/s;    873 sec
[2022-05-05 21:33:22,882 INFO] Weighted corpora loaded so far:
			* github: 74
[2022-05-05 21:33:24,606 INFO] Step 5000/100000; acc:  95.92; ppl:  1.14; xent: 0.13; lr: 0.00050; 51882/5216 tok/s;    882 sec
[2022-05-05 21:33:33,087 INFO] Step 5050/100000; acc:  95.82; ppl:  1.14; xent: 0.13; lr: 0.00050; 53300/5400 tok/s;    891 sec
[2022-05-05 21:33:34,155 INFO] Weighted corpora loaded so far:
			* github: 75
[2022-05-05 21:33:42,096 INFO] Step 5100/100000; acc:  96.02; ppl:  1.13; xent: 0.13; lr: 0.00050; 52518/5080 tok/s;    900 sec
[2022-05-05 21:33:45,481 INFO] Weighted corpora loaded so far:
			* github: 76
[2022-05-05 21:33:50,843 INFO] Step 5150/100000; acc:  96.18; ppl:  1.13; xent: 0.12; lr: 0.00050; 51068/5199 tok/s;    908 sec
[2022-05-05 21:33:56,724 INFO] Weighted corpora loaded so far:
			* github: 77
[2022-05-05 21:33:59,683 INFO] Step 5200/100000; acc:  96.24; ppl:  1.13; xent: 0.12; lr: 0.00050; 51800/5249 tok/s;    917 sec
[2022-05-05 21:34:08,540 INFO] Step 5250/100000; acc:  96.14; ppl:  1.13; xent: 0.12; lr: 0.00050; 52247/5177 tok/s;    926 sec
[2022-05-05 21:34:17,156 INFO] Step 5300/100000; acc:  96.37; ppl:  1.12; xent: 0.11; lr: 0.00050; 54911/5282 tok/s;    935 sec
[2022-05-05 21:34:19,135 INFO] Weighted corpora loaded so far:
			* github: 78
[2022-05-05 21:34:25,974 INFO] Step 5350/100000; acc:  96.28; ppl:  1.13; xent: 0.12; lr: 0.00050; 51319/5133 tok/s;    944 sec
[2022-05-05 21:34:30,559 INFO] Weighted corpora loaded so far:
			* github: 79
[2022-05-05 21:34:35,017 INFO] Step 5400/100000; acc:  96.30; ppl:  1.12; xent: 0.12; lr: 0.00050; 51679/5209 tok/s;    953 sec
[2022-05-05 21:34:41,851 INFO] Weighted corpora loaded so far:
			* github: 80
[2022-05-05 21:34:43,913 INFO] Step 5450/100000; acc:  96.37; ppl:  1.12; xent: 0.11; lr: 0.00050; 52023/5136 tok/s;    962 sec
[2022-05-05 21:34:52,474 INFO] Step 5500/100000; acc:  96.52; ppl:  1.12; xent: 0.11; lr: 0.00050; 54119/5323 tok/s;    970 sec
[2022-05-05 21:34:53,174 INFO] Weighted corpora loaded so far:
			* github: 81
[2022-05-05 21:35:01,486 INFO] Step 5550/100000; acc:  96.37; ppl:  1.12; xent: 0.11; lr: 0.00050; 52604/5145 tok/s;    979 sec
[2022-05-05 21:35:04,568 INFO] Weighted corpora loaded so far:
			* github: 82
[2022-05-05 21:35:10,338 INFO] Step 5600/100000; acc:  96.76; ppl:  1.11; xent: 0.10; lr: 0.00050; 50317/5051 tok/s;    988 sec
[2022-05-05 21:35:15,908 INFO] Weighted corpora loaded so far:
			* github: 83
[2022-05-05 21:35:19,226 INFO] Step 5650/100000; acc:  96.43; ppl:  1.12; xent: 0.11; lr: 0.00050; 51429/5207 tok/s;    997 sec
[2022-05-05 21:35:27,186 INFO] Weighted corpora loaded so far:
			* github: 84
[2022-05-05 21:35:28,226 INFO] Step 5700/100000; acc:  96.29; ppl:  1.12; xent: 0.11; lr: 0.00050; 52074/5159 tok/s;   1006 sec
[2022-05-05 21:35:36,883 INFO] Step 5750/100000; acc:  96.41; ppl:  1.12; xent: 0.11; lr: 0.00050; 54030/5326 tok/s;   1014 sec
[2022-05-05 21:35:38,557 INFO] Weighted corpora loaded so far:
			* github: 85
[2022-05-05 21:35:45,779 INFO] Step 5800/100000; acc:  96.60; ppl:  1.11; xent: 0.11; lr: 0.00050; 51768/5057 tok/s;   1023 sec
[2022-05-05 21:35:49,856 INFO] Weighted corpora loaded so far:
			* github: 86
[2022-05-05 21:35:54,592 INFO] Step 5850/100000; acc:  96.68; ppl:  1.11; xent: 0.10; lr: 0.00050; 51637/5213 tok/s;   1032 sec
[2022-05-05 21:36:01,696 INFO] Weighted corpora loaded so far:
			* github: 87
[2022-05-05 21:36:04,125 INFO] Step 5900/100000; acc:  96.55; ppl:  1.11; xent: 0.11; lr: 0.00050; 48056/4955 tok/s;   1042 sec
[2022-05-05 21:36:12,663 INFO] Step 5950/100000; acc:  96.74; ppl:  1.11; xent: 0.10; lr: 0.00050; 54619/5368 tok/s;   1050 sec
[2022-05-05 21:36:13,007 INFO] Weighted corpora loaded so far:
			* github: 88
[2022-05-05 21:36:21,531 INFO] Step 6000/100000; acc:  96.93; ppl:  1.10; xent: 0.10; lr: 0.00050; 52644/5110 tok/s;   1059 sec
[2022-05-05 21:36:24,193 INFO] Weighted corpora loaded so far:
			* github: 89
[2022-05-05 21:36:30,247 INFO] Step 6050/100000; acc:  97.00; ppl:  1.10; xent: 0.10; lr: 0.00050; 51418/5267 tok/s;   1068 sec
[2022-05-05 21:36:35,382 INFO] Weighted corpora loaded so far:
			* github: 90
[2022-05-05 21:36:39,055 INFO] Step 6100/100000; acc:  96.81; ppl:  1.11; xent: 0.10; lr: 0.00050; 52207/5200 tok/s;   1077 sec
[2022-05-05 21:36:47,971 INFO] Step 6150/100000; acc:  96.68; ppl:  1.11; xent: 0.10; lr: 0.00050; 52460/5250 tok/s;   1086 sec
[2022-05-05 21:36:56,457 INFO] Step 6200/100000; acc:  96.88; ppl:  1.10; xent: 0.10; lr: 0.00050; 54396/5271 tok/s;   1094 sec
[2022-05-05 21:36:57,818 INFO] Weighted corpora loaded so far:
			* github: 91
[2022-05-05 21:37:05,375 INFO] Step 6250/100000; acc:  96.86; ppl:  1.10; xent: 0.10; lr: 0.00050; 52505/5201 tok/s;   1103 sec
[2022-05-05 21:37:09,033 INFO] Weighted corpora loaded so far:
			* github: 92
[2022-05-05 21:37:14,134 INFO] Step 6300/100000; acc:  97.03; ppl:  1.10; xent: 0.10; lr: 0.00050; 51388/5225 tok/s;   1112 sec
[2022-05-05 21:37:20,342 INFO] Weighted corpora loaded so far:
			* github: 93
[2022-05-05 21:37:22,995 INFO] Step 6350/100000; acc:  97.07; ppl:  1.10; xent: 0.09; lr: 0.00050; 52029/5205 tok/s;   1121 sec
[2022-05-05 21:37:31,648 INFO] Step 6400/100000; acc:  97.00; ppl:  1.10; xent: 0.10; lr: 0.00050; 54312/5320 tok/s;   1129 sec
[2022-05-05 21:37:31,659 INFO] Weighted corpora loaded so far:
			* github: 94
[2022-05-05 21:37:40,643 INFO] Step 6450/100000; acc:  97.20; ppl:  1.09; xent: 0.09; lr: 0.00050; 52645/5118 tok/s;   1138 sec
[2022-05-05 21:37:42,950 INFO] Weighted corpora loaded so far:
			* github: 95
[2022-05-05 21:37:49,469 INFO] Step 6500/100000; acc:  97.06; ppl:  1.09; xent: 0.09; lr: 0.00050; 51083/5227 tok/s;   1147 sec
[2022-05-05 21:37:54,312 INFO] Weighted corpora loaded so far:
			* github: 96
[2022-05-05 21:37:58,449 INFO] Step 6550/100000; acc:  97.19; ppl:  1.09; xent: 0.09; lr: 0.00050; 51143/4985 tok/s;   1156 sec
[2022-05-05 21:38:05,670 INFO] Weighted corpora loaded so far:
			* github: 97
[2022-05-05 21:38:07,379 INFO] Step 6600/100000; acc:  97.07; ppl:  1.10; xent: 0.09; lr: 0.00050; 51886/5139 tok/s;   1165 sec
[2022-05-05 21:38:15,999 INFO] Step 6650/100000; acc:  97.06; ppl:  1.10; xent: 0.09; lr: 0.00050; 53093/5375 tok/s;   1174 sec
[2022-05-05 21:38:17,069 INFO] Weighted corpora loaded so far:
			* github: 98
[2022-05-05 21:38:25,048 INFO] Step 6700/100000; acc:  97.07; ppl:  1.10; xent: 0.09; lr: 0.00050; 52769/5166 tok/s;   1183 sec
[2022-05-05 21:38:28,387 INFO] Weighted corpora loaded so far:
			* github: 99
[2022-05-05 21:38:33,825 INFO] Step 6750/100000; acc:  97.27; ppl:  1.09; xent: 0.09; lr: 0.00050; 50977/5197 tok/s;   1191 sec
[2022-05-05 21:38:39,733 INFO] Weighted corpora loaded so far:
			* github: 100
[2022-05-05 21:38:42,684 INFO] Step 6800/100000; acc:  97.22; ppl:  1.09; xent: 0.09; lr: 0.00050; 51594/5223 tok/s;   1200 sec
[2022-05-05 21:38:50,961 INFO] Weighted corpora loaded so far:
			* github: 101
[2022-05-05 21:38:51,596 INFO] Step 6850/100000; acc:  97.10; ppl:  1.09; xent: 0.09; lr: 0.00050; 52043/5142 tok/s;   1209 sec
[2022-05-05 21:39:00,225 INFO] Step 6900/100000; acc:  97.16; ppl:  1.09; xent: 0.09; lr: 0.00050; 54417/5243 tok/s;   1218 sec
[2022-05-05 21:39:02,234 INFO] Weighted corpora loaded so far:
			* github: 102
[2022-05-05 21:39:09,042 INFO] Step 6950/100000; acc:  97.38; ppl:  1.09; xent: 0.09; lr: 0.00050; 50839/5221 tok/s;   1227 sec
[2022-05-05 21:39:17,984 INFO] Step 7000/100000; acc:  97.26; ppl:  1.09; xent: 0.09; lr: 0.00050; 51919/5151 tok/s;   1236 sec
[2022-05-05 21:39:24,768 INFO] Weighted corpora loaded so far:
			* github: 103
[2022-05-05 21:39:26,809 INFO] Step 7050/100000; acc:  97.27; ppl:  1.09; xent: 0.09; lr: 0.00050; 52327/5171 tok/s;   1244 sec
[2022-05-05 21:39:35,352 INFO] Step 7100/100000; acc:  97.33; ppl:  1.09; xent: 0.08; lr: 0.00050; 54373/5305 tok/s;   1253 sec
[2022-05-05 21:39:36,041 INFO] Weighted corpora loaded so far:
			* github: 104
[2022-05-05 21:39:44,350 INFO] Step 7150/100000; acc:  97.30; ppl:  1.09; xent: 0.09; lr: 0.00050; 52593/5144 tok/s;   1262 sec
[2022-05-05 21:39:47,324 INFO] Weighted corpora loaded so far:
			* github: 105
[2022-05-05 21:39:53,072 INFO] Step 7200/100000; acc:  97.43; ppl:  1.08; xent: 0.08; lr: 0.00050; 51506/5319 tok/s;   1271 sec
[2022-05-05 21:39:58,550 INFO] Weighted corpora loaded so far:
			* github: 106
[2022-05-05 21:40:01,901 INFO] Step 7250/100000; acc:  97.39; ppl:  1.09; xent: 0.08; lr: 0.00050; 52346/5151 tok/s;   1279 sec
[2022-05-05 21:40:09,949 INFO] Weighted corpora loaded so far:
			* github: 107
[2022-05-05 21:40:10,951 INFO] Step 7300/100000; acc:  97.41; ppl:  1.09; xent: 0.08; lr: 0.00050; 52042/5153 tok/s;   1289 sec
[2022-05-05 21:40:19,523 INFO] Step 7350/100000; acc:  97.38; ppl:  1.09; xent: 0.08; lr: 0.00050; 54041/5267 tok/s;   1297 sec
[2022-05-05 21:40:21,176 INFO] Weighted corpora loaded so far:
			* github: 108
[2022-05-05 21:40:28,368 INFO] Step 7400/100000; acc:  97.58; ppl:  1.08; xent: 0.08; lr: 0.00050; 51808/5223 tok/s;   1306 sec
[2022-05-05 21:40:32,425 INFO] Weighted corpora loaded so far:
			* github: 109
[2022-05-05 21:40:37,188 INFO] Step 7450/100000; acc:  97.55; ppl:  1.08; xent: 0.08; lr: 0.00050; 51341/5205 tok/s;   1315 sec
[2022-05-05 21:40:43,760 INFO] Weighted corpora loaded so far:
			* github: 110
[2022-05-05 21:40:46,047 INFO] Step 7500/100000; acc:  97.21; ppl:  1.09; xent: 0.09; lr: 0.00050; 51682/5194 tok/s;   1324 sec
[2022-05-05 21:40:54,669 INFO] Step 7550/100000; acc:  97.52; ppl:  1.08; xent: 0.08; lr: 0.00050; 54711/5286 tok/s;   1332 sec
[2022-05-05 21:40:55,017 INFO] Weighted corpora loaded so far:
			* github: 111
[2022-05-05 21:41:03,601 INFO] Step 7600/100000; acc:  97.53; ppl:  1.08; xent: 0.08; lr: 0.00050; 52721/5153 tok/s;   1341 sec
[2022-05-05 21:41:06,250 INFO] Weighted corpora loaded so far:
			* github: 112
[2022-05-05 21:41:12,330 INFO] Step 7650/100000; acc:  97.53; ppl:  1.08; xent: 0.08; lr: 0.00050; 51220/5289 tok/s;   1350 sec
[2022-05-05 21:41:17,522 INFO] Weighted corpora loaded so far:
			* github: 113
[2022-05-05 21:41:21,155 INFO] Step 7700/100000; acc:  97.54; ppl:  1.08; xent: 0.08; lr: 0.00050; 51872/5181 tok/s;   1359 sec
[2022-05-05 21:41:28,709 INFO] Weighted corpora loaded so far:
			* github: 114
[2022-05-05 21:41:30,076 INFO] Step 7750/100000; acc:  97.48; ppl:  1.08; xent: 0.08; lr: 0.00050; 52403/5246 tok/s;   1368 sec
[2022-05-05 21:41:38,550 INFO] Step 7800/100000; acc:  97.67; ppl:  1.08; xent: 0.07; lr: 0.00050; 54157/5311 tok/s;   1376 sec
[2022-05-05 21:41:39,936 INFO] Weighted corpora loaded so far:
			* github: 115
[2022-05-05 21:41:47,475 INFO] Step 7850/100000; acc:  97.70; ppl:  1.07; xent: 0.07; lr: 0.00050; 52213/5144 tok/s;   1385 sec
[2022-05-05 21:41:56,159 INFO] Step 7900/100000; acc:  97.65; ppl:  1.08; xent: 0.07; lr: 0.00050; 51631/5296 tok/s;   1394 sec
[2022-05-05 21:42:02,302 INFO] Weighted corpora loaded so far:
			* github: 116
[2022-05-05 21:42:04,960 INFO] Step 7950/100000; acc:  97.61; ppl:  1.08; xent: 0.08; lr: 0.00050; 52252/5230 tok/s;   1403 sec
[2022-05-05 21:42:13,554 INFO] Step 8000/100000; acc:  97.67; ppl:  1.08; xent: 0.08; lr: 0.00050; 54711/5310 tok/s;   1411 sec
[2022-05-05 21:42:13,559 INFO] Weighted corpora loaded so far:
			* github: 117
[2022-05-05 21:42:22,560 INFO] Step 8050/100000; acc:  97.72; ppl:  1.07; xent: 0.07; lr: 0.00050; 52485/5086 tok/s;   1420 sec
[2022-05-05 21:42:24,883 INFO] Weighted corpora loaded so far:
			* github: 118
[2022-05-05 21:42:31,442 INFO] Step 8100/100000; acc:  97.74; ppl:  1.07; xent: 0.07; lr: 0.00050; 51360/5278 tok/s;   1429 sec
[2022-05-05 21:42:36,243 INFO] Weighted corpora loaded so far:
			* github: 119
[2022-05-05 21:42:40,366 INFO] Step 8150/100000; acc:  97.78; ppl:  1.07; xent: 0.07; lr: 0.00050; 51986/5084 tok/s;   1438 sec
[2022-05-05 21:42:47,563 INFO] Weighted corpora loaded so far:
			* github: 120
[2022-05-05 21:42:49,300 INFO] Step 8200/100000; acc:  97.59; ppl:  1.08; xent: 0.07; lr: 0.00050; 51907/5129 tok/s;   1447 sec
[2022-05-05 21:42:57,822 INFO] Step 8250/100000; acc:  97.83; ppl:  1.07; xent: 0.07; lr: 0.00050; 53197/5369 tok/s;   1455 sec
[2022-05-05 21:42:58,881 INFO] Weighted corpora loaded so far:
			* github: 121
[2022-05-05 21:43:06,916 INFO] Step 8300/100000; acc:  97.79; ppl:  1.07; xent: 0.07; lr: 0.00050; 52095/5031 tok/s;   1465 sec
[2022-05-05 21:43:10,246 INFO] Weighted corpora loaded so far:
			* github: 122
[2022-05-05 21:43:15,696 INFO] Step 8350/100000; acc:  97.85; ppl:  1.07; xent: 0.07; lr: 0.00050; 50992/5324 tok/s;   1473 sec
[2022-05-05 21:43:21,521 INFO] Weighted corpora loaded so far:
			* github: 123
[2022-05-05 21:43:24,534 INFO] Step 8400/100000; acc:  97.88; ppl:  1.07; xent: 0.07; lr: 0.00050; 52058/5088 tok/s;   1482 sec
[2022-05-05 21:43:32,786 INFO] Weighted corpora loaded so far:
			* github: 124
[2022-05-05 21:43:33,452 INFO] Step 8450/100000; acc:  97.70; ppl:  1.07; xent: 0.07; lr: 0.00050; 52236/5198 tok/s;   1491 sec
[2022-05-05 21:43:42,055 INFO] Step 8500/100000; acc:  97.80; ppl:  1.07; xent: 0.07; lr: 0.00050; 54926/5274 tok/s;   1500 sec
[2022-05-05 21:43:44,041 INFO] Weighted corpora loaded so far:
			* github: 125
[2022-05-05 21:43:50,784 INFO] Step 8550/100000; acc:  97.83; ppl:  1.07; xent: 0.07; lr: 0.00050; 51462/5345 tok/s;   1508 sec
[2022-05-05 21:43:55,231 INFO] Weighted corpora loaded so far:
			* github: 126
[2022-05-05 21:43:59,633 INFO] Step 8600/100000; acc:  97.76; ppl:  1.07; xent: 0.07; lr: 0.00050; 52348/5210 tok/s;   1517 sec
[2022-05-05 21:44:06,454 INFO] Weighted corpora loaded so far:
			* github: 127
[2022-05-05 21:44:08,480 INFO] Step 8650/100000; acc:  97.66; ppl:  1.08; xent: 0.07; lr: 0.00050; 51925/5204 tok/s;   1526 sec
[2022-05-05 21:44:17,097 INFO] Step 8700/100000; acc:  97.93; ppl:  1.07; xent: 0.07; lr: 0.00050; 53468/5276 tok/s;   1535 sec
[2022-05-05 21:44:17,799 INFO] Weighted corpora loaded so far:
			* github: 128
[2022-05-05 21:44:26,034 INFO] Step 8750/100000; acc:  97.77; ppl:  1.07; xent: 0.07; lr: 0.00050; 52658/5127 tok/s;   1544 sec
[2022-05-05 21:44:34,830 INFO] Step 8800/100000; acc:  97.93; ppl:  1.07; xent: 0.07; lr: 0.00050; 50910/5232 tok/s;   1552 sec
[2022-05-05 21:44:40,340 INFO] Weighted corpora loaded so far:
			* github: 129
[2022-05-05 21:44:43,720 INFO] Step 8850/100000; acc:  98.01; ppl:  1.06; xent: 0.06; lr: 0.00050; 51893/5103 tok/s;   1561 sec
[2022-05-05 21:44:51,695 INFO] Weighted corpora loaded so far:
			* github: 130
[2022-05-05 21:44:52,708 INFO] Step 8900/100000; acc:  97.83; ppl:  1.07; xent: 0.07; lr: 0.00050; 52325/5201 tok/s;   1570 sec
[2022-05-05 21:45:01,326 INFO] Step 8950/100000; acc:  98.04; ppl:  1.07; xent: 0.06; lr: 0.00050; 54106/5310 tok/s;   1579 sec
[2022-05-05 21:45:02,961 INFO] Weighted corpora loaded so far:
			* github: 131
[2022-05-05 21:45:10,163 INFO] Step 9000/100000; acc:  98.01; ppl:  1.07; xent: 0.06; lr: 0.00050; 52331/5119 tok/s;   1588 sec
[2022-05-05 21:45:14,250 INFO] Weighted corpora loaded so far:
			* github: 132
[2022-05-05 21:45:19,010 INFO] Step 9050/100000; acc:  98.16; ppl:  1.06; xent: 0.06; lr: 0.00050; 51615/5211 tok/s;   1597 sec
[2022-05-05 21:45:25,578 INFO] Weighted corpora loaded so far:
			* github: 133
[2022-05-05 21:45:27,837 INFO] Step 9100/100000; acc:  97.95; ppl:  1.07; xent: 0.07; lr: 0.00050; 51911/5262 tok/s;   1605 sec
[2022-05-05 21:45:36,379 INFO] Step 9150/100000; acc:  97.89; ppl:  1.07; xent: 0.07; lr: 0.00050; 54281/5363 tok/s;   1614 sec
[2022-05-05 21:45:36,707 INFO] Weighted corpora loaded so far:
			* github: 134
[2022-05-05 21:45:45,280 INFO] Step 9200/100000; acc:  98.15; ppl:  1.06; xent: 0.06; lr: 0.00050; 52716/5155 tok/s;   1623 sec
[2022-05-05 21:45:48,168 INFO] Weighted corpora loaded so far:
			* github: 135
[2022-05-05 21:45:54,311 INFO] Step 9250/100000; acc:  97.96; ppl:  1.07; xent: 0.06; lr: 0.00050; 49984/4979 tok/s;   1632 sec
[2022-05-05 21:45:59,525 INFO] Weighted corpora loaded so far:
			* github: 136
[2022-05-05 21:46:03,163 INFO] Step 9300/100000; acc:  98.02; ppl:  1.06; xent: 0.06; lr: 0.00050; 52282/5270 tok/s;   1641 sec
[2022-05-05 21:46:10,695 INFO] Weighted corpora loaded so far:
			* github: 137
[2022-05-05 21:46:12,069 INFO] Step 9350/100000; acc:  97.93; ppl:  1.07; xent: 0.07; lr: 0.00050; 52658/5215 tok/s;   1650 sec
[2022-05-05 21:46:20,581 INFO] Step 9400/100000; acc:  97.98; ppl:  1.07; xent: 0.06; lr: 0.00050; 53822/5372 tok/s;   1658 sec
[2022-05-05 21:46:21,942 INFO] Weighted corpora loaded so far:
			* github: 138
[2022-05-05 21:46:29,482 INFO] Step 9450/100000; acc:  98.18; ppl:  1.06; xent: 0.06; lr: 0.00050; 52457/5111 tok/s;   1667 sec
[2022-05-05 21:46:33,171 INFO] Weighted corpora loaded so far:
			* github: 139
[2022-05-05 21:46:38,256 INFO] Step 9500/100000; acc:  98.09; ppl:  1.06; xent: 0.06; lr: 0.00050; 50937/5298 tok/s;   1676 sec
[2022-05-05 21:46:44,562 INFO] Weighted corpora loaded so far:
			* github: 140
[2022-05-05 21:46:47,167 INFO] Step 9550/100000; acc:  98.09; ppl:  1.06; xent: 0.06; lr: 0.00050; 51242/5120 tok/s;   1685 sec
[2022-05-05 21:46:55,662 INFO] Step 9600/100000; acc:  98.08; ppl:  1.06; xent: 0.06; lr: 0.00050; 55003/5415 tok/s;   1693 sec
[2022-05-05 21:47:04,580 INFO] Step 9650/100000; acc:  98.10; ppl:  1.06; xent: 0.06; lr: 0.00050; 52736/5156 tok/s;   1702 sec
[2022-05-05 21:47:06,874 INFO] Weighted corpora loaded so far:
			* github: 141
[2022-05-05 21:47:13,602 INFO] Step 9700/100000; acc:  98.17; ppl:  1.06; xent: 0.06; lr: 0.00050; 50507/5040 tok/s;   1711 sec
[2022-05-05 21:47:18,380 INFO] Weighted corpora loaded so far:
			* github: 142
[2022-05-05 21:47:22,500 INFO] Step 9750/100000; acc:  98.15; ppl:  1.06; xent: 0.06; lr: 0.00050; 52117/5175 tok/s;   1720 sec
[2022-05-05 21:47:29,695 INFO] Weighted corpora loaded so far:
			* github: 143
[2022-05-05 21:47:31,449 INFO] Step 9800/100000; acc:  98.09; ppl:  1.06; xent: 0.06; lr: 0.00050; 51853/5136 tok/s;   1729 sec
[2022-05-05 21:47:39,985 INFO] Step 9850/100000; acc:  98.17; ppl:  1.06; xent: 0.06; lr: 0.00050; 53618/5336 tok/s;   1738 sec
[2022-05-05 21:47:41,043 INFO] Weighted corpora loaded so far:
			* github: 144
[2022-05-05 21:47:49,083 INFO] Step 9900/100000; acc:  98.21; ppl:  1.06; xent: 0.06; lr: 0.00050; 52425/5081 tok/s;   1747 sec
[2022-05-05 21:47:52,415 INFO] Weighted corpora loaded so far:
			* github: 145
[2022-05-05 21:47:57,849 INFO] Step 9950/100000; acc:  98.23; ppl:  1.06; xent: 0.06; lr: 0.00050; 51153/5224 tok/s;   1755 sec
[2022-05-05 21:48:03,706 INFO] Weighted corpora loaded so far:
			* github: 146
[2022-05-05 21:48:06,718 INFO] Step 10000/100000; acc:  98.14; ppl:  1.06; xent: 0.06; lr: 0.00050; 51670/5189 tok/s;   1764 sec
[2022-05-05 21:48:14,962 INFO] Weighted corpora loaded so far:
			* github: 147
[2022-05-05 21:48:15,624 INFO] Step 10050/100000; acc:  98.16; ppl:  1.06; xent: 0.06; lr: 0.00050; 51922/5160 tok/s;   1773 sec
[2022-05-05 21:48:24,313 INFO] Step 10100/100000; acc:  98.05; ppl:  1.06; xent: 0.06; lr: 0.00050; 54132/5259 tok/s;   1782 sec
[2022-05-05 21:48:26,301 INFO] Weighted corpora loaded so far:
			* github: 148
[2022-05-05 21:48:33,123 INFO] Step 10150/100000; acc:  98.16; ppl:  1.06; xent: 0.06; lr: 0.00050; 51285/5146 tok/s;   1791 sec
[2022-05-05 21:48:37,520 INFO] Weighted corpora loaded so far:
			* github: 149
[2022-05-05 21:48:41,880 INFO] Step 10200/100000; acc:  98.22; ppl:  1.06; xent: 0.06; lr: 0.00050; 53446/5288 tok/s;   1799 sec
[2022-05-05 21:48:48,613 INFO] Weighted corpora loaded so far:
			* github: 150
[2022-05-05 21:48:50,615 INFO] Step 10250/100000; acc:  98.19; ppl:  1.06; xent: 0.06; lr: 0.00050; 53085/5345 tok/s;   1808 sec
[2022-05-05 21:48:59,046 INFO] Step 10300/100000; acc:  98.15; ppl:  1.06; xent: 0.06; lr: 0.00050; 54351/5478 tok/s;   1817 sec
[2022-05-05 21:48:59,712 INFO] Weighted corpora loaded so far:
			* github: 151
[2022-05-05 21:49:07,814 INFO] Step 10350/100000; acc:  98.22; ppl:  1.06; xent: 0.05; lr: 0.00050; 53648/5176 tok/s;   1825 sec
[2022-05-05 21:49:11,024 INFO] Weighted corpora loaded so far:
			* github: 152
[2022-05-05 21:49:16,764 INFO] Step 10400/100000; acc:  98.20; ppl:  1.06; xent: 0.06; lr: 0.00050; 49828/5133 tok/s;   1834 sec
[2022-05-05 21:49:22,286 INFO] Weighted corpora loaded so far:
			* github: 153
[2022-05-05 21:49:25,620 INFO] Step 10450/100000; acc:  98.29; ppl:  1.06; xent: 0.05; lr: 0.00050; 51749/5160 tok/s;   1843 sec
[2022-05-05 21:49:34,582 INFO] Step 10500/100000; acc:  98.36; ppl:  1.05; xent: 0.05; lr: 0.00050; 52165/5143 tok/s;   1852 sec
[2022-05-05 21:49:43,202 INFO] Step 10550/100000; acc:  98.37; ppl:  1.05; xent: 0.05; lr: 0.00050; 53927/5321 tok/s;   1861 sec
[2022-05-05 21:49:44,844 INFO] Weighted corpora loaded so far:
			* github: 154
[2022-05-05 21:49:52,065 INFO] Step 10600/100000; acc:  98.25; ppl:  1.06; xent: 0.05; lr: 0.00050; 52123/5187 tok/s;   1870 sec
[2022-05-05 21:49:56,117 INFO] Weighted corpora loaded so far:
			* github: 155
[2022-05-05 21:50:00,883 INFO] Step 10650/100000; acc:  98.27; ppl:  1.06; xent: 0.05; lr: 0.00050; 51695/5164 tok/s;   1878 sec
[2022-05-05 21:50:07,366 INFO] Weighted corpora loaded so far:
			* github: 156
[2022-05-05 21:50:09,694 INFO] Step 10700/100000; acc:  98.31; ppl:  1.06; xent: 0.06; lr: 0.00050; 52093/5270 tok/s;   1887 sec
[2022-05-05 21:50:18,332 INFO] Step 10750/100000; acc:  98.31; ppl:  1.05; xent: 0.05; lr: 0.00050; 54670/5287 tok/s;   1896 sec
[2022-05-05 21:50:18,669 INFO] Weighted corpora loaded so far:
			* github: 157
[2022-05-05 21:50:27,259 INFO] Step 10800/100000; acc:  98.27; ppl:  1.06; xent: 0.06; lr: 0.00050; 52778/5148 tok/s;   1905 sec
[2022-05-05 21:50:29,914 INFO] Weighted corpora loaded so far:
			* github: 158
[2022-05-05 21:50:36,017 INFO] Step 10850/100000; acc:  98.38; ppl:  1.05; xent: 0.05; lr: 0.00050; 51268/5228 tok/s;   1914 sec
[2022-05-05 21:50:41,158 INFO] Weighted corpora loaded so far:
			* github: 159
[2022-05-05 21:50:44,882 INFO] Step 10900/100000; acc:  98.36; ppl:  1.06; xent: 0.06; lr: 0.00050; 51751/5072 tok/s;   1922 sec
[2022-05-05 21:50:52,496 INFO] Weighted corpora loaded so far:
			* github: 160
[2022-05-05 21:50:53,879 INFO] Step 10950/100000; acc:  98.44; ppl:  1.05; xent: 0.05; lr: 0.00050; 51834/5218 tok/s;   1931 sec
[2022-05-05 21:51:02,445 INFO] Step 11000/100000; acc:  98.41; ppl:  1.05; xent: 0.05; lr: 0.00050; 53465/5330 tok/s;   1940 sec
[2022-05-05 21:51:03,816 INFO] Weighted corpora loaded so far:
			* github: 161
[2022-05-05 21:51:11,434 INFO] Step 11050/100000; acc:  98.34; ppl:  1.05; xent: 0.05; lr: 0.00050; 52295/4991 tok/s;   1949 sec
[2022-05-05 21:51:15,158 INFO] Weighted corpora loaded so far:
			* github: 162
[2022-05-05 21:51:20,269 INFO] Step 11100/100000; acc:  98.46; ppl:  1.05; xent: 0.05; lr: 0.00050; 51033/5335 tok/s;   1958 sec
[2022-05-05 21:51:26,513 INFO] Weighted corpora loaded so far:
			* github: 163
[2022-05-05 21:51:29,165 INFO] Step 11150/100000; acc:  98.40; ppl:  1.05; xent: 0.05; lr: 0.00050; 51595/5210 tok/s;   1967 sec
[2022-05-05 21:51:37,817 INFO] Step 11200/100000; acc:  98.31; ppl:  1.06; xent: 0.06; lr: 0.00050; 53706/5293 tok/s;   1975 sec
[2022-05-05 21:51:37,847 INFO] Weighted corpora loaded so far:
			* github: 164
[2022-05-05 21:51:46,838 INFO] Step 11250/100000; acc:  98.45; ppl:  1.05; xent: 0.05; lr: 0.00050; 52113/5165 tok/s;   1984 sec
[2022-05-05 21:51:49,160 INFO] Weighted corpora loaded so far:
			* github: 165
[2022-05-05 21:51:55,658 INFO] Step 11300/100000; acc:  98.34; ppl:  1.06; xent: 0.05; lr: 0.00050; 51317/5097 tok/s;   1993 sec
[2022-05-05 21:52:00,555 INFO] Weighted corpora loaded so far:
			* github: 166
[2022-05-05 21:52:04,546 INFO] Step 11350/100000; acc:  98.49; ppl:  1.05; xent: 0.05; lr: 0.00050; 51784/5169 tok/s;   2002 sec
[2022-05-05 21:52:13,453 INFO] Step 11400/100000; acc:  98.24; ppl:  1.06; xent: 0.06; lr: 0.00050; 51828/5172 tok/s;   2011 sec
[2022-05-05 21:52:21,965 INFO] Step 11450/100000; acc:  98.50; ppl:  1.05; xent: 0.05; lr: 0.00050; 53814/5328 tok/s;   2020 sec
[2022-05-05 21:52:23,009 INFO] Weighted corpora loaded so far:
			* github: 167
[2022-05-05 21:52:30,955 INFO] Step 11500/100000; acc:  98.64; ppl:  1.05; xent: 0.05; lr: 0.00050; 53039/5101 tok/s;   2029 sec
[2022-05-05 21:52:34,331 INFO] Weighted corpora loaded so far:
			* github: 168
[2022-05-05 21:52:39,806 INFO] Step 11550/100000; acc:  98.47; ppl:  1.05; xent: 0.05; lr: 0.00050; 50695/5262 tok/s;   2037 sec
[2022-05-05 21:52:45,644 INFO] Weighted corpora loaded so far:
			* github: 169
[2022-05-05 21:52:48,685 INFO] Step 11600/100000; acc:  98.54; ppl:  1.05; xent: 0.05; lr: 0.00050; 51839/5117 tok/s;   2046 sec
[2022-05-05 21:52:56,936 INFO] Weighted corpora loaded so far:
			* github: 170
[2022-05-05 21:52:57,604 INFO] Step 11650/100000; acc:  98.38; ppl:  1.06; xent: 0.05; lr: 0.00050; 52494/5235 tok/s;   2055 sec
[2022-05-05 21:53:06,292 INFO] Step 11700/100000; acc:  98.55; ppl:  1.05; xent: 0.05; lr: 0.00050; 54326/5205 tok/s;   2064 sec
[2022-05-05 21:53:08,288 INFO] Weighted corpora loaded so far:
			* github: 171
[2022-05-05 21:53:15,092 INFO] Step 11750/100000; acc:  98.41; ppl:  1.05; xent: 0.05; lr: 0.00050; 51010/5183 tok/s;   2073 sec
[2022-05-05 21:53:19,596 INFO] Weighted corpora loaded so far:
			* github: 172
[2022-05-05 21:53:23,998 INFO] Step 11800/100000; acc:  98.37; ppl:  1.05; xent: 0.05; lr: 0.00050; 52050/5056 tok/s;   2082 sec
[2022-05-05 21:53:30,851 INFO] Weighted corpora loaded so far:
			* github: 173
[2022-05-05 21:53:32,885 INFO] Step 11850/100000; acc:  98.38; ppl:  1.05; xent: 0.05; lr: 0.00050; 51862/5316 tok/s;   2090 sec
[2022-05-05 21:53:41,464 INFO] Step 11900/100000; acc:  98.42; ppl:  1.05; xent: 0.05; lr: 0.00050; 53947/5344 tok/s;   2099 sec
[2022-05-05 21:53:42,162 INFO] Weighted corpora loaded so far:
			* github: 174
[2022-05-05 21:53:50,459 INFO] Step 11950/100000; acc:  98.43; ppl:  1.05; xent: 0.05; lr: 0.00050; 52639/5069 tok/s;   2108 sec
[2022-05-05 21:53:53,449 INFO] Weighted corpora loaded so far:
			* github: 175
[2022-05-05 21:53:59,248 INFO] Step 12000/100000; acc:  98.45; ppl:  1.05; xent: 0.05; lr: 0.00050; 50961/5224 tok/s;   2117 sec
[2022-05-05 21:54:04,801 INFO] Weighted corpora loaded so far:
			* github: 176
[2022-05-05 21:54:08,154 INFO] Step 12050/100000; acc:  98.64; ppl:  1.05; xent: 0.04; lr: 0.00050; 51603/5220 tok/s;   2126 sec
[2022-05-05 21:54:16,108 INFO] Weighted corpora loaded so far:
			* github: 177
[2022-05-05 21:54:17,159 INFO] Step 12100/100000; acc:  98.33; ppl:  1.05; xent: 0.05; lr: 0.00050; 51928/5154 tok/s;   2135 sec
[2022-05-05 21:54:25,711 INFO] Step 12150/100000; acc:  98.59; ppl:  1.05; xent: 0.05; lr: 0.00050; 53972/5269 tok/s;   2143 sec
[2022-05-05 21:54:27,386 INFO] Weighted corpora loaded so far:
			* github: 178
[2022-05-05 21:54:34,614 INFO] Step 12200/100000; acc:  98.55; ppl:  1.05; xent: 0.05; lr: 0.00050; 51519/5220 tok/s;   2152 sec
[2022-05-05 21:54:38,756 INFO] Weighted corpora loaded so far:
			* github: 179
[2022-05-05 21:54:43,466 INFO] Step 12250/100000; acc:  98.55; ppl:  1.05; xent: 0.05; lr: 0.00050; 51237/5184 tok/s;   2161 sec
[2022-05-05 21:54:52,330 INFO] Step 12300/100000; acc:  98.53; ppl:  1.05; xent: 0.05; lr: 0.00050; 51664/5106 tok/s;   2170 sec
[2022-05-05 21:55:01,012 INFO] Step 12350/100000; acc:  98.58; ppl:  1.05; xent: 0.05; lr: 0.00050; 54305/5301 tok/s;   2179 sec
[2022-05-05 21:55:01,336 INFO] Weighted corpora loaded so far:
			* github: 180
[2022-05-05 21:55:09,956 INFO] Step 12400/100000; acc:  98.65; ppl:  1.05; xent: 0.04; lr: 0.00050; 52385/5118 tok/s;   2188 sec
[2022-05-05 21:55:12,611 INFO] Weighted corpora loaded so far:
			* github: 181
[2022-05-05 21:55:18,787 INFO] Step 12450/100000; acc:  98.57; ppl:  1.05; xent: 0.05; lr: 0.00050; 51131/5261 tok/s;   2196 sec
[2022-05-05 21:55:23,950 INFO] Weighted corpora loaded so far:
			* github: 182
[2022-05-05 21:55:27,684 INFO] Step 12500/100000; acc:  98.49; ppl:  1.05; xent: 0.05; lr: 0.00050; 52058/5113 tok/s;   2205 sec
[2022-05-05 21:55:35,288 INFO] Weighted corpora loaded so far:
			* github: 183
[2022-05-05 21:55:36,694 INFO] Step 12550/100000; acc:  98.54; ppl:  1.05; xent: 0.05; lr: 0.00050; 52122/5150 tok/s;   2214 sec
[2022-05-05 21:55:45,278 INFO] Step 12600/100000; acc:  98.60; ppl:  1.05; xent: 0.04; lr: 0.00050; 53671/5312 tok/s;   2223 sec
[2022-05-05 21:55:46,645 INFO] Weighted corpora loaded so far:
			* github: 184
[2022-05-05 21:55:54,215 INFO] Step 12650/100000; acc:  98.53; ppl:  1.05; xent: 0.05; lr: 0.00050; 52109/5126 tok/s;   2232 sec
[2022-05-05 21:55:57,920 INFO] Weighted corpora loaded so far:
			* github: 185
[2022-05-05 21:56:03,017 INFO] Step 12700/100000; acc:  98.54; ppl:  1.05; xent: 0.05; lr: 0.00050; 50712/5193 tok/s;   2241 sec
[2022-05-05 21:56:09,258 INFO] Weighted corpora loaded so far:
			* github: 186
[2022-05-05 21:56:11,910 INFO] Step 12750/100000; acc:  98.52; ppl:  1.05; xent: 0.05; lr: 0.00050; 51556/5144 tok/s;   2250 sec
[2022-05-05 21:56:20,573 INFO] Step 12800/100000; acc:  98.55; ppl:  1.05; xent: 0.05; lr: 0.00050; 54501/5352 tok/s;   2258 sec
[2022-05-05 21:56:20,593 INFO] Weighted corpora loaded so far:
			* github: 187
[2022-05-05 21:56:29,580 INFO] Step 12850/100000; acc:  98.63; ppl:  1.05; xent: 0.05; lr: 0.00050; 52486/5126 tok/s;   2267 sec
[2022-05-05 21:56:31,912 INFO] Weighted corpora loaded so far:
			* github: 188
[2022-05-05 21:56:38,433 INFO] Step 12900/100000; acc:  98.62; ppl:  1.05; xent: 0.05; lr: 0.00050; 51142/5199 tok/s;   2276 sec
[2022-05-05 21:56:43,274 INFO] Weighted corpora loaded so far:
			* github: 189
[2022-05-05 21:56:47,347 INFO] Step 12950/100000; acc:  98.75; ppl:  1.04; xent: 0.04; lr: 0.00050; 51613/5123 tok/s;   2285 sec
[2022-05-05 21:56:54,550 INFO] Weighted corpora loaded so far:
			* github: 190
[2022-05-05 21:56:56,254 INFO] Step 13000/100000; acc:  98.68; ppl:  1.04; xent: 0.04; lr: 0.00050; 51813/5187 tok/s;   2294 sec
[2022-05-05 21:57:04,780 INFO] Step 13050/100000; acc:  98.68; ppl:  1.04; xent: 0.04; lr: 0.00050; 53282/5321 tok/s;   2302 sec
[2022-05-05 21:57:05,867 INFO] Weighted corpora loaded so far:
			* github: 191
[2022-05-05 21:57:13,841 INFO] Step 13100/100000; acc:  98.64; ppl:  1.04; xent: 0.04; lr: 0.00050; 52160/5093 tok/s;   2311 sec
[2022-05-05 21:57:22,594 INFO] Step 13150/100000; acc:  98.71; ppl:  1.04; xent: 0.04; lr: 0.00050; 50998/5256 tok/s;   2320 sec
[2022-05-05 21:57:28,370 INFO] Weighted corpora loaded so far:
			* github: 192
[2022-05-05 21:57:31,355 INFO] Step 13200/100000; acc:  98.72; ppl:  1.04; xent: 0.04; lr: 0.00050; 52469/5243 tok/s;   2329 sec
[2022-05-05 21:57:39,504 INFO] Weighted corpora loaded so far:
			* github: 193
[2022-05-05 21:57:40,173 INFO] Step 13250/100000; acc:  98.61; ppl:  1.05; xent: 0.05; lr: 0.00050; 53191/5163 tok/s;   2338 sec
[2022-05-05 21:57:48,813 INFO] Step 13300/100000; acc:  98.60; ppl:  1.05; xent: 0.05; lr: 0.00050; 54568/5288 tok/s;   2346 sec
[2022-05-05 21:57:50,801 INFO] Weighted corpora loaded so far:
			* github: 194
[2022-05-05 21:57:57,660 INFO] Step 13350/100000; acc:  98.67; ppl:  1.04; xent: 0.04; lr: 0.00050; 51235/5250 tok/s;   2355 sec
[2022-05-05 21:58:02,146 INFO] Weighted corpora loaded so far:
			* github: 195
[2022-05-05 21:58:06,569 INFO] Step 13400/100000; acc:  98.76; ppl:  1.04; xent: 0.04; lr: 0.00050; 52534/5045 tok/s;   2364 sec
[2022-05-05 21:58:13,514 INFO] Weighted corpora loaded so far:
			* github: 196
[2022-05-05 21:58:15,771 INFO] Step 13450/100000; acc:  98.60; ppl:  1.04; xent: 0.04; lr: 0.00050; 50237/5160 tok/s;   2373 sec
[2022-05-05 21:58:24,466 INFO] Step 13500/100000; acc:  98.61; ppl:  1.04; xent: 0.04; lr: 0.00050; 52874/5140 tok/s;   2382 sec
[2022-05-05 21:58:25,163 INFO] Weighted corpora loaded so far:
			* github: 197
[2022-05-05 21:58:33,473 INFO] Step 13550/100000; acc:  98.70; ppl:  1.04; xent: 0.04; lr: 0.00050; 52269/5130 tok/s;   2391 sec
[2022-05-05 21:58:36,622 INFO] Weighted corpora loaded so far:
			* github: 198
[2022-05-05 21:58:42,578 INFO] Step 13600/100000; acc:  98.70; ppl:  1.04; xent: 0.04; lr: 0.00050; 48947/5059 tok/s;   2400 sec
[2022-05-05 21:58:48,069 INFO] Weighted corpora loaded so far:
			* github: 199
[2022-05-05 21:58:51,441 INFO] Step 13650/100000; acc:  98.72; ppl:  1.04; xent: 0.04; lr: 0.00050; 51956/5157 tok/s;   2409 sec
[2022-05-05 21:58:59,355 INFO] Weighted corpora loaded so far:
			* github: 200
[2022-05-05 21:59:00,417 INFO] Step 13700/100000; acc:  98.71; ppl:  1.04; xent: 0.04; lr: 0.00050; 52698/5170 tok/s;   2418 sec
[2022-05-05 21:59:08,959 INFO] Step 13750/100000; acc:  98.64; ppl:  1.05; xent: 0.04; lr: 0.00050; 54415/5264 tok/s;   2427 sec
[2022-05-05 21:59:10,634 INFO] Weighted corpora loaded so far:
			* github: 201
[2022-05-05 21:59:17,861 INFO] Step 13800/100000; acc:  98.81; ppl:  1.04; xent: 0.04; lr: 0.00050; 51296/5208 tok/s;   2435 sec
[2022-05-05 21:59:21,922 INFO] Weighted corpora loaded so far:
			* github: 202
[2022-05-05 21:59:26,642 INFO] Step 13850/100000; acc:  98.81; ppl:  1.04; xent: 0.04; lr: 0.00050; 51472/5163 tok/s;   2444 sec
[2022-05-05 21:59:33,218 INFO] Weighted corpora loaded so far:
			* github: 203
[2022-05-05 21:59:35,546 INFO] Step 13900/100000; acc:  98.75; ppl:  1.04; xent: 0.04; lr: 0.00050; 51364/5303 tok/s;   2453 sec
[2022-05-05 21:59:44,178 INFO] Step 13950/100000; acc:  98.64; ppl:  1.05; xent: 0.04; lr: 0.00050; 54341/5296 tok/s;   2462 sec
[2022-05-05 21:59:44,535 INFO] Weighted corpora loaded so far:
			* github: 204
[2022-05-05 21:59:53,178 INFO] Step 14000/100000; acc:  98.63; ppl:  1.04; xent: 0.04; lr: 0.00050; 51897/5092 tok/s;   2471 sec
[2022-05-05 22:00:01,904 INFO] Step 14050/100000; acc:  98.79; ppl:  1.04; xent: 0.04; lr: 0.00050; 51534/5199 tok/s;   2479 sec
[2022-05-05 22:00:07,034 INFO] Weighted corpora loaded so far:
			* github: 205
[2022-05-05 22:00:10,812 INFO] Step 14100/100000; acc:  98.61; ppl:  1.04; xent: 0.04; lr: 0.00050; 51844/5220 tok/s;   2488 sec
[2022-05-05 22:00:18,951 INFO] Weighted corpora loaded so far:
			* github: 206
[2022-05-05 22:00:20,367 INFO] Step 14150/100000; acc:  98.64; ppl:  1.04; xent: 0.04; lr: 0.00050; 49145/4798 tok/s;   2498 sec
[2022-05-05 22:00:28,900 INFO] Step 14200/100000; acc:  98.70; ppl:  1.04; xent: 0.04; lr: 0.00050; 53967/5313 tok/s;   2506 sec
[2022-05-05 22:00:30,259 INFO] Weighted corpora loaded so far:
			* github: 207
[2022-05-05 22:00:37,835 INFO] Step 14250/100000; acc:  98.74; ppl:  1.04; xent: 0.04; lr: 0.00050; 52824/5192 tok/s;   2515 sec
[2022-05-05 22:00:41,528 INFO] Weighted corpora loaded so far:
			* github: 208
[2022-05-05 22:00:46,749 INFO] Step 14300/100000; acc:  98.67; ppl:  1.04; xent: 0.04; lr: 0.00050; 50486/5110 tok/s;   2524 sec
[2022-05-05 22:00:53,250 INFO] Weighted corpora loaded so far:
			* github: 209
[2022-05-05 22:00:55,887 INFO] Step 14350/100000; acc:  98.76; ppl:  1.04; xent: 0.04; lr: 0.00050; 50100/4988 tok/s;   2533 sec
[2022-05-05 22:01:04,468 INFO] Step 14400/100000; acc:  98.69; ppl:  1.04; xent: 0.04; lr: 0.00050; 54432/5405 tok/s;   2542 sec
[2022-05-05 22:01:04,481 INFO] Weighted corpora loaded so far:
			* github: 210
[2022-05-05 22:01:13,374 INFO] Step 14450/100000; acc:  98.77; ppl:  1.04; xent: 0.04; lr: 0.00050; 52734/5164 tok/s;   2551 sec
[2022-05-05 22:01:15,675 INFO] Weighted corpora loaded so far:
			* github: 211
[2022-05-05 22:01:22,176 INFO] Step 14500/100000; acc:  98.78; ppl:  1.04; xent: 0.04; lr: 0.00050; 51516/5230 tok/s;   2560 sec
[2022-05-05 22:01:26,966 INFO] Weighted corpora loaded so far:
			* github: 212
[2022-05-05 22:01:31,070 INFO] Step 14550/100000; acc:  98.80; ppl:  1.04; xent: 0.04; lr: 0.00050; 51984/5137 tok/s;   2569 sec
[2022-05-05 22:01:38,270 INFO] Weighted corpora loaded so far:
			* github: 213
[2022-05-05 22:01:40,010 INFO] Step 14600/100000; acc:  98.73; ppl:  1.04; xent: 0.04; lr: 0.00050; 51931/5213 tok/s;   2578 sec
[2022-05-05 22:01:48,598 INFO] Step 14650/100000; acc:  98.74; ppl:  1.04; xent: 0.04; lr: 0.00050; 53319/5241 tok/s;   2586 sec
[2022-05-05 22:01:49,684 INFO] Weighted corpora loaded so far:
			* github: 214
[2022-05-05 22:01:57,603 INFO] Step 14700/100000; acc:  98.77; ppl:  1.04; xent: 0.04; lr: 0.00050; 52528/5169 tok/s;   2595 sec
[2022-05-05 22:02:00,924 INFO] Weighted corpora loaded so far:
			* github: 215
[2022-05-05 22:02:06,358 INFO] Step 14750/100000; acc:  98.79; ppl:  1.04; xent: 0.04; lr: 0.00050; 50818/5227 tok/s;   2604 sec
[2022-05-05 22:02:12,229 INFO] Weighted corpora loaded so far:
			* github: 216
[2022-05-05 22:02:15,224 INFO] Step 14800/100000; acc:  98.70; ppl:  1.04; xent: 0.04; lr: 0.00050; 51547/5215 tok/s;   2613 sec
[2022-05-05 22:02:23,524 INFO] Weighted corpora loaded so far:
			* github: 217
[2022-05-05 22:02:24,170 INFO] Step 14850/100000; acc:  98.74; ppl:  1.04; xent: 0.04; lr: 0.00050; 52069/5106 tok/s;   2622 sec
[2022-05-05 22:02:32,819 INFO] Step 14900/100000; acc:  98.79; ppl:  1.04; xent: 0.04; lr: 0.00050; 54123/5318 tok/s;   2630 sec
[2022-05-05 22:02:41,651 INFO] Step 14950/100000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 0.00050; 51187/5136 tok/s;   2639 sec
[2022-05-05 22:02:46,104 INFO] Weighted corpora loaded so far:
			* github: 218
[2022-05-05 22:02:50,568 INFO] Step 15000/100000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 0.00050; 52387/5162 tok/s;   2648 sec
[2022-05-05 22:02:57,388 INFO] Weighted corpora loaded so far:
			* github: 219
[2022-05-05 22:02:59,450 INFO] Step 15050/100000; acc:  98.82; ppl:  1.04; xent: 0.04; lr: 0.00050; 52013/5181 tok/s;   2657 sec
[2022-05-05 22:03:08,055 INFO] Step 15100/100000; acc:  98.74; ppl:  1.04; xent: 0.04; lr: 0.00050; 53740/5331 tok/s;   2666 sec
[2022-05-05 22:03:08,731 INFO] Weighted corpora loaded so far:
			* github: 220
[2022-05-05 22:03:17,081 INFO] Step 15150/100000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 0.00050; 52730/5054 tok/s;   2675 sec
[2022-05-05 22:03:20,103 INFO] Weighted corpora loaded so far:
			* github: 221
[2022-05-05 22:03:25,953 INFO] Step 15200/100000; acc:  98.75; ppl:  1.04; xent: 0.04; lr: 0.00050; 50601/5182 tok/s;   2684 sec
[2022-05-05 22:03:31,496 INFO] Weighted corpora loaded so far:
			* github: 222
[2022-05-05 22:03:34,864 INFO] Step 15250/100000; acc:  98.78; ppl:  1.04; xent: 0.04; lr: 0.00050; 51547/5144 tok/s;   2692 sec
[2022-05-05 22:03:43,077 INFO] Weighted corpora loaded so far:
			* github: 223
[2022-05-05 22:03:44,063 INFO] Step 15300/100000; acc:  98.84; ppl:  1.04; xent: 0.04; lr: 0.00050; 50772/5081 tok/s;   2702 sec
[2022-05-05 22:03:52,609 INFO] Step 15350/100000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 0.00050; 54090/5300 tok/s;   2710 sec
[2022-05-05 22:03:54,252 INFO] Weighted corpora loaded so far:
			* github: 224
[2022-05-05 22:04:01,443 INFO] Step 15400/100000; acc:  98.79; ppl:  1.04; xent: 0.04; lr: 0.00050; 52286/5173 tok/s;   2719 sec
[2022-05-05 22:04:05,520 INFO] Weighted corpora loaded so far:
			* github: 225
[2022-05-05 22:04:10,404 INFO] Step 15450/100000; acc:  98.85; ppl:  1.04; xent: 0.04; lr: 0.00050; 50943/5116 tok/s;   2728 sec
[2022-05-05 22:04:17,140 INFO] Weighted corpora loaded so far:
			* github: 226
[2022-05-05 22:04:19,419 INFO] Step 15500/100000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 0.00050; 50885/5195 tok/s;   2737 sec
[2022-05-05 22:04:28,092 INFO] Step 15550/100000; acc:  98.84; ppl:  1.04; xent: 0.04; lr: 0.00050; 54059/5261 tok/s;   2746 sec
[2022-05-05 22:04:28,435 INFO] Weighted corpora loaded so far:
			* github: 227
[2022-05-05 22:04:37,272 INFO] Step 15600/100000; acc:  98.78; ppl:  1.04; xent: 0.04; lr: 0.00050; 50779/4984 tok/s;   2755 sec
[2022-05-05 22:04:39,977 INFO] Weighted corpora loaded so far:
			* github: 228
[2022-05-05 22:04:46,073 INFO] Step 15650/100000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 0.00050; 50839/5184 tok/s;   2764 sec
[2022-05-05 22:04:51,261 INFO] Weighted corpora loaded so far:
			* github: 229
[2022-05-05 22:04:54,942 INFO] Step 15700/100000; acc:  98.92; ppl:  1.03; xent: 0.03; lr: 0.00050; 51778/5267 tok/s;   2773 sec
[2022-05-05 22:05:03,800 INFO] Step 15750/100000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 0.00050; 52771/5166 tok/s;   2781 sec
[2022-05-05 22:05:12,283 INFO] Step 15800/100000; acc:  98.92; ppl:  1.04; xent: 0.03; lr: 0.00050; 53946/5350 tok/s;   2790 sec
[2022-05-05 22:05:13,625 INFO] Weighted corpora loaded so far:
			* github: 230
[2022-05-05 22:05:21,260 INFO] Step 15850/100000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 0.00050; 52549/5109 tok/s;   2799 sec
[2022-05-05 22:05:24,912 INFO] Weighted corpora loaded so far:
			* github: 231
[2022-05-05 22:05:29,966 INFO] Step 15900/100000; acc:  98.77; ppl:  1.04; xent: 0.04; lr: 0.00050; 51691/5223 tok/s;   2808 sec
[2022-05-05 22:05:36,131 INFO] Weighted corpora loaded so far:
			* github: 232
[2022-05-05 22:05:38,781 INFO] Step 15950/100000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 0.00050; 52043/5230 tok/s;   2816 sec
[2022-05-05 22:05:47,548 INFO] Step 16000/100000; acc:  98.89; ppl:  1.04; xent: 0.03; lr: 0.00050; 53794/5310 tok/s;   2825 sec
[2022-05-05 22:05:47,556 INFO] Weighted corpora loaded so far:
			* github: 233
[2022-05-05 22:05:56,644 INFO] Step 16050/100000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 0.00050; 51922/4971 tok/s;   2834 sec
[2022-05-05 22:05:58,979 INFO] Weighted corpora loaded so far:
			* github: 234
[2022-05-05 22:06:05,533 INFO] Step 16100/100000; acc:  98.85; ppl:  1.04; xent: 0.04; lr: 0.00050; 51125/5130 tok/s;   2843 sec
[2022-05-05 22:06:10,327 INFO] Weighted corpora loaded so far:
			* github: 235
[2022-05-05 22:06:14,418 INFO] Step 16150/100000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 0.00050; 51901/5242 tok/s;   2852 sec
[2022-05-05 22:06:21,747 INFO] Weighted corpora loaded so far:
			* github: 236
[2022-05-05 22:06:23,478 INFO] Step 16200/100000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 0.00050; 50906/5085 tok/s;   2861 sec
[2022-05-05 22:06:31,984 INFO] Step 16250/100000; acc:  98.81; ppl:  1.04; xent: 0.04; lr: 0.00050; 53480/5362 tok/s;   2870 sec
[2022-05-05 22:06:33,037 INFO] Weighted corpora loaded so far:
			* github: 237
[2022-05-05 22:06:41,042 INFO] Step 16300/100000; acc:  98.94; ppl:  1.04; xent: 0.03; lr: 0.00050; 52620/5040 tok/s;   2879 sec
[2022-05-05 22:06:44,395 INFO] Weighted corpora loaded so far:
			* github: 238
[2022-05-05 22:06:49,827 INFO] Step 16350/100000; acc:  98.82; ppl:  1.04; xent: 0.04; lr: 0.00050; 51155/5260 tok/s;   2887 sec
[2022-05-05 22:06:55,701 INFO] Weighted corpora loaded so far:
			* github: 239
[2022-05-05 22:06:58,707 INFO] Step 16400/100000; acc:  98.93; ppl:  1.04; xent: 0.04; lr: 0.00050; 51819/5230 tok/s;   2896 sec
[2022-05-05 22:07:06,969 INFO] Weighted corpora loaded so far:
			* github: 240
[2022-05-05 22:07:07,631 INFO] Step 16450/100000; acc:  98.83; ppl:  1.04; xent: 0.04; lr: 0.00050; 51992/5188 tok/s;   2905 sec
[2022-05-05 22:07:16,555 INFO] Step 16500/100000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 0.00050; 52453/5083 tok/s;   2914 sec
[2022-05-05 22:07:18,558 INFO] Weighted corpora loaded so far:
			* github: 241
[2022-05-05 22:07:25,357 INFO] Step 16550/100000; acc:  98.95; ppl:  1.03; xent: 0.03; lr: 0.00050; 51097/5218 tok/s;   2923 sec
[2022-05-05 22:07:29,886 INFO] Weighted corpora loaded so far:
			* github: 242
[2022-05-05 22:07:34,214 INFO] Step 16600/100000; acc:  99.03; ppl:  1.03; xent: 0.03; lr: 0.00050; 52406/5138 tok/s;   2932 sec
[2022-05-05 22:07:43,105 INFO] Step 16650/100000; acc:  98.97; ppl:  1.03; xent: 0.03; lr: 0.00050; 51666/5204 tok/s;   2941 sec
[2022-05-05 22:07:51,884 INFO] Step 16700/100000; acc:  98.94; ppl:  1.03; xent: 0.03; lr: 0.00050; 52493/5245 tok/s;   2949 sec
[2022-05-05 22:07:52,615 INFO] Weighted corpora loaded so far:
			* github: 243
[2022-05-05 22:08:01,198 INFO] Step 16750/100000; acc:  98.94; ppl:  1.03; xent: 0.03; lr: 0.00050; 51083/4954 tok/s;   2959 sec
[2022-05-05 22:08:04,216 INFO] Weighted corpora loaded so far:
			* github: 244
[2022-05-05 22:08:09,972 INFO] Step 16800/100000; acc:  98.99; ppl:  1.03; xent: 0.03; lr: 0.00050; 51104/5180 tok/s;   2968 sec
[2022-05-05 22:08:15,412 INFO] Weighted corpora loaded so far:
			* github: 245
[2022-05-05 22:08:18,769 INFO] Step 16850/100000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 0.00050; 52403/5205 tok/s;   2976 sec
[2022-05-05 22:08:26,721 INFO] Weighted corpora loaded so far:
			* github: 246
[2022-05-05 22:08:27,877 INFO] Step 16900/100000; acc:  98.98; ppl:  1.03; xent: 0.03; lr: 0.00050; 51905/5132 tok/s;   2985 sec
[2022-05-05 22:08:36,643 INFO] Step 16950/100000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 0.00050; 53132/5181 tok/s;   2994 sec
[2022-05-05 22:08:38,311 INFO] Weighted corpora loaded so far:
			* github: 247
[2022-05-05 22:08:45,622 INFO] Step 17000/100000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 0.00050; 51175/5116 tok/s;   3003 sec
[2022-05-05 22:08:49,685 INFO] Weighted corpora loaded so far:
			* github: 248
[2022-05-05 22:08:54,428 INFO] Step 17050/100000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 0.00050; 51391/5096 tok/s;   3012 sec
[2022-05-05 22:09:00,940 INFO] Weighted corpora loaded so far:
			* github: 249
[2022-05-05 22:09:03,295 INFO] Step 17100/100000; acc:  99.00; ppl:  1.03; xent: 0.03; lr: 0.00050; 51406/5339 tok/s;   3021 sec
[2022-05-05 22:09:11,881 INFO] Step 17150/100000; acc:  98.94; ppl:  1.03; xent: 0.03; lr: 0.00050; 54567/5274 tok/s;   3029 sec
[2022-05-05 22:09:12,216 INFO] Weighted corpora loaded so far:
			* github: 250
[2022-05-05 22:09:21,231 INFO] Step 17200/100000; acc:  99.04; ppl:  1.03; xent: 0.03; lr: 0.00050; 50387/4854 tok/s;   3039 sec
[2022-05-05 22:09:24,145 INFO] Weighted corpora loaded so far:
			* github: 251
[2022-05-05 22:09:30,304 INFO] Step 17250/100000; acc:  98.84; ppl:  1.04; xent: 0.04; lr: 0.00050; 49748/5045 tok/s;   3048 sec
[2022-05-05 22:09:35,481 INFO] Weighted corpora loaded so far:
			* github: 252
[2022-05-05 22:09:39,176 INFO] Step 17300/100000; acc:  99.06; ppl:  1.03; xent: 0.03; lr: 0.00050; 51880/5217 tok/s;   3057 sec
[2022-05-05 22:09:46,715 INFO] Weighted corpora loaded so far:
			* github: 253
[2022-05-05 22:09:48,095 INFO] Step 17350/100000; acc:  98.94; ppl:  1.03; xent: 0.03; lr: 0.00050; 52114/5251 tok/s;   3066 sec
[2022-05-05 22:09:56,618 INFO] Step 17400/100000; acc:  98.96; ppl:  1.03; xent: 0.03; lr: 0.00050; 53714/5407 tok/s;   3074 sec
[2022-05-05 22:09:58,025 INFO] Weighted corpora loaded so far:
			* github: 254
[2022-05-05 22:10:05,538 INFO] Step 17450/100000; acc:  98.98; ppl:  1.03; xent: 0.03; lr: 0.00050; 52566/5094 tok/s;   3083 sec
[2022-05-05 22:10:09,240 INFO] Weighted corpora loaded so far:
			* github: 255
[2022-05-05 22:10:14,708 INFO] Step 17500/100000; acc:  98.99; ppl:  1.03; xent: 0.03; lr: 0.00050; 48715/4883 tok/s;   3092 sec
[2022-05-05 22:10:23,654 INFO] Step 17550/100000; acc:  98.99; ppl:  1.03; xent: 0.03; lr: 0.00050; 50990/5243 tok/s;   3101 sec
[2022-05-05 22:10:32,300 INFO] Step 17600/100000; acc:  99.00; ppl:  1.03; xent: 0.03; lr: 0.00050; 54483/5269 tok/s;   3110 sec
[2022-05-05 22:10:32,302 INFO] Weighted corpora loaded so far:
			* github: 256
[2022-05-05 22:10:41,231 INFO] Step 17650/100000; acc:  99.05; ppl:  1.03; xent: 0.03; lr: 0.00050; 52954/5166 tok/s;   3119 sec
[2022-05-05 22:10:43,541 INFO] Weighted corpora loaded so far:
			* github: 257
[2022-05-05 22:10:50,024 INFO] Step 17700/100000; acc:  99.06; ppl:  1.03; xent: 0.03; lr: 0.00050; 51686/5213 tok/s;   3128 sec
[2022-05-05 22:10:54,786 INFO] Weighted corpora loaded so far:
			* github: 258
[2022-05-05 22:10:58,879 INFO] Step 17750/100000; acc:  98.99; ppl:  1.03; xent: 0.03; lr: 0.00050; 52390/5161 tok/s;   3136 sec
[2022-05-05 22:11:06,112 INFO] Weighted corpora loaded so far:
			* github: 259
[2022-05-05 22:11:07,848 INFO] Step 17800/100000; acc:  98.92; ppl:  1.03; xent: 0.03; lr: 0.00050; 52035/5234 tok/s;   3145 sec
[2022-05-05 22:11:16,708 INFO] Step 17850/100000; acc:  99.01; ppl:  1.03; xent: 0.03; lr: 0.00050; 51520/5084 tok/s;   3154 sec
[2022-05-05 22:11:17,875 INFO] Weighted corpora loaded so far:
			* github: 260
[2022-05-05 22:11:26,015 INFO] Step 17900/100000; acc:  98.96; ppl:  1.03; xent: 0.03; lr: 0.00050; 50806/4884 tok/s;   3164 sec
[2022-05-05 22:11:29,383 INFO] Weighted corpora loaded so far:
			* github: 261
[2022-05-05 22:11:34,820 INFO] Step 17950/100000; acc:  99.05; ppl:  1.03; xent: 0.03; lr: 0.00050; 50548/5187 tok/s;   3172 sec
[2022-05-05 22:11:40,740 INFO] Weighted corpora loaded so far:
			* github: 262
[2022-05-05 22:11:43,783 INFO] Step 18000/100000; acc:  99.04; ppl:  1.03; xent: 0.03; lr: 0.00050; 51114/5295 tok/s;   3181 sec
[2022-05-05 22:11:52,069 INFO] Weighted corpora loaded so far:
			* github: 263
[2022-05-05 22:11:52,748 INFO] Step 18050/100000; acc:  99.05; ppl:  1.03; xent: 0.03; lr: 0.00050; 52133/5048 tok/s;   3190 sec
[2022-05-05 22:12:01,358 INFO] Step 18100/100000; acc:  99.03; ppl:  1.03; xent: 0.03; lr: 0.00050; 54725/5264 tok/s;   3199 sec
[2022-05-05 22:12:03,342 INFO] Weighted corpora loaded so far:
			* github: 264
[2022-05-05 22:12:10,148 INFO] Step 18150/100000; acc:  98.95; ppl:  1.03; xent: 0.03; lr: 0.00050; 51438/5243 tok/s;   3208 sec
[2022-05-05 22:12:14,663 INFO] Weighted corpora loaded so far:
			* github: 265
[2022-05-05 22:12:19,015 INFO] Step 18200/100000; acc:  99.05; ppl:  1.03; xent: 0.03; lr: 0.00050; 52530/5219 tok/s;   3217 sec
[2022-05-05 22:12:25,837 INFO] Weighted corpora loaded so far:
			* github: 266
[2022-05-05 22:12:27,852 INFO] Step 18250/100000; acc:  99.02; ppl:  1.03; xent: 0.03; lr: 0.00050; 51922/5269 tok/s;   3225 sec
[2022-05-05 22:12:36,343 INFO] Step 18300/100000; acc:  98.98; ppl:  1.03; xent: 0.03; lr: 0.00050; 53854/5370 tok/s;   3234 sec
[2022-05-05 22:12:37,038 INFO] Weighted corpora loaded so far:
			* github: 267
[2022-05-05 22:12:45,353 INFO] Step 18350/100000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 0.00050; 52495/5064 tok/s;   3243 sec
[2022-05-05 22:12:48,354 INFO] Weighted corpora loaded so far:
			* github: 268
[2022-05-05 22:12:54,097 INFO] Step 18400/100000; acc:  98.99; ppl:  1.03; xent: 0.03; lr: 0.00050; 51027/5295 tok/s;   3252 sec
[2022-05-05 22:13:02,944 INFO] Step 18450/100000; acc:  99.03; ppl:  1.03; xent: 0.03; lr: 0.00050; 51985/5073 tok/s;   3261 sec
[2022-05-05 22:13:10,880 INFO] Weighted corpora loaded so far:
			* github: 269
[2022-05-05 22:13:11,935 INFO] Step 18500/100000; acc:  98.96; ppl:  1.03; xent: 0.03; lr: 0.00050; 52539/5134 tok/s;   3270 sec
[2022-05-05 22:13:20,696 INFO] Step 18550/100000; acc:  99.07; ppl:  1.03; xent: 0.03; lr: 0.00050; 52813/5255 tok/s;   3278 sec
[2022-05-05 22:13:22,314 INFO] Weighted corpora loaded so far:
			* github: 270
[2022-05-05 22:13:29,490 INFO] Step 18600/100000; acc:  99.07; ppl:  1.03; xent: 0.03; lr: 0.00050; 52542/5226 tok/s;   3287 sec
[2022-05-05 22:13:33,552 INFO] Weighted corpora loaded so far:
			* github: 271
[2022-05-05 22:13:38,277 INFO] Step 18650/100000; acc:  98.96; ppl:  1.03; xent: 0.03; lr: 0.00050; 51982/5172 tok/s;   3296 sec
[2022-05-05 22:13:44,799 INFO] Weighted corpora loaded so far:
			* github: 272
[2022-05-05 22:13:47,133 INFO] Step 18700/100000; acc:  98.99; ppl:  1.03; xent: 0.03; lr: 0.00050; 51895/5231 tok/s;   3305 sec
[2022-05-05 22:13:55,779 INFO] Step 18750/100000; acc:  99.01; ppl:  1.03; xent: 0.03; lr: 0.00050; 54482/5363 tok/s;   3313 sec
[2022-05-05 22:13:56,113 INFO] Weighted corpora loaded so far:
			* github: 273
[2022-05-05 22:14:04,642 INFO] Step 18800/100000; acc:  99.08; ppl:  1.03; xent: 0.03; lr: 0.00050; 52478/5134 tok/s;   3322 sec
[2022-05-05 22:14:07,299 INFO] Weighted corpora loaded so far:
			* github: 274
[2022-05-05 22:14:13,412 INFO] Step 18850/100000; acc:  99.03; ppl:  1.03; xent: 0.03; lr: 0.00050; 51026/5216 tok/s;   3331 sec
[2022-05-05 22:14:18,558 INFO] Weighted corpora loaded so far:
			* github: 275
[2022-05-05 22:14:22,297 INFO] Step 18900/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 51934/5217 tok/s;   3340 sec
[2022-05-05 22:14:29,896 INFO] Weighted corpora loaded so far:
			* github: 276
[2022-05-05 22:14:31,219 INFO] Step 18950/100000; acc:  98.94; ppl:  1.03; xent: 0.03; lr: 0.00050; 52851/5098 tok/s;   3349 sec
[2022-05-05 22:14:39,739 INFO] Step 19000/100000; acc:  99.05; ppl:  1.03; xent: 0.03; lr: 0.00050; 53976/5399 tok/s;   3357 sec
[2022-05-05 22:14:41,098 INFO] Weighted corpora loaded so far:
			* github: 277
[2022-05-05 22:14:48,648 INFO] Step 19050/100000; acc:  99.13; ppl:  1.03; xent: 0.03; lr: 0.00050; 52596/5165 tok/s;   3366 sec
[2022-05-05 22:14:52,357 INFO] Weighted corpora loaded so far:
			* github: 278
[2022-05-05 22:14:57,406 INFO] Step 19100/100000; acc:  99.01; ppl:  1.03; xent: 0.03; lr: 0.00050; 51030/5201 tok/s;   3375 sec
[2022-05-05 22:15:03,677 INFO] Weighted corpora loaded so far:
			* github: 279
[2022-05-05 22:15:06,320 INFO] Step 19150/100000; acc:  98.95; ppl:  1.03; xent: 0.03; lr: 0.00050; 51147/5255 tok/s;   3384 sec
[2022-05-05 22:15:14,944 INFO] Step 19200/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 54252/5319 tok/s;   3393 sec
[2022-05-05 22:15:14,979 INFO] Weighted corpora loaded so far:
			* github: 280
[2022-05-05 22:15:23,988 INFO] Step 19250/100000; acc:  99.09; ppl:  1.03; xent: 0.03; lr: 0.00050; 51826/5067 tok/s;   3402 sec
[2022-05-05 22:15:32,818 INFO] Step 19300/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 51202/5176 tok/s;   3410 sec
[2022-05-05 22:15:37,767 INFO] Weighted corpora loaded so far:
			* github: 281
[2022-05-05 22:15:42,308 INFO] Step 19350/100000; acc:  99.06; ppl:  1.03; xent: 0.03; lr: 0.00050; 48806/4883 tok/s;   3420 sec
[2022-05-05 22:15:49,877 INFO] Weighted corpora loaded so far:
			* github: 282
[2022-05-05 22:15:51,610 INFO] Step 19400/100000; acc:  99.16; ppl:  1.03; xent: 0.03; lr: 0.00050; 50219/4849 tok/s;   3429 sec
[2022-05-05 22:16:00,172 INFO] Step 19450/100000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 0.00050; 53308/5406 tok/s;   3438 sec
[2022-05-05 22:16:01,213 INFO] Weighted corpora loaded so far:
			* github: 283
[2022-05-05 22:16:09,211 INFO] Step 19500/100000; acc:  99.06; ppl:  1.03; xent: 0.03; lr: 0.00050; 52746/5087 tok/s;   3447 sec
[2022-05-05 22:16:12,561 INFO] Weighted corpora loaded so far:
			* github: 284
[2022-05-05 22:16:18,397 INFO] Step 19550/100000; acc:  99.06; ppl:  1.03; xent: 0.03; lr: 0.00050; 48874/4921 tok/s;   3456 sec
[2022-05-05 22:16:24,289 INFO] Weighted corpora loaded so far:
			* github: 285
[2022-05-05 22:16:27,308 INFO] Step 19600/100000; acc:  99.15; ppl:  1.03; xent: 0.03; lr: 0.00050; 51586/5237 tok/s;   3465 sec
[2022-05-05 22:16:35,583 INFO] Weighted corpora loaded so far:
			* github: 286
[2022-05-05 22:16:36,266 INFO] Step 19650/100000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 0.00050; 51868/5120 tok/s;   3474 sec
[2022-05-05 22:16:44,876 INFO] Step 19700/100000; acc:  99.07; ppl:  1.03; xent: 0.03; lr: 0.00050; 54490/5301 tok/s;   3482 sec
[2022-05-05 22:16:46,873 INFO] Weighted corpora loaded so far:
			* github: 287
[2022-05-05 22:16:53,710 INFO] Step 19750/100000; acc:  99.03; ppl:  1.03; xent: 0.03; lr: 0.00050; 50922/5202 tok/s;   3491 sec
[2022-05-05 22:16:58,244 INFO] Weighted corpora loaded so far:
			* github: 288
[2022-05-05 22:17:02,854 INFO] Step 19800/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 51092/4909 tok/s;   3500 sec
[2022-05-05 22:17:09,760 INFO] Weighted corpora loaded so far:
			* github: 289
[2022-05-05 22:17:11,819 INFO] Step 19850/100000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 0.00050; 51777/5303 tok/s;   3509 sec
[2022-05-05 22:17:20,343 INFO] Step 19900/100000; acc:  99.11; ppl:  1.03; xent: 0.03; lr: 0.00050; 54175/5328 tok/s;   3518 sec
[2022-05-05 22:17:21,031 INFO] Weighted corpora loaded so far:
			* github: 290
[2022-05-05 22:17:29,316 INFO] Step 19950/100000; acc:  99.17; ppl:  1.03; xent: 0.03; lr: 0.00050; 52365/5225 tok/s;   3527 sec
[2022-05-05 22:17:32,278 INFO] Weighted corpora loaded so far:
			* github: 291
[2022-05-05 22:17:37,964 INFO] Step 20000/100000; acc:  99.17; ppl:  1.03; xent: 0.03; lr: 0.00050; 51334/5241 tok/s;   3536 sec
[2022-05-05 22:17:37,965 INFO] valid's transforms: TransformPipe()
[2022-05-05 22:17:39,657 INFO] Validation perplexity: 152.352
[2022-05-05 22:17:39,657 INFO] Validation accuracy: 50.0208
[2022-05-05 22:17:39,657 INFO] Model is improving acc: -inf --> 50.0208.
[2022-05-05 22:17:39,747 INFO] Saving checkpoint /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/model_step_20000.pt
[2022-05-05 22:17:45,336 INFO] Weighted corpora loaded so far:
			* github: 292
[2022-05-05 22:17:48,659 INFO] Step 20050/100000; acc:  99.11; ppl:  1.03; xent: 0.03; lr: 0.00050; 42819/4275 tok/s;   3546 sec
[2022-05-05 22:17:56,578 INFO] Weighted corpora loaded so far:
			* github: 293
[2022-05-05 22:17:57,545 INFO] Step 20100/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 52927/5184 tok/s;   3555 sec
[2022-05-05 22:18:06,067 INFO] Step 20150/100000; acc:  99.16; ppl:  1.03; xent: 0.03; lr: 0.00050; 54284/5327 tok/s;   3564 sec
[2022-05-05 22:18:14,877 INFO] Step 20200/100000; acc:  99.04; ppl:  1.03; xent: 0.03; lr: 0.00050; 52208/5232 tok/s;   3572 sec
[2022-05-05 22:18:18,877 INFO] Weighted corpora loaded so far:
			* github: 294
[2022-05-05 22:18:23,624 INFO] Step 20250/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 52068/5271 tok/s;   3581 sec
[2022-05-05 22:18:30,117 INFO] Weighted corpora loaded so far:
			* github: 295
[2022-05-05 22:18:32,438 INFO] Step 20300/100000; acc:  99.04; ppl:  1.03; xent: 0.03; lr: 0.00050; 52145/5201 tok/s;   3590 sec
[2022-05-05 22:18:41,025 INFO] Step 20350/100000; acc:  99.11; ppl:  1.03; xent: 0.03; lr: 0.00050; 54761/5283 tok/s;   3599 sec
[2022-05-05 22:18:41,362 INFO] Weighted corpora loaded so far:
			* github: 296
[2022-05-05 22:18:49,993 INFO] Step 20400/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 52707/5133 tok/s;   3608 sec
[2022-05-05 22:18:52,830 INFO] Weighted corpora loaded so far:
			* github: 297
[2022-05-05 22:18:58,995 INFO] Step 20450/100000; acc:  99.15; ppl:  1.03; xent: 0.03; lr: 0.00050; 50102/5149 tok/s;   3617 sec
[2022-05-05 22:19:04,220 INFO] Weighted corpora loaded so far:
			* github: 298
[2022-05-05 22:19:07,903 INFO] Step 20500/100000; acc:  99.19; ppl:  1.03; xent: 0.03; lr: 0.00050; 51698/5132 tok/s;   3625 sec
[2022-05-05 22:19:15,462 INFO] Weighted corpora loaded so far:
			* github: 299
[2022-05-05 22:19:16,837 INFO] Step 20550/100000; acc:  99.13; ppl:  1.03; xent: 0.03; lr: 0.00050; 52269/5138 tok/s;   3634 sec
[2022-05-05 22:19:25,368 INFO] Step 20600/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 53514/5372 tok/s;   3643 sec
[2022-05-05 22:19:26,732 INFO] Weighted corpora loaded so far:
			* github: 300
[2022-05-05 22:19:34,324 INFO] Step 20650/100000; acc:  99.16; ppl:  1.03; xent: 0.03; lr: 0.00050; 52351/5124 tok/s;   3652 sec
[2022-05-05 22:19:38,028 INFO] Weighted corpora loaded so far:
			* github: 301
[2022-05-05 22:19:43,131 INFO] Step 20700/100000; acc:  99.02; ppl:  1.03; xent: 0.03; lr: 0.00050; 50991/5224 tok/s;   3661 sec
[2022-05-05 22:19:49,325 INFO] Weighted corpora loaded so far:
			* github: 302
[2022-05-05 22:19:51,979 INFO] Step 20750/100000; acc:  99.06; ppl:  1.03; xent: 0.03; lr: 0.00050; 51921/5167 tok/s;   3670 sec
[2022-05-05 22:20:00,596 INFO] Step 20800/100000; acc:  99.17; ppl:  1.03; xent: 0.03; lr: 0.00050; 54775/5348 tok/s;   3678 sec
[2022-05-05 22:20:00,622 INFO] Weighted corpora loaded so far:
			* github: 303
[2022-05-05 22:20:09,537 INFO] Step 20850/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 52297/5078 tok/s;   3687 sec
[2022-05-05 22:20:11,894 INFO] Weighted corpora loaded so far:
			* github: 304
[2022-05-05 22:20:18,386 INFO] Step 20900/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 50887/5304 tok/s;   3696 sec
[2022-05-05 22:20:23,223 INFO] Weighted corpora loaded so far:
			* github: 305
[2022-05-05 22:20:27,249 INFO] Step 20950/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 51912/5157 tok/s;   3705 sec
[2022-05-05 22:20:34,350 INFO] Weighted corpora loaded so far:
			* github: 306
[2022-05-05 22:20:36,032 INFO] Step 21000/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 52728/5248 tok/s;   3714 sec
[2022-05-05 22:20:44,475 INFO] Step 21050/100000; acc:  99.14; ppl:  1.03; xent: 0.03; lr: 0.00050; 53665/5403 tok/s;   3722 sec
[2022-05-05 22:20:53,439 INFO] Step 21100/100000; acc:  99.26; ppl:  1.02; xent: 0.02; lr: 0.00050; 53287/5110 tok/s;   3731 sec
[2022-05-05 22:20:57,020 INFO] Weighted corpora loaded so far:
			* github: 307
[2022-05-05 22:21:02,374 INFO] Step 21150/100000; acc:  99.15; ppl:  1.03; xent: 0.03; lr: 0.00050; 50255/5096 tok/s;   3740 sec
[2022-05-05 22:21:08,195 INFO] Weighted corpora loaded so far:
			* github: 308
[2022-05-05 22:21:11,192 INFO] Step 21200/100000; acc:  99.11; ppl:  1.03; xent: 0.03; lr: 0.00050; 52139/5221 tok/s;   3749 sec
[2022-05-05 22:21:19,449 INFO] Weighted corpora loaded so far:
			* github: 309
[2022-05-05 22:21:20,136 INFO] Step 21250/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 52214/5188 tok/s;   3758 sec
[2022-05-05 22:21:28,781 INFO] Step 21300/100000; acc:  99.13; ppl:  1.03; xent: 0.03; lr: 0.00050; 54793/5245 tok/s;   3766 sec
[2022-05-05 22:21:30,778 INFO] Weighted corpora loaded so far:
			* github: 310
[2022-05-05 22:21:37,549 INFO] Step 21350/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 51610/5265 tok/s;   3775 sec
[2022-05-05 22:21:42,008 INFO] Weighted corpora loaded so far:
			* github: 311
[2022-05-05 22:21:46,744 INFO] Step 21400/100000; acc:  99.08; ppl:  1.03; xent: 0.03; lr: 0.00050; 50602/4943 tok/s;   3784 sec
[2022-05-05 22:21:53,565 INFO] Weighted corpora loaded so far:
			* github: 312
[2022-05-05 22:21:55,612 INFO] Step 21450/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 51748/5277 tok/s;   3793 sec
[2022-05-05 22:22:04,167 INFO] Step 21500/100000; acc:  99.14; ppl:  1.03; xent: 0.03; lr: 0.00050; 53585/5275 tok/s;   3802 sec
[2022-05-05 22:22:04,854 INFO] Weighted corpora loaded so far:
			* github: 313
[2022-05-05 22:22:13,153 INFO] Step 21550/100000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 0.00050; 52867/5119 tok/s;   3811 sec
[2022-05-05 22:22:16,146 INFO] Weighted corpora loaded so far:
			* github: 314
[2022-05-05 22:22:21,904 INFO] Step 21600/100000; acc:  99.09; ppl:  1.03; xent: 0.03; lr: 0.00050; 51256/5175 tok/s;   3819 sec
[2022-05-05 22:22:27,414 INFO] Weighted corpora loaded so far:
			* github: 315
[2022-05-05 22:22:30,767 INFO] Step 21650/100000; acc:  99.15; ppl:  1.03; xent: 0.03; lr: 0.00050; 51983/5253 tok/s;   3828 sec
[2022-05-05 22:22:38,720 INFO] Weighted corpora loaded so far:
			* github: 316
[2022-05-05 22:22:39,757 INFO] Step 21700/100000; acc:  99.17; ppl:  1.03; xent: 0.03; lr: 0.00050; 52346/5199 tok/s;   3837 sec
[2022-05-05 22:22:48,707 INFO] Step 21750/100000; acc:  99.14; ppl:  1.03; xent: 0.03; lr: 0.00050; 51390/5108 tok/s;   3846 sec
[2022-05-05 22:22:50,438 INFO] Weighted corpora loaded so far:
			* github: 317
[2022-05-05 22:22:57,658 INFO] Step 21800/100000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 0.00050; 51150/5101 tok/s;   3855 sec
[2022-05-05 22:23:01,734 INFO] Weighted corpora loaded so far:
			* github: 318
[2022-05-05 22:23:06,464 INFO] Step 21850/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 51495/5252 tok/s;   3864 sec
[2022-05-05 22:23:12,970 INFO] Weighted corpora loaded so far:
			* github: 319
[2022-05-05 22:23:15,197 INFO] Step 21900/100000; acc:  99.23; ppl:  1.03; xent: 0.02; lr: 0.00050; 52397/5238 tok/s;   3873 sec
[2022-05-05 22:23:23,675 INFO] Step 21950/100000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 0.00050; 55139/5423 tok/s;   3881 sec
[2022-05-05 22:23:32,671 INFO] Step 22000/100000; acc:  99.17; ppl:  1.03; xent: 0.03; lr: 0.00050; 52531/4997 tok/s;   3890 sec
[2022-05-05 22:23:35,354 INFO] Weighted corpora loaded so far:
			* github: 320
[2022-05-05 22:23:42,054 INFO] Step 22050/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 47938/4936 tok/s;   3900 sec
[2022-05-05 22:23:47,416 INFO] Weighted corpora loaded so far:
			* github: 321
[2022-05-05 22:23:51,093 INFO] Step 22100/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 51027/5075 tok/s;   3909 sec
[2022-05-05 22:23:58,678 INFO] Weighted corpora loaded so far:
			* github: 322
[2022-05-05 22:24:00,060 INFO] Step 22150/100000; acc:  99.26; ppl:  1.03; xent: 0.03; lr: 0.00050; 52540/5158 tok/s;   3918 sec
[2022-05-05 22:24:08,925 INFO] Step 22200/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 51913/5142 tok/s;   3927 sec
[2022-05-05 22:24:10,302 INFO] Weighted corpora loaded so far:
			* github: 323
[2022-05-05 22:24:17,962 INFO] Step 22250/100000; acc:  99.23; ppl:  1.03; xent: 0.03; lr: 0.00050; 52134/5043 tok/s;   3936 sec
[2022-05-05 22:24:21,699 INFO] Weighted corpora loaded so far:
			* github: 324
[2022-05-05 22:24:26,759 INFO] Step 22300/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 50858/5278 tok/s;   3944 sec
[2022-05-05 22:24:32,929 INFO] Weighted corpora loaded so far:
			* github: 325
[2022-05-05 22:24:35,581 INFO] Step 22350/100000; acc:  99.14; ppl:  1.03; xent: 0.03; lr: 0.00050; 51597/5217 tok/s;   3953 sec
[2022-05-05 22:24:44,221 INFO] Step 22400/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 54207/5263 tok/s;   3962 sec
[2022-05-05 22:24:44,239 INFO] Weighted corpora loaded so far:
			* github: 326
[2022-05-05 22:24:53,249 INFO] Step 22450/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 52365/5086 tok/s;   3971 sec
[2022-05-05 22:24:55,632 INFO] Weighted corpora loaded so far:
			* github: 327
[2022-05-05 22:25:02,122 INFO] Step 22500/100000; acc:  99.25; ppl:  1.02; xent: 0.02; lr: 0.00050; 51341/5234 tok/s;   3980 sec
[2022-05-05 22:25:06,919 INFO] Weighted corpora loaded so far:
			* github: 328
[2022-05-05 22:25:10,984 INFO] Step 22550/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 52195/5179 tok/s;   3989 sec
[2022-05-05 22:25:18,187 INFO] Weighted corpora loaded so far:
			* github: 329
[2022-05-05 22:25:19,899 INFO] Step 22600/100000; acc:  99.19; ppl:  1.03; xent: 0.03; lr: 0.00050; 51766/5176 tok/s;   3997 sec
[2022-05-05 22:25:28,377 INFO] Step 22650/100000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 0.00050; 53558/5384 tok/s;   4006 sec
[2022-05-05 22:25:29,459 INFO] Weighted corpora loaded so far:
			* github: 330
[2022-05-05 22:25:37,437 INFO] Step 22700/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 52336/5069 tok/s;   4015 sec
[2022-05-05 22:25:40,764 INFO] Weighted corpora loaded so far:
			* github: 331
[2022-05-05 22:25:46,122 INFO] Step 22750/100000; acc:  99.28; ppl:  1.02; xent: 0.02; lr: 0.00050; 51239/5227 tok/s;   4024 sec
[2022-05-05 22:25:54,976 INFO] Step 22800/100000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00050; 51563/5264 tok/s;   4033 sec
[2022-05-05 22:26:03,183 INFO] Weighted corpora loaded so far:
			* github: 332
[2022-05-05 22:26:03,870 INFO] Step 22850/100000; acc:  99.17; ppl:  1.03; xent: 0.03; lr: 0.00050; 52347/5138 tok/s;   4041 sec
[2022-05-05 22:26:12,501 INFO] Step 22900/100000; acc:  99.21; ppl:  1.02; xent: 0.02; lr: 0.00050; 54927/5281 tok/s;   4050 sec
[2022-05-05 22:26:14,555 INFO] Weighted corpora loaded so far:
			* github: 333
[2022-05-05 22:26:21,760 INFO] Step 22950/100000; acc:  99.31; ppl:  1.03; xent: 0.02; lr: 0.00050; 48824/5005 tok/s;   4059 sec
[2022-05-05 22:26:26,214 INFO] Weighted corpora loaded so far:
			* github: 334
[2022-05-05 22:26:30,826 INFO] Step 23000/100000; acc:  99.19; ppl:  1.03; xent: 0.03; lr: 0.00050; 51627/5043 tok/s;   4068 sec
[2022-05-05 22:26:37,595 INFO] Weighted corpora loaded so far:
			* github: 335
[2022-05-05 22:26:39,644 INFO] Step 23050/100000; acc:  99.12; ppl:  1.03; xent: 0.03; lr: 0.00050; 52660/5256 tok/s;   4077 sec
[2022-05-05 22:26:48,104 INFO] Step 23100/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 54560/5382 tok/s;   4086 sec
[2022-05-05 22:26:48,772 INFO] Weighted corpora loaded so far:
			* github: 336
[2022-05-05 22:26:57,119 INFO] Step 23150/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 52386/5077 tok/s;   4095 sec
[2022-05-05 22:27:00,098 INFO] Weighted corpora loaded so far:
			* github: 337
[2022-05-05 22:27:05,869 INFO] Step 23200/100000; acc:  99.21; ppl:  1.02; xent: 0.02; lr: 0.00050; 50864/5266 tok/s;   4103 sec
[2022-05-05 22:27:11,368 INFO] Weighted corpora loaded so far:
			* github: 338
[2022-05-05 22:27:14,773 INFO] Step 23250/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 51409/5168 tok/s;   4112 sec
[2022-05-05 22:27:22,721 INFO] Weighted corpora loaded so far:
			* github: 339
[2022-05-05 22:27:23,769 INFO] Step 23300/100000; acc:  99.25; ppl:  1.02; xent: 0.02; lr: 0.00050; 52167/5059 tok/s;   4121 sec
[2022-05-05 22:27:32,419 INFO] Step 23350/100000; acc:  99.20; ppl:  1.02; xent: 0.02; lr: 0.00050; 53900/5246 tok/s;   4130 sec
[2022-05-05 22:27:34,095 INFO] Weighted corpora loaded so far:
			* github: 340
[2022-05-05 22:27:41,361 INFO] Step 23400/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 51641/5198 tok/s;   4139 sec
[2022-05-05 22:27:45,452 INFO] Weighted corpora loaded so far:
			* github: 341
[2022-05-05 22:27:50,183 INFO] Step 23450/100000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 0.00050; 51377/5158 tok/s;   4148 sec
[2022-05-05 22:27:56,715 INFO] Weighted corpora loaded so far:
			* github: 342
[2022-05-05 22:27:59,042 INFO] Step 23500/100000; acc:  99.26; ppl:  1.03; xent: 0.02; lr: 0.00050; 51341/5281 tok/s;   4157 sec
[2022-05-05 22:28:07,722 INFO] Step 23550/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 53981/5335 tok/s;   4165 sec
[2022-05-05 22:28:08,065 INFO] Weighted corpora loaded so far:
			* github: 343
[2022-05-05 22:28:16,613 INFO] Step 23600/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 52802/5092 tok/s;   4174 sec
[2022-05-05 22:28:19,287 INFO] Weighted corpora loaded so far:
			* github: 344
[2022-05-05 22:28:25,308 INFO] Step 23650/100000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 0.00050; 51341/5268 tok/s;   4183 sec
[2022-05-05 22:28:34,105 INFO] Step 23700/100000; acc:  99.23; ppl:  1.03; xent: 0.03; lr: 0.00050; 52172/5246 tok/s;   4192 sec
[2022-05-05 22:28:41,735 INFO] Weighted corpora loaded so far:
			* github: 345
[2022-05-05 22:28:43,140 INFO] Step 23750/100000; acc:  99.23; ppl:  1.02; xent: 0.02; lr: 0.00050; 52116/5011 tok/s;   4201 sec
[2022-05-05 22:28:51,748 INFO] Step 23800/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 53469/5341 tok/s;   4209 sec
[2022-05-05 22:28:53,113 INFO] Weighted corpora loaded so far:
			* github: 346
[2022-05-05 22:29:00,814 INFO] Step 23850/100000; acc:  99.24; ppl:  1.03; xent: 0.03; lr: 0.00050; 51861/5094 tok/s;   4218 sec
[2022-05-05 22:29:04,843 INFO] Weighted corpora loaded so far:
			* github: 347
[2022-05-05 22:29:09,920 INFO] Step 23900/100000; acc:  99.26; ppl:  1.03; xent: 0.03; lr: 0.00050; 49524/5074 tok/s;   4228 sec
[2022-05-05 22:29:16,130 INFO] Weighted corpora loaded so far:
			* github: 348
[2022-05-05 22:29:18,776 INFO] Step 23950/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 52025/5156 tok/s;   4236 sec
[2022-05-05 22:29:27,374 INFO] Step 24000/100000; acc:  99.23; ppl:  1.02; xent: 0.02; lr: 0.00050; 54643/5369 tok/s;   4245 sec
[2022-05-05 22:29:27,385 INFO] Weighted corpora loaded so far:
			* github: 349
[2022-05-05 22:29:36,329 INFO] Step 24050/100000; acc:  99.27; ppl:  1.02; xent: 0.02; lr: 0.00050; 52422/5038 tok/s;   4254 sec
[2022-05-05 22:29:38,669 INFO] Weighted corpora loaded so far:
			* github: 350
[2022-05-05 22:29:45,162 INFO] Step 24100/100000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 0.00050; 51056/5191 tok/s;   4263 sec
[2022-05-05 22:29:49,982 INFO] Weighted corpora loaded so far:
			* github: 351
[2022-05-05 22:29:54,088 INFO] Step 24150/100000; acc:  99.26; ppl:  1.02; xent: 0.02; lr: 0.00050; 51710/5264 tok/s;   4272 sec
[2022-05-05 22:30:01,302 INFO] Weighted corpora loaded so far:
			* github: 352
[2022-05-05 22:30:03,016 INFO] Step 24200/100000; acc:  99.28; ppl:  1.02; xent: 0.02; lr: 0.00050; 52123/5080 tok/s;   4281 sec
[2022-05-05 22:30:11,531 INFO] Step 24250/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 53533/5357 tok/s;   4289 sec
[2022-05-05 22:30:12,587 INFO] Weighted corpora loaded so far:
			* github: 353
[2022-05-05 22:30:20,557 INFO] Step 24300/100000; acc:  99.26; ppl:  1.03; xent: 0.03; lr: 0.00050; 52865/5092 tok/s;   4298 sec
[2022-05-05 22:30:23,925 INFO] Weighted corpora loaded so far:
			* github: 354
[2022-05-05 22:30:29,317 INFO] Step 24350/100000; acc:  99.26; ppl:  1.03; xent: 0.02; lr: 0.00050; 51002/5308 tok/s;   4307 sec
[2022-05-05 22:30:35,116 INFO] Weighted corpora loaded so far:
			* github: 355
[2022-05-05 22:30:38,063 INFO] Step 24400/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 52133/5230 tok/s;   4316 sec
[2022-05-05 22:30:46,445 INFO] Weighted corpora loaded so far:
			* github: 356
[2022-05-05 22:30:47,104 INFO] Step 24450/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 51068/5161 tok/s;   4325 sec
[2022-05-05 22:30:55,682 INFO] Step 24500/100000; acc:  99.24; ppl:  1.02; xent: 0.02; lr: 0.00050; 54983/5234 tok/s;   4333 sec
[2022-05-05 22:30:57,677 INFO] Weighted corpora loaded so far:
			* github: 357
[2022-05-05 22:31:04,382 INFO] Step 24550/100000; acc:  99.26; ppl:  1.03; xent: 0.02; lr: 0.00050; 51656/5269 tok/s;   4342 sec
[2022-05-05 22:31:13,240 INFO] Step 24600/100000; acc:  99.25; ppl:  1.02; xent: 0.02; lr: 0.00050; 52623/5193 tok/s;   4351 sec
[2022-05-05 22:31:20,006 INFO] Weighted corpora loaded so far:
			* github: 358
[2022-05-05 22:31:22,063 INFO] Step 24650/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 52498/5228 tok/s;   4360 sec
[2022-05-05 22:31:30,567 INFO] Step 24700/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 53994/5376 tok/s;   4368 sec
[2022-05-05 22:31:31,235 INFO] Weighted corpora loaded so far:
			* github: 359
[2022-05-05 22:31:39,611 INFO] Step 24750/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 52630/5089 tok/s;   4377 sec
[2022-05-05 22:31:42,589 INFO] Weighted corpora loaded so far:
			* github: 360
[2022-05-05 22:31:48,374 INFO] Step 24800/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 51294/5279 tok/s;   4386 sec
[2022-05-05 22:31:53,888 INFO] Weighted corpora loaded so far:
			* github: 361
[2022-05-05 22:31:57,268 INFO] Step 24850/100000; acc:  99.27; ppl:  1.03; xent: 0.02; lr: 0.00050; 51926/5124 tok/s;   4395 sec
[2022-05-05 22:32:05,166 INFO] Weighted corpora loaded so far:
			* github: 362
[2022-05-05 22:32:06,224 INFO] Step 24900/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 52658/5238 tok/s;   4404 sec
[2022-05-05 22:32:14,737 INFO] Step 24950/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 53866/5323 tok/s;   4412 sec
[2022-05-05 22:32:16,381 INFO] Weighted corpora loaded so far:
			* github: 363
[2022-05-05 22:32:23,666 INFO] Step 25000/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 51305/5112 tok/s;   4421 sec
[2022-05-05 22:32:27,714 INFO] Weighted corpora loaded so far:
			* github: 364
[2022-05-05 22:32:32,482 INFO] Step 25050/100000; acc:  99.33; ppl:  1.02; xent: 0.02; lr: 0.00050; 51751/5189 tok/s;   4430 sec
[2022-05-05 22:32:39,046 INFO] Weighted corpora loaded so far:
			* github: 365
[2022-05-05 22:32:41,409 INFO] Step 25100/100000; acc:  99.28; ppl:  1.02; xent: 0.02; lr: 0.00050; 51715/5217 tok/s;   4439 sec
[2022-05-05 22:32:50,001 INFO] Step 25150/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 54649/5264 tok/s;   4448 sec
[2022-05-05 22:32:50,353 INFO] Weighted corpora loaded so far:
			* github: 366
[2022-05-05 22:32:59,010 INFO] Step 25200/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 52023/5125 tok/s;   4457 sec
[2022-05-05 22:33:01,926 INFO] Weighted corpora loaded so far:
			* github: 367
[2022-05-05 22:33:08,082 INFO] Step 25250/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 49340/5035 tok/s;   4466 sec
[2022-05-05 22:33:13,245 INFO] Weighted corpora loaded so far:
			* github: 368
[2022-05-05 22:33:16,977 INFO] Step 25300/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 51551/5215 tok/s;   4475 sec
[2022-05-05 22:33:24,574 INFO] Weighted corpora loaded so far:
			* github: 369
[2022-05-05 22:33:25,956 INFO] Step 25350/100000; acc:  99.28; ppl:  1.03; xent: 0.02; lr: 0.00050; 51988/5148 tok/s;   4484 sec
[2022-05-05 22:33:34,709 INFO] Step 25400/100000; acc:  99.33; ppl:  1.02; xent: 0.02; lr: 0.00050; 52213/5239 tok/s;   4492 sec
[2022-05-05 22:33:43,634 INFO] Step 25450/100000; acc:  99.33; ppl:  1.02; xent: 0.02; lr: 0.00050; 52470/5138 tok/s;   4501 sec
[2022-05-05 22:33:47,293 INFO] Weighted corpora loaded so far:
			* github: 370
[2022-05-05 22:33:52,431 INFO] Step 25500/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 51233/5193 tok/s;   4510 sec
[2022-05-05 22:33:58,647 INFO] Weighted corpora loaded so far:
			* github: 371
[2022-05-05 22:34:01,329 INFO] Step 25550/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 51806/5097 tok/s;   4519 sec
[2022-05-05 22:34:09,970 INFO] Step 25600/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 54210/5343 tok/s;   4528 sec
[2022-05-05 22:34:09,976 INFO] Weighted corpora loaded so far:
			* github: 372
[2022-05-05 22:34:18,921 INFO] Step 25650/100000; acc:  99.35; ppl:  1.02; xent: 0.02; lr: 0.00050; 52969/5143 tok/s;   4537 sec
[2022-05-05 22:34:21,229 INFO] Weighted corpora loaded so far:
			* github: 373
[2022-05-05 22:34:27,721 INFO] Step 25700/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 51689/5196 tok/s;   4545 sec
[2022-05-05 22:34:32,512 INFO] Weighted corpora loaded so far:
			* github: 374
[2022-05-05 22:34:36,614 INFO] Step 25750/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 51973/5224 tok/s;   4554 sec
[2022-05-05 22:34:43,818 INFO] Weighted corpora loaded so far:
			* github: 375
[2022-05-05 22:34:45,535 INFO] Step 25800/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 51855/5163 tok/s;   4563 sec
[2022-05-05 22:34:53,979 INFO] Step 25850/100000; acc:  99.27; ppl:  1.02; xent: 0.02; lr: 0.00050; 53652/5345 tok/s;   4572 sec
[2022-05-05 22:34:55,028 INFO] Weighted corpora loaded so far:
			* github: 376
[2022-05-05 22:35:02,820 INFO] Step 25900/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 53744/5192 tok/s;   4580 sec
[2022-05-05 22:35:06,076 INFO] Weighted corpora loaded so far:
			* github: 377
[2022-05-05 22:35:11,406 INFO] Step 25950/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 52232/5310 tok/s;   4589 sec
[2022-05-05 22:35:17,204 INFO] Weighted corpora loaded so far:
			* github: 378
[2022-05-05 22:35:20,121 INFO] Step 26000/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 52888/5288 tok/s;   4598 sec
[2022-05-05 22:35:28,538 INFO] Weighted corpora loaded so far:
			* github: 379
[2022-05-05 22:35:29,185 INFO] Step 26050/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 51665/5128 tok/s;   4607 sec
[2022-05-05 22:35:37,742 INFO] Step 26100/100000; acc:  99.33; ppl:  1.02; xent: 0.02; lr: 0.00050; 54599/5329 tok/s;   4615 sec
[2022-05-05 22:35:39,745 INFO] Weighted corpora loaded so far:
			* github: 380
[2022-05-05 22:35:46,506 INFO] Step 26150/100000; acc:  99.35; ppl:  1.02; xent: 0.02; lr: 0.00050; 51181/5253 tok/s;   4624 sec
[2022-05-05 22:35:50,995 INFO] Weighted corpora loaded so far:
			* github: 381
[2022-05-05 22:35:55,323 INFO] Step 26200/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 52746/5207 tok/s;   4633 sec
[2022-05-05 22:36:02,160 INFO] Weighted corpora loaded so far:
			* github: 382
[2022-05-05 22:36:04,177 INFO] Step 26250/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 52060/5270 tok/s;   4642 sec
[2022-05-05 22:36:12,624 INFO] Step 26300/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 54130/5393 tok/s;   4650 sec
[2022-05-05 22:36:21,565 INFO] Step 26350/100000; acc:  99.35; ppl:  1.02; xent: 0.02; lr: 0.00050; 52925/5127 tok/s;   4659 sec
[2022-05-05 22:36:24,708 INFO] Weighted corpora loaded so far:
			* github: 383
[2022-05-05 22:36:30,506 INFO] Step 26400/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 50209/5133 tok/s;   4668 sec
[2022-05-05 22:36:36,013 INFO] Weighted corpora loaded so far:
			* github: 384
[2022-05-05 22:36:39,401 INFO] Step 26450/100000; acc:  99.28; ppl:  1.02; xent: 0.02; lr: 0.00050; 51908/5182 tok/s;   4677 sec
[2022-05-05 22:36:47,323 INFO] Weighted corpora loaded so far:
			* github: 385
[2022-05-05 22:36:48,390 INFO] Step 26500/100000; acc:  99.33; ppl:  1.02; xent: 0.02; lr: 0.00050; 52383/5073 tok/s;   4686 sec
[2022-05-05 22:36:57,073 INFO] Step 26550/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 53780/5234 tok/s;   4695 sec
[2022-05-05 22:36:58,749 INFO] Weighted corpora loaded so far:
			* github: 386
[2022-05-05 22:37:05,986 INFO] Step 26600/100000; acc:  99.22; ppl:  1.03; xent: 0.03; lr: 0.00050; 51786/5200 tok/s;   4704 sec
[2022-05-05 22:37:10,001 INFO] Weighted corpora loaded so far:
			* github: 387
[2022-05-05 22:37:14,733 INFO] Step 26650/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 51954/5234 tok/s;   4712 sec
[2022-05-05 22:37:21,219 INFO] Weighted corpora loaded so far:
			* github: 388
[2022-05-05 22:37:23,534 INFO] Step 26700/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 51851/5194 tok/s;   4721 sec
[2022-05-05 22:37:32,198 INFO] Step 26750/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 53914/5317 tok/s;   4730 sec
[2022-05-05 22:37:32,572 INFO] Weighted corpora loaded so far:
			* github: 389
[2022-05-05 22:37:41,230 INFO] Step 26800/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 51954/5069 tok/s;   4739 sec
[2022-05-05 22:37:43,877 INFO] Weighted corpora loaded so far:
			* github: 390
[2022-05-05 22:37:49,961 INFO] Step 26850/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 51547/5173 tok/s;   4748 sec
[2022-05-05 22:37:55,155 INFO] Weighted corpora loaded so far:
			* github: 391
[2022-05-05 22:37:58,964 INFO] Step 26900/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 51360/5187 tok/s;   4757 sec
[2022-05-05 22:38:06,552 INFO] Weighted corpora loaded so far:
			* github: 392
[2022-05-05 22:38:07,963 INFO] Step 26950/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 52274/5219 tok/s;   4766 sec
[2022-05-05 22:38:16,397 INFO] Step 27000/100000; acc:  99.36; ppl:  1.02; xent: 0.02; lr: 0.00050; 53910/5299 tok/s;   4774 sec
[2022-05-05 22:38:17,766 INFO] Weighted corpora loaded so far:
			* github: 393
[2022-05-05 22:38:25,307 INFO] Step 27050/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 52353/5257 tok/s;   4783 sec
[2022-05-05 22:38:29,017 INFO] Weighted corpora loaded so far:
			* github: 394
[2022-05-05 22:38:33,985 INFO] Step 27100/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 51625/5180 tok/s;   4792 sec
[2022-05-05 22:38:40,163 INFO] Weighted corpora loaded so far:
			* github: 395
[2022-05-05 22:38:42,758 INFO] Step 27150/100000; acc:  99.35; ppl:  1.02; xent: 0.02; lr: 0.00050; 52163/5295 tok/s;   4800 sec
[2022-05-05 22:38:51,323 INFO] Step 27200/100000; acc:  99.35; ppl:  1.02; xent: 0.02; lr: 0.00050; 54398/5338 tok/s;   4809 sec
[2022-05-05 22:39:00,286 INFO] Step 27250/100000; acc:  99.28; ppl:  1.02; xent: 0.02; lr: 0.00050; 52867/5098 tok/s;   4818 sec
[2022-05-05 22:39:02,639 INFO] Weighted corpora loaded so far:
			* github: 396
[2022-05-05 22:39:09,091 INFO] Step 27300/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 51636/5179 tok/s;   4827 sec
[2022-05-05 22:39:13,852 INFO] Weighted corpora loaded so far:
			* github: 397
[2022-05-05 22:39:17,952 INFO] Step 27350/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 52250/5252 tok/s;   4836 sec
[2022-05-05 22:39:25,135 INFO] Weighted corpora loaded so far:
			* github: 398
[2022-05-05 22:39:26,878 INFO] Step 27400/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 52087/5139 tok/s;   4844 sec
[2022-05-05 22:39:35,361 INFO] Step 27450/100000; acc:  99.36; ppl:  1.02; xent: 0.02; lr: 0.00050; 53973/5364 tok/s;   4853 sec
[2022-05-05 22:39:36,464 INFO] Weighted corpora loaded so far:
			* github: 399
[2022-05-05 22:39:44,389 INFO] Step 27500/100000; acc:  99.33; ppl:  1.02; xent: 0.02; lr: 0.00050; 52817/5136 tok/s;   4862 sec
[2022-05-05 22:39:47,697 INFO] Weighted corpora loaded so far:
			* github: 400
[2022-05-05 22:39:53,247 INFO] Step 27550/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 50401/5059 tok/s;   4871 sec
[2022-05-05 22:39:58,991 INFO] Weighted corpora loaded so far:
			* github: 401
[2022-05-05 22:40:01,953 INFO] Step 27600/100000; acc:  99.32; ppl:  1.02; xent: 0.02; lr: 0.00050; 52431/5401 tok/s;   4880 sec
[2022-05-05 22:40:10,222 INFO] Weighted corpora loaded so far:
			* github: 402
[2022-05-05 22:40:10,890 INFO] Step 27650/100000; acc:  99.30; ppl:  1.02; xent: 0.02; lr: 0.00050; 51830/5163 tok/s;   4888 sec
[2022-05-05 22:40:19,578 INFO] Step 27700/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 54552/5215 tok/s;   4897 sec
[2022-05-05 22:40:21,576 INFO] Weighted corpora loaded so far:
			* github: 403
[2022-05-05 22:40:28,345 INFO] Step 27750/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 51534/5183 tok/s;   4906 sec
[2022-05-05 22:40:32,809 INFO] Weighted corpora loaded so far:
			* github: 404
[2022-05-05 22:40:37,214 INFO] Step 27800/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 52628/5188 tok/s;   4915 sec
[2022-05-05 22:40:44,267 INFO] Weighted corpora loaded so far:
			* github: 405
[2022-05-05 22:40:46,394 INFO] Step 27850/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 50332/5155 tok/s;   4924 sec
[2022-05-05 22:40:54,920 INFO] Step 27900/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 53726/5317 tok/s;   4933 sec
[2022-05-05 22:40:55,613 INFO] Weighted corpora loaded so far:
			* github: 406
[2022-05-05 22:41:03,853 INFO] Step 27950/100000; acc:  99.36; ppl:  1.02; xent: 0.02; lr: 0.00050; 52620/5119 tok/s;   4941 sec
[2022-05-05 22:41:06,863 INFO] Weighted corpora loaded so far:
			* github: 407
[2022-05-05 22:41:12,593 INFO] Step 28000/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 50985/5285 tok/s;   4950 sec
[2022-05-05 22:41:18,112 INFO] Weighted corpora loaded so far:
			* github: 408
[2022-05-05 22:41:21,413 INFO] Step 28050/100000; acc:  99.35; ppl:  1.02; xent: 0.02; lr: 0.00050; 52030/5126 tok/s;   4959 sec
[2022-05-05 22:41:30,318 INFO] Step 28100/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 52666/5249 tok/s;   4968 sec
[2022-05-05 22:41:38,899 INFO] Step 28150/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 54432/5310 tok/s;   4976 sec
[2022-05-05 22:41:40,549 INFO] Weighted corpora loaded so far:
			* github: 409
[2022-05-05 22:41:47,787 INFO] Step 28200/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 51699/5155 tok/s;   4985 sec
[2022-05-05 22:41:51,866 INFO] Weighted corpora loaded so far:
			* github: 410
[2022-05-05 22:41:56,618 INFO] Step 28250/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51612/5179 tok/s;   4994 sec
[2022-05-05 22:42:03,131 INFO] Weighted corpora loaded so far:
			* github: 411
[2022-05-05 22:42:05,459 INFO] Step 28300/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 52124/5235 tok/s;   5003 sec
[2022-05-05 22:42:14,109 INFO] Step 28350/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 54308/5307 tok/s;   5012 sec
[2022-05-05 22:42:14,439 INFO] Weighted corpora loaded so far:
			* github: 412
[2022-05-05 22:42:23,178 INFO] Step 28400/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 52030/5055 tok/s;   5021 sec
[2022-05-05 22:42:25,825 INFO] Weighted corpora loaded so far:
			* github: 413
[2022-05-05 22:42:31,938 INFO] Step 28450/100000; acc:  99.36; ppl:  1.02; xent: 0.02; lr: 0.00050; 51085/5222 tok/s;   5030 sec
[2022-05-05 22:42:37,075 INFO] Weighted corpora loaded so far:
			* github: 414
[2022-05-05 22:42:40,793 INFO] Step 28500/100000; acc:  99.36; ppl:  1.02; xent: 0.02; lr: 0.00050; 51709/5110 tok/s;   5038 sec
[2022-05-05 22:42:48,340 INFO] Weighted corpora loaded so far:
			* github: 415
[2022-05-05 22:42:49,729 INFO] Step 28550/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 52357/5160 tok/s;   5047 sec
[2022-05-05 22:42:58,298 INFO] Step 28600/100000; acc:  99.31; ppl:  1.02; xent: 0.02; lr: 0.00050; 53845/5396 tok/s;   5056 sec
[2022-05-05 22:42:59,667 INFO] Weighted corpora loaded so far:
			* github: 416
[2022-05-05 22:43:07,324 INFO] Step 28650/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 52177/5151 tok/s;   5065 sec
[2022-05-05 22:43:10,984 INFO] Weighted corpora loaded so far:
			* github: 417
[2022-05-05 22:43:16,035 INFO] Step 28700/100000; acc:  99.29; ppl:  1.02; xent: 0.02; lr: 0.00050; 51529/5258 tok/s;   5074 sec
[2022-05-05 22:43:22,225 INFO] Weighted corpora loaded so far:
			* github: 418
[2022-05-05 22:43:24,852 INFO] Step 28750/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 51761/5189 tok/s;   5082 sec
[2022-05-05 22:43:33,427 INFO] Step 28800/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 54403/5396 tok/s;   5091 sec
[2022-05-05 22:43:33,460 INFO] Weighted corpora loaded so far:
			* github: 419
[2022-05-05 22:43:42,444 INFO] Step 28850/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 52180/5057 tok/s;   5100 sec
[2022-05-05 22:43:44,765 INFO] Weighted corpora loaded so far:
			* github: 420
[2022-05-05 22:43:51,174 INFO] Step 28900/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 51611/5233 tok/s;   5109 sec
[2022-05-05 22:43:59,984 INFO] Step 28950/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 52224/5287 tok/s;   5118 sec
[2022-05-05 22:44:06,936 INFO] Weighted corpora loaded so far:
			* github: 421
[2022-05-05 22:44:08,655 INFO] Step 29000/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 53509/5269 tok/s;   5126 sec
[2022-05-05 22:44:17,102 INFO] Step 29050/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 54315/5322 tok/s;   5135 sec
[2022-05-05 22:44:18,140 INFO] Weighted corpora loaded so far:
			* github: 422
[2022-05-05 22:44:25,995 INFO] Step 29100/100000; acc:  99.36; ppl:  1.02; xent: 0.02; lr: 0.00050; 53532/5195 tok/s;   5144 sec
[2022-05-05 22:44:29,285 INFO] Weighted corpora loaded so far:
			* github: 423
[2022-05-05 22:44:34,683 INFO] Step 29150/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51797/5285 tok/s;   5152 sec
[2022-05-05 22:44:40,534 INFO] Weighted corpora loaded so far:
			* github: 424
[2022-05-05 22:44:43,532 INFO] Step 29200/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 52161/5211 tok/s;   5161 sec
[2022-05-05 22:44:51,836 INFO] Weighted corpora loaded so far:
			* github: 425
[2022-05-05 22:44:52,541 INFO] Step 29250/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 51720/5143 tok/s;   5170 sec
[2022-05-05 22:45:01,338 INFO] Step 29300/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 53380/5157 tok/s;   5179 sec
[2022-05-05 22:45:03,370 INFO] Weighted corpora loaded so far:
			* github: 426
[2022-05-05 22:45:10,129 INFO] Step 29350/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 51116/5216 tok/s;   5188 sec
[2022-05-05 22:45:14,577 INFO] Weighted corpora loaded so far:
			* github: 427
[2022-05-05 22:45:19,012 INFO] Step 29400/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 52327/5212 tok/s;   5197 sec
[2022-05-05 22:45:25,820 INFO] Weighted corpora loaded so far:
			* github: 428
[2022-05-05 22:45:27,868 INFO] Step 29450/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 52143/5151 tok/s;   5205 sec
[2022-05-05 22:45:36,377 INFO] Step 29500/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 54428/5349 tok/s;   5214 sec
[2022-05-05 22:45:37,069 INFO] Weighted corpora loaded so far:
			* github: 429
[2022-05-05 22:45:45,571 INFO] Step 29550/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 51540/5034 tok/s;   5223 sec
[2022-05-05 22:45:48,853 INFO] Weighted corpora loaded so far:
			* github: 430
[2022-05-05 22:45:54,972 INFO] Step 29600/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 47312/4909 tok/s;   5233 sec
[2022-05-05 22:46:00,469 INFO] Weighted corpora loaded so far:
			* github: 431
[2022-05-05 22:46:03,739 INFO] Step 29650/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 52100/5239 tok/s;   5241 sec
[2022-05-05 22:46:11,643 INFO] Weighted corpora loaded so far:
			* github: 432
[2022-05-05 22:46:12,671 INFO] Step 29700/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 52525/5231 tok/s;   5250 sec
[2022-05-05 22:46:21,179 INFO] Step 29750/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 54580/5318 tok/s;   5259 sec
[2022-05-05 22:46:22,852 INFO] Weighted corpora loaded so far:
			* github: 433
[2022-05-05 22:46:29,966 INFO] Step 29800/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 52004/5174 tok/s;   5268 sec
[2022-05-05 22:46:38,735 INFO] Step 29850/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 51759/5233 tok/s;   5276 sec
[2022-05-05 22:46:45,239 INFO] Weighted corpora loaded so far:
			* github: 434
[2022-05-05 22:46:47,578 INFO] Step 29900/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52001/5222 tok/s;   5285 sec
[2022-05-05 22:46:56,199 INFO] Step 29950/100000; acc:  99.34; ppl:  1.02; xent: 0.02; lr: 0.00050; 54587/5312 tok/s;   5294 sec
[2022-05-05 22:46:56,518 INFO] Weighted corpora loaded so far:
			* github: 435
[2022-05-05 22:47:05,103 INFO] Step 30000/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 52873/5134 tok/s;   5303 sec
[2022-05-05 22:47:07,749 INFO] Weighted corpora loaded so far:
			* github: 436
[2022-05-05 22:47:13,868 INFO] Step 30050/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 51621/5307 tok/s;   5311 sec
[2022-05-05 22:47:18,996 INFO] Weighted corpora loaded so far:
			* github: 437
[2022-05-05 22:47:22,705 INFO] Step 30100/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 52384/5162 tok/s;   5320 sec
[2022-05-05 22:47:30,235 INFO] Weighted corpora loaded so far:
			* github: 438
[2022-05-05 22:47:31,616 INFO] Step 30150/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 52560/5175 tok/s;   5329 sec
[2022-05-05 22:47:40,070 INFO] Step 30200/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 53976/5393 tok/s;   5338 sec
[2022-05-05 22:47:41,421 INFO] Weighted corpora loaded so far:
			* github: 439
[2022-05-05 22:47:48,991 INFO] Step 30250/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 52413/5136 tok/s;   5347 sec
[2022-05-05 22:47:52,645 INFO] Weighted corpora loaded so far:
			* github: 440
[2022-05-05 22:47:57,704 INFO] Step 30300/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 51494/5268 tok/s;   5355 sec
[2022-05-05 22:48:03,873 INFO] Weighted corpora loaded so far:
			* github: 441
[2022-05-05 22:48:06,591 INFO] Step 30350/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 51661/5164 tok/s;   5364 sec
[2022-05-05 22:48:15,347 INFO] Step 30400/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 53586/5236 tok/s;   5373 sec
[2022-05-05 22:48:15,372 INFO] Weighted corpora loaded so far:
			* github: 442
[2022-05-05 22:48:24,360 INFO] Step 30450/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 52564/5046 tok/s;   5382 sec
[2022-05-05 22:48:26,716 INFO] Weighted corpora loaded so far:
			* github: 443
[2022-05-05 22:48:33,209 INFO] Step 30500/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 51003/5299 tok/s;   5391 sec
[2022-05-05 22:48:38,005 INFO] Weighted corpora loaded so far:
			* github: 444
[2022-05-05 22:48:42,102 INFO] Step 30550/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 51574/5190 tok/s;   5400 sec
[2022-05-05 22:48:49,345 INFO] Weighted corpora loaded so far:
			* github: 445
[2022-05-05 22:48:51,042 INFO] Step 30600/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 51591/5198 tok/s;   5409 sec
[2022-05-05 22:48:59,507 INFO] Step 30650/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 53848/5293 tok/s;   5417 sec
[2022-05-05 22:49:00,582 INFO] Weighted corpora loaded so far:
			* github: 446
[2022-05-05 22:49:08,547 INFO] Step 30700/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 52380/5081 tok/s;   5426 sec
[2022-05-05 22:49:17,729 INFO] Step 30750/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 48822/5064 tok/s;   5435 sec
[2022-05-05 22:49:24,080 INFO] Weighted corpora loaded so far:
			* github: 447
[2022-05-05 22:49:27,096 INFO] Step 30800/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 49177/4796 tok/s;   5445 sec
[2022-05-05 22:49:35,372 INFO] Weighted corpora loaded so far:
			* github: 448
[2022-05-05 22:49:36,062 INFO] Step 30850/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 51924/5218 tok/s;   5454 sec
[2022-05-05 22:49:44,666 INFO] Step 30900/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 54910/5287 tok/s;   5462 sec
[2022-05-05 22:49:46,650 INFO] Weighted corpora loaded so far:
			* github: 449
[2022-05-05 22:49:53,539 INFO] Step 30950/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 51121/5198 tok/s;   5471 sec
[2022-05-05 22:49:57,980 INFO] Weighted corpora loaded so far:
			* github: 450
[2022-05-05 22:50:02,424 INFO] Step 31000/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 52731/5060 tok/s;   5480 sec
[2022-05-05 22:50:09,305 INFO] Weighted corpora loaded so far:
			* github: 451
[2022-05-05 22:50:11,358 INFO] Step 31050/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 51725/5247 tok/s;   5489 sec
[2022-05-05 22:50:19,821 INFO] Step 31100/100000; acc:  99.37; ppl:  1.02; xent: 0.02; lr: 0.00050; 53898/5403 tok/s;   5497 sec
[2022-05-05 22:50:20,500 INFO] Weighted corpora loaded so far:
			* github: 452
[2022-05-05 22:50:28,780 INFO] Step 31150/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52600/5103 tok/s;   5506 sec
[2022-05-05 22:50:31,734 INFO] Weighted corpora loaded so far:
			* github: 453
[2022-05-05 22:50:37,457 INFO] Step 31200/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 51698/5230 tok/s;   5515 sec
[2022-05-05 22:50:42,973 INFO] Weighted corpora loaded so far:
			* github: 454
[2022-05-05 22:50:46,312 INFO] Step 31250/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 52191/5226 tok/s;   5524 sec
[2022-05-05 22:50:54,196 INFO] Weighted corpora loaded so far:
			* github: 455
[2022-05-05 22:50:55,252 INFO] Step 31300/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 52655/5241 tok/s;   5533 sec
[2022-05-05 22:51:03,815 INFO] Step 31350/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 54171/5313 tok/s;   5541 sec
[2022-05-05 22:51:05,469 INFO] Weighted corpora loaded so far:
			* github: 456
[2022-05-05 22:51:12,667 INFO] Step 31400/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 51691/5213 tok/s;   5550 sec
[2022-05-05 22:51:16,678 INFO] Weighted corpora loaded so far:
			* github: 457
[2022-05-05 22:51:21,395 INFO] Step 31450/100000; acc:  99.39; ppl:  1.02; xent: 0.02; lr: 0.00050; 51840/5255 tok/s;   5559 sec
[2022-05-05 22:51:27,924 INFO] Weighted corpora loaded so far:
			* github: 458
[2022-05-05 22:51:30,241 INFO] Step 31500/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 51611/5233 tok/s;   5568 sec
[2022-05-05 22:51:38,803 INFO] Step 31550/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 54589/5321 tok/s;   5576 sec
[2022-05-05 22:51:47,737 INFO] Step 31600/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52492/5112 tok/s;   5585 sec
[2022-05-05 22:51:50,371 INFO] Weighted corpora loaded so far:
			* github: 459
[2022-05-05 22:51:56,545 INFO] Step 31650/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 51268/5204 tok/s;   5594 sec
[2022-05-05 22:52:01,682 INFO] Weighted corpora loaded so far:
			* github: 460
[2022-05-05 22:52:05,425 INFO] Step 31700/100000; acc:  99.36; ppl:  1.02; xent: 0.02; lr: 0.00050; 52087/5120 tok/s;   5603 sec
[2022-05-05 22:52:12,973 INFO] Weighted corpora loaded so far:
			* github: 461
[2022-05-05 22:52:14,385 INFO] Step 31750/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 52306/5184 tok/s;   5612 sec
[2022-05-05 22:52:23,150 INFO] Step 31800/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 52594/5225 tok/s;   5621 sec
[2022-05-05 22:52:24,503 INFO] Weighted corpora loaded so far:
			* github: 462
[2022-05-05 22:52:32,096 INFO] Step 31850/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 52593/5109 tok/s;   5630 sec
[2022-05-05 22:52:35,815 INFO] Weighted corpora loaded so far:
			* github: 463
[2022-05-05 22:52:40,912 INFO] Step 31900/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 51012/5180 tok/s;   5639 sec
[2022-05-05 22:52:47,132 INFO] Weighted corpora loaded so far:
			* github: 464
[2022-05-05 22:52:49,788 INFO] Step 31950/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 51571/5202 tok/s;   5647 sec
[2022-05-05 22:52:58,466 INFO] Step 32000/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 53641/5295 tok/s;   5656 sec
[2022-05-05 22:52:58,481 INFO] Weighted corpora loaded so far:
			* github: 465
[2022-05-05 22:53:07,406 INFO] Step 32050/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 52711/5112 tok/s;   5665 sec
[2022-05-05 22:53:09,730 INFO] Weighted corpora loaded so far:
			* github: 466
[2022-05-05 22:53:16,235 INFO] Step 32100/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51434/5117 tok/s;   5674 sec
[2022-05-05 22:53:21,070 INFO] Weighted corpora loaded so far:
			* github: 467
[2022-05-05 22:53:25,180 INFO] Step 32150/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 51822/5284 tok/s;   5683 sec
[2022-05-05 22:53:32,395 INFO] Weighted corpora loaded so far:
			* github: 468
[2022-05-05 22:53:34,107 INFO] Step 32200/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 52168/5161 tok/s;   5692 sec
[2022-05-05 22:53:42,668 INFO] Step 32250/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 52993/5378 tok/s;   5700 sec
[2022-05-05 22:53:43,724 INFO] Weighted corpora loaded so far:
			* github: 469
[2022-05-05 22:53:51,675 INFO] Step 32300/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 52508/5031 tok/s;   5709 sec
[2022-05-05 22:53:55,022 INFO] Weighted corpora loaded so far:
			* github: 470
[2022-05-05 22:54:00,447 INFO] Step 32350/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 50853/5282 tok/s;   5718 sec
[2022-05-05 22:54:06,327 INFO] Weighted corpora loaded so far:
			* github: 471
[2022-05-05 22:54:09,313 INFO] Step 32400/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 51589/5172 tok/s;   5727 sec
[2022-05-05 22:54:18,255 INFO] Step 32450/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51772/5128 tok/s;   5736 sec
[2022-05-05 22:54:26,920 INFO] Step 32500/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 54378/5236 tok/s;   5745 sec
[2022-05-05 22:54:28,914 INFO] Weighted corpora loaded so far:
			* github: 472
[2022-05-05 22:54:35,775 INFO] Step 32550/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 51155/5230 tok/s;   5753 sec
[2022-05-05 22:54:40,246 INFO] Weighted corpora loaded so far:
			* github: 473
[2022-05-05 22:54:44,655 INFO] Step 32600/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 52648/5127 tok/s;   5762 sec
[2022-05-05 22:54:51,481 INFO] Weighted corpora loaded so far:
			* github: 474
[2022-05-05 22:54:53,561 INFO] Step 32650/100000; acc:  99.40; ppl:  1.02; xent: 0.02; lr: 0.00050; 51918/5238 tok/s;   5771 sec
[2022-05-05 22:55:02,170 INFO] Step 32700/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 53891/5303 tok/s;   5780 sec
[2022-05-05 22:55:02,856 INFO] Weighted corpora loaded so far:
			* github: 475
[2022-05-05 22:55:11,178 INFO] Step 32750/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 52660/5090 tok/s;   5789 sec
[2022-05-05 22:55:14,171 INFO] Weighted corpora loaded so far:
			* github: 476
[2022-05-05 22:55:19,987 INFO] Step 32800/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 50729/5254 tok/s;   5798 sec
[2022-05-05 22:55:25,469 INFO] Weighted corpora loaded so far:
			* github: 477
[2022-05-05 22:55:28,844 INFO] Step 32850/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51742/5038 tok/s;   5806 sec
[2022-05-05 22:55:36,821 INFO] Weighted corpora loaded so far:
			* github: 478
[2022-05-05 22:55:37,804 INFO] Step 32900/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52206/5215 tok/s;   5815 sec
[2022-05-05 22:55:46,422 INFO] Step 32950/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 53824/5326 tok/s;   5824 sec
[2022-05-05 22:55:48,075 INFO] Weighted corpora loaded so far:
			* github: 479
[2022-05-05 22:55:55,306 INFO] Step 33000/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51881/5050 tok/s;   5833 sec
[2022-05-05 22:55:59,379 INFO] Weighted corpora loaded so far:
			* github: 480
[2022-05-05 22:56:04,146 INFO] Step 33050/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51618/5293 tok/s;   5842 sec
[2022-05-05 22:56:10,677 INFO] Weighted corpora loaded so far:
			* github: 481
[2022-05-05 22:56:13,009 INFO] Step 33100/100000; acc:  99.41; ppl:  1.02; xent: 0.02; lr: 0.00050; 51764/5244 tok/s;   5851 sec
[2022-05-05 22:56:21,582 INFO] Step 33150/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 54206/5350 tok/s;   5859 sec
[2022-05-05 22:56:21,922 INFO] Weighted corpora loaded so far:
			* github: 482
[2022-05-05 22:56:30,520 INFO] Step 33200/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52405/5162 tok/s;   5868 sec
[2022-05-05 22:56:33,163 INFO] Weighted corpora loaded so far:
			* github: 483
[2022-05-05 22:56:39,234 INFO] Step 33250/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 51538/5196 tok/s;   5877 sec
[2022-05-05 22:56:44,384 INFO] Weighted corpora loaded so far:
			* github: 484
[2022-05-05 22:56:48,050 INFO] Step 33300/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 52086/5183 tok/s;   5886 sec
[2022-05-05 22:56:56,878 INFO] Step 33350/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52739/5257 tok/s;   5894 sec
[2022-05-05 22:57:05,390 INFO] Step 33400/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 54190/5308 tok/s;   5903 sec
[2022-05-05 22:57:06,736 INFO] Weighted corpora loaded so far:
			* github: 485
[2022-05-05 22:57:14,325 INFO] Step 33450/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 52652/5142 tok/s;   5912 sec
[2022-05-05 22:57:18,031 INFO] Weighted corpora loaded so far:
			* github: 486
[2022-05-05 22:57:23,220 INFO] Step 33500/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 50619/5204 tok/s;   5921 sec
[2022-05-05 22:57:29,943 INFO] Weighted corpora loaded so far:
			* github: 487
[2022-05-05 22:57:32,621 INFO] Step 33550/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 48916/4905 tok/s;   5930 sec
[2022-05-05 22:57:41,213 INFO] Step 33600/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 54874/5354 tok/s;   5939 sec
[2022-05-05 22:57:41,222 INFO] Weighted corpora loaded so far:
			* github: 488
[2022-05-05 22:57:50,202 INFO] Step 33650/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 52584/5072 tok/s;   5948 sec
[2022-05-05 22:57:52,516 INFO] Weighted corpora loaded so far:
			* github: 489
[2022-05-05 22:57:58,952 INFO] Step 33700/100000; acc:  99.43; ppl:  1.02; xent: 0.02; lr: 0.00050; 51560/5214 tok/s;   5957 sec
[2022-05-05 22:58:03,711 INFO] Weighted corpora loaded so far:
			* github: 490
[2022-05-05 22:58:07,750 INFO] Step 33750/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 52182/5124 tok/s;   5965 sec
[2022-05-05 22:58:14,964 INFO] Weighted corpora loaded so far:
			* github: 491
[2022-05-05 22:58:16,679 INFO] Step 33800/100000; acc:  99.42; ppl:  1.02; xent: 0.02; lr: 0.00050; 51833/5336 tok/s;   5974 sec
[2022-05-05 22:58:25,123 INFO] Step 33850/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 54191/5341 tok/s;   5983 sec
[2022-05-05 22:58:26,189 INFO] Weighted corpora loaded so far:
			* github: 492
[2022-05-05 22:58:34,093 INFO] Step 33900/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 53075/5105 tok/s;   5992 sec
[2022-05-05 22:58:37,396 INFO] Weighted corpora loaded so far:
			* github: 493
[2022-05-05 22:58:42,799 INFO] Step 33950/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 51510/5255 tok/s;   6000 sec
[2022-05-05 22:58:48,659 INFO] Weighted corpora loaded so far:
			* github: 494
[2022-05-05 22:58:51,651 INFO] Step 34000/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 51853/5305 tok/s;   6009 sec
[2022-05-05 22:58:59,862 INFO] Weighted corpora loaded so far:
			* github: 495
[2022-05-05 22:59:00,525 INFO] Step 34050/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52186/5185 tok/s;   6018 sec
[2022-05-05 22:59:09,077 INFO] Step 34100/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 54712/5302 tok/s;   6027 sec
[2022-05-05 22:59:11,071 INFO] Weighted corpora loaded so far:
			* github: 496
[2022-05-05 22:59:17,805 INFO] Step 34150/100000; acc:  99.38; ppl:  1.02; xent: 0.02; lr: 0.00050; 51574/5291 tok/s;   6035 sec
[2022-05-05 22:59:22,282 INFO] Weighted corpora loaded so far:
			* github: 497
[2022-05-05 22:59:26,640 INFO] Step 34200/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 52664/5169 tok/s;   6044 sec
[2022-05-05 22:59:35,419 INFO] Step 34250/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52510/5205 tok/s;   6053 sec
[2022-05-05 22:59:43,946 INFO] Step 34300/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 54249/5370 tok/s;   6062 sec
[2022-05-05 22:59:44,610 INFO] Weighted corpora loaded so far:
			* github: 498
[2022-05-05 22:59:52,872 INFO] Step 34350/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 52945/5194 tok/s;   6070 sec
[2022-05-05 22:59:55,881 INFO] Weighted corpora loaded so far:
			* github: 499
[2022-05-05 23:00:01,632 INFO] Step 34400/100000; acc:  99.44; ppl:  1.02; xent: 0.02; lr: 0.00050; 51223/5208 tok/s;   6079 sec
[2022-05-05 23:00:07,100 INFO] Weighted corpora loaded so far:
			* github: 500
[2022-05-05 23:00:10,430 INFO] Step 34450/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52524/5197 tok/s;   6088 sec
[2022-05-05 23:00:18,330 INFO] Weighted corpora loaded so far:
			* github: 501
[2022-05-05 23:00:19,390 INFO] Step 34500/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 52615/5189 tok/s;   6097 sec
[2022-05-05 23:00:27,977 INFO] Step 34550/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 54340/5326 tok/s;   6106 sec
[2022-05-05 23:00:29,615 INFO] Weighted corpora loaded so far:
			* github: 502
[2022-05-05 23:00:36,721 INFO] Step 34600/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52249/5291 tok/s;   6114 sec
[2022-05-05 23:00:40,724 INFO] Weighted corpora loaded so far:
			* github: 503
[2022-05-05 23:00:45,594 INFO] Step 34650/100000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00050; 50923/5053 tok/s;   6123 sec
[2022-05-05 23:00:52,104 INFO] Weighted corpora loaded so far:
			* github: 504
[2022-05-05 23:00:54,435 INFO] Step 34700/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 51784/5235 tok/s;   6132 sec
[2022-05-05 23:01:03,045 INFO] Step 34750/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 54834/5374 tok/s;   6141 sec
[2022-05-05 23:01:03,432 INFO] Weighted corpora loaded so far:
			* github: 505
[2022-05-05 23:01:11,995 INFO] Step 34800/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 52676/5216 tok/s;   6150 sec
[2022-05-05 23:01:14,622 INFO] Weighted corpora loaded so far:
			* github: 506
[2022-05-05 23:01:20,692 INFO] Step 34850/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 51616/5219 tok/s;   6158 sec
[2022-05-05 23:01:25,828 INFO] Weighted corpora loaded so far:
			* github: 507
[2022-05-05 23:01:29,504 INFO] Step 34900/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 52059/5176 tok/s;   6167 sec
[2022-05-05 23:01:37,109 INFO] Weighted corpora loaded so far:
			* github: 508
[2022-05-05 23:01:38,417 INFO] Step 34950/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 52337/5184 tok/s;   6176 sec
[2022-05-05 23:01:47,049 INFO] Step 35000/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 52998/5241 tok/s;   6185 sec
[2022-05-05 23:01:48,574 INFO] Weighted corpora loaded so far:
			* github: 509
[2022-05-05 23:01:56,091 INFO] Step 35050/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 51587/5136 tok/s;   6194 sec
[2022-05-05 23:02:04,830 INFO] Step 35100/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 51188/5268 tok/s;   6202 sec
[2022-05-05 23:02:11,608 INFO] Weighted corpora loaded so far:
			* github: 510
[2022-05-05 23:02:14,475 INFO] Step 35150/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 47553/4740 tok/s;   6212 sec
[2022-05-05 23:02:23,146 INFO] Step 35200/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 54474/5252 tok/s;   6221 sec
[2022-05-05 23:02:23,149 INFO] Weighted corpora loaded so far:
			* github: 511
[2022-05-05 23:02:32,156 INFO] Step 35250/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 52447/5093 tok/s;   6230 sec
[2022-05-05 23:02:34,499 INFO] Weighted corpora loaded so far:
			* github: 512
[2022-05-05 23:02:41,109 INFO] Step 35300/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 50852/5213 tok/s;   6239 sec
[2022-05-05 23:02:45,881 INFO] Weighted corpora loaded so far:
			* github: 513
[2022-05-05 23:02:49,997 INFO] Step 35350/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 52180/5067 tok/s;   6248 sec
[2022-05-05 23:02:57,317 INFO] Weighted corpora loaded so far:
			* github: 514
[2022-05-05 23:02:59,083 INFO] Step 35400/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 51139/5180 tok/s;   6257 sec
[2022-05-05 23:03:07,817 INFO] Step 35450/100000; acc:  99.49; ppl:  1.01; xent: 0.01; lr: 0.00050; 52004/5111 tok/s;   6265 sec
[2022-05-05 23:03:08,913 INFO] Weighted corpora loaded so far:
			* github: 515
[2022-05-05 23:03:16,878 INFO] Step 35500/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52289/5060 tok/s;   6274 sec
[2022-05-05 23:03:20,197 INFO] Weighted corpora loaded so far:
			* github: 516
[2022-05-05 23:03:25,596 INFO] Step 35550/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 51163/5271 tok/s;   6283 sec
[2022-05-05 23:03:31,454 INFO] Weighted corpora loaded so far:
			* github: 517
[2022-05-05 23:03:34,667 INFO] Step 35600/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 50655/5115 tok/s;   6292 sec
[2022-05-05 23:03:43,297 INFO] Weighted corpora loaded so far:
			* github: 518
[2022-05-05 23:03:43,972 INFO] Step 35650/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 50426/4945 tok/s;   6302 sec
[2022-05-05 23:03:52,595 INFO] Step 35700/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 54590/5255 tok/s;   6310 sec
[2022-05-05 23:03:54,590 INFO] Weighted corpora loaded so far:
			* github: 519
[2022-05-05 23:04:01,331 INFO] Step 35750/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 51292/5337 tok/s;   6319 sec
[2022-05-05 23:04:05,793 INFO] Weighted corpora loaded so far:
			* github: 520
[2022-05-05 23:04:10,219 INFO] Step 35800/100000; acc:  99.52; ppl:  1.01; xent: 0.01; lr: 0.00050; 52140/5078 tok/s;   6328 sec
[2022-05-05 23:04:17,099 INFO] Weighted corpora loaded so far:
			* github: 521
[2022-05-05 23:04:19,137 INFO] Step 35850/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 51640/5286 tok/s;   6337 sec
[2022-05-05 23:04:28,049 INFO] Step 35900/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 51701/5132 tok/s;   6346 sec
[2022-05-05 23:04:28,748 INFO] Weighted corpora loaded so far:
			* github: 522
[2022-05-05 23:04:36,973 INFO] Step 35950/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 52698/5101 tok/s;   6355 sec
[2022-05-05 23:04:45,708 INFO] Step 36000/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 51181/5253 tok/s;   6363 sec
[2022-05-05 23:04:51,172 INFO] Weighted corpora loaded so far:
			* github: 523
[2022-05-05 23:04:54,550 INFO] Step 36050/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52155/5201 tok/s;   6372 sec
[2022-05-05 23:05:02,510 INFO] Weighted corpora loaded so far:
			* github: 524
[2022-05-05 23:05:03,510 INFO] Step 36100/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52601/5118 tok/s;   6381 sec
[2022-05-05 23:05:12,153 INFO] Step 36150/100000; acc:  99.56; ppl:  1.02; xent: 0.01; lr: 0.00050; 53851/5267 tok/s;   6390 sec
[2022-05-05 23:05:13,816 INFO] Weighted corpora loaded so far:
			* github: 525
[2022-05-05 23:05:21,069 INFO] Step 36200/100000; acc:  99.45; ppl:  1.02; xent: 0.02; lr: 0.00050; 51931/5199 tok/s;   6399 sec
[2022-05-05 23:05:25,159 INFO] Weighted corpora loaded so far:
			* github: 526
[2022-05-05 23:05:29,911 INFO] Step 36250/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 51591/5115 tok/s;   6408 sec
[2022-05-05 23:05:36,477 INFO] Weighted corpora loaded so far:
			* github: 527
[2022-05-05 23:05:38,749 INFO] Step 36300/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 51798/5243 tok/s;   6416 sec
[2022-05-05 23:05:47,399 INFO] Step 36350/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 54034/5350 tok/s;   6425 sec
[2022-05-05 23:05:47,723 INFO] Weighted corpora loaded so far:
			* github: 528
[2022-05-05 23:05:56,342 INFO] Step 36400/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 52315/5072 tok/s;   6434 sec
[2022-05-05 23:05:59,008 INFO] Weighted corpora loaded so far:
			* github: 529
[2022-05-05 23:06:05,152 INFO] Step 36450/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 50993/5219 tok/s;   6443 sec
[2022-05-05 23:06:10,330 INFO] Weighted corpora loaded so far:
			* github: 530
[2022-05-05 23:06:14,076 INFO] Step 36500/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 51689/5219 tok/s;   6452 sec
[2022-05-05 23:06:21,732 INFO] Weighted corpora loaded so far:
			* github: 531
[2022-05-05 23:06:23,243 INFO] Step 36550/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 51220/4980 tok/s;   6461 sec
[2022-05-05 23:06:31,914 INFO] Step 36600/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 53111/5191 tok/s;   6470 sec
[2022-05-05 23:06:33,311 INFO] Weighted corpora loaded so far:
			* github: 532
[2022-05-05 23:06:40,879 INFO] Step 36650/100000; acc:  99.46; ppl:  1.02; xent: 0.02; lr: 0.00050; 52036/5203 tok/s;   6478 sec
[2022-05-05 23:06:44,575 INFO] Weighted corpora loaded so far:
			* github: 533
[2022-05-05 23:06:49,646 INFO] Step 36700/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 50898/5217 tok/s;   6487 sec
[2022-05-05 23:06:55,873 INFO] Weighted corpora loaded so far:
			* github: 534
[2022-05-05 23:06:58,416 INFO] Step 36750/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 52057/5319 tok/s;   6496 sec
[2022-05-05 23:07:06,967 INFO] Step 36800/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 54827/5315 tok/s;   6505 sec
[2022-05-05 23:07:07,004 INFO] Weighted corpora loaded so far:
			* github: 535
[2022-05-05 23:07:15,891 INFO] Step 36850/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52537/5196 tok/s;   6513 sec
[2022-05-05 23:07:24,698 INFO] Step 36900/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 51601/5186 tok/s;   6522 sec
[2022-05-05 23:07:29,488 INFO] Weighted corpora loaded so far:
			* github: 536
[2022-05-05 23:07:33,572 INFO] Step 36950/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 52186/5114 tok/s;   6531 sec
[2022-05-05 23:07:40,876 INFO] Weighted corpora loaded so far:
			* github: 537
[2022-05-05 23:07:42,605 INFO] Step 37000/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 51356/5131 tok/s;   6540 sec
[2022-05-05 23:07:51,157 INFO] Step 37050/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 53433/5341 tok/s;   6549 sec
[2022-05-05 23:07:52,210 INFO] Weighted corpora loaded so far:
			* github: 538
[2022-05-05 23:08:00,291 INFO] Step 37100/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 52417/4991 tok/s;   6558 sec
[2022-05-05 23:08:03,648 INFO] Weighted corpora loaded so far:
			* github: 539
[2022-05-05 23:08:09,109 INFO] Step 37150/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 50982/5190 tok/s;   6567 sec
[2022-05-05 23:08:14,967 INFO] Weighted corpora loaded so far:
			* github: 540
[2022-05-05 23:08:17,966 INFO] Step 37200/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 51789/5186 tok/s;   6576 sec
[2022-05-05 23:08:26,233 INFO] Weighted corpora loaded so far:
			* github: 541
[2022-05-05 23:08:26,903 INFO] Step 37250/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 51791/5259 tok/s;   6584 sec
[2022-05-05 23:08:35,589 INFO] Step 37300/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 53897/5214 tok/s;   6593 sec
[2022-05-05 23:08:37,586 INFO] Weighted corpora loaded so far:
			* github: 542
[2022-05-05 23:08:44,430 INFO] Step 37350/100000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00050; 51212/5156 tok/s;   6602 sec
[2022-05-05 23:08:48,957 INFO] Weighted corpora loaded so far:
			* github: 543
[2022-05-05 23:08:53,422 INFO] Step 37400/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 52062/5148 tok/s;   6611 sec
[2022-05-05 23:09:00,311 INFO] Weighted corpora loaded so far:
			* github: 544
[2022-05-05 23:09:02,375 INFO] Step 37450/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 51636/5174 tok/s;   6620 sec
[2022-05-05 23:09:10,993 INFO] Step 37500/100000; acc:  99.57; ppl:  1.02; xent: 0.02; lr: 0.00050; 53470/5291 tok/s;   6629 sec
[2022-05-05 23:09:11,690 INFO] Weighted corpora loaded so far:
			* github: 545
[2022-05-05 23:09:19,983 INFO] Step 37550/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 52181/5106 tok/s;   6638 sec
[2022-05-05 23:09:22,982 INFO] Weighted corpora loaded so far:
			* github: 546
[2022-05-05 23:09:28,748 INFO] Step 37600/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 50753/5240 tok/s;   6646 sec
[2022-05-05 23:09:34,282 INFO] Weighted corpora loaded so far:
			* github: 547
[2022-05-05 23:09:37,655 INFO] Step 37650/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 51484/5243 tok/s;   6655 sec
[2022-05-05 23:09:46,762 INFO] Step 37700/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 51594/5000 tok/s;   6664 sec
[2022-05-05 23:09:55,349 INFO] Step 37750/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 53900/5290 tok/s;   6673 sec
[2022-05-05 23:09:56,982 INFO] Weighted corpora loaded so far:
			* github: 548
[2022-05-05 23:10:04,212 INFO] Step 37800/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 52123/5173 tok/s;   6682 sec
[2022-05-05 23:10:08,258 INFO] Weighted corpora loaded so far:
			* github: 549
[2022-05-05 23:10:12,998 INFO] Step 37850/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 51869/5153 tok/s;   6691 sec
[2022-05-05 23:10:19,530 INFO] Weighted corpora loaded so far:
			* github: 550
[2022-05-05 23:10:21,913 INFO] Step 37900/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 51457/5218 tok/s;   6700 sec
[2022-05-05 23:10:30,757 INFO] Step 37950/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 53305/5222 tok/s;   6708 sec
[2022-05-05 23:10:31,079 INFO] Weighted corpora loaded so far:
			* github: 551
[2022-05-05 23:10:39,529 INFO] Step 38000/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 53638/5182 tok/s;   6717 sec
[2022-05-05 23:10:42,134 INFO] Weighted corpora loaded so far:
			* github: 552
[2022-05-05 23:10:48,174 INFO] Step 38050/100000; acc:  99.47; ppl:  1.02; xent: 0.02; lr: 0.00050; 52157/5265 tok/s;   6726 sec
[2022-05-05 23:10:53,232 INFO] Weighted corpora loaded so far:
			* github: 553
[2022-05-05 23:10:56,882 INFO] Step 38100/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 52869/5326 tok/s;   6734 sec
[2022-05-05 23:11:04,291 INFO] Weighted corpora loaded so far:
			* github: 554
[2022-05-05 23:11:05,591 INFO] Step 38150/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 53471/5275 tok/s;   6743 sec
[2022-05-05 23:11:14,031 INFO] Step 38200/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 54262/5441 tok/s;   6752 sec
[2022-05-05 23:11:15,378 INFO] Weighted corpora loaded so far:
			* github: 555
[2022-05-05 23:11:22,927 INFO] Step 38250/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 52833/5093 tok/s;   6761 sec
[2022-05-05 23:11:26,618 INFO] Weighted corpora loaded so far:
			* github: 556
[2022-05-05 23:11:31,690 INFO] Step 38300/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 51421/5388 tok/s;   6769 sec
[2022-05-05 23:11:37,871 INFO] Weighted corpora loaded so far:
			* github: 557
[2022-05-05 23:11:40,503 INFO] Step 38350/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52147/5224 tok/s;   6778 sec
[2022-05-05 23:11:49,047 INFO] Step 38400/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 54694/5333 tok/s;   6787 sec
[2022-05-05 23:11:49,071 INFO] Weighted corpora loaded so far:
			* github: 558
[2022-05-05 23:11:57,950 INFO] Step 38450/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 52695/5128 tok/s;   6796 sec
[2022-05-05 23:12:00,267 INFO] Weighted corpora loaded so far:
			* github: 559
[2022-05-05 23:12:06,712 INFO] Step 38500/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 51598/5243 tok/s;   6804 sec
[2022-05-05 23:12:11,518 INFO] Weighted corpora loaded so far:
			* github: 560
[2022-05-05 23:12:15,540 INFO] Step 38550/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 52090/5210 tok/s;   6813 sec
[2022-05-05 23:12:24,397 INFO] Step 38600/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 52036/5215 tok/s;   6822 sec
[2022-05-05 23:12:32,752 INFO] Step 38650/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 54527/5445 tok/s;   6830 sec
[2022-05-05 23:12:33,768 INFO] Weighted corpora loaded so far:
			* github: 561
[2022-05-05 23:12:41,663 INFO] Step 38700/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 53671/5172 tok/s;   6839 sec
[2022-05-05 23:12:44,944 INFO] Weighted corpora loaded so far:
			* github: 562
[2022-05-05 23:12:50,303 INFO] Step 38750/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 52012/5231 tok/s;   6848 sec
[2022-05-05 23:12:56,079 INFO] Weighted corpora loaded so far:
			* github: 563
[2022-05-05 23:12:59,061 INFO] Step 38800/100000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00050; 52551/5309 tok/s;   6857 sec
[2022-05-05 23:13:07,224 INFO] Weighted corpora loaded so far:
			* github: 564
[2022-05-05 23:13:07,912 INFO] Step 38850/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 52922/5268 tok/s;   6866 sec
[2022-05-05 23:13:16,631 INFO] Step 38900/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 54125/5191 tok/s;   6874 sec
[2022-05-05 23:13:18,717 INFO] Weighted corpora loaded so far:
			* github: 565
[2022-05-05 23:13:25,564 INFO] Step 38950/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 50422/5113 tok/s;   6883 sec
[2022-05-05 23:13:29,990 INFO] Weighted corpora loaded so far:
			* github: 566
[2022-05-05 23:13:34,405 INFO] Step 39000/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 52542/5167 tok/s;   6892 sec
[2022-05-05 23:13:41,216 INFO] Weighted corpora loaded so far:
			* github: 567
[2022-05-05 23:13:43,297 INFO] Step 39050/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 51711/5264 tok/s;   6901 sec
[2022-05-05 23:13:51,904 INFO] Step 39100/100000; acc:  99.53; ppl:  1.01; xent: 0.01; lr: 0.00050; 53359/5246 tok/s;   6909 sec
[2022-05-05 23:13:52,588 INFO] Weighted corpora loaded so far:
			* github: 568
[2022-05-05 23:14:00,870 INFO] Step 39150/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 52936/5072 tok/s;   6918 sec
[2022-05-05 23:14:03,843 INFO] Weighted corpora loaded so far:
			* github: 569
[2022-05-05 23:14:09,582 INFO] Step 39200/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 51513/5317 tok/s;   6927 sec
[2022-05-05 23:14:15,073 INFO] Weighted corpora loaded so far:
			* github: 570
[2022-05-05 23:14:18,407 INFO] Step 39250/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 52069/5204 tok/s;   6936 sec
[2022-05-05 23:14:26,272 INFO] Weighted corpora loaded so far:
			* github: 571
[2022-05-05 23:14:27,308 INFO] Step 39300/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52411/5259 tok/s;   6945 sec
[2022-05-05 23:14:35,879 INFO] Step 39350/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 54029/5355 tok/s;   6953 sec
[2022-05-05 23:14:37,541 INFO] Weighted corpora loaded so far:
			* github: 572
[2022-05-05 23:14:44,731 INFO] Step 39400/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 51995/5166 tok/s;   6962 sec
[2022-05-05 23:14:48,797 INFO] Weighted corpora loaded so far:
			* github: 573
[2022-05-05 23:14:53,537 INFO] Step 39450/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 51382/5153 tok/s;   6971 sec
[2022-05-05 23:15:02,385 INFO] Step 39500/100000; acc:  99.54; ppl:  1.01; xent: 0.01; lr: 0.00050; 51470/5214 tok/s;   6980 sec
[2022-05-05 23:15:11,013 INFO] Step 39550/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 54623/5281 tok/s;   6989 sec
[2022-05-05 23:15:11,336 INFO] Weighted corpora loaded so far:
			* github: 574
[2022-05-05 23:15:19,983 INFO] Step 39600/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 52526/5094 tok/s;   6998 sec
[2022-05-05 23:15:22,636 INFO] Weighted corpora loaded so far:
			* github: 575
[2022-05-05 23:15:28,753 INFO] Step 39650/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 51432/5275 tok/s;   7006 sec
[2022-05-05 23:15:33,896 INFO] Weighted corpora loaded so far:
			* github: 576
[2022-05-05 23:15:37,623 INFO] Step 39700/100000; acc:  99.55; ppl:  1.01; xent: 0.01; lr: 0.00050; 52152/5197 tok/s;   7015 sec
[2022-05-05 23:15:45,208 INFO] Weighted corpora loaded so far:
			* github: 577
[2022-05-05 23:15:46,622 INFO] Step 39750/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 52356/5132 tok/s;   7024 sec
[2022-05-05 23:15:55,197 INFO] Step 39800/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 53621/5266 tok/s;   7033 sec
[2022-05-05 23:15:56,564 INFO] Weighted corpora loaded so far:
			* github: 578
[2022-05-05 23:16:04,151 INFO] Step 39850/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52129/5110 tok/s;   7042 sec
[2022-05-05 23:16:07,868 INFO] Weighted corpora loaded so far:
			* github: 579
[2022-05-05 23:16:12,940 INFO] Step 39900/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 50759/5169 tok/s;   7051 sec
[2022-05-05 23:16:19,183 INFO] Weighted corpora loaded so far:
			* github: 580
[2022-05-05 23:16:21,871 INFO] Step 39950/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 51190/5301 tok/s;   7059 sec
[2022-05-05 23:16:30,554 INFO] Step 40000/100000; acc:  99.53; ppl:  1.01; xent: 0.01; lr: 0.00050; 54266/5227 tok/s;   7068 sec
[2022-05-05 23:16:32,276 INFO] Validation perplexity: 233.369
[2022-05-05 23:16:32,276 INFO] Validation accuracy: 50.3955
[2022-05-05 23:16:32,276 INFO] Model is improving acc: 50.0208 --> 50.3955.
[2022-05-05 23:16:32,366 INFO] Saving checkpoint /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/model_step_40000.pt
[2022-05-05 23:16:32,502 INFO] Weighted corpora loaded so far:
			* github: 581
[2022-05-05 23:16:41,421 INFO] Step 40050/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 43413/4208 tok/s;   7079 sec
[2022-05-05 23:16:43,731 INFO] Weighted corpora loaded so far:
			* github: 582
[2022-05-05 23:16:50,231 INFO] Step 40100/100000; acc:  99.58; ppl:  1.02; xent: 0.02; lr: 0.00050; 51567/5190 tok/s;   7088 sec
[2022-05-05 23:16:55,101 INFO] Weighted corpora loaded so far:
			* github: 583
[2022-05-05 23:16:59,213 INFO] Step 40150/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 51401/5211 tok/s;   7097 sec
[2022-05-05 23:17:06,448 INFO] Weighted corpora loaded so far:
			* github: 584
[2022-05-05 23:17:08,147 INFO] Step 40200/100000; acc:  99.52; ppl:  1.01; xent: 0.01; lr: 0.00050; 51631/5165 tok/s;   7106 sec
[2022-05-05 23:17:16,609 INFO] Step 40250/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 53380/5345 tok/s;   7114 sec
[2022-05-05 23:17:17,685 INFO] Weighted corpora loaded so far:
			* github: 585
[2022-05-05 23:17:25,621 INFO] Step 40300/100000; acc:  99.51; ppl:  1.01; xent: 0.01; lr: 0.00050; 52758/5122 tok/s;   7123 sec
[2022-05-05 23:17:28,975 INFO] Weighted corpora loaded so far:
			* github: 586
[2022-05-05 23:17:34,396 INFO] Step 40350/100000; acc:  99.48; ppl:  1.02; xent: 0.02; lr: 0.00050; 50917/5218 tok/s;   7132 sec
[2022-05-05 23:17:43,266 INFO] Step 40400/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 51708/5145 tok/s;   7141 sec
[2022-05-05 23:17:51,509 INFO] Weighted corpora loaded so far:
			* github: 587
[2022-05-05 23:17:52,194 INFO] Step 40450/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 52428/5157 tok/s;   7150 sec
[2022-05-05 23:18:00,786 INFO] Step 40500/100000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00050; 54618/5363 tok/s;   7158 sec
[2022-05-05 23:18:02,749 INFO] Weighted corpora loaded so far:
			* github: 588
[2022-05-05 23:18:09,643 INFO] Step 40550/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 51115/5142 tok/s;   7167 sec
[2022-05-05 23:18:14,127 INFO] Weighted corpora loaded so far:
			* github: 589
[2022-05-05 23:18:18,563 INFO] Step 40600/100000; acc:  99.54; ppl:  1.01; xent: 0.01; lr: 0.00050; 52550/5110 tok/s;   7176 sec
[2022-05-05 23:18:25,420 INFO] Weighted corpora loaded so far:
			* github: 590
[2022-05-05 23:18:27,449 INFO] Step 40650/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 52208/5262 tok/s;   7185 sec
[2022-05-05 23:18:35,943 INFO] Step 40700/100000; acc:  99.53; ppl:  1.01; xent: 0.01; lr: 0.00050; 54451/5373 tok/s;   7194 sec
[2022-05-05 23:18:36,633 INFO] Weighted corpora loaded so far:
			* github: 591
[2022-05-05 23:18:44,847 INFO] Step 40750/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 52530/5165 tok/s;   7202 sec
[2022-05-05 23:18:47,806 INFO] Weighted corpora loaded so far:
			* github: 592
[2022-05-05 23:18:53,550 INFO] Step 40800/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 51101/5258 tok/s;   7211 sec
[2022-05-05 23:18:59,029 INFO] Weighted corpora loaded so far:
			* github: 593
[2022-05-05 23:19:02,374 INFO] Step 40850/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 52193/5199 tok/s;   7220 sec
[2022-05-05 23:19:10,291 INFO] Weighted corpora loaded so far:
			* github: 594
[2022-05-05 23:19:11,347 INFO] Step 40900/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 52760/5126 tok/s;   7229 sec
[2022-05-05 23:19:19,885 INFO] Step 40950/100000; acc:  99.55; ppl:  1.01; xent: 0.01; lr: 0.00050; 54502/5381 tok/s;   7237 sec
[2022-05-05 23:19:21,558 INFO] Weighted corpora loaded so far:
			* github: 595
[2022-05-05 23:19:28,810 INFO] Step 41000/100000; acc:  99.58; ppl:  1.02; xent: 0.01; lr: 0.00050; 51514/5115 tok/s;   7246 sec
[2022-05-05 23:19:32,867 INFO] Weighted corpora loaded so far:
			* github: 596
[2022-05-05 23:19:37,554 INFO] Step 41050/100000; acc:  99.54; ppl:  1.01; xent: 0.01; lr: 0.00050; 51768/5224 tok/s;   7255 sec
[2022-05-05 23:19:44,070 INFO] Weighted corpora loaded so far:
			* github: 597
[2022-05-05 23:19:46,386 INFO] Step 41100/100000; acc:  99.50; ppl:  1.02; xent: 0.02; lr: 0.00050; 51581/5357 tok/s;   7264 sec
[2022-05-05 23:19:55,248 INFO] Step 41150/100000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00050; 52790/5129 tok/s;   7273 sec
[2022-05-05 23:19:55,607 INFO] Weighted corpora loaded so far:
			* github: 598
[2022-05-05 23:20:04,245 INFO] Step 41200/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 51929/5076 tok/s;   7282 sec
[2022-05-05 23:20:13,027 INFO] Step 41250/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 51053/5236 tok/s;   7291 sec
[2022-05-05 23:20:18,159 INFO] Weighted corpora loaded so far:
			* github: 599
[2022-05-05 23:20:21,926 INFO] Step 41300/100000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00050; 51864/5172 tok/s;   7300 sec
[2022-05-05 23:20:29,498 INFO] Weighted corpora loaded so far:
			* github: 600
[2022-05-05 23:20:30,909 INFO] Step 41350/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 52536/5060 tok/s;   7308 sec
[2022-05-05 23:20:39,459 INFO] Step 41400/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 53758/5393 tok/s;   7317 sec
[2022-05-05 23:20:40,805 INFO] Weighted corpora loaded so far:
			* github: 601
[2022-05-05 23:20:48,453 INFO] Step 41450/100000; acc:  99.55; ppl:  1.01; xent: 0.01; lr: 0.00050; 52345/5092 tok/s;   7326 sec
[2022-05-05 23:20:52,131 INFO] Weighted corpora loaded so far:
			* github: 602
[2022-05-05 23:20:57,230 INFO] Step 41500/100000; acc:  99.57; ppl:  1.02; xent: 0.01; lr: 0.00050; 51277/5224 tok/s;   7335 sec
[2022-05-05 23:21:03,430 INFO] Weighted corpora loaded so far:
			* github: 603
[2022-05-05 23:21:06,100 INFO] Step 41550/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 51726/5222 tok/s;   7344 sec
[2022-05-05 23:21:14,909 INFO] Step 41600/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 53204/5193 tok/s;   7352 sec
[2022-05-05 23:21:14,922 INFO] Weighted corpora loaded so far:
			* github: 604
[2022-05-05 23:21:24,762 INFO] Step 41650/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 47638/4619 tok/s;   7362 sec
[2022-05-05 23:21:27,131 INFO] Weighted corpora loaded so far:
			* github: 605
[2022-05-05 23:21:33,562 INFO] Step 41700/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 51352/5156 tok/s;   7371 sec
[2022-05-05 23:21:38,319 INFO] Weighted corpora loaded so far:
			* github: 606
[2022-05-05 23:21:42,376 INFO] Step 41750/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 52482/5169 tok/s;   7380 sec
[2022-05-05 23:21:49,611 INFO] Weighted corpora loaded so far:
			* github: 607
[2022-05-05 23:21:51,377 INFO] Step 41800/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 51801/5239 tok/s;   7389 sec
[2022-05-05 23:21:59,887 INFO] Step 41850/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 53725/5385 tok/s;   7397 sec
[2022-05-05 23:22:00,935 INFO] Weighted corpora loaded so far:
			* github: 608
[2022-05-05 23:22:08,878 INFO] Step 41900/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 52540/5082 tok/s;   7406 sec
[2022-05-05 23:22:12,213 INFO] Weighted corpora loaded so far:
			* github: 609
[2022-05-05 23:22:17,617 INFO] Step 41950/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 50910/5228 tok/s;   7415 sec
[2022-05-05 23:22:23,464 INFO] Weighted corpora loaded so far:
			* github: 610
[2022-05-05 23:22:26,464 INFO] Step 42000/100000; acc:  99.51; ppl:  1.02; xent: 0.02; lr: 0.00050; 51722/5271 tok/s;   7424 sec
[2022-05-05 23:22:34,869 INFO] Weighted corpora loaded so far:
			* github: 611
[2022-05-05 23:22:35,513 INFO] Step 42050/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 51477/5091 tok/s;   7433 sec
[2022-05-05 23:22:44,102 INFO] Step 42100/100000; acc:  99.52; ppl:  1.02; xent: 0.02; lr: 0.00050; 54504/5288 tok/s;   7442 sec
[2022-05-05 23:22:52,840 INFO] Step 42150/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 51571/5259 tok/s;   7450 sec
[2022-05-05 23:22:57,607 INFO] Weighted corpora loaded so far:
			* github: 612
[2022-05-05 23:23:02,548 INFO] Step 42200/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 48124/4777 tok/s;   7460 sec
[2022-05-05 23:23:09,423 INFO] Weighted corpora loaded so far:
			* github: 613
[2022-05-05 23:23:11,492 INFO] Step 42250/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 51811/5096 tok/s;   7469 sec
[2022-05-05 23:23:20,099 INFO] Step 42300/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 53654/5255 tok/s;   7478 sec
[2022-05-05 23:23:20,781 INFO] Weighted corpora loaded so far:
			* github: 614
[2022-05-05 23:23:29,026 INFO] Step 42350/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 53313/5222 tok/s;   7487 sec
[2022-05-05 23:23:31,987 INFO] Weighted corpora loaded so far:
			* github: 615
[2022-05-05 23:23:37,747 INFO] Step 42400/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 51468/5257 tok/s;   7495 sec
[2022-05-05 23:23:43,343 INFO] Weighted corpora loaded so far:
			* github: 616
[2022-05-05 23:23:47,032 INFO] Step 42450/100000; acc:  99.55; ppl:  1.02; xent: 0.02; lr: 0.00050; 49544/4925 tok/s;   7505 sec
[2022-05-05 23:23:55,011 INFO] Weighted corpora loaded so far:
			* github: 617
[2022-05-05 23:23:56,052 INFO] Step 42500/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 51934/5134 tok/s;   7514 sec
[2022-05-05 23:24:04,655 INFO] Step 42550/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 53665/5326 tok/s;   7522 sec
[2022-05-05 23:24:06,309 INFO] Weighted corpora loaded so far:
			* github: 618
[2022-05-05 23:24:13,529 INFO] Step 42600/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51802/5122 tok/s;   7531 sec
[2022-05-05 23:24:17,610 INFO] Weighted corpora loaded so far:
			* github: 619
[2022-05-05 23:24:22,395 INFO] Step 42650/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51324/5158 tok/s;   7540 sec
[2022-05-05 23:24:28,947 INFO] Weighted corpora loaded so far:
			* github: 620
[2022-05-05 23:24:31,307 INFO] Step 42700/100000; acc:  99.55; ppl:  1.01; xent: 0.01; lr: 0.00050; 51548/5205 tok/s;   7549 sec
[2022-05-05 23:24:39,974 INFO] Step 42750/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 54398/5244 tok/s;   7558 sec
[2022-05-05 23:24:40,329 INFO] Weighted corpora loaded so far:
			* github: 621
[2022-05-05 23:24:48,948 INFO] Step 42800/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 51930/5142 tok/s;   7567 sec
[2022-05-05 23:24:51,629 INFO] Weighted corpora loaded so far:
			* github: 622
[2022-05-05 23:24:57,783 INFO] Step 42850/100000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00050; 50573/5263 tok/s;   7575 sec
[2022-05-05 23:25:03,020 INFO] Weighted corpora loaded so far:
			* github: 623
[2022-05-05 23:25:06,721 INFO] Step 42900/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 51370/5086 tok/s;   7584 sec
[2022-05-05 23:25:14,355 INFO] Weighted corpora loaded so far:
			* github: 624
[2022-05-05 23:25:15,711 INFO] Step 42950/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 52085/5150 tok/s;   7593 sec
[2022-05-05 23:25:24,357 INFO] Step 43000/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52771/5297 tok/s;   7602 sec
[2022-05-05 23:25:33,332 INFO] Step 43050/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52438/5114 tok/s;   7611 sec
[2022-05-05 23:25:37,023 INFO] Weighted corpora loaded so far:
			* github: 625
[2022-05-05 23:25:42,118 INFO] Step 43100/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 51207/5145 tok/s;   7620 sec
[2022-05-05 23:25:48,324 INFO] Weighted corpora loaded so far:
			* github: 626
[2022-05-05 23:25:50,991 INFO] Step 43150/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 51730/5242 tok/s;   7629 sec
[2022-05-05 23:25:59,635 INFO] Step 43200/100000; acc:  99.54; ppl:  1.02; xent: 0.02; lr: 0.00050; 54419/5306 tok/s;   7637 sec
[2022-05-05 23:25:59,642 INFO] Weighted corpora loaded so far:
			* github: 627
[2022-05-05 23:26:08,599 INFO] Step 43250/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 52931/5085 tok/s;   7646 sec
[2022-05-05 23:26:10,935 INFO] Weighted corpora loaded so far:
			* github: 628
[2022-05-05 23:26:17,414 INFO] Step 43300/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51610/5191 tok/s;   7655 sec
[2022-05-05 23:26:22,177 INFO] Weighted corpora loaded so far:
			* github: 629
[2022-05-05 23:26:26,260 INFO] Step 43350/100000; acc:  99.54; ppl:  1.01; xent: 0.01; lr: 0.00050; 52114/5257 tok/s;   7664 sec
[2022-05-05 23:26:33,418 INFO] Weighted corpora loaded so far:
			* github: 630
[2022-05-05 23:26:35,083 INFO] Step 43400/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52211/5221 tok/s;   7673 sec
[2022-05-05 23:26:43,534 INFO] Step 43450/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 53676/5363 tok/s;   7681 sec
[2022-05-05 23:26:44,581 INFO] Weighted corpora loaded so far:
			* github: 631
[2022-05-05 23:26:52,510 INFO] Step 43500/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 53289/5149 tok/s;   7690 sec
[2022-05-05 23:26:55,845 INFO] Weighted corpora loaded so far:
			* github: 632
[2022-05-05 23:27:01,244 INFO] Step 43550/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 51398/5216 tok/s;   7699 sec
[2022-05-05 23:27:07,069 INFO] Weighted corpora loaded so far:
			* github: 633
[2022-05-05 23:27:10,073 INFO] Step 43600/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 52011/5239 tok/s;   7708 sec
[2022-05-05 23:27:18,334 INFO] Weighted corpora loaded so far:
			* github: 634
[2022-05-05 23:27:18,986 INFO] Step 43650/100000; acc:  99.55; ppl:  1.01; xent: 0.01; lr: 0.00050; 52319/5201 tok/s;   7717 sec
[2022-05-05 23:27:27,550 INFO] Step 43700/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 54471/5311 tok/s;   7725 sec
[2022-05-05 23:27:29,538 INFO] Weighted corpora loaded so far:
			* github: 635
[2022-05-05 23:27:36,280 INFO] Step 43750/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 51418/5220 tok/s;   7734 sec
[2022-05-05 23:27:40,752 INFO] Weighted corpora loaded so far:
			* github: 636
[2022-05-05 23:27:45,135 INFO] Step 43800/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52505/5275 tok/s;   7743 sec
[2022-05-05 23:27:52,051 INFO] Weighted corpora loaded so far:
			* github: 637
[2022-05-05 23:27:54,068 INFO] Step 43850/100000; acc:  99.53; ppl:  1.02; xent: 0.02; lr: 0.00050; 51607/5139 tok/s;   7752 sec
[2022-05-05 23:28:02,552 INFO] Step 43900/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 54136/5374 tok/s;   7760 sec
[2022-05-05 23:28:11,482 INFO] Step 43950/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 53273/5080 tok/s;   7769 sec
[2022-05-05 23:28:14,458 INFO] Weighted corpora loaded so far:
			* github: 638
[2022-05-05 23:28:20,213 INFO] Step 44000/100000; acc:  99.59; ppl:  1.02; xent: 0.02; lr: 0.00050; 51239/5250 tok/s;   7778 sec
[2022-05-05 23:28:25,673 INFO] Weighted corpora loaded so far:
			* github: 639
[2022-05-05 23:28:29,052 INFO] Step 44050/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 52074/5209 tok/s;   7787 sec
[2022-05-05 23:28:37,028 INFO] Weighted corpora loaded so far:
			* github: 640
[2022-05-05 23:28:38,084 INFO] Step 44100/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 52387/5156 tok/s;   7796 sec
[2022-05-05 23:28:46,649 INFO] Step 44150/100000; acc:  99.49; ppl:  1.02; xent: 0.02; lr: 0.00050; 54290/5290 tok/s;   7804 sec
[2022-05-05 23:28:48,449 INFO] Weighted corpora loaded so far:
			* github: 641
[2022-05-05 23:28:56,028 INFO] Step 44200/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 49270/4936 tok/s;   7814 sec
[2022-05-05 23:29:00,088 INFO] Weighted corpora loaded so far:
			* github: 642
[2022-05-05 23:29:04,850 INFO] Step 44250/100000; acc:  99.59; ppl:  1.02; xent: 0.02; lr: 0.00050; 51406/5197 tok/s;   7822 sec
[2022-05-05 23:29:11,630 INFO] Weighted corpora loaded so far:
			* github: 643
[2022-05-05 23:29:13,915 INFO] Step 44300/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 50178/5060 tok/s;   7832 sec
[2022-05-05 23:29:22,522 INFO] Step 44350/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 54407/5323 tok/s;   7840 sec
[2022-05-05 23:29:22,851 INFO] Weighted corpora loaded so far:
			* github: 644
[2022-05-05 23:29:31,456 INFO] Step 44400/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 52732/5113 tok/s;   7849 sec
[2022-05-05 23:29:34,126 INFO] Weighted corpora loaded so far:
			* github: 645
[2022-05-05 23:29:40,246 INFO] Step 44450/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51367/5320 tok/s;   7858 sec
[2022-05-05 23:29:45,420 INFO] Weighted corpora loaded so far:
			* github: 646
[2022-05-05 23:29:49,128 INFO] Step 44500/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 51961/5176 tok/s;   7867 sec
[2022-05-05 23:29:56,855 INFO] Weighted corpora loaded so far:
			* github: 647
[2022-05-05 23:29:58,257 INFO] Step 44550/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51099/5032 tok/s;   7876 sec
[2022-05-05 23:30:06,780 INFO] Step 44600/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 53641/5340 tok/s;   7884 sec
[2022-05-05 23:30:08,171 INFO] Weighted corpora loaded so far:
			* github: 648
[2022-05-05 23:30:15,814 INFO] Step 44650/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51784/5040 tok/s;   7893 sec
[2022-05-05 23:30:19,522 INFO] Weighted corpora loaded so far:
			* github: 649
[2022-05-05 23:30:24,548 INFO] Step 44700/100000; acc:  99.55; ppl:  1.01; xent: 0.01; lr: 0.00050; 51098/5210 tok/s;   7902 sec
[2022-05-05 23:30:33,415 INFO] Step 44750/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 51386/5295 tok/s;   7911 sec
[2022-05-05 23:30:41,999 INFO] Step 44800/100000; acc:  99.53; ppl:  1.01; xent: 0.01; lr: 0.00050; 54568/5297 tok/s;   7920 sec
[2022-05-05 23:30:42,000 INFO] Weighted corpora loaded so far:
			* github: 650
[2022-05-05 23:30:51,002 INFO] Step 44850/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52761/5045 tok/s;   7929 sec
[2022-05-05 23:30:53,332 INFO] Weighted corpora loaded so far:
			* github: 651
[2022-05-05 23:30:59,855 INFO] Step 44900/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 51369/5243 tok/s;   7937 sec
[2022-05-05 23:31:04,630 INFO] Weighted corpora loaded so far:
			* github: 652
[2022-05-05 23:31:08,701 INFO] Step 44950/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 52404/5256 tok/s;   7946 sec
[2022-05-05 23:31:15,808 INFO] Weighted corpora loaded so far:
			* github: 653
[2022-05-05 23:31:17,540 INFO] Step 45000/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 52725/5215 tok/s;   7955 sec
[2022-05-05 23:31:25,987 INFO] Step 45050/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 54071/5353 tok/s;   7964 sec
[2022-05-05 23:31:27,087 INFO] Weighted corpora loaded so far:
			* github: 654
[2022-05-05 23:31:34,985 INFO] Step 45100/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 52771/5117 tok/s;   7973 sec
[2022-05-05 23:31:38,261 INFO] Weighted corpora loaded so far:
			* github: 655
[2022-05-05 23:31:43,665 INFO] Step 45150/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 51350/5251 tok/s;   7981 sec
[2022-05-05 23:31:49,435 INFO] Weighted corpora loaded so far:
			* github: 656
[2022-05-05 23:31:52,454 INFO] Step 45200/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 52007/5286 tok/s;   7990 sec
[2022-05-05 23:32:00,743 INFO] Weighted corpora loaded so far:
			* github: 657
[2022-05-05 23:32:01,349 INFO] Step 45250/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 52266/5106 tok/s;   7999 sec
[2022-05-05 23:32:10,024 INFO] Step 45300/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 54508/5224 tok/s;   8008 sec
[2022-05-05 23:32:12,040 INFO] Weighted corpora loaded so far:
			* github: 658
[2022-05-05 23:32:18,879 INFO] Step 45350/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51111/5231 tok/s;   8016 sec
[2022-05-05 23:32:23,362 INFO] Weighted corpora loaded so far:
			* github: 659
[2022-05-05 23:32:27,778 INFO] Step 45400/100000; acc:  99.60; ppl:  1.02; xent: 0.02; lr: 0.00050; 52252/5148 tok/s;   8025 sec
[2022-05-05 23:32:34,819 INFO] Weighted corpora loaded so far:
			* github: 660
[2022-05-05 23:32:36,776 INFO] Step 45450/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 50942/5204 tok/s;   8034 sec
[2022-05-05 23:32:45,365 INFO] Step 45500/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 53512/5347 tok/s;   8043 sec
[2022-05-05 23:32:46,053 INFO] Weighted corpora loaded so far:
			* github: 661
[2022-05-05 23:32:54,319 INFO] Step 45550/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52829/5087 tok/s;   8052 sec
[2022-05-05 23:32:57,332 INFO] Weighted corpora loaded so far:
			* github: 662
[2022-05-05 23:33:03,085 INFO] Step 45600/100000; acc:  99.55; ppl:  1.01; xent: 0.01; lr: 0.00050; 50675/5203 tok/s;   8061 sec
[2022-05-05 23:33:11,943 INFO] Step 45650/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 51681/5220 tok/s;   8070 sec
[2022-05-05 23:33:19,804 INFO] Weighted corpora loaded so far:
			* github: 663
[2022-05-05 23:33:20,845 INFO] Step 45700/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 53051/5105 tok/s;   8078 sec
[2022-05-05 23:33:29,425 INFO] Step 45750/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 54259/5411 tok/s;   8087 sec
[2022-05-05 23:33:31,064 INFO] Weighted corpora loaded so far:
			* github: 664
[2022-05-05 23:33:38,568 INFO] Step 45800/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 50487/5005 tok/s;   8096 sec
[2022-05-05 23:33:42,592 INFO] Weighted corpora loaded so far:
			* github: 665
[2022-05-05 23:33:47,341 INFO] Step 45850/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 52083/5204 tok/s;   8105 sec
[2022-05-05 23:33:53,878 INFO] Weighted corpora loaded so far:
			* github: 666
[2022-05-05 23:33:56,221 INFO] Step 45900/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51862/5225 tok/s;   8114 sec
[2022-05-05 23:34:05,203 INFO] Step 45950/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52289/5095 tok/s;   8123 sec
[2022-05-05 23:34:05,541 INFO] Weighted corpora loaded so far:
			* github: 667
[2022-05-05 23:34:14,087 INFO] Step 46000/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52658/5058 tok/s;   8132 sec
[2022-05-05 23:34:16,809 INFO] Weighted corpora loaded so far:
			* github: 668
[2022-05-05 23:34:23,186 INFO] Step 46050/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 49176/5041 tok/s;   8141 sec
[2022-05-05 23:34:28,359 INFO] Weighted corpora loaded so far:
			* github: 669
[2022-05-05 23:34:32,052 INFO] Step 46100/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51907/5323 tok/s;   8150 sec
[2022-05-05 23:34:39,529 INFO] Weighted corpora loaded so far:
			* github: 670
[2022-05-05 23:34:40,903 INFO] Step 46150/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 53073/5131 tok/s;   8158 sec
[2022-05-05 23:34:49,468 INFO] Step 46200/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 53583/5305 tok/s;   8167 sec
[2022-05-05 23:34:50,841 INFO] Weighted corpora loaded so far:
			* github: 671
[2022-05-05 23:34:58,489 INFO] Step 46250/100000; acc:  99.59; ppl:  1.02; xent: 0.02; lr: 0.00050; 52186/5052 tok/s;   8176 sec
[2022-05-05 23:35:02,206 INFO] Weighted corpora loaded so far:
			* github: 672
[2022-05-05 23:35:07,274 INFO] Step 46300/100000; acc:  99.58; ppl:  1.01; xent: 0.01; lr: 0.00050; 51021/5346 tok/s;   8185 sec
[2022-05-05 23:35:13,467 INFO] Weighted corpora loaded so far:
			* github: 673
[2022-05-05 23:35:16,098 INFO] Step 46350/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51584/5229 tok/s;   8194 sec
[2022-05-05 23:35:24,668 INFO] Step 46400/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 54240/5371 tok/s;   8202 sec
[2022-05-05 23:35:24,698 INFO] Weighted corpora loaded so far:
			* github: 674
[2022-05-05 23:35:33,640 INFO] Step 46450/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52665/5074 tok/s;   8211 sec
[2022-05-05 23:35:36,029 INFO] Weighted corpora loaded so far:
			* github: 675
[2022-05-05 23:35:42,466 INFO] Step 46500/100000; acc:  99.65; ppl:  1.01; xent: 0.01; lr: 0.00050; 51176/5153 tok/s;   8220 sec
[2022-05-05 23:35:51,334 INFO] Step 46550/100000; acc:  99.59; ppl:  1.02; xent: 0.02; lr: 0.00050; 52059/5254 tok/s;   8229 sec
[2022-05-05 23:35:58,451 INFO] Weighted corpora loaded so far:
			* github: 676
[2022-05-05 23:36:00,187 INFO] Step 46600/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52609/5154 tok/s;   8238 sec
[2022-05-05 23:36:08,638 INFO] Step 46650/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 53838/5426 tok/s;   8246 sec
[2022-05-05 23:36:09,669 INFO] Weighted corpora loaded so far:
			* github: 677
[2022-05-05 23:36:17,644 INFO] Step 46700/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 53038/5132 tok/s;   8255 sec
[2022-05-05 23:36:21,003 INFO] Weighted corpora loaded so far:
			* github: 678
[2022-05-05 23:36:26,434 INFO] Step 46750/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 51189/5204 tok/s;   8264 sec
[2022-05-05 23:36:32,228 INFO] Weighted corpora loaded so far:
			* github: 679
[2022-05-05 23:36:35,234 INFO] Step 46800/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52393/5218 tok/s;   8273 sec
[2022-05-05 23:36:43,467 INFO] Weighted corpora loaded so far:
			* github: 680
[2022-05-05 23:36:44,133 INFO] Step 46850/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52470/5183 tok/s;   8282 sec
[2022-05-05 23:36:52,686 INFO] Step 46900/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 54383/5345 tok/s;   8290 sec
[2022-05-05 23:36:54,654 INFO] Weighted corpora loaded so far:
			* github: 681
[2022-05-05 23:37:01,487 INFO] Step 46950/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00050; 51046/5192 tok/s;   8299 sec
[2022-05-05 23:37:05,909 INFO] Weighted corpora loaded so far:
			* github: 682
[2022-05-05 23:37:10,323 INFO] Step 47000/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 52935/5121 tok/s;   8308 sec
[2022-05-05 23:37:17,180 INFO] Weighted corpora loaded so far:
			* github: 683
[2022-05-05 23:37:19,243 INFO] Step 47050/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 52122/5298 tok/s;   8317 sec
[2022-05-05 23:37:27,934 INFO] Step 47100/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 53027/5207 tok/s;   8326 sec
[2022-05-05 23:37:28,703 INFO] Weighted corpora loaded so far:
			* github: 684
[2022-05-05 23:37:37,064 INFO] Step 47150/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51759/5046 tok/s;   8335 sec
[2022-05-05 23:37:40,039 INFO] Weighted corpora loaded so far:
			* github: 685
[2022-05-05 23:37:45,747 INFO] Step 47200/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 51286/5226 tok/s;   8343 sec
[2022-05-05 23:37:51,256 INFO] Weighted corpora loaded so far:
			* github: 686
[2022-05-05 23:37:54,598 INFO] Step 47250/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 51720/5236 tok/s;   8352 sec
[2022-05-05 23:38:02,502 INFO] Weighted corpora loaded so far:
			* github: 687
[2022-05-05 23:38:03,540 INFO] Step 47300/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 52419/5208 tok/s;   8361 sec
[2022-05-05 23:38:12,140 INFO] Step 47350/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 53736/5316 tok/s;   8370 sec
[2022-05-05 23:38:20,997 INFO] Step 47400/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51823/5140 tok/s;   8379 sec
[2022-05-05 23:38:25,071 INFO] Weighted corpora loaded so far:
			* github: 688
[2022-05-05 23:38:29,867 INFO] Step 47450/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 51434/5178 tok/s;   8387 sec
[2022-05-05 23:38:36,317 INFO] Weighted corpora loaded so far:
			* github: 689
[2022-05-05 23:38:38,643 INFO] Step 47500/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 52521/5193 tok/s;   8396 sec
[2022-05-05 23:38:47,142 INFO] Step 47550/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 55103/5400 tok/s;   8405 sec
[2022-05-05 23:38:47,472 INFO] Weighted corpora loaded so far:
			* github: 690
[2022-05-05 23:38:55,946 INFO] Step 47600/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 53631/5225 tok/s;   8414 sec
[2022-05-05 23:38:58,557 INFO] Weighted corpora loaded so far:
			* github: 691
[2022-05-05 23:39:04,594 INFO] Step 47650/100000; acc:  99.56; ppl:  1.01; xent: 0.01; lr: 0.00050; 52171/5286 tok/s;   8422 sec
[2022-05-05 23:39:09,692 INFO] Weighted corpora loaded so far:
			* github: 692
[2022-05-05 23:39:13,371 INFO] Step 47700/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 52575/5228 tok/s;   8431 sec
[2022-05-05 23:39:20,880 INFO] Weighted corpora loaded so far:
			* github: 693
[2022-05-05 23:39:22,260 INFO] Step 47750/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 52685/5278 tok/s;   8440 sec
[2022-05-05 23:39:30,788 INFO] Step 47800/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 53437/5290 tok/s;   8448 sec
[2022-05-05 23:39:32,157 INFO] Weighted corpora loaded so far:
			* github: 694
[2022-05-05 23:39:39,796 INFO] Step 47850/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52019/5067 tok/s;   8457 sec
[2022-05-05 23:39:43,520 INFO] Weighted corpora loaded so far:
			* github: 695
[2022-05-05 23:39:48,631 INFO] Step 47900/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00050; 50845/5160 tok/s;   8466 sec
[2022-05-05 23:39:54,913 INFO] Weighted corpora loaded so far:
			* github: 696
[2022-05-05 23:39:57,528 INFO] Step 47950/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00050; 51688/5212 tok/s;   8475 sec
[2022-05-05 23:40:06,054 INFO] Step 48000/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 55311/5413 tok/s;   8484 sec
[2022-05-05 23:40:06,078 INFO] Weighted corpora loaded so far:
			* github: 697
[2022-05-05 23:40:14,863 INFO] Step 48050/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 53178/5251 tok/s;   8492 sec
[2022-05-05 23:40:17,172 INFO] Weighted corpora loaded so far:
			* github: 698
[2022-05-05 23:40:23,554 INFO] Step 48100/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 51878/5236 tok/s;   8501 sec
[2022-05-05 23:40:28,387 INFO] Weighted corpora loaded so far:
			* github: 699
[2022-05-05 23:40:32,445 INFO] Step 48150/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00050; 51820/5179 tok/s;   8510 sec
[2022-05-05 23:40:39,628 INFO] Weighted corpora loaded so far:
			* github: 700
[2022-05-05 23:40:41,326 INFO] Step 48200/100000; acc:  99.57; ppl:  1.01; xent: 0.01; lr: 0.00050; 52157/5272 tok/s;   8519 sec
[2022-05-05 23:40:49,769 INFO] Step 48250/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 53552/5356 tok/s;   8527 sec
[2022-05-05 23:40:58,807 INFO] Step 48300/100000; acc:  99.65; ppl:  1.01; xent: 0.01; lr: 0.00050; 52602/5071 tok/s;   8536 sec
[2022-05-05 23:41:02,085 INFO] Weighted corpora loaded so far:
			* github: 701
[2022-05-05 23:41:07,554 INFO] Step 48350/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 51370/5253 tok/s;   8545 sec
[2022-05-05 23:41:13,371 INFO] Weighted corpora loaded so far:
			* github: 702
[2022-05-05 23:41:16,377 INFO] Step 48400/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 52255/5160 tok/s;   8554 sec
[2022-05-05 23:41:24,612 INFO] Weighted corpora loaded so far:
			* github: 703
[2022-05-05 23:41:25,290 INFO] Step 48450/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 52282/5217 tok/s;   8563 sec
[2022-05-05 23:41:33,934 INFO] Step 48500/100000; acc:  99.65; ppl:  1.01; xent: 0.01; lr: 0.00050; 54777/5201 tok/s;   8572 sec
[2022-05-05 23:41:35,932 INFO] Weighted corpora loaded so far:
			* github: 704
[2022-05-05 23:41:42,739 INFO] Step 48550/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51423/5257 tok/s;   8580 sec
[2022-05-05 23:41:47,199 INFO] Weighted corpora loaded so far:
			* github: 705
[2022-05-05 23:41:51,636 INFO] Step 48600/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 52423/5152 tok/s;   8589 sec
[2022-05-05 23:41:58,456 INFO] Weighted corpora loaded so far:
			* github: 706
[2022-05-05 23:42:00,509 INFO] Step 48650/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51855/5211 tok/s;   8598 sec
[2022-05-05 23:42:09,058 INFO] Step 48700/100000; acc:  99.66; ppl:  1.01; xent: 0.01; lr: 0.00050; 53630/5346 tok/s;   8607 sec
[2022-05-05 23:42:09,742 INFO] Weighted corpora loaded so far:
			* github: 707
[2022-05-05 23:42:18,019 INFO] Step 48750/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00050; 52664/5151 tok/s;   8616 sec
[2022-05-05 23:42:21,011 INFO] Weighted corpora loaded so far:
			* github: 708
[2022-05-05 23:42:26,754 INFO] Step 48800/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 51261/5149 tok/s;   8624 sec
[2022-05-05 23:42:32,257 INFO] Weighted corpora loaded so far:
			* github: 709
[2022-05-05 23:42:35,629 INFO] Step 48850/100000; acc:  99.60; ppl:  1.01; xent: 0.01; lr: 0.00050; 52027/5238 tok/s;   8633 sec
[2022-05-05 23:42:43,558 INFO] Weighted corpora loaded so far:
			* github: 710
[2022-05-05 23:42:44,605 INFO] Step 48900/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 52579/5212 tok/s;   8642 sec
[2022-05-05 23:42:53,172 INFO] Step 48950/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00050; 53692/5262 tok/s;   8651 sec
[2022-05-05 23:42:54,832 INFO] Weighted corpora loaded so far:
			* github: 711
[2022-05-05 23:43:02,032 INFO] Step 49000/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51689/5283 tok/s;   8660 sec
[2022-05-05 23:43:06,084 INFO] Weighted corpora loaded so far:
			* github: 712
[2022-05-05 23:43:10,806 INFO] Step 49050/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 51737/5135 tok/s;   8668 sec
[2022-05-05 23:43:17,354 INFO] Weighted corpora loaded so far:
			* github: 713
[2022-05-05 23:43:19,669 INFO] Step 49100/100000; acc:  99.59; ppl:  1.01; xent: 0.01; lr: 0.00050; 51609/5239 tok/s;   8677 sec
[2022-05-05 23:43:28,267 INFO] Step 49150/100000; acc:  99.66; ppl:  1.01; xent: 0.01; lr: 0.00050; 54121/5316 tok/s;   8686 sec
[2022-05-05 23:43:37,158 INFO] Step 49200/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 53086/5126 tok/s;   8695 sec
[2022-05-05 23:43:39,790 INFO] Weighted corpora loaded so far:
			* github: 714
[2022-05-05 23:43:45,896 INFO] Step 49250/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51652/5217 tok/s;   8703 sec
[2022-05-05 23:43:51,037 INFO] Weighted corpora loaded so far:
			* github: 715
[2022-05-05 23:43:54,751 INFO] Step 49300/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 52166/5259 tok/s;   8712 sec
[2022-05-05 23:44:02,254 INFO] Weighted corpora loaded so far:
			* github: 716
[2022-05-05 23:44:03,649 INFO] Step 49350/100000; acc:  99.63; ppl:  1.01; xent: 0.01; lr: 0.00050; 52728/5167 tok/s;   8721 sec
[2022-05-05 23:44:12,151 INFO] Step 49400/100000; acc:  99.64; ppl:  1.01; xent: 0.01; lr: 0.00050; 54278/5333 tok/s;   8730 sec
[2022-05-05 23:44:13,521 INFO] Weighted corpora loaded so far:
			* github: 717
[2022-05-05 23:44:21,267 INFO] Step 49450/100000; acc:  99.57; ppl:  1.02; xent: 0.01; lr: 0.00050; 51629/5024 tok/s;   8739 sec
[2022-05-05 23:44:24,940 INFO] Weighted corpora loaded so far:
			* github: 718
[2022-05-05 23:44:29,990 INFO] Step 49500/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00050; 51300/5239 tok/s;   8748 sec
[2022-05-05 23:44:36,152 INFO] Weighted corpora loaded so far:
			* github: 719
[2022-05-05 23:44:38,785 INFO] Step 49550/100000; acc:  99.66; ppl:  1.01; xent: 0.01; lr: 0.00050; 51778/5235 tok/s;   8756 sec
[2022-05-05 23:44:47,487 INFO] Step 49600/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 53670/5338 tok/s;   8765 sec
[2022-05-05 23:44:47,503 INFO] Weighted corpora loaded so far:
			* github: 720
[2022-05-05 23:44:56,492 INFO] Step 49650/100000; acc:  99.66; ppl:  1.01; xent: 0.01; lr: 0.00050; 52661/5091 tok/s;   8774 sec
[2022-05-05 23:44:58,831 INFO] Weighted corpora loaded so far:
			* github: 721
[2022-05-05 23:45:05,335 INFO] Step 49700/100000; acc:  99.65; ppl:  1.01; xent: 0.01; lr: 0.00050; 51386/5161 tok/s;   8783 sec
[2022-05-05 23:45:10,109 INFO] Weighted corpora loaded so far:
			* github: 722
[2022-05-05 23:45:14,181 INFO] Step 49750/100000; acc:  99.65; ppl:  1.01; xent: 0.01; lr: 0.00050; 52275/5204 tok/s;   8792 sec
[2022-05-05 23:45:21,415 INFO] Weighted corpora loaded so far:
			* github: 723
[2022-05-05 23:45:23,128 INFO] Step 49800/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00050; 51828/5228 tok/s;   8801 sec
[2022-05-05 23:45:31,617 INFO] Step 49850/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00050; 53415/5361 tok/s;   8809 sec
[2022-05-05 23:45:32,686 INFO] Weighted corpora loaded so far:
			* github: 724
[2022-05-05 23:45:40,842 INFO] Step 49900/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00050; 51233/4963 tok/s;   8818 sec
[2022-05-05 23:45:44,564 INFO] Weighted corpora loaded so far:
			* github: 725
[2022-05-05 23:45:50,175 INFO] Step 49950/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00050; 47796/4983 tok/s;   8828 sec
[2022-05-05 23:45:56,036 INFO] Weighted corpora loaded so far:
			* github: 726
[2022-05-05 23:45:59,016 INFO] Step 50000/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 51814/5131 tok/s;   8837 sec
[2022-05-05 23:46:07,884 INFO] Step 50050/100000; acc:  99.61; ppl:  1.01; xent: 0.01; lr: 0.00045; 52362/5193 tok/s;   8845 sec
[2022-05-05 23:46:16,499 INFO] Step 50100/100000; acc:  99.66; ppl:  1.01; xent: 0.01; lr: 0.00045; 54923/5245 tok/s;   8854 sec
[2022-05-05 23:46:18,485 INFO] Weighted corpora loaded so far:
			* github: 727
[2022-05-05 23:46:25,304 INFO] Step 50150/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 51201/5248 tok/s;   8863 sec
[2022-05-05 23:46:29,817 INFO] Weighted corpora loaded so far:
			* github: 728
[2022-05-05 23:46:34,267 INFO] Step 50200/100000; acc:  99.66; ppl:  1.01; xent: 0.01; lr: 0.00045; 52140/5146 tok/s;   8872 sec
[2022-05-05 23:46:41,087 INFO] Weighted corpora loaded so far:
			* github: 729
[2022-05-05 23:46:43,129 INFO] Step 50250/100000; acc:  99.65; ppl:  1.01; xent: 0.01; lr: 0.00045; 52436/5179 tok/s;   8881 sec
[2022-05-05 23:46:51,671 INFO] Step 50300/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 54050/5353 tok/s;   8889 sec
[2022-05-05 23:46:52,361 INFO] Weighted corpora loaded so far:
			* github: 730
[2022-05-05 23:47:01,189 INFO] Step 50350/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 49862/4822 tok/s;   8899 sec
[2022-05-05 23:47:04,423 INFO] Weighted corpora loaded so far:
			* github: 731
[2022-05-05 23:47:10,142 INFO] Step 50400/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 49703/5158 tok/s;   8908 sec
[2022-05-05 23:47:15,652 INFO] Weighted corpora loaded so far:
			* github: 732
[2022-05-05 23:47:19,078 INFO] Step 50450/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 51122/5116 tok/s;   8917 sec
[2022-05-05 23:47:27,064 INFO] Weighted corpora loaded so far:
			* github: 733
[2022-05-05 23:47:28,125 INFO] Step 50500/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 51876/5087 tok/s;   8926 sec
[2022-05-05 23:47:36,819 INFO] Step 50550/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 53775/5316 tok/s;   8934 sec
[2022-05-05 23:47:38,476 INFO] Weighted corpora loaded so far:
			* github: 734
[2022-05-05 23:47:45,686 INFO] Step 50600/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52091/5181 tok/s;   8943 sec
[2022-05-05 23:47:49,755 INFO] Weighted corpora loaded so far:
			* github: 735
[2022-05-05 23:47:54,488 INFO] Step 50650/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 51630/5196 tok/s;   8952 sec
[2022-05-05 23:48:01,050 INFO] Weighted corpora loaded so far:
			* github: 736
[2022-05-05 23:48:03,389 INFO] Step 50700/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51229/5222 tok/s;   8961 sec
[2022-05-05 23:48:12,038 INFO] Step 50750/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 53965/5296 tok/s;   8970 sec
[2022-05-05 23:48:12,378 INFO] Weighted corpora loaded so far:
			* github: 737
[2022-05-05 23:48:20,956 INFO] Step 50800/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 52553/5099 tok/s;   8979 sec
[2022-05-05 23:48:23,603 INFO] Weighted corpora loaded so far:
			* github: 738
[2022-05-05 23:48:29,776 INFO] Step 50850/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 50700/5197 tok/s;   8987 sec
[2022-05-05 23:48:38,712 INFO] Step 50900/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 51340/5153 tok/s;   8996 sec
[2022-05-05 23:48:46,275 INFO] Weighted corpora loaded so far:
			* github: 739
[2022-05-05 23:48:47,691 INFO] Step 50950/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52142/5120 tok/s;   9005 sec
[2022-05-05 23:48:56,296 INFO] Step 51000/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 53744/5257 tok/s;   9014 sec
[2022-05-05 23:48:57,696 INFO] Weighted corpora loaded so far:
			* github: 740
[2022-05-05 23:49:05,253 INFO] Step 51050/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52413/5079 tok/s;   9023 sec
[2022-05-05 23:49:08,946 INFO] Weighted corpora loaded so far:
			* github: 741
[2022-05-05 23:49:14,045 INFO] Step 51100/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 51281/5253 tok/s;   9032 sec
[2022-05-05 23:49:20,267 INFO] Weighted corpora loaded so far:
			* github: 742
[2022-05-05 23:49:22,938 INFO] Step 51150/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 51839/5238 tok/s;   9041 sec
[2022-05-05 23:49:31,553 INFO] Step 51200/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 54549/5311 tok/s;   9049 sec
[2022-05-05 23:49:31,564 INFO] Weighted corpora loaded so far:
			* github: 743
[2022-05-05 23:49:40,442 INFO] Step 51250/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 52936/5120 tok/s;   9058 sec
[2022-05-05 23:49:42,757 INFO] Weighted corpora loaded so far:
			* github: 744
[2022-05-05 23:49:49,210 INFO] Step 51300/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 51485/5241 tok/s;   9067 sec
[2022-05-05 23:49:54,000 INFO] Weighted corpora loaded so far:
			* github: 745
[2022-05-05 23:49:58,096 INFO] Step 51350/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 51784/5223 tok/s;   9076 sec
[2022-05-05 23:50:05,291 INFO] Weighted corpora loaded so far:
			* github: 746
[2022-05-05 23:50:06,959 INFO] Step 51400/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 52276/5162 tok/s;   9085 sec
[2022-05-05 23:50:15,481 INFO] Step 51450/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 53781/5320 tok/s;   9093 sec
[2022-05-05 23:50:16,545 INFO] Weighted corpora loaded so far:
			* github: 747
[2022-05-05 23:50:24,494 INFO] Step 51500/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52883/5140 tok/s;   9102 sec
[2022-05-05 23:50:27,830 INFO] Weighted corpora loaded so far:
			* github: 748
[2022-05-05 23:50:33,267 INFO] Step 51550/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 50804/5231 tok/s;   9111 sec
[2022-05-05 23:50:39,178 INFO] Weighted corpora loaded so far:
			* github: 749
[2022-05-05 23:50:42,161 INFO] Step 51600/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 51260/5177 tok/s;   9120 sec
[2022-05-05 23:50:50,459 INFO] Weighted corpora loaded so far:
			* github: 750
[2022-05-05 23:50:51,109 INFO] Step 51650/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 51929/5242 tok/s;   9129 sec
[2022-05-05 23:50:59,752 INFO] Step 51700/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00045; 54439/5223 tok/s;   9137 sec
[2022-05-05 23:51:01,788 INFO] Weighted corpora loaded so far:
			* github: 751
[2022-05-05 23:51:08,631 INFO] Step 51750/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 50527/5127 tok/s;   9146 sec
[2022-05-05 23:51:17,555 INFO] Step 51800/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 52155/5143 tok/s;   9155 sec
[2022-05-05 23:51:24,422 INFO] Weighted corpora loaded so far:
			* github: 752
[2022-05-05 23:51:26,505 INFO] Step 51850/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 51754/5175 tok/s;   9164 sec
[2022-05-05 23:51:35,087 INFO] Step 51900/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 53746/5278 tok/s;   9173 sec
[2022-05-05 23:51:35,796 INFO] Weighted corpora loaded so far:
			* github: 753
[2022-05-05 23:51:44,160 INFO] Step 51950/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52294/5122 tok/s;   9182 sec
[2022-05-05 23:51:47,139 INFO] Weighted corpora loaded so far:
			* github: 754
[2022-05-05 23:51:52,947 INFO] Step 52000/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51196/5308 tok/s;   9191 sec
[2022-05-05 23:51:58,423 INFO] Weighted corpora loaded so far:
			* github: 755
[2022-05-05 23:52:01,778 INFO] Step 52050/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 52309/5088 tok/s;   9199 sec
[2022-05-05 23:52:09,648 INFO] Weighted corpora loaded so far:
			* github: 756
[2022-05-05 23:52:10,703 INFO] Step 52100/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52656/5160 tok/s;   9208 sec
[2022-05-05 23:52:19,256 INFO] Step 52150/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 54029/5319 tok/s;   9217 sec
[2022-05-05 23:52:20,966 INFO] Weighted corpora loaded so far:
			* github: 757
[2022-05-05 23:52:28,194 INFO] Step 52200/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51320/5168 tok/s;   9226 sec
[2022-05-05 23:52:32,236 INFO] Weighted corpora loaded so far:
			* github: 758
[2022-05-05 23:52:36,986 INFO] Step 52250/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 51699/5229 tok/s;   9235 sec
[2022-05-05 23:52:43,529 INFO] Weighted corpora loaded so far:
			* github: 759
[2022-05-05 23:52:45,878 INFO] Step 52300/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 51599/5176 tok/s;   9243 sec
[2022-05-05 23:52:54,477 INFO] Step 52350/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 54508/5264 tok/s;   9252 sec
[2022-05-05 23:52:54,823 INFO] Weighted corpora loaded so far:
			* github: 760
[2022-05-05 23:53:03,484 INFO] Step 52400/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00045; 52447/5101 tok/s;   9261 sec
[2022-05-05 23:53:06,151 INFO] Weighted corpora loaded so far:
			* github: 761
[2022-05-05 23:53:12,234 INFO] Step 52450/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51192/5347 tok/s;   9270 sec
[2022-05-05 23:53:17,353 INFO] Weighted corpora loaded so far:
			* github: 762
[2022-05-05 23:53:21,052 INFO] Step 52500/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 51872/5198 tok/s;   9279 sec
[2022-05-05 23:53:28,590 INFO] Weighted corpora loaded so far:
			* github: 763
[2022-05-05 23:53:29,971 INFO] Step 52550/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00045; 52244/5238 tok/s;   9288 sec
[2022-05-05 23:53:38,441 INFO] Step 52600/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 54174/5273 tok/s;   9296 sec
[2022-05-05 23:53:39,877 INFO] Weighted corpora loaded so far:
			* github: 764
[2022-05-05 23:53:47,395 INFO] Step 52650/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 52148/5154 tok/s;   9305 sec
[2022-05-05 23:53:56,138 INFO] Step 52700/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 51381/5300 tok/s;   9314 sec
[2022-05-05 23:54:02,296 INFO] Weighted corpora loaded so far:
			* github: 765
[2022-05-05 23:54:04,953 INFO] Step 52750/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52180/5107 tok/s;   9323 sec
[2022-05-05 23:54:13,565 INFO] Step 52800/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 54439/5375 tok/s;   9331 sec
[2022-05-05 23:54:13,570 INFO] Weighted corpora loaded so far:
			* github: 766
[2022-05-05 23:54:22,564 INFO] Step 52850/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 52617/5082 tok/s;   9340 sec
[2022-05-05 23:54:24,898 INFO] Weighted corpora loaded so far:
			* github: 767
[2022-05-05 23:54:31,464 INFO] Step 52900/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 51222/5201 tok/s;   9349 sec
[2022-05-05 23:54:36,232 INFO] Weighted corpora loaded so far:
			* github: 768
[2022-05-05 23:54:40,326 INFO] Step 52950/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00045; 52361/5089 tok/s;   9358 sec
[2022-05-05 23:54:47,552 INFO] Weighted corpora loaded so far:
			* github: 769
[2022-05-05 23:54:49,281 INFO] Step 53000/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 51835/5217 tok/s;   9367 sec
[2022-05-05 23:54:58,300 INFO] Step 53050/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 50030/5054 tok/s;   9376 sec
[2022-05-05 23:54:59,465 INFO] Weighted corpora loaded so far:
			* github: 770
[2022-05-05 23:55:07,704 INFO] Step 53100/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 50394/4865 tok/s;   9385 sec
[2022-05-05 23:55:11,336 INFO] Weighted corpora loaded so far:
			* github: 771
[2022-05-05 23:55:16,765 INFO] Step 53150/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 49537/5012 tok/s;   9394 sec
[2022-05-05 23:55:22,645 INFO] Weighted corpora loaded so far:
			* github: 772
[2022-05-05 23:55:25,657 INFO] Step 53200/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 51897/5268 tok/s;   9403 sec
[2022-05-05 23:55:33,949 INFO] Weighted corpora loaded so far:
			* github: 773
[2022-05-05 23:55:34,615 INFO] Step 53250/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 52104/5170 tok/s;   9412 sec
[2022-05-05 23:55:43,283 INFO] Step 53300/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 54248/5277 tok/s;   9421 sec
[2022-05-05 23:55:45,280 INFO] Weighted corpora loaded so far:
			* github: 774
[2022-05-05 23:55:52,064 INFO] Step 53350/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 51045/5212 tok/s;   9430 sec
[2022-05-05 23:55:56,547 INFO] Weighted corpora loaded so far:
			* github: 775
[2022-05-05 23:56:00,984 INFO] Step 53400/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 51998/5142 tok/s;   9439 sec
[2022-05-05 23:56:07,845 INFO] Weighted corpora loaded so far:
			* github: 776
[2022-05-05 23:56:09,884 INFO] Step 53450/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 51712/5233 tok/s;   9447 sec
[2022-05-05 23:56:18,466 INFO] Step 53500/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 53464/5297 tok/s;   9456 sec
[2022-05-05 23:56:27,420 INFO] Step 53550/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 52747/5126 tok/s;   9465 sec
[2022-05-05 23:56:30,381 INFO] Weighted corpora loaded so far:
			* github: 777
[2022-05-05 23:56:36,207 INFO] Step 53600/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 51098/5214 tok/s;   9474 sec
[2022-05-05 23:56:41,702 INFO] Weighted corpora loaded so far:
			* github: 778
[2022-05-05 23:56:45,086 INFO] Step 53650/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 52011/5084 tok/s;   9483 sec
[2022-05-05 23:56:53,055 INFO] Weighted corpora loaded so far:
			* github: 779
[2022-05-05 23:56:54,071 INFO] Step 53700/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 52323/5211 tok/s;   9492 sec
[2022-05-05 23:57:02,646 INFO] Step 53750/100000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00045; 54420/5300 tok/s;   9500 sec
[2022-05-05 23:57:04,301 INFO] Weighted corpora loaded so far:
			* github: 780
[2022-05-05 23:57:11,516 INFO] Step 53800/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 52025/5184 tok/s;   9509 sec
[2022-05-05 23:57:15,582 INFO] Weighted corpora loaded so far:
			* github: 781
[2022-05-05 23:57:20,321 INFO] Step 53850/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 51756/5165 tok/s;   9518 sec
[2022-05-05 23:57:26,877 INFO] Weighted corpora loaded so far:
			* github: 782
[2022-05-05 23:57:29,185 INFO] Step 53900/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51664/5259 tok/s;   9527 sec
[2022-05-05 23:57:37,715 INFO] Step 53950/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 54569/5345 tok/s;   9535 sec
[2022-05-05 23:57:38,046 INFO] Weighted corpora loaded so far:
			* github: 783
[2022-05-05 23:57:46,616 INFO] Step 54000/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 52712/5151 tok/s;   9544 sec
[2022-05-05 23:57:49,269 INFO] Weighted corpora loaded so far:
			* github: 784
[2022-05-05 23:57:55,385 INFO] Step 54050/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51358/5146 tok/s;   9553 sec
[2022-05-05 23:58:00,606 INFO] Weighted corpora loaded so far:
			* github: 785
[2022-05-05 23:58:04,262 INFO] Step 54100/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 52097/5264 tok/s;   9562 sec
[2022-05-05 23:58:11,830 INFO] Weighted corpora loaded so far:
			* github: 786
[2022-05-05 23:58:13,194 INFO] Step 54150/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52679/5171 tok/s;   9571 sec
[2022-05-05 23:58:21,717 INFO] Step 54200/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 53624/5434 tok/s;   9579 sec
[2022-05-05 23:58:23,084 INFO] Weighted corpora loaded so far:
			* github: 787
[2022-05-05 23:58:30,974 INFO] Step 54250/100000; acc:  99.67; ppl:  1.01; xent: 0.01; lr: 0.00045; 50387/4905 tok/s;   9589 sec
[2022-05-05 23:58:34,660 INFO] Weighted corpora loaded so far:
			* github: 788
[2022-05-05 23:58:39,722 INFO] Step 54300/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 51091/5246 tok/s;   9597 sec
[2022-05-05 23:58:45,960 INFO] Weighted corpora loaded so far:
			* github: 789
[2022-05-05 23:58:48,598 INFO] Step 54350/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51448/5223 tok/s;   9606 sec
[2022-05-05 23:58:57,175 INFO] Step 54400/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 54369/5315 tok/s;   9615 sec
[2022-05-05 23:59:06,233 INFO] Step 54450/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52079/5082 tok/s;   9624 sec
[2022-05-05 23:59:08,518 INFO] Weighted corpora loaded so far:
			* github: 790
[2022-05-05 23:59:14,984 INFO] Step 54500/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 52009/5244 tok/s;   9633 sec
[2022-05-05 23:59:19,738 INFO] Weighted corpora loaded so far:
			* github: 791
[2022-05-05 23:59:23,820 INFO] Step 54550/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 52430/5094 tok/s;   9641 sec
[2022-05-05 23:59:31,101 INFO] Weighted corpora loaded so far:
			* github: 792
[2022-05-05 23:59:32,993 INFO] Step 54600/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 50625/5113 tok/s;   9651 sec
[2022-05-05 23:59:41,551 INFO] Step 54650/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 53662/5367 tok/s;   9659 sec
[2022-05-05 23:59:42,600 INFO] Weighted corpora loaded so far:
			* github: 793
[2022-05-05 23:59:50,550 INFO] Step 54700/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 53046/5109 tok/s;   9668 sec
[2022-05-05 23:59:53,874 INFO] Weighted corpora loaded so far:
			* github: 794
[2022-05-05 23:59:59,317 INFO] Step 54750/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 51044/5255 tok/s;   9677 sec
[2022-05-06 00:00:05,101 INFO] Weighted corpora loaded so far:
			* github: 795
[2022-05-06 00:00:08,103 INFO] Step 54800/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52048/5093 tok/s;   9686 sec
[2022-05-06 00:00:16,354 INFO] Weighted corpora loaded so far:
			* github: 796
[2022-05-06 00:00:17,005 INFO] Step 54850/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51982/5235 tok/s;   9695 sec
[2022-05-06 00:00:25,588 INFO] Step 54900/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 54791/5354 tok/s;   9703 sec
[2022-05-06 00:00:27,572 INFO] Weighted corpora loaded so far:
			* github: 797
[2022-05-06 00:00:34,343 INFO] Step 54950/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51603/5096 tok/s;   9712 sec
[2022-05-06 00:00:38,801 INFO] Weighted corpora loaded so far:
			* github: 798
[2022-05-06 00:00:43,221 INFO] Step 55000/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 52707/5307 tok/s;   9721 sec
[2022-05-06 00:00:50,043 INFO] Weighted corpora loaded so far:
			* github: 799
[2022-05-06 00:00:52,077 INFO] Step 55050/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 52245/5217 tok/s;   9730 sec
[2022-05-06 00:01:00,546 INFO] Step 55100/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 53872/5423 tok/s;   9738 sec
[2022-05-06 00:01:01,238 INFO] Weighted corpora loaded so far:
			* github: 800
[2022-05-06 00:01:09,827 INFO] Step 55150/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 50803/5007 tok/s;   9747 sec
[2022-05-06 00:01:12,906 INFO] Weighted corpora loaded so far:
			* github: 801
[2022-05-06 00:01:18,633 INFO] Step 55200/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 50694/5141 tok/s;   9756 sec
[2022-05-06 00:01:24,124 INFO] Weighted corpora loaded so far:
			* github: 802
[2022-05-06 00:01:27,435 INFO] Step 55250/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52090/5166 tok/s;   9765 sec
[2022-05-06 00:01:36,676 INFO] Step 55300/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 50614/5001 tok/s;   9774 sec
[2022-05-06 00:01:45,838 INFO] Step 55350/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 50930/4964 tok/s;   9783 sec
[2022-05-06 00:01:47,476 INFO] Weighted corpora loaded so far:
			* github: 803
[2022-05-06 00:01:54,700 INFO] Step 55400/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52076/5194 tok/s;   9792 sec
[2022-05-06 00:01:58,745 INFO] Weighted corpora loaded so far:
			* github: 804
[2022-05-06 00:02:03,479 INFO] Step 55450/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 51929/5246 tok/s;   9801 sec
[2022-05-06 00:02:09,876 INFO] Weighted corpora loaded so far:
			* github: 805
[2022-05-06 00:02:12,172 INFO] Step 55500/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52868/5300 tok/s;   9810 sec
[2022-05-06 00:02:20,656 INFO] Step 55550/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 55653/5388 tok/s;   9818 sec
[2022-05-06 00:02:20,992 INFO] Weighted corpora loaded so far:
			* github: 806
[2022-05-06 00:02:29,492 INFO] Step 55600/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 53219/5218 tok/s;   9827 sec
[2022-05-06 00:02:32,131 INFO] Weighted corpora loaded so far:
			* github: 807
[2022-05-06 00:02:38,216 INFO] Step 55650/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 51309/5162 tok/s;   9836 sec
[2022-05-06 00:02:43,372 INFO] Weighted corpora loaded so far:
			* github: 808
[2022-05-06 00:02:47,039 INFO] Step 55700/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 51901/5198 tok/s;   9845 sec
[2022-05-06 00:02:54,553 INFO] Weighted corpora loaded so far:
			* github: 809
[2022-05-06 00:02:55,928 INFO] Step 55750/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52557/5273 tok/s;   9854 sec
[2022-05-06 00:03:04,442 INFO] Step 55800/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 54152/5344 tok/s;   9862 sec
[2022-05-06 00:03:05,800 INFO] Weighted corpora loaded so far:
			* github: 810
[2022-05-06 00:03:13,345 INFO] Step 55850/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 52774/5092 tok/s;   9871 sec
[2022-05-06 00:03:17,306 INFO] Weighted corpora loaded so far:
			* github: 811
[2022-05-06 00:03:22,321 INFO] Step 55900/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 50089/5142 tok/s;   9880 sec
[2022-05-06 00:03:28,582 INFO] Weighted corpora loaded so far:
			* github: 812
[2022-05-06 00:03:31,246 INFO] Step 55950/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 51342/5289 tok/s;   9889 sec
[2022-05-06 00:03:39,843 INFO] Step 56000/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 54245/5301 tok/s;   9897 sec
[2022-05-06 00:03:39,869 INFO] Weighted corpora loaded so far:
			* github: 813
[2022-05-06 00:03:48,828 INFO] Step 56050/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52141/5083 tok/s;   9906 sec
[2022-05-06 00:03:51,164 INFO] Weighted corpora loaded so far:
			* github: 814
[2022-05-06 00:03:57,641 INFO] Step 56100/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 51335/5178 tok/s;   9915 sec
[2022-05-06 00:04:02,519 INFO] Weighted corpora loaded so far:
			* github: 815
[2022-05-06 00:04:06,544 INFO] Step 56150/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 51794/5229 tok/s;   9924 sec
[2022-05-06 00:04:15,408 INFO] Step 56200/100000; acc:  99.68; ppl:  1.01; xent: 0.01; lr: 0.00045; 52226/5106 tok/s;   9933 sec
[2022-05-06 00:04:23,898 INFO] Step 56250/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 53953/5398 tok/s;   9941 sec
[2022-05-06 00:04:24,935 INFO] Weighted corpora loaded so far:
			* github: 816
[2022-05-06 00:04:32,859 INFO] Step 56300/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52981/5164 tok/s;   9950 sec
[2022-05-06 00:04:36,159 INFO] Weighted corpora loaded so far:
			* github: 817
[2022-05-06 00:04:41,600 INFO] Step 56350/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 51351/5237 tok/s;   9959 sec
[2022-05-06 00:04:47,465 INFO] Weighted corpora loaded so far:
			* github: 818
[2022-05-06 00:04:50,467 INFO] Step 56400/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 52034/5140 tok/s;   9968 sec
[2022-05-06 00:04:58,719 INFO] Weighted corpora loaded so far:
			* github: 819
[2022-05-06 00:04:59,403 INFO] Step 56450/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 52275/5223 tok/s;   9977 sec
[2022-05-06 00:05:08,016 INFO] Step 56500/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 54869/5303 tok/s;   9986 sec
[2022-05-06 00:05:09,989 INFO] Weighted corpora loaded so far:
			* github: 820
[2022-05-06 00:05:16,738 INFO] Step 56550/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51377/5314 tok/s;   9994 sec
[2022-05-06 00:05:21,204 INFO] Weighted corpora loaded so far:
			* github: 821
[2022-05-06 00:05:25,613 INFO] Step 56600/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52235/5061 tok/s;  10003 sec
[2022-05-06 00:05:32,395 INFO] Weighted corpora loaded so far:
			* github: 822
[2022-05-06 00:05:34,424 INFO] Step 56650/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00045; 52377/5197 tok/s;  10012 sec
[2022-05-06 00:05:42,982 INFO] Step 56700/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 54123/5428 tok/s;  10021 sec
[2022-05-06 00:05:43,678 INFO] Weighted corpora loaded so far:
			* github: 823
[2022-05-06 00:05:51,990 INFO] Step 56750/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52710/5222 tok/s;  10030 sec
[2022-05-06 00:05:54,977 INFO] Weighted corpora loaded so far:
			* github: 824
[2022-05-06 00:06:00,760 INFO] Step 56800/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 50943/5126 tok/s;  10038 sec
[2022-05-06 00:06:06,316 INFO] Weighted corpora loaded so far:
			* github: 825
[2022-05-06 00:06:09,716 INFO] Step 56850/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 51124/5159 tok/s;  10047 sec
[2022-05-06 00:06:18,002 INFO] Weighted corpora loaded so far:
			* github: 826
[2022-05-06 00:06:19,037 INFO] Step 56900/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 50200/4927 tok/s;  10057 sec
[2022-05-06 00:06:27,682 INFO] Step 56950/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 53585/5238 tok/s;  10065 sec
[2022-05-06 00:06:29,354 INFO] Weighted corpora loaded so far:
			* github: 827
[2022-05-06 00:06:36,557 INFO] Step 57000/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51528/5199 tok/s;  10074 sec
[2022-05-06 00:06:45,346 INFO] Step 57050/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 51551/5238 tok/s;  10083 sec
[2022-05-06 00:06:51,845 INFO] Weighted corpora loaded so far:
			* github: 828
[2022-05-06 00:06:54,205 INFO] Step 57100/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51768/5187 tok/s;  10092 sec
[2022-05-06 00:07:02,814 INFO] Step 57150/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 54895/5281 tok/s;  10100 sec
[2022-05-06 00:07:03,145 INFO] Weighted corpora loaded so far:
			* github: 829
[2022-05-06 00:07:11,793 INFO] Step 57200/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 52444/5129 tok/s;  10109 sec
[2022-05-06 00:07:14,453 INFO] Weighted corpora loaded so far:
			* github: 830
[2022-05-06 00:07:20,602 INFO] Step 57250/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 51219/5255 tok/s;  10118 sec
[2022-05-06 00:07:25,786 INFO] Weighted corpora loaded so far:
			* github: 831
[2022-05-06 00:07:29,511 INFO] Step 57300/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51872/5071 tok/s;  10127 sec
[2022-05-06 00:07:37,080 INFO] Weighted corpora loaded so far:
			* github: 832
[2022-05-06 00:07:38,499 INFO] Step 57350/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52239/5261 tok/s;  10136 sec
[2022-05-06 00:07:46,991 INFO] Step 57400/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 53914/5235 tok/s;  10145 sec
[2022-05-06 00:07:48,373 INFO] Weighted corpora loaded so far:
			* github: 833
[2022-05-06 00:07:56,028 INFO] Step 57450/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51712/5070 tok/s;  10154 sec
[2022-05-06 00:07:59,713 INFO] Weighted corpora loaded so far:
			* github: 834
[2022-05-06 00:08:05,050 INFO] Step 57500/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 49546/5132 tok/s;  10163 sec
[2022-05-06 00:08:11,280 INFO] Weighted corpora loaded so far:
			* github: 835
[2022-05-06 00:08:13,950 INFO] Step 57550/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 51502/5176 tok/s;  10172 sec
[2022-05-06 00:08:22,597 INFO] Step 57600/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 54662/5284 tok/s;  10180 sec
[2022-05-06 00:08:22,621 INFO] Weighted corpora loaded so far:
			* github: 836
[2022-05-06 00:08:31,596 INFO] Step 57650/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 52495/5093 tok/s;  10189 sec
[2022-05-06 00:08:33,929 INFO] Weighted corpora loaded so far:
			* github: 837
[2022-05-06 00:08:40,409 INFO] Step 57700/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 51146/5278 tok/s;  10198 sec
[2022-05-06 00:08:45,230 INFO] Weighted corpora loaded so far:
			* github: 838
[2022-05-06 00:08:49,299 INFO] Step 57750/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00045; 51589/5140 tok/s;  10207 sec
[2022-05-06 00:08:56,498 INFO] Weighted corpora loaded so far:
			* github: 839
[2022-05-06 00:08:58,219 INFO] Step 57800/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 51763/5231 tok/s;  10216 sec
[2022-05-06 00:09:06,687 INFO] Step 57850/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 53854/5361 tok/s;  10224 sec
[2022-05-06 00:09:07,751 INFO] Weighted corpora loaded so far:
			* github: 840
[2022-05-06 00:09:15,669 INFO] Step 57900/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 52718/5052 tok/s;  10233 sec
[2022-05-06 00:09:24,337 INFO] Step 57950/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 51605/5321 tok/s;  10242 sec
[2022-05-06 00:09:30,119 INFO] Weighted corpora loaded so far:
			* github: 841
[2022-05-06 00:09:33,133 INFO] Step 58000/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 52280/5234 tok/s;  10251 sec
[2022-05-06 00:09:41,387 INFO] Weighted corpora loaded so far:
			* github: 842
[2022-05-06 00:09:42,065 INFO] Step 58050/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00045; 52292/5146 tok/s;  10260 sec
[2022-05-06 00:09:50,784 INFO] Step 58100/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00045; 54128/5221 tok/s;  10268 sec
[2022-05-06 00:09:52,972 INFO] Weighted corpora loaded so far:
			* github: 843
[2022-05-06 00:09:59,778 INFO] Step 58150/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 50423/5158 tok/s;  10277 sec
[2022-05-06 00:10:04,230 INFO] Weighted corpora loaded so far:
			* github: 844
[2022-05-06 00:10:08,649 INFO] Step 58200/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 52757/5093 tok/s;  10286 sec
[2022-05-06 00:10:15,514 INFO] Weighted corpora loaded so far:
			* github: 845
[2022-05-06 00:10:17,576 INFO] Step 58250/100000; acc:  99.69; ppl:  1.01; xent: 0.01; lr: 0.00045; 51744/5229 tok/s;  10295 sec
[2022-05-06 00:10:26,169 INFO] Step 58300/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 53400/5304 tok/s;  10304 sec
[2022-05-06 00:10:26,852 INFO] Weighted corpora loaded so far:
			* github: 846
[2022-05-06 00:10:35,104 INFO] Step 58350/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 52687/5138 tok/s;  10313 sec
[2022-05-06 00:10:38,075 INFO] Weighted corpora loaded so far:
			* github: 847
[2022-05-06 00:10:43,865 INFO] Step 58400/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 50988/5287 tok/s;  10321 sec
[2022-05-06 00:10:49,641 INFO] Weighted corpora loaded so far:
			* github: 848
[2022-05-06 00:10:53,051 INFO] Step 58450/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 50119/4982 tok/s;  10331 sec
[2022-05-06 00:11:00,991 INFO] Weighted corpora loaded so far:
			* github: 849
[2022-05-06 00:11:02,042 INFO] Step 58500/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52388/5109 tok/s;  10340 sec
[2022-05-06 00:11:11,031 INFO] Step 58550/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 51941/5006 tok/s;  10349 sec
[2022-05-06 00:11:12,721 INFO] Weighted corpora loaded so far:
			* github: 850
[2022-05-06 00:11:19,875 INFO] Step 58600/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00045; 51721/5258 tok/s;  10357 sec
[2022-05-06 00:11:23,853 INFO] Weighted corpora loaded so far:
			* github: 851
[2022-05-06 00:11:28,509 INFO] Step 58650/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00045; 52286/5371 tok/s;  10366 sec
[2022-05-06 00:11:34,911 INFO] Weighted corpora loaded so far:
			* github: 852
[2022-05-06 00:11:37,181 INFO] Step 58700/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52601/5333 tok/s;  10375 sec
[2022-05-06 00:11:45,623 INFO] Step 58750/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 55549/5381 tok/s;  10383 sec
[2022-05-06 00:11:45,968 INFO] Weighted corpora loaded so far:
			* github: 853
[2022-05-06 00:11:54,509 INFO] Step 58800/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 52599/5160 tok/s;  10392 sec
[2022-05-06 00:12:03,240 INFO] Step 58850/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00045; 51610/5245 tok/s;  10401 sec
[2022-05-06 00:12:08,364 INFO] Weighted corpora loaded so far:
			* github: 854
[2022-05-06 00:12:12,372 INFO] Step 58900/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 50582/4988 tok/s;  10410 sec
[2022-05-06 00:12:19,934 INFO] Weighted corpora loaded so far:
			* github: 855
[2022-05-06 00:12:21,319 INFO] Step 58950/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52358/5183 tok/s;  10419 sec
[2022-05-06 00:12:30,102 INFO] Step 59000/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00045; 52488/5219 tok/s;  10428 sec
[2022-05-06 00:12:31,588 INFO] Weighted corpora loaded so far:
			* github: 856
[2022-05-06 00:12:39,332 INFO] Step 59050/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00045; 51109/4916 tok/s;  10437 sec
[2022-05-06 00:12:43,020 INFO] Weighted corpora loaded so far:
			* github: 857
[2022-05-06 00:12:48,073 INFO] Step 59100/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 51549/5236 tok/s;  10446 sec
[2022-05-06 00:12:54,136 INFO] Weighted corpora loaded so far:
			* github: 858
[2022-05-06 00:12:56,726 INFO] Step 59150/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52938/5351 tok/s;  10454 sec
[2022-05-06 00:13:05,127 INFO] Step 59200/100000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00045; 55433/5501 tok/s;  10463 sec
[2022-05-06 00:13:05,142 INFO] Weighted corpora loaded so far:
			* github: 859
[2022-05-06 00:13:14,001 INFO] Step 59250/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 52926/5146 tok/s;  10472 sec
[2022-05-06 00:13:16,297 INFO] Weighted corpora loaded so far:
			* github: 860
[2022-05-06 00:13:22,743 INFO] Step 59300/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 52020/5198 tok/s;  10480 sec
[2022-05-06 00:13:27,879 INFO] Weighted corpora loaded so far:
			* github: 861
[2022-05-06 00:13:32,065 INFO] Step 59350/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 49724/5013 tok/s;  10490 sec
[2022-05-06 00:13:39,238 INFO] Weighted corpora loaded so far:
			* github: 862
[2022-05-06 00:13:40,954 INFO] Step 59400/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52237/5192 tok/s;  10499 sec
[2022-05-06 00:13:49,389 INFO] Step 59450/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00045; 54110/5390 tok/s;  10507 sec
[2022-05-06 00:13:50,452 INFO] Weighted corpora loaded so far:
			* github: 863
[2022-05-06 00:13:58,340 INFO] Step 59500/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 52707/5173 tok/s;  10516 sec
[2022-05-06 00:14:01,651 INFO] Weighted corpora loaded so far:
			* github: 864
[2022-05-06 00:14:07,069 INFO] Step 59550/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 50975/5245 tok/s;  10525 sec
[2022-05-06 00:14:12,920 INFO] Weighted corpora loaded so far:
			* github: 865
[2022-05-06 00:14:15,917 INFO] Step 59600/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00045; 51714/5261 tok/s;  10534 sec
[2022-05-06 00:14:24,770 INFO] Step 59650/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 52608/5144 tok/s;  10542 sec
[2022-05-06 00:14:33,338 INFO] Step 59700/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00045; 54757/5307 tok/s;  10551 sec
[2022-05-06 00:14:35,302 INFO] Weighted corpora loaded so far:
			* github: 866
[2022-05-06 00:14:42,119 INFO] Step 59750/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 51535/5270 tok/s;  10560 sec
[2022-05-06 00:14:46,563 INFO] Weighted corpora loaded so far:
			* github: 867
[2022-05-06 00:14:51,003 INFO] Step 59800/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52609/5064 tok/s;  10569 sec
[2022-05-06 00:14:57,817 INFO] Weighted corpora loaded so far:
			* github: 868
[2022-05-06 00:14:59,867 INFO] Step 59850/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00045; 52153/5234 tok/s;  10577 sec
[2022-05-06 00:15:08,421 INFO] Step 59900/100000; acc:  99.72; ppl:  1.01; xent: 0.01; lr: 0.00045; 54138/5370 tok/s;  10586 sec
[2022-05-06 00:15:09,108 INFO] Weighted corpora loaded so far:
			* github: 869
[2022-05-06 00:15:17,405 INFO] Step 59950/100000; acc:  99.70; ppl:  1.01; xent: 0.01; lr: 0.00045; 52755/5142 tok/s;  10595 sec
[2022-05-06 00:15:20,385 INFO] Weighted corpora loaded so far:
			* github: 870
[2022-05-06 00:15:26,186 INFO] Step 60000/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 51092/5165 tok/s;  10604 sec
[2022-05-06 00:15:27,896 INFO] Validation perplexity: 388.925
[2022-05-06 00:15:27,896 INFO] Validation accuracy: 50.0729
[2022-05-06 00:15:27,896 INFO] Decreasing patience: 1/2
[2022-05-06 00:15:27,985 INFO] Saving checkpoint /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/model_step_60000.pt
[2022-05-06 00:15:33,605 INFO] Weighted corpora loaded so far:
			* github: 871
[2022-05-06 00:15:36,965 INFO] Step 60050/100000; acc:  99.71; ppl:  1.01; xent: 0.01; lr: 0.00041; 42663/4310 tok/s;  10615 sec
[2022-05-06 00:15:44,837 INFO] Weighted corpora loaded so far:
			* github: 872
[2022-05-06 00:15:45,872 INFO] Step 60100/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00041; 52430/5112 tok/s;  10623 sec
[2022-05-06 00:15:54,464 INFO] Step 60150/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00041; 53906/5396 tok/s;  10632 sec
[2022-05-06 00:15:56,114 INFO] Weighted corpora loaded so far:
			* github: 873
[2022-05-06 00:16:03,353 INFO] Step 60200/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51867/5085 tok/s;  10641 sec
[2022-05-06 00:16:07,442 INFO] Weighted corpora loaded so far:
			* github: 874
[2022-05-06 00:16:12,211 INFO] Step 60250/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51533/5279 tok/s;  10650 sec
[2022-05-06 00:16:18,789 INFO] Weighted corpora loaded so far:
			* github: 875
[2022-05-06 00:16:21,115 INFO] Step 60300/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51602/5163 tok/s;  10659 sec
[2022-05-06 00:16:29,763 INFO] Step 60350/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 53984/5286 tok/s;  10667 sec
[2022-05-06 00:16:30,114 INFO] Weighted corpora loaded so far:
			* github: 876
[2022-05-06 00:16:38,823 INFO] Step 60400/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51619/5020 tok/s;  10676 sec
[2022-05-06 00:16:41,503 INFO] Weighted corpora loaded so far:
			* github: 877
[2022-05-06 00:16:47,604 INFO] Step 60450/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51069/5273 tok/s;  10685 sec
[2022-05-06 00:16:52,792 INFO] Weighted corpora loaded so far:
			* github: 878
[2022-05-06 00:16:56,445 INFO] Step 60500/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51906/5198 tok/s;  10694 sec
[2022-05-06 00:17:05,314 INFO] Step 60550/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52515/5209 tok/s;  10703 sec
[2022-05-06 00:17:13,864 INFO] Step 60600/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 53615/5280 tok/s;  10711 sec
[2022-05-06 00:17:15,219 INFO] Weighted corpora loaded so far:
			* github: 879
[2022-05-06 00:17:22,874 INFO] Step 60650/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52345/5127 tok/s;  10720 sec
[2022-05-06 00:17:26,544 INFO] Weighted corpora loaded so far:
			* github: 880
[2022-05-06 00:17:31,633 INFO] Step 60700/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51444/5239 tok/s;  10729 sec
[2022-05-06 00:17:37,810 INFO] Weighted corpora loaded so far:
			* github: 881
[2022-05-06 00:17:40,478 INFO] Step 60750/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51944/5217 tok/s;  10738 sec
[2022-05-06 00:17:49,067 INFO] Step 60800/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 54953/5346 tok/s;  10747 sec
[2022-05-06 00:17:49,076 INFO] Weighted corpora loaded so far:
			* github: 882
[2022-05-06 00:17:58,030 INFO] Step 60850/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52739/5123 tok/s;  10756 sec
[2022-05-06 00:18:00,391 INFO] Weighted corpora loaded so far:
			* github: 883
[2022-05-06 00:18:06,857 INFO] Step 60900/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00041; 51289/5221 tok/s;  10764 sec
[2022-05-06 00:18:11,579 INFO] Weighted corpora loaded so far:
			* github: 884
[2022-05-06 00:18:15,654 INFO] Step 60950/100000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00041; 52330/5160 tok/s;  10773 sec
[2022-05-06 00:18:22,813 INFO] Weighted corpora loaded so far:
			* github: 885
[2022-05-06 00:18:24,541 INFO] Step 61000/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51975/5230 tok/s;  10782 sec
[2022-05-06 00:18:33,003 INFO] Step 61050/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 53669/5339 tok/s;  10791 sec
[2022-05-06 00:18:34,056 INFO] Weighted corpora loaded so far:
			* github: 886
[2022-05-06 00:18:42,073 INFO] Step 61100/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52567/4994 tok/s;  10800 sec
[2022-05-06 00:18:45,414 INFO] Weighted corpora loaded so far:
			* github: 887
[2022-05-06 00:18:50,868 INFO] Step 61150/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51079/5320 tok/s;  10808 sec
[2022-05-06 00:18:56,741 INFO] Weighted corpora loaded so far:
			* github: 888
[2022-05-06 00:18:59,758 INFO] Step 61200/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51630/5135 tok/s;  10817 sec
[2022-05-06 00:19:08,051 INFO] Weighted corpora loaded so far:
			* github: 889
[2022-05-06 00:19:08,712 INFO] Step 61250/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 51588/5249 tok/s;  10826 sec
[2022-05-06 00:19:17,644 INFO] Step 61300/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 52620/5107 tok/s;  10835 sec
[2022-05-06 00:19:19,648 INFO] Weighted corpora loaded so far:
			* github: 890
[2022-05-06 00:19:26,417 INFO] Step 61350/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51365/5219 tok/s;  10844 sec
[2022-05-06 00:19:30,889 INFO] Weighted corpora loaded so far:
			* github: 891
[2022-05-06 00:19:35,295 INFO] Step 61400/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 52280/5122 tok/s;  10853 sec
[2022-05-06 00:19:44,146 INFO] Step 61450/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51857/5237 tok/s;  10862 sec
[2022-05-06 00:19:52,740 INFO] Step 61500/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 53814/5237 tok/s;  10870 sec
[2022-05-06 00:19:53,419 INFO] Weighted corpora loaded so far:
			* github: 892
[2022-05-06 00:20:01,755 INFO] Step 61550/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52669/5180 tok/s;  10879 sec
[2022-05-06 00:20:04,729 INFO] Weighted corpora loaded so far:
			* github: 893
[2022-05-06 00:20:10,514 INFO] Step 61600/100000; acc:  99.75; ppl:  1.01; xent: 0.01; lr: 0.00041; 51223/5215 tok/s;  10888 sec
[2022-05-06 00:20:16,031 INFO] Weighted corpora loaded so far:
			* github: 894
[2022-05-06 00:20:19,414 INFO] Step 61650/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51863/5177 tok/s;  10897 sec
[2022-05-06 00:20:27,382 INFO] Weighted corpora loaded so far:
			* github: 895
[2022-05-06 00:20:28,436 INFO] Step 61700/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52396/5109 tok/s;  10906 sec
[2022-05-06 00:20:36,991 INFO] Step 61750/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 54373/5306 tok/s;  10915 sec
[2022-05-06 00:20:38,640 INFO] Weighted corpora loaded so far:
			* github: 896
[2022-05-06 00:20:45,823 INFO] Step 61800/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 51902/5153 tok/s;  10923 sec
[2022-05-06 00:20:49,884 INFO] Weighted corpora loaded so far:
			* github: 897
[2022-05-06 00:20:54,614 INFO] Step 61850/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51429/5187 tok/s;  10932 sec
[2022-05-06 00:21:01,187 INFO] Weighted corpora loaded so far:
			* github: 898
[2022-05-06 00:21:03,528 INFO] Step 61900/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51246/5327 tok/s;  10941 sec
[2022-05-06 00:21:12,098 INFO] Step 61950/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 54988/5282 tok/s;  10950 sec
[2022-05-06 00:21:12,426 INFO] Weighted corpora loaded so far:
			* github: 899
[2022-05-06 00:21:20,942 INFO] Step 62000/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 53122/5123 tok/s;  10959 sec
[2022-05-06 00:21:23,561 INFO] Weighted corpora loaded so far:
			* github: 900
[2022-05-06 00:21:29,675 INFO] Step 62050/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51560/5283 tok/s;  10967 sec
[2022-05-06 00:21:34,865 INFO] Weighted corpora loaded so far:
			* github: 901
[2022-05-06 00:21:38,565 INFO] Step 62100/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51814/5202 tok/s;  10976 sec
[2022-05-06 00:21:46,088 INFO] Weighted corpora loaded so far:
			* github: 902
[2022-05-06 00:21:47,458 INFO] Step 62150/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52439/5194 tok/s;  10985 sec
[2022-05-06 00:21:55,934 INFO] Step 62200/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 53674/5349 tok/s;  10994 sec
[2022-05-06 00:21:57,315 INFO] Weighted corpora loaded so far:
			* github: 903
[2022-05-06 00:22:04,864 INFO] Step 62250/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52485/5216 tok/s;  11002 sec
[2022-05-06 00:22:08,600 INFO] Weighted corpora loaded so far:
			* github: 904
[2022-05-06 00:22:13,645 INFO] Step 62300/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51007/5150 tok/s;  11011 sec
[2022-05-06 00:22:22,429 INFO] Step 62350/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52115/5258 tok/s;  11020 sec
[2022-05-06 00:22:30,999 INFO] Step 62400/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 55021/5335 tok/s;  11029 sec
[2022-05-06 00:22:31,002 INFO] Weighted corpora loaded so far:
			* github: 905
[2022-05-06 00:22:39,891 INFO] Step 62450/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52868/5171 tok/s;  11037 sec
[2022-05-06 00:22:42,224 INFO] Weighted corpora loaded so far:
			* github: 906
[2022-05-06 00:22:48,677 INFO] Step 62500/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51787/5259 tok/s;  11046 sec
[2022-05-06 00:22:53,416 INFO] Weighted corpora loaded so far:
			* github: 907
[2022-05-06 00:22:57,484 INFO] Step 62550/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52750/5152 tok/s;  11055 sec
[2022-05-06 00:23:04,852 INFO] Weighted corpora loaded so far:
			* github: 908
[2022-05-06 00:23:06,602 INFO] Step 62600/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51091/5123 tok/s;  11064 sec
[2022-05-06 00:23:15,185 INFO] Step 62650/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 53328/5325 tok/s;  11073 sec
[2022-05-06 00:23:16,236 INFO] Weighted corpora loaded so far:
			* github: 909
[2022-05-06 00:23:24,139 INFO] Step 62700/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 52528/5165 tok/s;  11082 sec
[2022-05-06 00:23:27,467 INFO] Weighted corpora loaded so far:
			* github: 910
[2022-05-06 00:23:33,423 INFO] Step 62750/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 47913/4862 tok/s;  11091 sec
[2022-05-06 00:23:39,281 INFO] Weighted corpora loaded so far:
			* github: 911
[2022-05-06 00:23:42,332 INFO] Step 62800/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51602/5198 tok/s;  11100 sec
[2022-05-06 00:23:51,068 INFO] Weighted corpora loaded so far:
			* github: 912
[2022-05-06 00:23:51,676 INFO] Step 62850/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 50224/4923 tok/s;  11109 sec
[2022-05-06 00:24:00,288 INFO] Step 62900/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 54734/5264 tok/s;  11118 sec
[2022-05-06 00:24:02,278 INFO] Weighted corpora loaded so far:
			* github: 913
[2022-05-06 00:24:09,040 INFO] Step 62950/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51493/5234 tok/s;  11127 sec
[2022-05-06 00:24:13,516 INFO] Weighted corpora loaded so far:
			* github: 914
[2022-05-06 00:24:17,908 INFO] Step 63000/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 52399/5185 tok/s;  11135 sec
[2022-05-06 00:24:24,891 INFO] Weighted corpora loaded so far:
			* github: 915
[2022-05-06 00:24:26,934 INFO] Step 63050/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 50906/5203 tok/s;  11145 sec
[2022-05-06 00:24:35,468 INFO] Step 63100/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 53790/5318 tok/s;  11153 sec
[2022-05-06 00:24:36,168 INFO] Weighted corpora loaded so far:
			* github: 916
[2022-05-06 00:24:44,362 INFO] Step 63150/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 52943/5182 tok/s;  11162 sec
[2022-05-06 00:24:53,072 INFO] Step 63200/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51158/5262 tok/s;  11171 sec
[2022-05-06 00:24:58,532 INFO] Weighted corpora loaded so far:
			* github: 917
[2022-05-06 00:25:01,930 INFO] Step 63250/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51990/5169 tok/s;  11180 sec
[2022-05-06 00:25:09,873 INFO] Weighted corpora loaded so far:
			* github: 918
[2022-05-06 00:25:10,934 INFO] Step 63300/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52693/5094 tok/s;  11189 sec
[2022-05-06 00:25:19,530 INFO] Step 63350/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 53975/5387 tok/s;  11197 sec
[2022-05-06 00:25:21,179 INFO] Weighted corpora loaded so far:
			* github: 919
[2022-05-06 00:25:28,445 INFO] Step 63400/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51802/5160 tok/s;  11206 sec
[2022-05-06 00:25:32,506 INFO] Weighted corpora loaded so far:
			* github: 920
[2022-05-06 00:25:37,292 INFO] Step 63450/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51546/5093 tok/s;  11215 sec
[2022-05-06 00:25:43,834 INFO] Weighted corpora loaded so far:
			* github: 921
[2022-05-06 00:25:46,185 INFO] Step 63500/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 51589/5243 tok/s;  11224 sec
[2022-05-06 00:25:54,857 INFO] Step 63550/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 54085/5249 tok/s;  11232 sec
[2022-05-06 00:25:55,198 INFO] Weighted corpora loaded so far:
			* github: 922
[2022-05-06 00:26:03,827 INFO] Step 63600/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 52107/5111 tok/s;  11241 sec
[2022-05-06 00:26:06,473 INFO] Weighted corpora loaded so far:
			* github: 923
[2022-05-06 00:26:12,593 INFO] Step 63650/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51129/5164 tok/s;  11250 sec
[2022-05-06 00:26:17,768 INFO] Weighted corpora loaded so far:
			* github: 924
[2022-05-06 00:26:21,486 INFO] Step 63700/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51862/5146 tok/s;  11259 sec
[2022-05-06 00:26:29,099 INFO] Weighted corpora loaded so far:
			* github: 925
[2022-05-06 00:26:30,485 INFO] Step 63750/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 52292/5172 tok/s;  11268 sec
[2022-05-06 00:26:39,016 INFO] Step 63800/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 54008/5376 tok/s;  11277 sec
[2022-05-06 00:26:40,385 INFO] Weighted corpora loaded so far:
			* github: 926
[2022-05-06 00:26:47,925 INFO] Step 63850/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52347/5138 tok/s;  11286 sec
[2022-05-06 00:26:51,684 INFO] Weighted corpora loaded so far:
			* github: 927
[2022-05-06 00:26:56,676 INFO] Step 63900/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51001/5242 tok/s;  11294 sec
[2022-05-06 00:27:02,893 INFO] Weighted corpora loaded so far:
			* github: 928
[2022-05-06 00:27:05,506 INFO] Step 63950/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51748/5260 tok/s;  11303 sec
[2022-05-06 00:27:14,030 INFO] Step 64000/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 54982/5419 tok/s;  11312 sec
[2022-05-06 00:27:14,062 INFO] Weighted corpora loaded so far:
			* github: 929
[2022-05-06 00:27:22,728 INFO] Step 64050/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 53881/5264 tok/s;  11320 sec
[2022-05-06 00:27:31,445 INFO] Step 64100/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00041; 51949/5227 tok/s;  11329 sec
[2022-05-06 00:27:36,169 INFO] Weighted corpora loaded so far:
			* github: 930
[2022-05-06 00:27:40,270 INFO] Step 64150/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52452/5299 tok/s;  11338 sec
[2022-05-06 00:27:47,414 INFO] Weighted corpora loaded so far:
			* github: 931
[2022-05-06 00:27:49,133 INFO] Step 64200/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52529/5132 tok/s;  11347 sec
[2022-05-06 00:27:57,631 INFO] Step 64250/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 53743/5327 tok/s;  11355 sec
[2022-05-06 00:27:58,678 INFO] Weighted corpora loaded so far:
			* github: 932
[2022-05-06 00:28:06,684 INFO] Step 64300/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52864/5123 tok/s;  11364 sec
[2022-05-06 00:28:10,025 INFO] Weighted corpora loaded so far:
			* github: 933
[2022-05-06 00:28:15,472 INFO] Step 64350/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51125/5201 tok/s;  11373 sec
[2022-05-06 00:28:21,344 INFO] Weighted corpora loaded so far:
			* github: 934
[2022-05-06 00:28:24,341 INFO] Step 64400/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51778/5190 tok/s;  11382 sec
[2022-05-06 00:28:32,548 INFO] Weighted corpora loaded so far:
			* github: 935
[2022-05-06 00:28:33,202 INFO] Step 64450/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 52379/5192 tok/s;  11391 sec
[2022-05-06 00:28:42,124 INFO] Step 64500/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52502/5128 tok/s;  11400 sec
[2022-05-06 00:28:44,300 INFO] Weighted corpora loaded so far:
			* github: 936
[2022-05-06 00:28:51,121 INFO] Step 64550/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 50040/5089 tok/s;  11409 sec
[2022-05-06 00:28:55,663 INFO] Weighted corpora loaded so far:
			* github: 937
[2022-05-06 00:29:00,238 INFO] Step 64600/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51167/4972 tok/s;  11418 sec
[2022-05-06 00:29:07,079 INFO] Weighted corpora loaded so far:
			* github: 938
[2022-05-06 00:29:09,113 INFO] Step 64650/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 52164/5239 tok/s;  11427 sec
[2022-05-06 00:29:17,575 INFO] Step 64700/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 54734/5383 tok/s;  11435 sec
[2022-05-06 00:29:18,283 INFO] Weighted corpora loaded so far:
			* github: 939
[2022-05-06 00:29:26,510 INFO] Step 64750/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 52576/5204 tok/s;  11444 sec
[2022-05-06 00:29:29,487 INFO] Weighted corpora loaded so far:
			* github: 940
[2022-05-06 00:29:35,235 INFO] Step 64800/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 50943/5281 tok/s;  11453 sec
[2022-05-06 00:29:41,070 INFO] Weighted corpora loaded so far:
			* github: 941
[2022-05-06 00:29:44,345 INFO] Step 64850/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 50279/4997 tok/s;  11462 sec
[2022-05-06 00:29:52,470 INFO] Weighted corpora loaded so far:
			* github: 942
[2022-05-06 00:29:53,562 INFO] Step 64900/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 50945/5039 tok/s;  11471 sec
[2022-05-06 00:30:02,214 INFO] Step 64950/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 53359/5276 tok/s;  11480 sec
[2022-05-06 00:30:11,063 INFO] Step 65000/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52142/5156 tok/s;  11489 sec
[2022-05-06 00:30:15,129 INFO] Weighted corpora loaded so far:
			* github: 943
[2022-05-06 00:30:19,844 INFO] Step 65050/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51935/5172 tok/s;  11497 sec
[2022-05-06 00:30:26,319 INFO] Weighted corpora loaded so far:
			* github: 944
[2022-05-06 00:30:28,639 INFO] Step 65100/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00041; 52213/5310 tok/s;  11506 sec
[2022-05-06 00:30:37,209 INFO] Step 65150/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 54811/5317 tok/s;  11515 sec
[2022-05-06 00:30:37,545 INFO] Weighted corpora loaded so far:
			* github: 945
[2022-05-06 00:30:46,575 INFO] Step 65200/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 50483/4926 tok/s;  11524 sec
[2022-05-06 00:30:49,381 INFO] Weighted corpora loaded so far:
			* github: 946
[2022-05-06 00:30:55,497 INFO] Step 65250/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 50576/5098 tok/s;  11533 sec
[2022-05-06 00:31:00,488 INFO] Weighted corpora loaded so far:
			* github: 947
[2022-05-06 00:31:04,110 INFO] Step 65300/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 53392/5400 tok/s;  11542 sec
[2022-05-06 00:31:11,519 INFO] Weighted corpora loaded so far:
			* github: 948
[2022-05-06 00:31:12,904 INFO] Step 65350/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52929/5246 tok/s;  11550 sec
[2022-05-06 00:31:21,407 INFO] Step 65400/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 53725/5322 tok/s;  11559 sec
[2022-05-06 00:31:22,758 INFO] Weighted corpora loaded so far:
			* github: 949
[2022-05-06 00:31:30,367 INFO] Step 65450/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52615/5117 tok/s;  11568 sec
[2022-05-06 00:31:34,093 INFO] Weighted corpora loaded so far:
			* github: 950
[2022-05-06 00:31:39,196 INFO] Step 65500/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 51011/5217 tok/s;  11577 sec
[2022-05-06 00:31:45,393 INFO] Weighted corpora loaded so far:
			* github: 951
[2022-05-06 00:31:48,046 INFO] Step 65550/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51829/5199 tok/s;  11586 sec
[2022-05-06 00:31:56,690 INFO] Step 65600/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 54309/5330 tok/s;  11594 sec
[2022-05-06 00:31:56,718 INFO] Weighted corpora loaded so far:
			* github: 952
[2022-05-06 00:32:05,658 INFO] Step 65650/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52216/5061 tok/s;  11603 sec
[2022-05-06 00:32:08,013 INFO] Weighted corpora loaded so far:
			* github: 953
[2022-05-06 00:32:14,516 INFO] Step 65700/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 50891/5282 tok/s;  11612 sec
[2022-05-06 00:32:19,431 INFO] Weighted corpora loaded so far:
			* github: 954
[2022-05-06 00:32:23,502 INFO] Step 65750/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51218/5160 tok/s;  11621 sec
[2022-05-06 00:32:30,657 INFO] Weighted corpora loaded so far:
			* github: 955
[2022-05-06 00:32:32,302 INFO] Step 65800/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52627/5190 tok/s;  11630 sec
[2022-05-06 00:32:40,751 INFO] Step 65850/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 53779/5376 tok/s;  11638 sec
[2022-05-06 00:32:49,697 INFO] Step 65900/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 53422/5105 tok/s;  11647 sec
[2022-05-06 00:32:53,019 INFO] Weighted corpora loaded so far:
			* github: 956
[2022-05-06 00:32:58,463 INFO] Step 65950/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51104/5223 tok/s;  11656 sec
[2022-05-06 00:33:04,314 INFO] Weighted corpora loaded so far:
			* github: 957
[2022-05-06 00:33:07,277 INFO] Step 66000/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52104/5180 tok/s;  11665 sec
[2022-05-06 00:33:15,577 INFO] Weighted corpora loaded so far:
			* github: 958
[2022-05-06 00:33:16,246 INFO] Step 66050/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52276/5230 tok/s;  11674 sec
[2022-05-06 00:33:24,812 INFO] Step 66100/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 54997/5258 tok/s;  11682 sec
[2022-05-06 00:33:26,817 INFO] Weighted corpora loaded so far:
			* github: 959
[2022-05-06 00:33:33,667 INFO] Step 66150/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51171/5249 tok/s;  11691 sec
[2022-05-06 00:33:38,164 INFO] Weighted corpora loaded so far:
			* github: 960
[2022-05-06 00:33:42,573 INFO] Step 66200/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52275/5156 tok/s;  11700 sec
[2022-05-06 00:33:49,335 INFO] Weighted corpora loaded so far:
			* github: 961
[2022-05-06 00:33:51,379 INFO] Step 66250/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 52064/5173 tok/s;  11709 sec
[2022-05-06 00:33:59,941 INFO] Step 66300/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 53663/5369 tok/s;  11718 sec
[2022-05-06 00:34:00,629 INFO] Weighted corpora loaded so far:
			* github: 962
[2022-05-06 00:34:08,936 INFO] Step 66350/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52808/5014 tok/s;  11727 sec
[2022-05-06 00:34:12,115 INFO] Weighted corpora loaded so far:
			* github: 963
[2022-05-06 00:34:18,317 INFO] Step 66400/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 47852/4980 tok/s;  11736 sec
[2022-05-06 00:34:23,818 INFO] Weighted corpora loaded so far:
			* github: 964
[2022-05-06 00:34:27,171 INFO] Step 66450/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52013/5242 tok/s;  11745 sec
[2022-05-06 00:34:35,091 INFO] Weighted corpora loaded so far:
			* github: 965
[2022-05-06 00:34:36,136 INFO] Step 66500/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52249/5162 tok/s;  11754 sec
[2022-05-06 00:34:44,733 INFO] Step 66550/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 53774/5265 tok/s;  11762 sec
[2022-05-06 00:34:46,404 INFO] Weighted corpora loaded so far:
			* github: 966
[2022-05-06 00:34:53,593 INFO] Step 66600/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51786/5117 tok/s;  11771 sec
[2022-05-06 00:34:57,674 INFO] Weighted corpora loaded so far:
			* github: 967
[2022-05-06 00:35:02,347 INFO] Step 66650/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51658/5178 tok/s;  11780 sec
[2022-05-06 00:35:11,173 INFO] Step 66700/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51621/5292 tok/s;  11789 sec
[2022-05-06 00:35:19,799 INFO] Step 66750/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 54254/5335 tok/s;  11797 sec
[2022-05-06 00:35:20,152 INFO] Weighted corpora loaded so far:
			* github: 968
[2022-05-06 00:35:28,847 INFO] Step 66800/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52330/5042 tok/s;  11806 sec
[2022-05-06 00:35:31,493 INFO] Weighted corpora loaded so far:
			* github: 969
[2022-05-06 00:35:37,607 INFO] Step 66850/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51481/5269 tok/s;  11815 sec
[2022-05-06 00:35:42,721 INFO] Weighted corpora loaded so far:
			* github: 970
[2022-05-06 00:35:46,460 INFO] Step 66900/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52189/5227 tok/s;  11824 sec
[2022-05-06 00:35:53,991 INFO] Weighted corpora loaded so far:
			* github: 971
[2022-05-06 00:35:55,412 INFO] Step 66950/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52645/5136 tok/s;  11833 sec
[2022-05-06 00:36:03,968 INFO] Step 67000/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 53745/5294 tok/s;  11842 sec
[2022-05-06 00:36:05,388 INFO] Weighted corpora loaded so far:
			* github: 972
[2022-05-06 00:36:12,936 INFO] Step 67050/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52219/5124 tok/s;  11851 sec
[2022-05-06 00:36:16,595 INFO] Weighted corpora loaded so far:
			* github: 973
[2022-05-06 00:36:21,651 INFO] Step 67100/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 51293/5247 tok/s;  11859 sec
[2022-05-06 00:36:27,859 INFO] Weighted corpora loaded so far:
			* github: 974
[2022-05-06 00:36:30,525 INFO] Step 67150/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 51433/5247 tok/s;  11868 sec
[2022-05-06 00:36:39,111 INFO] Step 67200/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 54472/5302 tok/s;  11877 sec
[2022-05-06 00:36:39,133 INFO] Weighted corpora loaded so far:
			* github: 975
[2022-05-06 00:36:48,094 INFO] Step 67250/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52775/5049 tok/s;  11886 sec
[2022-05-06 00:36:50,421 INFO] Weighted corpora loaded so far:
			* github: 976
[2022-05-06 00:36:56,860 INFO] Step 67300/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 51896/5269 tok/s;  11894 sec
[2022-05-06 00:37:01,628 INFO] Weighted corpora loaded so far:
			* github: 977
[2022-05-06 00:37:05,691 INFO] Step 67350/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 52181/5235 tok/s;  11903 sec
[2022-05-06 00:37:12,901 INFO] Weighted corpora loaded so far:
			* github: 978
[2022-05-06 00:37:14,545 INFO] Step 67400/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 51978/5264 tok/s;  11912 sec
[2022-05-06 00:37:23,034 INFO] Step 67450/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 53522/5421 tok/s;  11921 sec
[2022-05-06 00:37:24,078 INFO] Weighted corpora loaded so far:
			* github: 979
[2022-05-06 00:37:32,195 INFO] Step 67500/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 51912/4945 tok/s;  11930 sec
[2022-05-06 00:37:35,544 INFO] Weighted corpora loaded so far:
			* github: 980
[2022-05-06 00:37:40,902 INFO] Step 67550/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51159/5206 tok/s;  11938 sec
[2022-05-06 00:37:49,733 INFO] Step 67600/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51742/5318 tok/s;  11947 sec
[2022-05-06 00:37:57,966 INFO] Weighted corpora loaded so far:
			* github: 981
[2022-05-06 00:37:58,652 INFO] Step 67650/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52426/5119 tok/s;  11956 sec
[2022-05-06 00:38:07,298 INFO] Step 67700/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 54576/5286 tok/s;  11965 sec
[2022-05-06 00:38:09,272 INFO] Weighted corpora loaded so far:
			* github: 982
[2022-05-06 00:38:16,092 INFO] Step 67750/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51448/5211 tok/s;  11974 sec
[2022-05-06 00:38:20,557 INFO] Weighted corpora loaded so far:
			* github: 983
[2022-05-06 00:38:25,020 INFO] Step 67800/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52505/5136 tok/s;  11983 sec
[2022-05-06 00:38:31,862 INFO] Weighted corpora loaded so far:
			* github: 984
[2022-05-06 00:38:33,937 INFO] Step 67850/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52092/5267 tok/s;  11992 sec
[2022-05-06 00:38:42,492 INFO] Step 67900/100000; acc:  99.89; ppl:  1.00; xent: 0.00; lr: 0.00041; 53841/5239 tok/s;  12000 sec
[2022-05-06 00:38:43,169 INFO] Weighted corpora loaded so far:
			* github: 985
[2022-05-06 00:38:51,463 INFO] Step 67950/100000; acc:  99.83; ppl:  1.00; xent: 0.00; lr: 0.00041; 52532/5061 tok/s;  12009 sec
[2022-05-06 00:38:54,417 INFO] Weighted corpora loaded so far:
			* github: 986
[2022-05-06 00:39:00,068 INFO] Step 68000/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 51725/5302 tok/s;  12018 sec
[2022-05-06 00:39:05,466 INFO] Weighted corpora loaded so far:
			* github: 987
[2022-05-06 00:39:08,797 INFO] Step 68050/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 52597/5420 tok/s;  12026 sec
[2022-05-06 00:39:16,730 INFO] Weighted corpora loaded so far:
			* github: 988
[2022-05-06 00:39:17,719 INFO] Step 68100/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52809/5117 tok/s;  12035 sec
[2022-05-06 00:39:26,245 INFO] Step 68150/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 54481/5330 tok/s;  12044 sec
[2022-05-06 00:39:27,894 INFO] Weighted corpora loaded so far:
			* github: 989
[2022-05-06 00:39:35,062 INFO] Step 68200/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52370/5113 tok/s;  12053 sec
[2022-05-06 00:39:39,148 INFO] Weighted corpora loaded so far:
			* github: 990
[2022-05-06 00:39:43,861 INFO] Step 68250/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51615/5309 tok/s;  12061 sec
[2022-05-06 00:39:50,409 INFO] Weighted corpora loaded so far:
			* github: 991
[2022-05-06 00:39:52,675 INFO] Step 68300/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51636/5351 tok/s;  12070 sec
[2022-05-06 00:40:01,259 INFO] Step 68350/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 54253/5312 tok/s;  12079 sec
[2022-05-06 00:40:01,609 INFO] Weighted corpora loaded so far:
			* github: 992
[2022-05-06 00:40:10,177 INFO] Step 68400/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52694/5065 tok/s;  12088 sec
[2022-05-06 00:40:12,865 INFO] Weighted corpora loaded so far:
			* github: 993
[2022-05-06 00:40:18,956 INFO] Step 68450/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51022/5249 tok/s;  12097 sec
[2022-05-06 00:40:27,759 INFO] Step 68500/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 52275/5165 tok/s;  12105 sec
[2022-05-06 00:40:35,359 INFO] Weighted corpora loaded so far:
			* github: 994
[2022-05-06 00:40:36,753 INFO] Step 68550/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 52344/5148 tok/s;  12114 sec
[2022-05-06 00:40:45,241 INFO] Step 68600/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00041; 54010/5414 tok/s;  12123 sec
[2022-05-06 00:40:46,580 INFO] Weighted corpora loaded so far:
			* github: 995
[2022-05-06 00:40:54,212 INFO] Step 68650/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52491/5123 tok/s;  12132 sec
[2022-05-06 00:40:57,871 INFO] Weighted corpora loaded so far:
			* github: 996
[2022-05-06 00:41:02,924 INFO] Step 68700/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51781/5240 tok/s;  12141 sec
[2022-05-06 00:41:09,088 INFO] Weighted corpora loaded so far:
			* github: 997
[2022-05-06 00:41:11,741 INFO] Step 68750/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 52210/5221 tok/s;  12149 sec
[2022-05-06 00:41:20,337 INFO] Step 68800/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 54759/5381 tok/s;  12158 sec
[2022-05-06 00:41:20,349 INFO] Weighted corpora loaded so far:
			* github: 998
[2022-05-06 00:41:29,272 INFO] Step 68850/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 52140/5140 tok/s;  12167 sec
[2022-05-06 00:41:31,567 INFO] Weighted corpora loaded so far:
			* github: 999
[2022-05-06 00:41:38,019 INFO] Step 68900/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51595/5247 tok/s;  12176 sec
[2022-05-06 00:41:42,753 INFO] Weighted corpora loaded so far:
			* github: 1000
[2022-05-06 00:41:46,839 INFO] Step 68950/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 52500/5142 tok/s;  12184 sec
[2022-05-06 00:41:54,112 INFO] Weighted corpora loaded so far:
			* github: 1001
[2022-05-06 00:41:55,839 INFO] Step 69000/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 51884/5145 tok/s;  12193 sec
[2022-05-06 00:42:04,302 INFO] Step 69050/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00041; 53911/5395 tok/s;  12202 sec
[2022-05-06 00:42:05,357 INFO] Weighted corpora loaded so far:
			* github: 1002
[2022-05-06 00:42:13,464 INFO] Step 69100/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 51833/5035 tok/s;  12211 sec
[2022-05-06 00:42:16,789 INFO] Weighted corpora loaded so far:
			* github: 1003
[2022-05-06 00:42:22,163 INFO] Step 69150/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 51268/5224 tok/s;  12220 sec
[2022-05-06 00:42:28,024 INFO] Weighted corpora loaded so far:
			* github: 1004
[2022-05-06 00:42:31,009 INFO] Step 69200/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 51651/5238 tok/s;  12229 sec
[2022-05-06 00:42:39,250 INFO] Weighted corpora loaded so far:
			* github: 1005
[2022-05-06 00:42:39,899 INFO] Step 69250/100000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00041; 52224/5218 tok/s;  12237 sec
[2022-05-06 00:42:48,464 INFO] Step 69300/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 54709/5343 tok/s;  12246 sec
[2022-05-06 00:42:57,248 INFO] Step 69350/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 51217/5186 tok/s;  12255 sec
[2022-05-06 00:43:01,640 INFO] Weighted corpora loaded so far:
			* github: 1006
[2022-05-06 00:43:06,095 INFO] Step 69400/100000; acc:  99.76; ppl:  1.01; xent: 0.01; lr: 0.00041; 52852/5180 tok/s;  12264 sec
[2022-05-06 00:43:12,937 INFO] Weighted corpora loaded so far:
			* github: 1007
[2022-05-06 00:43:14,997 INFO] Step 69450/100000; acc:  99.78; ppl:  1.01; xent: 0.01; lr: 0.00041; 52195/5160 tok/s;  12273 sec
[2022-05-06 00:43:23,844 INFO] Step 69500/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00041; 52004/5165 tok/s;  12281 sec
[2022-05-06 00:43:24,593 INFO] Weighted corpora loaded so far:
			* github: 1008
[2022-05-06 00:43:33,072 INFO] Step 69550/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51495/5007 tok/s;  12291 sec
[2022-05-06 00:43:36,050 INFO] Weighted corpora loaded so far:
			* github: 1009
[2022-05-06 00:43:41,840 INFO] Step 69600/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00041; 51172/5193 tok/s;  12299 sec
[2022-05-06 00:43:47,379 INFO] Weighted corpora loaded so far:
			* github: 1010
[2022-05-06 00:43:50,774 INFO] Step 69650/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00041; 51567/5160 tok/s;  12308 sec
[2022-05-06 00:43:59,323 INFO] Weighted corpora loaded so far:
			* github: 1011
[2022-05-06 00:44:00,457 INFO] Step 69700/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00041; 48554/4795 tok/s;  12318 sec
[2022-05-06 00:44:09,034 INFO] Step 69750/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 53755/5326 tok/s;  12327 sec
[2022-05-06 00:44:10,702 INFO] Weighted corpora loaded so far:
			* github: 1012
[2022-05-06 00:44:17,808 INFO] Step 69800/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 52366/5173 tok/s;  12335 sec
[2022-05-06 00:44:21,830 INFO] Weighted corpora loaded so far:
			* github: 1013
[2022-05-06 00:44:26,562 INFO] Step 69850/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00041; 51973/5172 tok/s;  12344 sec
[2022-05-06 00:44:33,103 INFO] Weighted corpora loaded so far:
			* github: 1014
[2022-05-06 00:44:35,429 INFO] Step 69900/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00041; 51823/5254 tok/s;  12353 sec
[2022-05-06 00:44:44,037 INFO] Step 69950/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00041; 54797/5357 tok/s;  12362 sec
[2022-05-06 00:44:44,395 INFO] Weighted corpora loaded so far:
			* github: 1015
[2022-05-06 00:44:53,011 INFO] Step 70000/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 52108/5216 tok/s;  12371 sec
[2022-05-06 00:44:55,660 INFO] Weighted corpora loaded so far:
			* github: 1016
[2022-05-06 00:45:01,732 INFO] Step 70050/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00036; 51278/5166 tok/s;  12379 sec
[2022-05-06 00:45:06,889 INFO] Weighted corpora loaded so far:
			* github: 1017
[2022-05-06 00:45:10,577 INFO] Step 70100/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51887/5181 tok/s;  12388 sec
[2022-05-06 00:45:18,160 INFO] Weighted corpora loaded so far:
			* github: 1018
[2022-05-06 00:45:19,538 INFO] Step 70150/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 52188/5235 tok/s;  12397 sec
[2022-05-06 00:45:28,049 INFO] Step 70200/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 53522/5324 tok/s;  12406 sec
[2022-05-06 00:45:36,956 INFO] Step 70250/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 52671/5119 tok/s;  12415 sec
[2022-05-06 00:45:40,643 INFO] Weighted corpora loaded so far:
			* github: 1019
[2022-05-06 00:45:45,765 INFO] Step 70300/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 51137/5254 tok/s;  12423 sec
[2022-05-06 00:45:51,959 INFO] Weighted corpora loaded so far:
			* github: 1020
[2022-05-06 00:45:54,649 INFO] Step 70350/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00036; 51806/5142 tok/s;  12432 sec
[2022-05-06 00:46:03,284 INFO] Step 70400/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 54319/5314 tok/s;  12441 sec
[2022-05-06 00:46:03,290 INFO] Weighted corpora loaded so far:
			* github: 1021
[2022-05-06 00:46:12,326 INFO] Step 70450/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52458/5005 tok/s;  12450 sec
[2022-05-06 00:46:14,669 INFO] Weighted corpora loaded so far:
			* github: 1022
[2022-05-06 00:46:21,196 INFO] Step 70500/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 51297/5239 tok/s;  12459 sec
[2022-05-06 00:46:26,007 INFO] Weighted corpora loaded so far:
			* github: 1023
[2022-05-06 00:46:30,130 INFO] Step 70550/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51719/5191 tok/s;  12468 sec
[2022-05-06 00:46:37,325 INFO] Weighted corpora loaded so far:
			* github: 1024
[2022-05-06 00:46:39,064 INFO] Step 70600/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51746/5112 tok/s;  12477 sec
[2022-05-06 00:46:47,604 INFO] Step 70650/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 53085/5375 tok/s;  12485 sec
[2022-05-06 00:46:48,648 INFO] Weighted corpora loaded so far:
			* github: 1025
[2022-05-06 00:46:56,600 INFO] Step 70700/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52759/5090 tok/s;  12494 sec
[2022-05-06 00:46:59,944 INFO] Weighted corpora loaded so far:
			* github: 1026
[2022-05-06 00:47:05,345 INFO] Step 70750/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51254/5173 tok/s;  12503 sec
[2022-05-06 00:47:11,115 INFO] Weighted corpora loaded so far:
			* github: 1027
[2022-05-06 00:47:14,092 INFO] Step 70800/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 52677/5281 tok/s;  12512 sec
[2022-05-06 00:47:22,287 INFO] Weighted corpora loaded so far:
			* github: 1028
[2022-05-06 00:47:22,941 INFO] Step 70850/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 52869/5299 tok/s;  12521 sec
[2022-05-06 00:47:31,515 INFO] Step 70900/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 54366/5264 tok/s;  12529 sec
[2022-05-06 00:47:33,538 INFO] Weighted corpora loaded so far:
			* github: 1029
[2022-05-06 00:47:40,350 INFO] Step 70950/100000; acc:  99.84; ppl:  1.00; xent: 0.00; lr: 0.00036; 50800/5267 tok/s;  12538 sec
[2022-05-06 00:47:44,812 INFO] Weighted corpora loaded so far:
			* github: 1030
[2022-05-06 00:47:49,233 INFO] Step 71000/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 52406/5099 tok/s;  12547 sec
[2022-05-06 00:47:56,172 INFO] Weighted corpora loaded so far:
			* github: 1031
[2022-05-06 00:47:58,151 INFO] Step 71050/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 51711/5250 tok/s;  12556 sec
[2022-05-06 00:48:06,705 INFO] Step 71100/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 53408/5328 tok/s;  12564 sec
[2022-05-06 00:48:15,801 INFO] Step 71150/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52275/5026 tok/s;  12573 sec
[2022-05-06 00:48:18,776 INFO] Weighted corpora loaded so far:
			* github: 1032
[2022-05-06 00:48:24,660 INFO] Step 71200/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 50647/5108 tok/s;  12582 sec
[2022-05-06 00:48:30,241 INFO] Weighted corpora loaded so far:
			* github: 1033
[2022-05-06 00:48:33,637 INFO] Step 71250/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 51341/5155 tok/s;  12591 sec
[2022-05-06 00:48:41,574 INFO] Weighted corpora loaded so far:
			* github: 1034
[2022-05-06 00:48:42,641 INFO] Step 71300/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00036; 52305/5125 tok/s;  12600 sec
[2022-05-06 00:48:51,546 INFO] Step 71350/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 52442/5134 tok/s;  12609 sec
[2022-05-06 00:48:53,212 INFO] Weighted corpora loaded so far:
			* github: 1035
[2022-05-06 00:49:00,442 INFO] Step 71400/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00036; 51913/5129 tok/s;  12618 sec
[2022-05-06 00:49:04,518 INFO] Weighted corpora loaded so far:
			* github: 1036
[2022-05-06 00:49:09,253 INFO] Step 71450/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51460/5220 tok/s;  12627 sec
[2022-05-06 00:49:15,774 INFO] Weighted corpora loaded so far:
			* github: 1037
[2022-05-06 00:49:18,099 INFO] Step 71500/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51411/5188 tok/s;  12636 sec
[2022-05-06 00:49:26,768 INFO] Step 71550/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 53911/5359 tok/s;  12644 sec
[2022-05-06 00:49:27,099 INFO] Weighted corpora loaded so far:
			* github: 1038
[2022-05-06 00:49:35,732 INFO] Step 71600/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 52669/5069 tok/s;  12653 sec
[2022-05-06 00:49:38,412 INFO] Weighted corpora loaded so far:
			* github: 1039
[2022-05-06 00:49:44,551 INFO] Step 71650/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 51101/5224 tok/s;  12662 sec
[2022-05-06 00:49:49,700 INFO] Weighted corpora loaded so far:
			* github: 1040
[2022-05-06 00:49:53,433 INFO] Step 71700/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51948/5131 tok/s;  12671 sec
[2022-05-06 00:50:01,060 INFO] Weighted corpora loaded so far:
			* github: 1041
[2022-05-06 00:50:02,440 INFO] Step 71750/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 52072/5199 tok/s;  12680 sec
[2022-05-06 00:50:10,976 INFO] Step 71800/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 53439/5384 tok/s;  12689 sec
[2022-05-06 00:50:12,343 INFO] Weighted corpora loaded so far:
			* github: 1042
[2022-05-06 00:50:19,913 INFO] Step 71850/100000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00036; 52189/5072 tok/s;  12698 sec
[2022-05-06 00:50:23,644 INFO] Weighted corpora loaded so far:
			* github: 1043
[2022-05-06 00:50:28,718 INFO] Step 71900/100000; acc:  99.84; ppl:  1.00; xent: 0.00; lr: 0.00036; 50780/5268 tok/s;  12706 sec
[2022-05-06 00:50:34,979 INFO] Weighted corpora loaded so far:
			* github: 1044
[2022-05-06 00:50:37,582 INFO] Step 71950/100000; acc:  99.84; ppl:  1.00; xent: 0.00; lr: 0.00036; 51600/5172 tok/s;  12715 sec
[2022-05-06 00:50:46,210 INFO] Step 72000/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 54234/5291 tok/s;  12724 sec
[2022-05-06 00:50:55,186 INFO] Step 72050/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52776/5026 tok/s;  12733 sec
[2022-05-06 00:50:57,523 INFO] Weighted corpora loaded so far:
			* github: 1045
[2022-05-06 00:51:04,045 INFO] Step 72100/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51137/5259 tok/s;  12742 sec
[2022-05-06 00:51:08,871 INFO] Weighted corpora loaded so far:
			* github: 1046
[2022-05-06 00:51:12,949 INFO] Step 72150/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51968/5197 tok/s;  12751 sec
[2022-05-06 00:51:20,192 INFO] Weighted corpora loaded so far:
			* github: 1047
[2022-05-06 00:51:21,924 INFO] Step 72200/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 52001/5110 tok/s;  12760 sec
[2022-05-06 00:51:30,875 INFO] Step 72250/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51014/5114 tok/s;  12768 sec
[2022-05-06 00:51:31,934 INFO] Weighted corpora loaded so far:
			* github: 1048
[2022-05-06 00:51:39,980 INFO] Step 72300/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 52419/4988 tok/s;  12778 sec
[2022-05-06 00:51:43,298 INFO] Weighted corpora loaded so far:
			* github: 1049
[2022-05-06 00:51:48,660 INFO] Step 72350/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51351/5315 tok/s;  12786 sec
[2022-05-06 00:51:54,449 INFO] Weighted corpora loaded so far:
			* github: 1050
[2022-05-06 00:51:57,442 INFO] Step 72400/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51915/5192 tok/s;  12795 sec
[2022-05-06 00:52:05,693 INFO] Weighted corpora loaded so far:
			* github: 1051
[2022-05-06 00:52:06,363 INFO] Step 72450/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 52131/5189 tok/s;  12804 sec
[2022-05-06 00:52:14,994 INFO] Step 72500/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 54862/5329 tok/s;  12813 sec
[2022-05-06 00:52:17,053 INFO] Weighted corpora loaded so far:
			* github: 1052
[2022-05-06 00:52:24,236 INFO] Step 72550/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 49000/4995 tok/s;  12822 sec
[2022-05-06 00:52:28,720 INFO] Weighted corpora loaded so far:
			* github: 1053
[2022-05-06 00:52:33,159 INFO] Step 72600/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52267/5176 tok/s;  12831 sec
[2022-05-06 00:52:40,030 INFO] Weighted corpora loaded so far:
			* github: 1054
[2022-05-06 00:52:42,077 INFO] Step 72650/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51582/5143 tok/s;  12840 sec
[2022-05-06 00:52:50,690 INFO] Step 72700/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 53212/5328 tok/s;  12848 sec
[2022-05-06 00:52:51,383 INFO] Weighted corpora loaded so far:
			* github: 1055
[2022-05-06 00:52:59,668 INFO] Step 72750/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52545/5033 tok/s;  12857 sec
[2022-05-06 00:53:02,693 INFO] Weighted corpora loaded so far:
			* github: 1056
[2022-05-06 00:53:08,403 INFO] Step 72800/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 50887/5237 tok/s;  12866 sec
[2022-05-06 00:53:17,302 INFO] Step 72850/100000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00036; 51448/5250 tok/s;  12875 sec
[2022-05-06 00:53:25,191 INFO] Weighted corpora loaded so far:
			* github: 1057
[2022-05-06 00:53:26,260 INFO] Step 72900/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 52490/5088 tok/s;  12884 sec
[2022-05-06 00:53:35,061 INFO] Step 72950/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 53108/5195 tok/s;  12893 sec
[2022-05-06 00:53:36,698 INFO] Weighted corpora loaded so far:
			* github: 1058
[2022-05-06 00:53:43,920 INFO] Step 73000/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52057/5146 tok/s;  12902 sec
[2022-05-06 00:53:47,986 INFO] Weighted corpora loaded so far:
			* github: 1059
[2022-05-06 00:53:52,788 INFO] Step 73050/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51488/5233 tok/s;  12910 sec
[2022-05-06 00:53:59,346 INFO] Weighted corpora loaded so far:
			* github: 1060
[2022-05-06 00:54:01,716 INFO] Step 73100/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 51562/5151 tok/s;  12919 sec
[2022-05-06 00:54:10,372 INFO] Step 73150/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 54262/5315 tok/s;  12928 sec
[2022-05-06 00:54:10,701 INFO] Weighted corpora loaded so far:
			* github: 1061
[2022-05-06 00:54:19,369 INFO] Step 73200/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52154/5044 tok/s;  12937 sec
[2022-05-06 00:54:22,042 INFO] Weighted corpora loaded so far:
			* github: 1062
[2022-05-06 00:54:28,170 INFO] Step 73250/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 50877/5219 tok/s;  12946 sec
[2022-05-06 00:54:33,332 INFO] Weighted corpora loaded so far:
			* github: 1063
[2022-05-06 00:54:37,075 INFO] Step 73300/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51512/5159 tok/s;  12955 sec
[2022-05-06 00:54:44,614 INFO] Weighted corpora loaded so far:
			* github: 1064
[2022-05-06 00:54:45,998 INFO] Step 73350/100000; acc:  99.83; ppl:  1.00; xent: 0.00; lr: 0.00036; 52428/5189 tok/s;  12964 sec
[2022-05-06 00:54:54,681 INFO] Step 73400/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 53187/5215 tok/s;  12972 sec
[2022-05-06 00:54:56,066 INFO] Weighted corpora loaded so far:
			* github: 1065
[2022-05-06 00:55:03,640 INFO] Step 73450/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 52515/5129 tok/s;  12981 sec
[2022-05-06 00:55:07,356 INFO] Weighted corpora loaded so far:
			* github: 1066
[2022-05-06 00:55:12,448 INFO] Step 73500/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 50738/5293 tok/s;  12990 sec
[2022-05-06 00:55:18,662 INFO] Weighted corpora loaded so far:
			* github: 1067
[2022-05-06 00:55:21,302 INFO] Step 73550/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51364/5173 tok/s;  12999 sec
[2022-05-06 00:55:30,278 INFO] Step 73600/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 52131/5157 tok/s;  13008 sec
[2022-05-06 00:55:30,309 INFO] Weighted corpora loaded so far:
			* github: 1068
[2022-05-06 00:55:39,265 INFO] Step 73650/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 52445/5068 tok/s;  13017 sec
[2022-05-06 00:55:41,641 INFO] Weighted corpora loaded so far:
			* github: 1069
[2022-05-06 00:55:48,076 INFO] Step 73700/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 51209/5206 tok/s;  13026 sec
[2022-05-06 00:55:56,969 INFO] Step 73750/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51832/5206 tok/s;  13035 sec
[2022-05-06 00:56:04,524 INFO] Weighted corpora loaded so far:
			* github: 1070
[2022-05-06 00:56:06,196 INFO] Step 73800/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 50412/4945 tok/s;  13044 sec
[2022-05-06 00:56:14,685 INFO] Step 73850/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 53779/5349 tok/s;  13052 sec
[2022-05-06 00:56:15,727 INFO] Weighted corpora loaded so far:
			* github: 1071
[2022-05-06 00:56:23,682 INFO] Step 73900/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 53021/5172 tok/s;  13061 sec
[2022-05-06 00:56:26,995 INFO] Weighted corpora loaded so far:
			* github: 1072
[2022-05-06 00:56:32,449 INFO] Step 73950/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 51356/5275 tok/s;  13070 sec
[2022-05-06 00:56:38,313 INFO] Weighted corpora loaded so far:
			* github: 1073
[2022-05-06 00:56:41,316 INFO] Step 74000/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 52013/5095 tok/s;  13079 sec
[2022-05-06 00:56:49,504 INFO] Weighted corpora loaded so far:
			* github: 1074
[2022-05-06 00:56:50,155 INFO] Step 74050/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 52667/5223 tok/s;  13088 sec
[2022-05-06 00:56:58,706 INFO] Step 74100/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 54797/5301 tok/s;  13096 sec
[2022-05-06 00:57:00,702 INFO] Weighted corpora loaded so far:
			* github: 1075
[2022-05-06 00:57:07,495 INFO] Step 74150/100000; acc:  99.84; ppl:  1.00; xent: 0.00; lr: 0.00036; 51127/5246 tok/s;  13105 sec
[2022-05-06 00:57:11,978 INFO] Weighted corpora loaded so far:
			* github: 1076
[2022-05-06 00:57:16,400 INFO] Step 74200/100000; acc:  99.84; ppl:  1.00; xent: 0.00; lr: 0.00036; 52327/5185 tok/s;  13114 sec
[2022-05-06 00:57:23,179 INFO] Weighted corpora loaded so far:
			* github: 1077
[2022-05-06 00:57:25,226 INFO] Step 74250/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 52385/5241 tok/s;  13123 sec
[2022-05-06 00:57:33,711 INFO] Step 74300/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 54233/5294 tok/s;  13131 sec
[2022-05-06 00:57:34,399 INFO] Weighted corpora loaded so far:
			* github: 1078
[2022-05-06 00:57:42,689 INFO] Step 74350/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 52983/5096 tok/s;  13140 sec
[2022-05-06 00:57:45,722 INFO] Weighted corpora loaded so far:
			* github: 1079
[2022-05-06 00:57:51,428 INFO] Step 74400/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 51034/5382 tok/s;  13149 sec
[2022-05-06 00:57:56,842 INFO] Weighted corpora loaded so far:
			* github: 1080
[2022-05-06 00:58:00,113 INFO] Step 74450/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52596/5259 tok/s;  13158 sec
[2022-05-06 00:58:07,875 INFO] Weighted corpora loaded so far:
			* github: 1081
[2022-05-06 00:58:08,889 INFO] Step 74500/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 53269/5306 tok/s;  13166 sec
[2022-05-06 00:58:17,304 INFO] Step 74550/100000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00036; 55130/5368 tok/s;  13175 sec
[2022-05-06 00:58:19,041 INFO] Weighted corpora loaded so far:
			* github: 1082
[2022-05-06 00:58:26,242 INFO] Step 74600/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 51241/5193 tok/s;  13184 sec
[2022-05-06 00:58:35,058 INFO] Step 74650/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 51612/5184 tok/s;  13193 sec
[2022-05-06 00:58:41,551 INFO] Weighted corpora loaded so far:
			* github: 1083
[2022-05-06 00:58:43,907 INFO] Step 74700/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 51977/5146 tok/s;  13201 sec
[2022-05-06 00:58:52,522 INFO] Step 74750/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 54391/5329 tok/s;  13210 sec
[2022-05-06 00:58:52,850 INFO] Weighted corpora loaded so far:
			* github: 1084
[2022-05-06 00:59:01,511 INFO] Step 74800/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52462/5101 tok/s;  13219 sec
[2022-05-06 00:59:04,158 INFO] Weighted corpora loaded so far:
			* github: 1085
[2022-05-06 00:59:10,305 INFO] Step 74850/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51424/5254 tok/s;  13228 sec
[2022-05-06 00:59:15,491 INFO] Weighted corpora loaded so far:
			* github: 1086
[2022-05-06 00:59:19,221 INFO] Step 74900/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51936/5051 tok/s;  13237 sec
[2022-05-06 00:59:26,789 INFO] Weighted corpora loaded so far:
			* github: 1087
[2022-05-06 00:59:28,186 INFO] Step 74950/100000; acc:  99.84; ppl:  1.00; xent: 0.00; lr: 0.00036; 52339/5242 tok/s;  13246 sec
[2022-05-06 00:59:36,674 INFO] Step 75000/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 53568/5337 tok/s;  13254 sec
[2022-05-06 00:59:38,032 INFO] Weighted corpora loaded so far:
			* github: 1088
[2022-05-06 00:59:45,645 INFO] Step 75050/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52099/5129 tok/s;  13263 sec
[2022-05-06 00:59:49,308 INFO] Weighted corpora loaded so far:
			* github: 1089
[2022-05-06 00:59:54,384 INFO] Step 75100/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 51465/5248 tok/s;  13272 sec
[2022-05-06 01:00:00,608 INFO] Weighted corpora loaded so far:
			* github: 1090
[2022-05-06 01:00:03,274 INFO] Step 75150/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51818/5180 tok/s;  13281 sec
[2022-05-06 01:00:11,952 INFO] Step 75200/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 54134/5295 tok/s;  13290 sec
[2022-05-06 01:00:11,974 INFO] Weighted corpora loaded so far:
			* github: 1091
[2022-05-06 01:00:20,888 INFO] Step 75250/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 52729/5191 tok/s;  13298 sec
[2022-05-06 01:00:23,220 INFO] Weighted corpora loaded so far:
			* github: 1092
[2022-05-06 01:00:29,700 INFO] Step 75300/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 51140/5191 tok/s;  13307 sec
[2022-05-06 01:00:34,505 INFO] Weighted corpora loaded so far:
			* github: 1093
[2022-05-06 01:00:38,601 INFO] Step 75350/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51603/5226 tok/s;  13316 sec
[2022-05-06 01:00:45,791 INFO] Weighted corpora loaded so far:
			* github: 1094
[2022-05-06 01:00:47,491 INFO] Step 75400/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 51983/5189 tok/s;  13325 sec
[2022-05-06 01:00:55,943 INFO] Step 75450/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 53723/5361 tok/s;  13334 sec
[2022-05-06 01:01:04,996 INFO] Step 75500/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 52437/5052 tok/s;  13343 sec
[2022-05-06 01:01:08,213 INFO] Weighted corpora loaded so far:
			* github: 1095
[2022-05-06 01:01:14,019 INFO] Step 75550/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 49809/5086 tok/s;  13352 sec
[2022-05-06 01:01:20,120 INFO] Weighted corpora loaded so far:
			* github: 1096
[2022-05-06 01:01:23,080 INFO] Step 75600/100000; acc:  99.87; ppl:  1.01; xent: 0.01; lr: 0.00036; 50906/4996 tok/s;  13361 sec
[2022-05-06 01:01:31,432 INFO] Weighted corpora loaded so far:
			* github: 1097
[2022-05-06 01:01:32,105 INFO] Step 75650/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51574/5160 tok/s;  13370 sec
[2022-05-06 01:01:40,738 INFO] Step 75700/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 54801/5247 tok/s;  13378 sec
[2022-05-06 01:01:42,747 INFO] Weighted corpora loaded so far:
			* github: 1098
[2022-05-06 01:01:49,566 INFO] Step 75750/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 51243/5170 tok/s;  13387 sec
[2022-05-06 01:01:54,066 INFO] Weighted corpora loaded so far:
			* github: 1099
[2022-05-06 01:01:58,523 INFO] Step 75800/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52164/5167 tok/s;  13396 sec
[2022-05-06 01:02:05,444 INFO] Weighted corpora loaded so far:
			* github: 1100
[2022-05-06 01:02:07,475 INFO] Step 75850/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51606/5163 tok/s;  13405 sec
[2022-05-06 01:02:16,005 INFO] Step 75900/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 53641/5345 tok/s;  13414 sec
[2022-05-06 01:02:16,696 INFO] Weighted corpora loaded so far:
			* github: 1101
[2022-05-06 01:02:25,036 INFO] Step 75950/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52285/5119 tok/s;  13423 sec
[2022-05-06 01:02:28,034 INFO] Weighted corpora loaded so far:
			* github: 1102
[2022-05-06 01:02:33,830 INFO] Step 76000/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 50896/5136 tok/s;  13431 sec
[2022-05-06 01:02:39,427 INFO] Weighted corpora loaded so far:
			* github: 1103
[2022-05-06 01:02:42,790 INFO] Step 76050/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51485/5182 tok/s;  13440 sec
[2022-05-06 01:02:50,730 INFO] Weighted corpora loaded so far:
			* github: 1104
[2022-05-06 01:02:51,751 INFO] Step 76100/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 52692/5148 tok/s;  13449 sec
[2022-05-06 01:03:00,369 INFO] Step 76150/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 53695/5391 tok/s;  13458 sec
[2022-05-06 01:03:02,035 INFO] Weighted corpora loaded so far:
			* github: 1105
[2022-05-06 01:03:09,278 INFO] Step 76200/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51393/5100 tok/s;  13467 sec
[2022-05-06 01:03:13,332 INFO] Weighted corpora loaded so far:
			* github: 1106
[2022-05-06 01:03:18,064 INFO] Step 76250/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 51542/5224 tok/s;  13476 sec
[2022-05-06 01:03:24,572 INFO] Weighted corpora loaded so far:
			* github: 1107
[2022-05-06 01:03:26,876 INFO] Step 76300/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51790/5302 tok/s;  13484 sec
[2022-05-06 01:03:35,385 INFO] Step 76350/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 54743/5340 tok/s;  13493 sec
[2022-05-06 01:03:44,337 INFO] Step 76400/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 52505/5113 tok/s;  13502 sec
[2022-05-06 01:03:46,949 INFO] Weighted corpora loaded so far:
			* github: 1108
[2022-05-06 01:03:53,081 INFO] Step 76450/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 51657/5252 tok/s;  13511 sec
[2022-05-06 01:03:58,244 INFO] Weighted corpora loaded so far:
			* github: 1109
[2022-05-06 01:04:01,966 INFO] Step 76500/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52057/5095 tok/s;  13520 sec
[2022-05-06 01:04:09,459 INFO] Weighted corpora loaded so far:
			* github: 1110
[2022-05-06 01:04:10,866 INFO] Step 76550/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52677/5236 tok/s;  13528 sec
[2022-05-06 01:04:19,740 INFO] Step 76600/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52054/5135 tok/s;  13537 sec
[2022-05-06 01:04:21,100 INFO] Weighted corpora loaded so far:
			* github: 1111
[2022-05-06 01:04:28,696 INFO] Step 76650/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 52582/5157 tok/s;  13546 sec
[2022-05-06 01:04:32,488 INFO] Weighted corpora loaded so far:
			* github: 1112
[2022-05-06 01:04:37,563 INFO] Step 76700/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 50607/5176 tok/s;  13555 sec
[2022-05-06 01:04:43,750 INFO] Weighted corpora loaded so far:
			* github: 1113
[2022-05-06 01:04:46,392 INFO] Step 76750/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 51724/5104 tok/s;  13564 sec
[2022-05-06 01:04:54,985 INFO] Step 76800/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 54271/5406 tok/s;  13573 sec
[2022-05-06 01:04:55,001 INFO] Weighted corpora loaded so far:
			* github: 1114
[2022-05-06 01:05:03,960 INFO] Step 76850/100000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00036; 52458/5128 tok/s;  13582 sec
[2022-05-06 01:05:06,282 INFO] Weighted corpora loaded so far:
			* github: 1115
[2022-05-06 01:05:12,829 INFO] Step 76900/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 51203/5061 tok/s;  13590 sec
[2022-05-06 01:05:17,627 INFO] Weighted corpora loaded so far:
			* github: 1116
[2022-05-06 01:05:21,712 INFO] Step 76950/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 52189/5300 tok/s;  13599 sec
[2022-05-06 01:05:28,915 INFO] Weighted corpora loaded so far:
			* github: 1117
[2022-05-06 01:05:30,639 INFO] Step 77000/100000; acc:  99.87; ppl:  1.01; xent: 0.01; lr: 0.00036; 52079/5151 tok/s;  13608 sec
[2022-05-06 01:05:39,063 INFO] Step 77050/100000; acc:  99.84; ppl:  1.00; xent: 0.00; lr: 0.00036; 53571/5424 tok/s;  13617 sec
[2022-05-06 01:05:40,132 INFO] Weighted corpora loaded so far:
			* github: 1118
[2022-05-06 01:05:48,074 INFO] Step 77100/100000; acc:  99.83; ppl:  1.00; xent: 0.00; lr: 0.00036; 52578/5176 tok/s;  13626 sec
[2022-05-06 01:05:51,428 INFO] Weighted corpora loaded so far:
			* github: 1119
[2022-05-06 01:05:56,813 INFO] Step 77150/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 51197/5205 tok/s;  13634 sec
[2022-05-06 01:06:02,628 INFO] Weighted corpora loaded so far:
			* github: 1120
[2022-05-06 01:06:05,584 INFO] Step 77200/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52248/5194 tok/s;  13643 sec
[2022-05-06 01:06:14,461 INFO] Step 77250/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 52069/5218 tok/s;  13652 sec
[2022-05-06 01:06:23,104 INFO] Step 77300/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 54660/5189 tok/s;  13661 sec
[2022-05-06 01:06:25,093 INFO] Weighted corpora loaded so far:
			* github: 1121
[2022-05-06 01:06:31,960 INFO] Step 77350/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 51106/5245 tok/s;  13670 sec
[2022-05-06 01:06:36,470 INFO] Weighted corpora loaded so far:
			* github: 1122
[2022-05-06 01:06:40,937 INFO] Step 77400/100000; acc:  99.87; ppl:  1.01; xent: 0.01; lr: 0.00036; 52093/5102 tok/s;  13679 sec
[2022-05-06 01:06:47,676 INFO] Weighted corpora loaded so far:
			* github: 1123
[2022-05-06 01:06:49,721 INFO] Step 77450/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52741/5280 tok/s;  13687 sec
[2022-05-06 01:06:58,188 INFO] Step 77500/100000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00036; 54777/5359 tok/s;  13696 sec
[2022-05-06 01:06:58,877 INFO] Weighted corpora loaded so far:
			* github: 1124
[2022-05-06 01:07:07,054 INFO] Step 77550/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 53427/5200 tok/s;  13705 sec
[2022-05-06 01:07:10,001 INFO] Weighted corpora loaded so far:
			* github: 1125
[2022-05-06 01:07:15,684 INFO] Step 77600/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51611/5261 tok/s;  13713 sec
[2022-05-06 01:07:21,117 INFO] Weighted corpora loaded so far:
			* github: 1126
[2022-05-06 01:07:24,427 INFO] Step 77650/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 52308/5230 tok/s;  13722 sec
[2022-05-06 01:07:32,245 INFO] Weighted corpora loaded so far:
			* github: 1127
[2022-05-06 01:07:33,285 INFO] Step 77700/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52901/5300 tok/s;  13731 sec
[2022-05-06 01:07:42,023 INFO] Step 77750/100000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00036; 53339/5178 tok/s;  13740 sec
[2022-05-06 01:07:43,677 INFO] Weighted corpora loaded so far:
			* github: 1128
[2022-05-06 01:07:50,993 INFO] Step 77800/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 51366/5109 tok/s;  13749 sec
[2022-05-06 01:07:55,043 INFO] Weighted corpora loaded so far:
			* github: 1129
[2022-05-06 01:07:59,766 INFO] Step 77850/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 51920/5191 tok/s;  13757 sec
[2022-05-06 01:08:06,354 INFO] Weighted corpora loaded so far:
			* github: 1130
[2022-05-06 01:08:08,626 INFO] Step 77900/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 51721/5384 tok/s;  13766 sec
[2022-05-06 01:08:17,200 INFO] Step 77950/100000; acc:  99.81; ppl:  1.01; xent: 0.01; lr: 0.00036; 54377/5271 tok/s;  13775 sec
[2022-05-06 01:08:17,542 INFO] Weighted corpora loaded so far:
			* github: 1131
[2022-05-06 01:08:26,108 INFO] Step 78000/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52407/5101 tok/s;  13784 sec
[2022-05-06 01:08:28,801 INFO] Weighted corpora loaded so far:
			* github: 1132
[2022-05-06 01:08:35,297 INFO] Step 78050/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 48841/5018 tok/s;  13793 sec
[2022-05-06 01:08:40,598 INFO] Weighted corpora loaded so far:
			* github: 1133
[2022-05-06 01:08:44,304 INFO] Step 78100/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 51091/5106 tok/s;  13802 sec
[2022-05-06 01:08:53,255 INFO] Step 78150/100000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00036; 52221/5164 tok/s;  13811 sec
[2022-05-06 01:09:01,828 INFO] Step 78200/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 53786/5224 tok/s;  13819 sec
[2022-05-06 01:09:03,196 INFO] Weighted corpora loaded so far:
			* github: 1134
[2022-05-06 01:09:10,814 INFO] Step 78250/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 52088/5160 tok/s;  13828 sec
[2022-05-06 01:09:14,542 INFO] Weighted corpora loaded so far:
			* github: 1135
[2022-05-06 01:09:19,624 INFO] Step 78300/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 51049/5208 tok/s;  13837 sec
[2022-05-06 01:09:25,839 INFO] Weighted corpora loaded so far:
			* github: 1136
[2022-05-06 01:09:28,490 INFO] Step 78350/100000; acc:  99.80; ppl:  1.01; xent: 0.01; lr: 0.00036; 51972/5180 tok/s;  13846 sec
[2022-05-06 01:09:37,276 INFO] Step 78400/100000; acc:  99.84; ppl:  1.01; xent: 0.00; lr: 0.00036; 53575/5276 tok/s;  13855 sec
[2022-05-06 01:09:37,287 INFO] Weighted corpora loaded so far:
			* github: 1137
[2022-05-06 01:09:46,349 INFO] Step 78450/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52198/5058 tok/s;  13864 sec
[2022-05-06 01:09:48,660 INFO] Weighted corpora loaded so far:
			* github: 1138
[2022-05-06 01:09:55,100 INFO] Step 78500/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 51465/5274 tok/s;  13873 sec
[2022-05-06 01:09:59,864 INFO] Weighted corpora loaded so far:
			* github: 1139
[2022-05-06 01:10:04,064 INFO] Step 78550/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 51197/5025 tok/s;  13882 sec
[2022-05-06 01:10:11,440 INFO] Weighted corpora loaded so far:
			* github: 1140
[2022-05-06 01:10:13,164 INFO] Step 78600/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 50924/5070 tok/s;  13891 sec
[2022-05-06 01:10:21,689 INFO] Step 78650/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 53763/5410 tok/s;  13899 sec
[2022-05-06 01:10:22,800 INFO] Weighted corpora loaded so far:
			* github: 1141
[2022-05-06 01:10:30,732 INFO] Step 78700/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52774/5159 tok/s;  13908 sec
[2022-05-06 01:10:34,050 INFO] Weighted corpora loaded so far:
			* github: 1142
[2022-05-06 01:10:39,465 INFO] Step 78750/100000; acc:  99.88; ppl:  1.00; xent: 0.00; lr: 0.00036; 51258/5203 tok/s;  13917 sec
[2022-05-06 01:10:45,443 INFO] Weighted corpora loaded so far:
			* github: 1143
[2022-05-06 01:10:48,738 INFO] Step 78800/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 49326/5020 tok/s;  13926 sec
[2022-05-06 01:10:57,130 INFO] Weighted corpora loaded so far:
			* github: 1144
[2022-05-06 01:10:57,773 INFO] Step 78850/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 51277/5051 tok/s;  13935 sec
[2022-05-06 01:11:06,357 INFO] Step 78900/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 54669/5262 tok/s;  13944 sec
[2022-05-06 01:11:08,379 INFO] Weighted corpora loaded so far:
			* github: 1145
[2022-05-06 01:11:15,189 INFO] Step 78950/100000; acc:  99.86; ppl:  1.01; xent: 0.01; lr: 0.00036; 50793/5262 tok/s;  13953 sec
[2022-05-06 01:11:24,103 INFO] Step 79000/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52124/5156 tok/s;  13962 sec
[2022-05-06 01:11:30,972 INFO] Weighted corpora loaded so far:
			* github: 1146
[2022-05-06 01:11:32,989 INFO] Step 79050/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 52008/5146 tok/s;  13971 sec
[2022-05-06 01:11:41,580 INFO] Step 79100/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 54046/5293 tok/s;  13979 sec
[2022-05-06 01:11:42,262 INFO] Weighted corpora loaded so far:
			* github: 1147
[2022-05-06 01:11:50,594 INFO] Step 79150/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52556/5117 tok/s;  13988 sec
[2022-05-06 01:11:53,590 INFO] Weighted corpora loaded so far:
			* github: 1148
[2022-05-06 01:11:59,417 INFO] Step 79200/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 50831/5263 tok/s;  13997 sec
[2022-05-06 01:12:04,977 INFO] Weighted corpora loaded so far:
			* github: 1149
[2022-05-06 01:12:08,300 INFO] Step 79250/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 51943/5046 tok/s;  14006 sec
[2022-05-06 01:12:16,264 INFO] Weighted corpora loaded so far:
			* github: 1150
[2022-05-06 01:12:17,318 INFO] Step 79300/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 52277/5251 tok/s;  14015 sec
[2022-05-06 01:12:25,874 INFO] Step 79350/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 54122/5207 tok/s;  14023 sec
[2022-05-06 01:12:27,557 INFO] Weighted corpora loaded so far:
			* github: 1151
[2022-05-06 01:12:34,793 INFO] Step 79400/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 51444/5161 tok/s;  14032 sec
[2022-05-06 01:12:38,912 INFO] Weighted corpora loaded so far:
			* github: 1152
[2022-05-06 01:12:43,611 INFO] Step 79450/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 51379/5209 tok/s;  14041 sec
[2022-05-06 01:12:50,194 INFO] Weighted corpora loaded so far:
			* github: 1153
[2022-05-06 01:12:52,523 INFO] Step 79500/100000; acc:  99.83; ppl:  1.01; xent: 0.01; lr: 0.00036; 51377/5146 tok/s;  14050 sec
[2022-05-06 01:13:01,207 INFO] Step 79550/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 54369/5310 tok/s;  14059 sec
[2022-05-06 01:13:01,556 INFO] Weighted corpora loaded so far:
			* github: 1154
[2022-05-06 01:13:10,244 INFO] Step 79600/100000; acc:  99.85; ppl:  1.00; xent: 0.00; lr: 0.00036; 52123/5140 tok/s;  14068 sec
[2022-05-06 01:13:12,914 INFO] Weighted corpora loaded so far:
			* github: 1155
[2022-05-06 01:13:19,057 INFO] Step 79650/100000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00036; 50812/5215 tok/s;  14077 sec
[2022-05-06 01:13:24,443 INFO] Weighted corpora loaded so far:
			* github: 1156
[2022-05-06 01:13:28,142 INFO] Step 79700/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 50342/5018 tok/s;  14086 sec
[2022-05-06 01:13:36,004 INFO] Weighted corpora loaded so far:
			* github: 1157
[2022-05-06 01:13:37,508 INFO] Step 79750/100000; acc:  99.85; ppl:  1.01; xent: 0.01; lr: 0.00036; 49726/4996 tok/s;  14095 sec
[2022-05-06 01:13:46,267 INFO] Step 79800/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 52424/5188 tok/s;  14104 sec
[2022-05-06 01:13:47,634 INFO] Weighted corpora loaded so far:
			* github: 1158
[2022-05-06 01:13:55,461 INFO] Step 79850/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 50794/4902 tok/s;  14113 sec
[2022-05-06 01:14:04,181 INFO] Step 79900/100000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00036; 51420/5296 tok/s;  14122 sec
[2022-05-06 01:14:10,337 INFO] Weighted corpora loaded so far:
			* github: 1159
[2022-05-06 01:14:13,005 INFO] Step 79950/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00036; 52065/5256 tok/s;  14131 sec
[2022-05-06 01:14:21,621 INFO] Step 80000/100000; acc:  99.84; ppl:  1.01; xent: 0.01; lr: 0.00033; 54599/5265 tok/s;  14139 sec
[2022-05-06 01:14:23,334 INFO] Validation perplexity: 662.939
[2022-05-06 01:14:23,334 INFO] Validation accuracy: 49.948
[2022-05-06 01:14:23,334 INFO] Decreasing patience: 0/2
[2022-05-06 01:14:23,334 INFO] Training finished after not improving. Early Stop!
[2022-05-06 01:14:23,334 INFO] Best model found at step 40000
[2022-05-06 01:14:23,425 INFO] Saving checkpoint /home/lgm/VRepair/param_sweep_tgt/0_parameter_sweep/model_step_80000.pt
[2022-05-17 19:49:58,699 INFO] Missing transforms field for github data, set to default: [].
[2022-05-17 19:49:58,699 WARNING] Corpus github's weight should be given. We default it to 1 for you.
[2022-05-17 19:49:58,699 INFO] Missing transforms field for valid data, set to default: [].
[2022-05-17 19:49:58,699 INFO] Parsed 2 corpora from -data.
[2022-05-17 19:49:58,699 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-05-17 19:49:58,699 INFO] Loading vocab from text file...
[2022-05-17 19:49:58,699 INFO] Loading src vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.src
[2022-05-17 19:49:58,743 INFO] Loaded src vocab has 36397 tokens.
[2022-05-17 19:49:58,752 INFO] Loading tgt vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.tgt
[2022-05-17 19:49:58,758 INFO] Loaded tgt vocab has 5924 tokens.
[2022-05-17 19:49:58,760 INFO] Building fields with vocab in counters...
[2022-05-17 19:49:58,762 INFO]  * tgt vocab size: 2004.
[2022-05-17 19:49:58,794 INFO]  * src vocab size: 2002.
[2022-05-17 19:49:58,795 INFO]  * src vocab size = 2002
[2022-05-17 19:49:58,795 INFO]  * tgt vocab size = 2004
[2022-05-17 19:49:58,795 INFO] Building model...
[2022-05-17 19:50:01,414 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2002, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2004, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=2004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2022-05-17 19:50:01,415 INFO] encoder: 2882304
[2022-05-17 19:50:01,415 INFO] decoder: 4189141
[2022-05-17 19:50:01,415 INFO] * number of parameters: 7071445
[2022-05-17 19:50:01,445 INFO] Starting training on GPU: [0]
[2022-05-17 19:50:01,445 INFO] Start training loop and validate every 20000 steps...
[2022-05-17 19:50:01,445 INFO] github's transforms: TransformPipe()
[2022-05-17 19:50:01,445 INFO] Weighted corpora loaded so far:
			* github: 1
/home/lgm/miniconda3/lib/python3.8/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  var = torch.tensor(arr, dtype=self.dtype, device=device)
Traceback (most recent call last):
  File "/home/lgm/miniconda3/bin/onmt_train", line 8, in <module>
    sys.exit(main())
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/bin/train.py", line 172, in main
    train(opt)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/bin/train.py", line 157, in train
    train_process(opt, device_id=0)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/train_single.py", line 109, in main
    trainer.train(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/trainer.py", line 242, in train
    self._gradient_accumulation(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/trainer.py", line 366, in _gradient_accumulation
    outputs, attns = self.model(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/models/model.py", line 63, in forward
    enc_state, memory_bank, lengths = self.encoder(src, lengths)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/encoders/transformer.py", line 138, in forward
    out = layer(out, mask)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/encoders/transformer.py", line 54, in forward
    context, _ = self.self_attn(input_norm, input_norm, input_norm,
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/modules/multi_headed_attn.py", line 203, in forward
    drop_attn = self.dropout(attn)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 1279, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 224.42 MiB already allocated; 5.56 MiB free; 256.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2022-05-17 19:52:22,944 INFO] Missing transforms field for github data, set to default: [].
[2022-05-17 19:52:22,944 WARNING] Corpus github's weight should be given. We default it to 1 for you.
[2022-05-17 19:52:22,944 INFO] Missing transforms field for valid data, set to default: [].
[2022-05-17 19:52:22,944 INFO] Parsed 2 corpora from -data.
[2022-05-17 19:52:22,944 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-05-17 19:52:22,944 INFO] Loading vocab from text file...
[2022-05-17 19:52:22,944 INFO] Loading src vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.src
[2022-05-17 19:52:22,990 INFO] Loaded src vocab has 36412 tokens.
[2022-05-17 19:52:22,999 INFO] Loading tgt vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.tgt
[2022-05-17 19:52:23,005 INFO] Loaded tgt vocab has 5924 tokens.
[2022-05-17 19:52:23,007 INFO] Building fields with vocab in counters...
[2022-05-17 19:52:23,009 INFO]  * tgt vocab size: 2004.
[2022-05-17 19:52:23,043 INFO]  * src vocab size: 2002.
[2022-05-17 19:52:23,044 INFO]  * src vocab size = 2002
[2022-05-17 19:52:23,044 INFO]  * tgt vocab size = 2004
[2022-05-17 19:52:23,045 INFO] Building model...
[2022-05-17 19:52:25,776 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2002, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2004, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=2004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2022-05-17 19:52:25,777 INFO] encoder: 2882304
[2022-05-17 19:52:25,777 INFO] decoder: 4189141
[2022-05-17 19:52:25,777 INFO] * number of parameters: 7071445
[2022-05-17 19:52:25,806 INFO] Starting training on GPU: [0]
[2022-05-17 19:52:25,806 INFO] Start training loop and validate every 20000 steps...
[2022-05-17 19:52:25,806 INFO] github's transforms: TransformPipe()
[2022-05-17 19:52:25,806 INFO] Weighted corpora loaded so far:
			* github: 1
/home/lgm/miniconda3/lib/python3.8/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  var = torch.tensor(arr, dtype=self.dtype, device=device)
Traceback (most recent call last):
  File "/home/lgm/miniconda3/bin/onmt_train", line 8, in <module>
    sys.exit(main())
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/bin/train.py", line 172, in main
    train(opt)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/bin/train.py", line 157, in train
    train_process(opt, device_id=0)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/train_single.py", line 109, in main
    trainer.train(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/trainer.py", line 242, in train
    self._gradient_accumulation(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/trainer.py", line 366, in _gradient_accumulation
    outputs, attns = self.model(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/models/model.py", line 63, in forward
    enc_state, memory_bank, lengths = self.encoder(src, lengths)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/encoders/transformer.py", line 138, in forward
    out = layer(out, mask)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/encoders/transformer.py", line 54, in forward
    context, _ = self.self_attn(input_norm, input_norm, input_norm,
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/modules/multi_headed_attn.py", line 203, in forward
    drop_attn = self.dropout(attn)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 1279, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
RuntimeError: CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 23.65 GiB total capacity; 250.60 MiB already allocated; 3.56 MiB free; 266.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2022-05-17 19:55:17,053 INFO] Missing transforms field for github data, set to default: [].
[2022-05-17 19:55:17,053 WARNING] Corpus github's weight should be given. We default it to 1 for you.
[2022-05-17 19:55:17,053 INFO] Missing transforms field for valid data, set to default: [].
[2022-05-17 19:55:17,053 INFO] Parsed 2 corpora from -data.
[2022-05-17 19:55:17,053 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-05-17 19:55:17,053 INFO] Loading vocab from text file...
[2022-05-17 19:55:17,053 INFO] Loading src vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.src
[2022-05-17 19:55:17,102 INFO] Loaded src vocab has 36427 tokens.
[2022-05-17 19:55:17,111 INFO] Loading tgt vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.tgt
[2022-05-17 19:55:17,118 INFO] Loaded tgt vocab has 5924 tokens.
[2022-05-17 19:55:17,120 INFO] Building fields with vocab in counters...
[2022-05-17 19:55:17,123 INFO]  * tgt vocab size: 2004.
[2022-05-17 19:55:17,156 INFO]  * src vocab size: 2002.
[2022-05-17 19:55:17,157 INFO]  * src vocab size = 2002
[2022-05-17 19:55:17,157 INFO]  * tgt vocab size = 2004
[2022-05-17 19:55:17,158 INFO] Building model...
[2022-05-17 19:55:19,832 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2002, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2004, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=2004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2022-05-17 19:55:19,833 INFO] encoder: 2882304
[2022-05-17 19:55:19,833 INFO] decoder: 4189141
[2022-05-17 19:55:19,833 INFO] * number of parameters: 7071445
[2022-05-17 19:55:19,861 INFO] Starting training on GPU: [0]
[2022-05-17 19:55:19,861 INFO] Start training loop and validate every 20000 steps...
[2022-05-17 19:55:19,861 INFO] github's transforms: TransformPipe()
[2022-05-17 19:55:19,861 INFO] Weighted corpora loaded so far:
			* github: 1
/home/lgm/miniconda3/lib/python3.8/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  var = torch.tensor(arr, dtype=self.dtype, device=device)
Traceback (most recent call last):
  File "/home/lgm/miniconda3/bin/onmt_train", line 8, in <module>
    sys.exit(main())
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/bin/train.py", line 172, in main
    train(opt)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/bin/train.py", line 157, in train
    train_process(opt, device_id=0)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/train_single.py", line 109, in main
    trainer.train(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/trainer.py", line 242, in train
    self._gradient_accumulation(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/trainer.py", line 366, in _gradient_accumulation
    outputs, attns = self.model(
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/models/model.py", line 63, in forward
    enc_state, memory_bank, lengths = self.encoder(src, lengths)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/encoders/transformer.py", line 138, in forward
    out = layer(out, mask)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/encoders/transformer.py", line 54, in forward
    context, _ = self.self_attn(input_norm, input_norm, input_norm,
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/onmt/modules/multi_headed_attn.py", line 202, in forward
    attn = self.softmax(scores).to(query.dtype)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1261, in forward
    return F.softmax(input, self.dim, _stacklevel=5)
  File "/home/lgm/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 1818, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 23.65 GiB total capacity; 211.70 MiB already allocated; 13.56 MiB free; 248.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2022-05-17 20:26:05,116 INFO] Missing transforms field for github data, set to default: [].
[2022-05-17 20:26:05,116 WARNING] Corpus github's weight should be given. We default it to 1 for you.
[2022-05-17 20:26:05,116 INFO] Missing transforms field for valid data, set to default: [].
[2022-05-17 20:26:05,116 INFO] Parsed 2 corpora from -data.
[2022-05-17 20:26:05,117 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.
[2022-05-17 20:26:05,117 INFO] Loading vocab from text file...
[2022-05-17 20:26:05,117 INFO] Loading src vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.src
[2022-05-17 20:26:05,160 INFO] Loaded src vocab has 36442 tokens.
[2022-05-17 20:26:05,169 INFO] Loading tgt vocabulary from /home/lgm/VRepair2.0/param_sweep_tgt/0_parameter_sweep/data.vocab.tgt
[2022-05-17 20:26:05,176 INFO] Loaded tgt vocab has 5924 tokens.
[2022-05-17 20:26:05,177 INFO] Building fields with vocab in counters...
[2022-05-17 20:26:05,180 INFO]  * tgt vocab size: 2004.
[2022-05-17 20:26:05,211 INFO]  * src vocab size: 2002.
[2022-05-17 20:26:05,212 INFO]  * src vocab size = 2002
[2022-05-17 20:26:05,212 INFO]  * tgt vocab size = 2004
[2022-05-17 20:26:05,212 INFO] Building model...
[2022-05-17 20:26:06,781 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2002, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(2004, 256, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=256, out_features=256, bias=True)
          (linear_values): Linear(in_features=256, out_features=256, bias=True)
          (linear_query): Linear(in_features=256, out_features=256, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=256, out_features=256, bias=True)
        )
        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=2004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2022-05-17 20:26:06,782 INFO] encoder: 2882304
[2022-05-17 20:26:06,782 INFO] decoder: 4189141
[2022-05-17 20:26:06,782 INFO] * number of parameters: 7071445
[2022-05-17 20:26:06,810 INFO] Starting training on GPU: [0]
[2022-05-17 20:26:06,810 INFO] Start training loop and validate every 20000 steps...
[2022-05-17 20:26:06,810 INFO] github's transforms: TransformPipe()
[2022-05-17 20:26:06,810 INFO] Weighted corpora loaded so far:
			* github: 1
/home/lgm/miniconda3/lib/python3.8/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  var = torch.tensor(arr, dtype=self.dtype, device=device)
[2022-05-17 20:26:15,725 INFO] Step 50/100000; acc:  12.88; ppl: 67.91; xent: 4.22; lr: 0.00050; 51429/5050 tok/s;      9 sec
[2022-05-17 20:26:18,115 INFO] Weighted corpora loaded so far:
			* github: 2
[2022-05-17 20:26:24,483 INFO] Step 100/100000; acc:  22.58; ppl: 28.07; xent: 3.33; lr: 0.00050; 53554/5256 tok/s;     18 sec
[2022-05-17 20:26:29,213 INFO] Weighted corpora loaded so far:
			* github: 3
[2022-05-17 20:26:33,325 INFO] Step 150/100000; acc:  28.35; ppl: 19.56; xent: 2.97; lr: 0.00050; 52433/5293 tok/s;     27 sec
[2022-05-17 20:26:40,457 INFO] Weighted corpora loaded so far:
			* github: 4
[2022-05-17 20:26:42,181 INFO] Step 200/100000; acc:  33.78; ppl: 14.58; xent: 2.68; lr: 0.00050; 52938/5194 tok/s;     35 sec
[2022-05-17 20:26:50,603 INFO] Step 250/100000; acc:  38.15; ppl: 11.81; xent: 2.47; lr: 0.00050; 53745/5400 tok/s;     44 sec
[2022-05-17 20:26:51,669 INFO] Weighted corpora loaded so far:
			* github: 5
[2022-05-17 20:26:59,406 INFO] Step 300/100000; acc:  41.50; ppl: 10.05; xent: 2.31; lr: 0.00050; 52698/5275 tok/s;     53 sec
[2022-05-17 20:27:02,825 INFO] Weighted corpora loaded so far:
			* github: 6
[2022-05-17 20:27:08,190 INFO] Step 350/100000; acc:  43.83; ppl:  8.84; xent: 2.18; lr: 0.00050; 52372/5200 tok/s;     61 sec
[2022-05-17 20:27:13,969 INFO] Weighted corpora loaded so far:
			* github: 7
[2022-05-17 20:27:17,047 INFO] Step 400/100000; acc:  46.96; ppl:  7.67; xent: 2.04; lr: 0.00050; 52829/5193 tok/s;     70 sec
[2022-05-17 20:27:25,294 INFO] Weighted corpora loaded so far:
			* github: 8
[2022-05-17 20:27:25,993 INFO] Step 450/100000; acc:  48.88; ppl:  7.01; xent: 1.95; lr: 0.00050; 50912/5052 tok/s;     79 sec
[2022-05-17 20:27:34,782 INFO] Step 500/100000; acc:  51.88; ppl:  6.07; xent: 1.80; lr: 0.00050; 52352/5209 tok/s;     88 sec
[2022-05-17 20:27:36,853 INFO] Weighted corpora loaded so far:
			* github: 9
[2022-05-17 20:27:43,585 INFO] Step 550/100000; acc:  53.91; ppl:  5.51; xent: 1.71; lr: 0.00050; 52193/5173 tok/s;     97 sec
[2022-05-17 20:27:48,090 INFO] Weighted corpora loaded so far:
			* github: 10
[2022-05-17 20:27:52,543 INFO] Step 600/100000; acc:  55.53; ppl:  5.17; xent: 1.64; lr: 0.00050; 52183/5198 tok/s;    106 sec
[2022-05-17 20:27:59,405 INFO] Weighted corpora loaded so far:
			* github: 11
[2022-05-17 20:28:01,471 INFO] Step 650/100000; acc:  57.17; ppl:  4.75; xent: 1.56; lr: 0.00050; 52125/5220 tok/s;    115 sec
[2022-05-17 20:28:09,935 INFO] Step 700/100000; acc:  59.54; ppl:  4.32; xent: 1.46; lr: 0.00050; 53429/5436 tok/s;    123 sec
[2022-05-17 20:28:10,659 INFO] Weighted corpora loaded so far:
			* github: 12
[2022-05-17 20:28:18,777 INFO] Step 750/100000; acc:  61.45; ppl:  3.94; xent: 1.37; lr: 0.00050; 51852/5201 tok/s;    132 sec
[2022-05-17 20:28:21,937 INFO] Weighted corpora loaded so far:
			* github: 13
[2022-05-17 20:28:27,595 INFO] Step 800/100000; acc:  62.89; ppl:  3.72; xent: 1.31; lr: 0.00050; 52081/5139 tok/s;    141 sec
