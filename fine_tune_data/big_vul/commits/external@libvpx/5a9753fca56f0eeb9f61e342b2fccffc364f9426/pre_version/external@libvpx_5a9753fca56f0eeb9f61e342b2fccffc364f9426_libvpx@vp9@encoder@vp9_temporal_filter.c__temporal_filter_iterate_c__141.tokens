static void temporal_filter_iterate_c ( VP9_COMP * cpi , //<S2SV> int frame_count , //<S2SV> int alt_ref_index , //<S2SV> int strength , //<S2SV> struct scale_factors * scale ) { //<S2SV> int byte ; //<S2SV> int frame ; //<S2SV> int mb_col , mb_row ; //<S2SV> unsigned int filter_weight ; //<S2SV> int mb_cols = cpi -> common . mb_cols ; //<S2SV> int mb_rows = cpi -> common . mb_rows ; //<S2SV> int mb_y_offset = 0 ; //<S2SV> int mb_uv_offset = 0 ; //<S2SV> DECLARE_ALIGNED_ARRAY ( 16 , unsigned int , accumulator , 16 * 16 * 3 ) ; //<S2SV> DECLARE_ALIGNED_ARRAY ( 16 , uint16_t , count , 16 * 16 * 3 ) ; //<S2SV> MACROBLOCKD * mbd = & cpi -> mb . e_mbd ; //<S2SV> YV12_BUFFER_CONFIG * f = cpi -> frames [ alt_ref_index ] ; //<S2SV> uint8_t * dst1 , * dst2 ; //<S2SV> DECLARE_ALIGNED_ARRAY ( 16 , uint8_t , predictor , 16 * 16 * 3 ) ; //<S2SV> const int mb_uv_height = 16 >> mbd -> plane [ 1 ] . subsampling_y ; //<S2SV> uint8_t * input_buffer [ MAX_MB_PLANE ] ; //<S2SV> int i ; //<S2SV> assert ( mbd -> plane [ 1 ] . subsampling_x == mbd -> plane [ 1 ] . subsampling_y ) ; //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) //<S2SV> input_buffer [ i ] = mbd -> plane [ i ] . pre [ 0 ] . buf ; //<S2SV> for ( mb_row = 0 ; mb_row < mb_rows ; mb_row ++ ) { //<S2SV> # if ALT_REF_MC_ENABLED //<S2SV> cpi -> mb . mv_row_min = - ( ( mb_row * 16 ) + ( 17 - 2 * VP9_INTERP_EXTEND ) ) ; //<S2SV> cpi -> mb . mv_row_max = ( ( cpi -> common . mb_rows - 1 - mb_row ) * 16 ) //<S2SV> + ( 17 - 2 * VP9_INTERP_EXTEND ) ; //<S2SV> # endif //<S2SV> for ( mb_col = 0 ; mb_col < mb_cols ; mb_col ++ ) { //<S2SV> int i , j , k ; //<S2SV> int stride ; //<S2SV> vpx_memset ( accumulator , 0 , 16 * 16 * 3 * sizeof ( accumulator [ 0 ] ) ) ; //<S2SV> vpx_memset ( count , 0 , 16 * 16 * 3 * sizeof ( count [ 0 ] ) ) ; //<S2SV> # if ALT_REF_MC_ENABLED //<S2SV> cpi -> mb . mv_col_min = - ( ( mb_col * 16 ) + ( 17 - 2 * VP9_INTERP_EXTEND ) ) ; //<S2SV> cpi -> mb . mv_col_max = ( ( cpi -> common . mb_cols - 1 - mb_col ) * 16 ) //<S2SV> + ( 17 - 2 * VP9_INTERP_EXTEND ) ; //<S2SV> # endif //<S2SV> for ( frame = 0 ; frame < frame_count ; frame ++ ) { //<S2SV> if ( cpi -> frames [ frame ] == NULL ) //<S2SV> continue ; //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . row = 0 ; //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . col = 0 ; //<S2SV> if ( frame == alt_ref_index ) { //<S2SV> filter_weight = 2 ; //<S2SV> } else { //<S2SV> int err = 0 ; //<S2SV> # if ALT_REF_MC_ENABLED //<S2SV> # define THRESH_LOW 10000 //<S2SV> # define THRESH_HIGH 20000 //<S2SV> err = temporal_filter_find_matching_mb_c //<S2SV> ( cpi , //<S2SV> cpi -> frames [ alt_ref_index ] -> y_buffer + mb_y_offset , //<S2SV> cpi -> frames [ frame ] -> y_buffer + mb_y_offset , //<S2SV> cpi -> frames [ frame ] -> y_stride ) ; //<S2SV> # endif //<S2SV> filter_weight = err < THRESH_LOW //<S2SV> ? 2 : err < THRESH_HIGH ? 1 : 0 ; //<S2SV> } //<S2SV> if ( filter_weight != 0 ) { //<S2SV> temporal_filter_predictors_mb_c //<S2SV> ( mbd , //<S2SV> cpi -> frames [ frame ] -> y_buffer + mb_y_offset , //<S2SV> cpi -> frames [ frame ] -> u_buffer + mb_uv_offset , //<S2SV> cpi -> frames [ frame ] -> v_buffer + mb_uv_offset , //<S2SV> cpi -> frames [ frame ] -> y_stride , //<S2SV> mb_uv_height , //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . row , //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . col , //<S2SV> predictor , scale , //<S2SV> mb_col * 16 , mb_row * 16 ) ; //<S2SV> vp9_temporal_filter_apply ( f -> y_buffer + mb_y_offset , f -> y_stride , //<S2SV> predictor , 16 , strength , filter_weight , //<S2SV> accumulator , count ) ; //<S2SV> vp9_temporal_filter_apply ( f -> u_buffer + mb_uv_offset , f -> uv_stride , //<S2SV> predictor + 256 , mb_uv_height , strength , //<S2SV> filter_weight , accumulator + 256 , //<S2SV> count + 256 ) ; //<S2SV> vp9_temporal_filter_apply ( f -> v_buffer + mb_uv_offset , f -> uv_stride , //<S2SV> predictor + 512 , mb_uv_height , strength , //<S2SV> filter_weight , accumulator + 512 , //<S2SV> count + 512 ) ; //<S2SV> } //<S2SV> } //<S2SV> dst1 = cpi -> alt_ref_buffer . y_buffer ; //<S2SV> stride = cpi -> alt_ref_buffer . y_stride ; //<S2SV> byte = mb_y_offset ; //<S2SV> for ( i = 0 , k = 0 ; i < 16 ; i ++ ) { //<S2SV> for ( j = 0 ; j < 16 ; j ++ , k ++ ) { //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= cpi -> fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1 [ byte ] = ( uint8_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - 16 ; //<S2SV> } //<S2SV> dst1 = cpi -> alt_ref_buffer . u_buffer ; //<S2SV> dst2 = cpi -> alt_ref_buffer . v_buffer ; //<S2SV> stride = cpi -> alt_ref_buffer . uv_stride ; //<S2SV> byte = mb_uv_offset ; //<S2SV> for ( i = 0 , k = 256 ; i < mb_uv_height ; i ++ ) { //<S2SV> for ( j = 0 ; j < mb_uv_height ; j ++ , k ++ ) { //<S2SV> int m = k + 256 ; //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= cpi -> fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1 [ byte ] = ( uint8_t ) pval ; //<S2SV> pval = accumulator [ m ] + ( count [ m ] >> 1 ) ; //<S2SV> pval *= cpi -> fixed_divide [ count [ m ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst2 [ byte ] = ( uint8_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - mb_uv_height ; //<S2SV> } //<S2SV> mb_y_offset += 16 ; //<S2SV> mb_uv_offset += mb_uv_height ; //<S2SV> } //<S2SV> mb_y_offset += 16 * ( f -> y_stride - mb_cols ) ; //<S2SV> mb_uv_offset += mb_uv_height * ( f -> uv_stride - mb_cols ) ; //<S2SV> } //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) //<S2SV> mbd -> plane [ i ] . pre [ 0 ] . buf = input_buffer [ i ] ; //<S2SV> } //<S2SV> 