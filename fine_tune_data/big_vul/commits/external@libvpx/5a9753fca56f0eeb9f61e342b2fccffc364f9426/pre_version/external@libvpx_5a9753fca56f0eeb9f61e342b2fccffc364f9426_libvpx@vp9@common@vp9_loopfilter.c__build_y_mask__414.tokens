static void build_y_mask ( const loop_filter_info_n * const lfi_n , //<S2SV> const MODE_INFO * mi , const int shift_y , //<S2SV> LOOP_FILTER_MASK * lfm ) { //<S2SV> const MB_MODE_INFO * mbmi = & mi -> mbmi ; //<S2SV> const BLOCK_SIZE block_size = mbmi -> sb_type ; //<S2SV> const TX_SIZE tx_size_y = mbmi -> tx_size ; //<S2SV> const int filter_level = get_filter_level ( lfi_n , mbmi ) ; //<S2SV> uint64_t * const left_y = & lfm -> left_y [ tx_size_y ] ; //<S2SV> uint64_t * const above_y = & lfm -> above_y [ tx_size_y ] ; //<S2SV> uint64_t * const int_4x4_y = & lfm -> int_4x4_y ; //<S2SV> int i ; //<S2SV> if ( ! filter_level ) { //<S2SV> return ; //<S2SV> } else { //<S2SV> const int w = num_8x8_blocks_wide_lookup [ block_size ] ; //<S2SV> const int h = num_8x8_blocks_high_lookup [ block_size ] ; //<S2SV> int index = shift_y ; //<S2SV> for ( i = 0 ; i < h ; i ++ ) { //<S2SV> vpx_memset ( & lfm -> lfl_y [ index ] , filter_level , w ) ; //<S2SV> index += 8 ; //<S2SV> } //<S2SV> } //<S2SV> * above_y |= above_prediction_mask [ block_size ] << shift_y ; //<S2SV> * left_y |= left_prediction_mask [ block_size ] << shift_y ; //<S2SV> if ( mbmi -> skip && is_inter_block ( mbmi ) ) //<S2SV> return ; //<S2SV> * above_y |= ( size_mask [ block_size ] & //<S2SV> above_64x64_txform_mask [ tx_size_y ] ) << shift_y ; //<S2SV> * left_y |= ( size_mask [ block_size ] & //<S2SV> left_64x64_txform_mask [ tx_size_y ] ) << shift_y ; //<S2SV> if ( tx_size_y == TX_4X4 ) //<S2SV> * int_4x4_y |= ( size_mask [ block_size ] & 0xffffffffffffffff ) << shift_y ; //<S2SV> } //<S2SV> 