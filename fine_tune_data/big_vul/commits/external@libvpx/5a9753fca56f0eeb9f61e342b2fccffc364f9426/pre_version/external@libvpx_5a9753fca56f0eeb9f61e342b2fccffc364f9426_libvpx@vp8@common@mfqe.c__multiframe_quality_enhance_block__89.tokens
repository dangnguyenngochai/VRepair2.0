static void multiframe_quality_enhance_block //<S2SV> ( //<S2SV> int blksize , //<S2SV> int qcurr , //<S2SV> int qprev , //<S2SV> unsigned char * y , //<S2SV> unsigned char * u , //<S2SV> unsigned char * v , //<S2SV> int y_stride , //<S2SV> int uv_stride , //<S2SV> unsigned char * yd , //<S2SV> unsigned char * ud , //<S2SV> unsigned char * vd , //<S2SV> int yd_stride , //<S2SV> int uvd_stride //<S2SV> ) //<S2SV> { //<S2SV> static const unsigned char VP8_ZEROS [ 16 ] = //<S2SV> { //<S2SV> 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 //<S2SV> } ; //<S2SV> int uvblksize = blksize >> 1 ; //<S2SV> int qdiff = qcurr - qprev ; //<S2SV> int i ; //<S2SV> unsigned char * up ; //<S2SV> unsigned char * udp ; //<S2SV> unsigned char * vp ; //<S2SV> unsigned char * vdp ; //<S2SV> unsigned int act , actd , sad , usad , vsad , sse , thr , thrsq , actrisk ; //<S2SV> if ( blksize == 16 ) //<S2SV> { //<S2SV> actd = ( vp8_variance16x16 ( yd , yd_stride , VP8_ZEROS , 0 , & sse ) + 128 ) >> 8 ; //<S2SV> act = ( vp8_variance16x16 ( y , y_stride , VP8_ZEROS , 0 , & sse ) + 128 ) >> 8 ; //<S2SV> # ifdef USE_SSD //<S2SV> sad = ( vp8_variance16x16 ( y , y_stride , yd , yd_stride , & sse ) ) ; //<S2SV> sad = ( sse + 128 ) >> 8 ; //<S2SV> usad = ( vp8_variance8x8 ( u , uv_stride , ud , uvd_stride , & sse ) ) ; //<S2SV> usad = ( sse + 32 ) >> 6 ; //<S2SV> vsad = ( vp8_variance8x8 ( v , uv_stride , vd , uvd_stride , & sse ) ) ; //<S2SV> vsad = ( sse + 32 ) >> 6 ; //<S2SV> # else //<S2SV> sad = ( vp8_sad16x16 ( y , y_stride , yd , yd_stride , UINT_MAX ) + 128 ) >> 8 ; //<S2SV> usad = ( vp8_sad8x8 ( u , uv_stride , ud , uvd_stride , UINT_MAX ) + 32 ) >> 6 ; //<S2SV> vsad = ( vp8_sad8x8 ( v , uv_stride , vd , uvd_stride , UINT_MAX ) + 32 ) >> 6 ; //<S2SV> # endif //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> actd = ( vp8_variance8x8 ( yd , yd_stride , VP8_ZEROS , 0 , & sse ) + 32 ) >> 6 ; //<S2SV> act = ( vp8_variance8x8 ( y , y_stride , VP8_ZEROS , 0 , & sse ) + 32 ) >> 6 ; //<S2SV> # ifdef USE_SSD //<S2SV> sad = ( vp8_variance8x8 ( y , y_stride , yd , yd_stride , & sse ) ) ; //<S2SV> sad = ( sse + 32 ) >> 6 ; //<S2SV> usad = ( vp8_variance4x4 ( u , uv_stride , ud , uvd_stride , & sse ) ) ; //<S2SV> usad = ( sse + 8 ) >> 4 ; //<S2SV> vsad = ( vp8_variance4x4 ( v , uv_stride , vd , uvd_stride , & sse ) ) ; //<S2SV> vsad = ( sse + 8 ) >> 4 ; //<S2SV> # else //<S2SV> sad = ( vp8_sad8x8 ( y , y_stride , yd , yd_stride , UINT_MAX ) + 32 ) >> 6 ; //<S2SV> usad = ( vp8_sad4x4 ( u , uv_stride , ud , uvd_stride , UINT_MAX ) + 8 ) >> 4 ; //<S2SV> vsad = ( vp8_sad4x4 ( v , uv_stride , vd , uvd_stride , UINT_MAX ) + 8 ) >> 4 ; //<S2SV> # endif //<S2SV> } //<S2SV> actrisk = ( actd > act * 5 ) ; //<S2SV> thr = ( qdiff >> 4 ) ; //<S2SV> while ( actd >>= 1 ) thr ++ ; //<S2SV> while ( qprev >>= 2 ) thr ++ ; //<S2SV> # ifdef USE_SSD //<S2SV> thrsq = thr * thr ; //<S2SV> if ( sad < thrsq && //<S2SV> 4 * usad < thrsq && 4 * vsad < thrsq && ! actrisk ) //<S2SV> # else //<S2SV> if ( sad < thr && //<S2SV> 2 * usad < thr && 2 * vsad < thr && ! actrisk ) //<S2SV> # endif //<S2SV> { //<S2SV> int ifactor ; //<S2SV> # ifdef USE_SSD //<S2SV> sad = int_sqrt ( sad ) ; //<S2SV> # endif //<S2SV> ifactor = ( sad << MFQE_PRECISION ) / thr ; //<S2SV> ifactor >>= ( qdiff >> 5 ) ; //<S2SV> if ( ifactor ) //<S2SV> { //<S2SV> apply_ifactor ( y , y_stride , yd , yd_stride , //<S2SV> u , v , uv_stride , //<S2SV> ud , vd , uvd_stride , //<S2SV> blksize , ifactor ) ; //<S2SV> } //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> if ( blksize == 16 ) //<S2SV> { //<S2SV> vp8_copy_mem16x16 ( y , y_stride , yd , yd_stride ) ; //<S2SV> vp8_copy_mem8x8 ( u , uv_stride , ud , uvd_stride ) ; //<S2SV> vp8_copy_mem8x8 ( v , uv_stride , vd , uvd_stride ) ; //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> vp8_copy_mem8x8 ( y , y_stride , yd , yd_stride ) ; //<S2SV> for ( up = u , udp = ud , i = 0 ; i < uvblksize ; ++ i , up += uv_stride , udp += uvd_stride ) //<S2SV> vpx_memcpy ( udp , up , uvblksize ) ; //<S2SV> for ( vp = v , vdp = vd , i = 0 ; i < uvblksize ; ++ i , vp += uv_stride , vdp += uvd_stride ) //<S2SV> vpx_memcpy ( vdp , vp , uvblksize ) ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> 