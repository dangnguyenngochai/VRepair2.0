static int64_t handle_inter_mode ( VP9_COMP * cpi , MACROBLOCK * x , //<S2SV> BLOCK_SIZE bsize , //<S2SV> int * rate2 , int64_t * distortion , //<S2SV> int * skippable , //<S2SV> int * rate_y , int * rate_uv , //<S2SV> int * disable_skip , //<S2SV> int_mv ( * mode_mv ) [ MAX_REF_FRAMES ] , //<S2SV> int mi_row , int mi_col , //<S2SV> int_mv single_newmv [ MAX_REF_FRAMES ] , //<S2SV> INTERP_FILTER ( * single_filter ) [ MAX_REF_FRAMES ] , //<S2SV> int ( * single_skippable ) [ MAX_REF_FRAMES ] , //<S2SV> int64_t * psse , //<S2SV> const int64_t ref_best_rd , //<S2SV> int64_t * mask_filter , //<S2SV> int64_t filter_cache [ ] ) { //<S2SV> VP9_COMMON * cm = & cpi -> common ; //<S2SV> MACROBLOCKD * xd = & x -> e_mbd ; //<S2SV> MB_MODE_INFO * mbmi = & xd -> mi [ 0 ] -> mbmi ; //<S2SV> MB_MODE_INFO_EXT * const mbmi_ext = x -> mbmi_ext ; //<S2SV> const int is_comp_pred = has_second_ref ( mbmi ) ; //<S2SV> const int this_mode = mbmi -> mode ; //<S2SV> int_mv * frame_mv = mode_mv [ this_mode ] ; //<S2SV> int i ; //<S2SV> int refs [ 2 ] = { mbmi -> ref_frame [ 0 ] , //<S2SV> ( mbmi -> ref_frame [ 1 ] < 0 ? 0 : mbmi -> ref_frame [ 1 ] ) } ; //<S2SV> int_mv cur_mv [ 2 ] ; //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> DECLARE_ALIGNED ( 16 , uint16_t , tmp_buf16 [ MAX_MB_PLANE * 64 * 64 ] ) ; //<S2SV> uint8_t * tmp_buf ; //<S2SV> # else //<S2SV> DECLARE_ALIGNED ( 16 , uint8_t , tmp_buf [ MAX_MB_PLANE * 64 * 64 ] ) ; //<S2SV> # endif //<S2SV> int pred_exists = 0 ; //<S2SV> int intpel_mv ; //<S2SV> int64_t rd , tmp_rd , best_rd = INT64_MAX ; //<S2SV> int best_needs_copy = 0 ; //<S2SV> uint8_t * orig_dst [ MAX_MB_PLANE ] ; //<S2SV> int orig_dst_stride [ MAX_MB_PLANE ] ; //<S2SV> int rs = 0 ; //<S2SV> INTERP_FILTER best_filter = SWITCHABLE ; //<S2SV> uint8_t skip_txfm [ MAX_MB_PLANE << 2 ] = { 0 } ; //<S2SV> int64_t bsse [ MAX_MB_PLANE << 2 ] = { 0 } ; //<S2SV> int bsl = mi_width_log2_lookup [ bsize ] ; //<S2SV> int pred_filter_search = cpi -> sf . cb_pred_filter_search ? //<S2SV> ( ( ( mi_row + mi_col ) >> bsl ) + //<S2SV> get_chessboard_index ( cm -> current_video_frame ) ) & 0x1 : 0 ; //<S2SV> int skip_txfm_sb = 0 ; //<S2SV> int64_t skip_sse_sb = INT64_MAX ; //<S2SV> int64_t distortion_y = 0 , distortion_uv = 0 ; //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> if ( xd -> cur_buf -> flags & YV12_FLAG_HIGHBITDEPTH ) { //<S2SV> tmp_buf = CONVERT_TO_BYTEPTR ( tmp_buf16 ) ; //<S2SV> } else { //<S2SV> tmp_buf = ( uint8_t * ) tmp_buf16 ; //<S2SV> } //<S2SV> # endif //<S2SV> if ( pred_filter_search ) { //<S2SV> INTERP_FILTER af = SWITCHABLE , lf = SWITCHABLE ; //<S2SV> if ( xd -> up_available ) //<S2SV> af = xd -> mi [ - xd -> mi_stride ] -> mbmi . interp_filter ; //<S2SV> if ( xd -> left_available ) //<S2SV> lf = xd -> mi [ - 1 ] -> mbmi . interp_filter ; //<S2SV> if ( ( this_mode != NEWMV ) || ( af == lf ) ) //<S2SV> best_filter = af ; //<S2SV> } //<S2SV> if ( is_comp_pred ) { //<S2SV> if ( frame_mv [ refs [ 0 ] ] . as_int == INVALID_MV || //<S2SV> frame_mv [ refs [ 1 ] ] . as_int == INVALID_MV ) //<S2SV> return INT64_MAX ; //<S2SV> if ( cpi -> sf . adaptive_mode_search ) { //<S2SV> if ( single_filter [ this_mode ] [ refs [ 0 ] ] == //<S2SV> single_filter [ this_mode ] [ refs [ 1 ] ] ) //<S2SV> best_filter = single_filter [ this_mode ] [ refs [ 0 ] ] ; //<S2SV> } //<S2SV> } //<S2SV> if ( this_mode == NEWMV ) { //<S2SV> int rate_mv ; //<S2SV> if ( is_comp_pred ) { //<S2SV> frame_mv [ refs [ 0 ] ] . as_int = single_newmv [ refs [ 0 ] ] . as_int ; //<S2SV> frame_mv [ refs [ 1 ] ] . as_int = single_newmv [ refs [ 1 ] ] . as_int ; //<S2SV> if ( cpi -> sf . comp_inter_joint_search_thresh <= bsize ) { //<S2SV> joint_motion_search ( cpi , x , bsize , frame_mv , //<S2SV> mi_row , mi_col , single_newmv , & rate_mv ) ; //<S2SV> } else { //<S2SV> rate_mv = vp9_mv_bit_cost ( & frame_mv [ refs [ 0 ] ] . as_mv , //<S2SV> & x -> mbmi_ext -> ref_mvs [ refs [ 0 ] ] [ 0 ] . as_mv , //<S2SV> x -> nmvjointcost , x -> mvcost , MV_COST_WEIGHT ) ; //<S2SV> rate_mv += vp9_mv_bit_cost ( & frame_mv [ refs [ 1 ] ] . as_mv , //<S2SV> & x -> mbmi_ext -> ref_mvs [ refs [ 1 ] ] [ 0 ] . as_mv , //<S2SV> x -> nmvjointcost , x -> mvcost , MV_COST_WEIGHT ) ; //<S2SV> } //<S2SV> * rate2 += rate_mv ; //<S2SV> } else { //<S2SV> int_mv tmp_mv ; //<S2SV> single_motion_search ( cpi , x , bsize , mi_row , mi_col , //<S2SV> & tmp_mv , & rate_mv ) ; //<S2SV> if ( tmp_mv . as_int == INVALID_MV ) //<S2SV> return INT64_MAX ; //<S2SV> frame_mv [ refs [ 0 ] ] . as_int = //<S2SV> xd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_int = tmp_mv . as_int ; //<S2SV> single_newmv [ refs [ 0 ] ] . as_int = tmp_mv . as_int ; //<S2SV> if ( discount_newmv_test ( cpi , this_mode , tmp_mv , mode_mv , refs [ 0 ] ) ) { //<S2SV> * rate2 += MAX ( ( rate_mv / NEW_MV_DISCOUNT_FACTOR ) , 1 ) ; //<S2SV> } else { //<S2SV> * rate2 += rate_mv ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> for ( i = 0 ; i < is_comp_pred + 1 ; ++ i ) { //<S2SV> cur_mv [ i ] = frame_mv [ refs [ i ] ] ; //<S2SV> if ( this_mode != NEWMV ) //<S2SV> clamp_mv2 ( & cur_mv [ i ] . as_mv , xd ) ; //<S2SV> if ( mv_check_bounds ( x , & cur_mv [ i ] . as_mv ) ) //<S2SV> return INT64_MAX ; //<S2SV> mbmi -> mv [ i ] . as_int = cur_mv [ i ] . as_int ; //<S2SV> } //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) { //<S2SV> orig_dst [ i ] = xd -> plane [ i ] . dst . buf ; //<S2SV> orig_dst_stride [ i ] = xd -> plane [ i ] . dst . stride ; //<S2SV> } //<S2SV> if ( discount_newmv_test ( cpi , this_mode , frame_mv [ refs [ 0 ] ] , //<S2SV> mode_mv , refs [ 0 ] ) ) { //<S2SV> * rate2 += MIN ( cost_mv_ref ( cpi , this_mode , //<S2SV> mbmi_ext -> mode_context [ refs [ 0 ] ] ) , //<S2SV> cost_mv_ref ( cpi , NEARESTMV , //<S2SV> mbmi_ext -> mode_context [ refs [ 0 ] ] ) ) ; //<S2SV> } else { //<S2SV> * rate2 += cost_mv_ref ( cpi , this_mode , mbmi_ext -> mode_context [ refs [ 0 ] ] ) ; //<S2SV> } //<S2SV> if ( RDCOST ( x -> rdmult , x -> rddiv , * rate2 , 0 ) > ref_best_rd && //<S2SV> mbmi -> mode != NEARESTMV ) //<S2SV> return INT64_MAX ; //<S2SV> pred_exists = 0 ; //<S2SV> intpel_mv = ! mv_has_subpel ( & mbmi -> mv [ 0 ] . as_mv ) ; //<S2SV> if ( is_comp_pred ) //<S2SV> intpel_mv &= ! mv_has_subpel ( & mbmi -> mv [ 1 ] . as_mv ) ; //<S2SV> for ( i = 0 ; i < SWITCHABLE_FILTER_CONTEXTS ; ++ i ) //<S2SV> filter_cache [ i ] = INT64_MAX ; //<S2SV> if ( cm -> interp_filter != BILINEAR ) { //<S2SV> if ( x -> source_variance < cpi -> sf . disable_filter_search_var_thresh ) { //<S2SV> best_filter = EIGHTTAP ; //<S2SV> } else if ( best_filter == SWITCHABLE ) { //<S2SV> int newbest ; //<S2SV> int tmp_rate_sum = 0 ; //<S2SV> int64_t tmp_dist_sum = 0 ; //<S2SV> for ( i = 0 ; i < SWITCHABLE_FILTERS ; ++ i ) { //<S2SV> int j ; //<S2SV> int64_t rs_rd ; //<S2SV> int tmp_skip_sb = 0 ; //<S2SV> int64_t tmp_skip_sse = INT64_MAX ; //<S2SV> mbmi -> interp_filter = i ; //<S2SV> rs = vp9_get_switchable_rate ( cpi , xd ) ; //<S2SV> rs_rd = RDCOST ( x -> rdmult , x -> rddiv , rs , 0 ) ; //<S2SV> if ( i > 0 && intpel_mv ) { //<S2SV> rd = RDCOST ( x -> rdmult , x -> rddiv , tmp_rate_sum , tmp_dist_sum ) ; //<S2SV> filter_cache [ i ] = rd ; //<S2SV> filter_cache [ SWITCHABLE_FILTERS ] = //<S2SV> MIN ( filter_cache [ SWITCHABLE_FILTERS ] , rd + rs_rd ) ; //<S2SV> if ( cm -> interp_filter == SWITCHABLE ) //<S2SV> rd += rs_rd ; //<S2SV> * mask_filter = MAX ( * mask_filter , rd ) ; //<S2SV> } else { //<S2SV> int rate_sum = 0 ; //<S2SV> int64_t dist_sum = 0 ; //<S2SV> if ( i > 0 && cpi -> sf . adaptive_interp_filter_search && //<S2SV> ( cpi -> sf . interp_filter_search_mask & ( 1 << i ) ) ) { //<S2SV> rate_sum = INT_MAX ; //<S2SV> dist_sum = INT64_MAX ; //<S2SV> continue ; //<S2SV> } //<S2SV> if ( ( cm -> interp_filter == SWITCHABLE && //<S2SV> ( ! i || best_needs_copy ) ) || //<S2SV> ( cm -> interp_filter != SWITCHABLE && //<S2SV> ( cm -> interp_filter == mbmi -> interp_filter || //<S2SV> ( i == 0 && intpel_mv ) ) ) ) { //<S2SV> restore_dst_buf ( xd , orig_dst , orig_dst_stride ) ; //<S2SV> } else { //<S2SV> for ( j = 0 ; j < MAX_MB_PLANE ; j ++ ) { //<S2SV> xd -> plane [ j ] . dst . buf = tmp_buf + j * 64 * 64 ; //<S2SV> xd -> plane [ j ] . dst . stride = 64 ; //<S2SV> } //<S2SV> } //<S2SV> vp9_build_inter_predictors_sb ( xd , mi_row , mi_col , bsize ) ; //<S2SV> model_rd_for_sb ( cpi , bsize , x , xd , & rate_sum , & dist_sum , //<S2SV> & tmp_skip_sb , & tmp_skip_sse ) ; //<S2SV> rd = RDCOST ( x -> rdmult , x -> rddiv , rate_sum , dist_sum ) ; //<S2SV> filter_cache [ i ] = rd ; //<S2SV> filter_cache [ SWITCHABLE_FILTERS ] = //<S2SV> MIN ( filter_cache [ SWITCHABLE_FILTERS ] , rd + rs_rd ) ; //<S2SV> if ( cm -> interp_filter == SWITCHABLE ) //<S2SV> rd += rs_rd ; //<S2SV> * mask_filter = MAX ( * mask_filter , rd ) ; //<S2SV> if ( i == 0 && intpel_mv ) { //<S2SV> tmp_rate_sum = rate_sum ; //<S2SV> tmp_dist_sum = dist_sum ; //<S2SV> } //<S2SV> } //<S2SV> if ( i == 0 && cpi -> sf . use_rd_breakout && ref_best_rd < INT64_MAX ) { //<S2SV> if ( rd / 2 > ref_best_rd ) { //<S2SV> restore_dst_buf ( xd , orig_dst , orig_dst_stride ) ; //<S2SV> return INT64_MAX ; //<S2SV> } //<S2SV> } //<S2SV> newbest = i == 0 || rd < best_rd ; //<S2SV> if ( newbest ) { //<S2SV> best_rd = rd ; //<S2SV> best_filter = mbmi -> interp_filter ; //<S2SV> if ( cm -> interp_filter == SWITCHABLE && i && ! intpel_mv ) //<S2SV> best_needs_copy = ! best_needs_copy ; //<S2SV> } //<S2SV> if ( ( cm -> interp_filter == SWITCHABLE && newbest ) || //<S2SV> ( cm -> interp_filter != SWITCHABLE && //<S2SV> cm -> interp_filter == mbmi -> interp_filter ) ) { //<S2SV> pred_exists = 1 ; //<S2SV> tmp_rd = best_rd ; //<S2SV> skip_txfm_sb = tmp_skip_sb ; //<S2SV> skip_sse_sb = tmp_skip_sse ; //<S2SV> memcpy ( skip_txfm , x -> skip_txfm , sizeof ( skip_txfm ) ) ; //<S2SV> memcpy ( bsse , x -> bsse , sizeof ( bsse ) ) ; //<S2SV> } //<S2SV> } //<S2SV> restore_dst_buf ( xd , orig_dst , orig_dst_stride ) ; //<S2SV> } //<S2SV> } //<S2SV> mbmi -> interp_filter = cm -> interp_filter != SWITCHABLE ? //<S2SV> cm -> interp_filter : best_filter ; //<S2SV> rs = cm -> interp_filter == SWITCHABLE ? vp9_get_switchable_rate ( cpi , xd ) : 0 ; //<S2SV> if ( pred_exists ) { //<S2SV> if ( best_needs_copy ) { //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) { //<S2SV> xd -> plane [ i ] . dst . buf = tmp_buf + i * 64 * 64 ; //<S2SV> xd -> plane [ i ] . dst . stride = 64 ; //<S2SV> } //<S2SV> } //<S2SV> rd = tmp_rd + RDCOST ( x -> rdmult , x -> rddiv , rs , 0 ) ; //<S2SV> } else { //<S2SV> int tmp_rate ; //<S2SV> int64_t tmp_dist ; //<S2SV> vp9_build_inter_predictors_sb ( xd , mi_row , mi_col , bsize ) ; //<S2SV> model_rd_for_sb ( cpi , bsize , x , xd , & tmp_rate , & tmp_dist , //<S2SV> & skip_txfm_sb , & skip_sse_sb ) ; //<S2SV> rd = RDCOST ( x -> rdmult , x -> rddiv , rs + tmp_rate , tmp_dist ) ; //<S2SV> memcpy ( skip_txfm , x -> skip_txfm , sizeof ( skip_txfm ) ) ; //<S2SV> memcpy ( bsse , x -> bsse , sizeof ( bsse ) ) ; //<S2SV> } //<S2SV> if ( ! is_comp_pred ) //<S2SV> single_filter [ this_mode ] [ refs [ 0 ] ] = mbmi -> interp_filter ; //<S2SV> if ( cpi -> sf . adaptive_mode_search ) //<S2SV> if ( is_comp_pred ) //<S2SV> if ( single_skippable [ this_mode ] [ refs [ 0 ] ] && //<S2SV> single_skippable [ this_mode ] [ refs [ 1 ] ] ) //<S2SV> memset ( skip_txfm , SKIP_TXFM_AC_DC , sizeof ( skip_txfm ) ) ; //<S2SV> if ( cpi -> sf . use_rd_breakout && ref_best_rd < INT64_MAX ) { //<S2SV> if ( rd / 2 > ref_best_rd ) { //<S2SV> restore_dst_buf ( xd , orig_dst , orig_dst_stride ) ; //<S2SV> return INT64_MAX ; //<S2SV> } //<S2SV> } //<S2SV> if ( cm -> interp_filter == SWITCHABLE ) //<S2SV> * rate2 += rs ; //<S2SV> memcpy ( x -> skip_txfm , skip_txfm , sizeof ( skip_txfm ) ) ; //<S2SV> memcpy ( x -> bsse , bsse , sizeof ( bsse ) ) ; //<S2SV> if ( ! skip_txfm_sb ) { //<S2SV> int skippable_y , skippable_uv ; //<S2SV> int64_t sseuv = INT64_MAX ; //<S2SV> int64_t rdcosty = INT64_MAX ; //<S2SV> vp9_subtract_plane ( x , bsize , 0 ) ; //<S2SV> super_block_yrd ( cpi , x , rate_y , & distortion_y , & skippable_y , psse , //<S2SV> bsize , ref_best_rd ) ; //<S2SV> if ( * rate_y == INT_MAX ) { //<S2SV> * rate2 = INT_MAX ; //<S2SV> * distortion = INT64_MAX ; //<S2SV> restore_dst_buf ( xd , orig_dst , orig_dst_stride ) ; //<S2SV> return INT64_MAX ; //<S2SV> } //<S2SV> * rate2 += * rate_y ; //<S2SV> * distortion += distortion_y ; //<S2SV> rdcosty = RDCOST ( x -> rdmult , x -> rddiv , * rate2 , * distortion ) ; //<S2SV> rdcosty = MIN ( rdcosty , RDCOST ( x -> rdmult , x -> rddiv , 0 , * psse ) ) ; //<S2SV> if ( ! super_block_uvrd ( cpi , x , rate_uv , & distortion_uv , & skippable_uv , //<S2SV> & sseuv , bsize , ref_best_rd - rdcosty ) ) { //<S2SV> * rate2 = INT_MAX ; //<S2SV> * distortion = INT64_MAX ; //<S2SV> restore_dst_buf ( xd , orig_dst , orig_dst_stride ) ; //<S2SV> return INT64_MAX ; //<S2SV> } //<S2SV> * psse += sseuv ; //<S2SV> * rate2 += * rate_uv ; //<S2SV> * distortion += distortion_uv ; //<S2SV> * skippable = skippable_y && skippable_uv ; //<S2SV> } else { //<S2SV> x -> skip = 1 ; //<S2SV> * disable_skip = 1 ; //<S2SV> * rate2 += vp9_cost_bit ( vp9_get_skip_prob ( cm , xd ) , 1 ) ; //<S2SV> * distortion = skip_sse_sb ; //<S2SV> } //<S2SV> if ( ! is_comp_pred ) //<S2SV> single_skippable [ this_mode ] [ refs [ 0 ] ] = * skippable ; //<S2SV> restore_dst_buf ( xd , orig_dst , orig_dst_stride ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> 