static void joint_motion_search ( VP9_COMP * cpi , MACROBLOCK * x , //<S2SV> BLOCK_SIZE bsize , //<S2SV> int_mv * frame_mv , //<S2SV> int mi_row , int mi_col , //<S2SV> int_mv single_newmv [ MAX_REF_FRAMES ] , //<S2SV> int * rate_mv ) { //<S2SV> const VP9_COMMON * const cm = & cpi -> common ; //<S2SV> const int pw = 4 * num_4x4_blocks_wide_lookup [ bsize ] ; //<S2SV> const int ph = 4 * num_4x4_blocks_high_lookup [ bsize ] ; //<S2SV> MACROBLOCKD * xd = & x -> e_mbd ; //<S2SV> MB_MODE_INFO * mbmi = & xd -> mi [ 0 ] -> mbmi ; //<S2SV> const int refs [ 2 ] = { mbmi -> ref_frame [ 0 ] , //<S2SV> mbmi -> ref_frame [ 1 ] < 0 ? 0 : mbmi -> ref_frame [ 1 ] } ; //<S2SV> int_mv ref_mv [ 2 ] ; //<S2SV> int ite , ref ; //<S2SV> const InterpKernel * kernel = vp9_filter_kernels [ mbmi -> interp_filter ] ; //<S2SV> struct scale_factors sf ; //<S2SV> struct buf_2d backup_yv12 [ 2 ] [ MAX_MB_PLANE ] ; //<S2SV> int last_besterr [ 2 ] = { INT_MAX , INT_MAX } ; //<S2SV> const YV12_BUFFER_CONFIG * const scaled_ref_frame [ 2 ] = { //<S2SV> vp9_get_scaled_ref_frame ( cpi , mbmi -> ref_frame [ 0 ] ) , //<S2SV> vp9_get_scaled_ref_frame ( cpi , mbmi -> ref_frame [ 1 ] ) //<S2SV> } ; //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> DECLARE_ALIGNED ( 16 , uint16_t , second_pred_alloc_16 [ 64 * 64 ] ) ; //<S2SV> uint8_t * second_pred ; //<S2SV> # else //<S2SV> DECLARE_ALIGNED ( 16 , uint8_t , second_pred [ 64 * 64 ] ) ; //<S2SV> # endif //<S2SV> for ( ref = 0 ; ref < 2 ; ++ ref ) { //<S2SV> ref_mv [ ref ] = x -> mbmi_ext -> ref_mvs [ refs [ ref ] ] [ 0 ] ; //<S2SV> if ( scaled_ref_frame [ ref ] ) { //<S2SV> int i ; //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) //<S2SV> backup_yv12 [ ref ] [ i ] = xd -> plane [ i ] . pre [ ref ] ; //<S2SV> vp9_setup_pre_planes ( xd , ref , scaled_ref_frame [ ref ] , mi_row , mi_col , //<S2SV> NULL ) ; //<S2SV> } //<S2SV> frame_mv [ refs [ ref ] ] . as_int = single_newmv [ refs [ ref ] ] . as_int ; //<S2SV> } //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> vp9_setup_scale_factors_for_frame ( & sf , cm -> width , cm -> height , //<S2SV> cm -> width , cm -> height , //<S2SV> cm -> use_highbitdepth ) ; //<S2SV> # else //<S2SV> vp9_setup_scale_factors_for_frame ( & sf , cm -> width , cm -> height , //<S2SV> cm -> width , cm -> height ) ; //<S2SV> # endif //<S2SV> for ( ite = 0 ; ite < 4 ; ite ++ ) { //<S2SV> struct buf_2d ref_yv12 [ 2 ] ; //<S2SV> int bestsme = INT_MAX ; //<S2SV> int sadpb = x -> sadperbit16 ; //<S2SV> MV tmp_mv ; //<S2SV> int search_range = 3 ; //<S2SV> int tmp_col_min = x -> mv_col_min ; //<S2SV> int tmp_col_max = x -> mv_col_max ; //<S2SV> int tmp_row_min = x -> mv_row_min ; //<S2SV> int tmp_row_max = x -> mv_row_max ; //<S2SV> int id = ite % 2 ; //<S2SV> ref_yv12 [ 0 ] = xd -> plane [ 0 ] . pre [ 0 ] ; //<S2SV> ref_yv12 [ 1 ] = xd -> plane [ 0 ] . pre [ 1 ] ; //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> if ( xd -> cur_buf -> flags & YV12_FLAG_HIGHBITDEPTH ) { //<S2SV> second_pred = CONVERT_TO_BYTEPTR ( second_pred_alloc_16 ) ; //<S2SV> vp9_highbd_build_inter_predictor ( ref_yv12 [ ! id ] . buf , //<S2SV> ref_yv12 [ ! id ] . stride , //<S2SV> second_pred , pw , //<S2SV> & frame_mv [ refs [ ! id ] ] . as_mv , //<S2SV> & sf , pw , ph , 0 , //<S2SV> kernel , MV_PRECISION_Q3 , //<S2SV> mi_col * MI_SIZE , mi_row * MI_SIZE , //<S2SV> xd -> bd ) ; //<S2SV> } else { //<S2SV> second_pred = ( uint8_t * ) second_pred_alloc_16 ; //<S2SV> vp9_build_inter_predictor ( ref_yv12 [ ! id ] . buf , //<S2SV> ref_yv12 [ ! id ] . stride , //<S2SV> second_pred , pw , //<S2SV> & frame_mv [ refs [ ! id ] ] . as_mv , //<S2SV> & sf , pw , ph , 0 , //<S2SV> kernel , MV_PRECISION_Q3 , //<S2SV> mi_col * MI_SIZE , mi_row * MI_SIZE ) ; //<S2SV> } //<S2SV> # else //<S2SV> vp9_build_inter_predictor ( ref_yv12 [ ! id ] . buf , //<S2SV> ref_yv12 [ ! id ] . stride , //<S2SV> second_pred , pw , //<S2SV> & frame_mv [ refs [ ! id ] ] . as_mv , //<S2SV> & sf , pw , ph , 0 , //<S2SV> kernel , MV_PRECISION_Q3 , //<S2SV> mi_col * MI_SIZE , mi_row * MI_SIZE ) ; //<S2SV> # endif //<S2SV> if ( id ) //<S2SV> xd -> plane [ 0 ] . pre [ 0 ] = ref_yv12 [ id ] ; //<S2SV> vp9_set_mv_search_range ( x , & ref_mv [ id ] . as_mv ) ; //<S2SV> tmp_mv = frame_mv [ refs [ id ] ] . as_mv ; //<S2SV> tmp_mv . col >>= 3 ; //<S2SV> tmp_mv . row >>= 3 ; //<S2SV> bestsme = vp9_refining_search_8p_c ( x , & tmp_mv , sadpb , //<S2SV> search_range , //<S2SV> & cpi -> fn_ptr [ bsize ] , //<S2SV> & ref_mv [ id ] . as_mv , second_pred ) ; //<S2SV> if ( bestsme < INT_MAX ) //<S2SV> bestsme = vp9_get_mvpred_av_var ( x , & tmp_mv , & ref_mv [ id ] . as_mv , //<S2SV> second_pred , & cpi -> fn_ptr [ bsize ] , 1 ) ; //<S2SV> x -> mv_col_min = tmp_col_min ; //<S2SV> x -> mv_col_max = tmp_col_max ; //<S2SV> x -> mv_row_min = tmp_row_min ; //<S2SV> x -> mv_row_max = tmp_row_max ; //<S2SV> if ( bestsme < INT_MAX ) { //<S2SV> int dis ; //<S2SV> unsigned int sse ; //<S2SV> bestsme = cpi -> find_fractional_mv_step ( //<S2SV> x , & tmp_mv , //<S2SV> & ref_mv [ id ] . as_mv , //<S2SV> cpi -> common . allow_high_precision_mv , //<S2SV> x -> errorperbit , //<S2SV> & cpi -> fn_ptr [ bsize ] , //<S2SV> 0 , cpi -> sf . mv . subpel_iters_per_step , //<S2SV> NULL , //<S2SV> x -> nmvjointcost , x -> mvcost , //<S2SV> & dis , & sse , second_pred , //<S2SV> pw , ph ) ; //<S2SV> } //<S2SV> if ( id ) //<S2SV> xd -> plane [ 0 ] . pre [ 0 ] = ref_yv12 [ 0 ] ; //<S2SV> if ( bestsme < last_besterr [ id ] ) { //<S2SV> frame_mv [ refs [ id ] ] . as_mv = tmp_mv ; //<S2SV> last_besterr [ id ] = bestsme ; //<S2SV> } else { //<S2SV> break ; //<S2SV> } //<S2SV> } //<S2SV> * rate_mv = 0 ; //<S2SV> for ( ref = 0 ; ref < 2 ; ++ ref ) { //<S2SV> if ( scaled_ref_frame [ ref ] ) { //<S2SV> int i ; //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) //<S2SV> xd -> plane [ i ] . pre [ ref ] = backup_yv12 [ ref ] [ i ] ; //<S2SV> } //<S2SV> * rate_mv += vp9_mv_bit_cost ( & frame_mv [ refs [ ref ] ] . as_mv , //<S2SV> & x -> mbmi_ext -> ref_mvs [ refs [ ref ] ] [ 0 ] . as_mv , //<S2SV> x -> nmvjointcost , x -> mvcost , MV_COST_WEIGHT ) ; //<S2SV> } //<S2SV> } //<S2SV> 