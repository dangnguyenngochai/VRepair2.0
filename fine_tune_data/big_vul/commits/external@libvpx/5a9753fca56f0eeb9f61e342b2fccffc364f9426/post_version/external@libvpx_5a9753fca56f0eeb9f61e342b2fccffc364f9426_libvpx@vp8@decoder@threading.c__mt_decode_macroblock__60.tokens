static void mt_decode_macroblock ( VP8D_COMP * pbi , MACROBLOCKD * xd , //<S2SV> unsigned int mb_idx ) //<S2SV> { //<S2SV> MB_PREDICTION_MODE mode ; //<S2SV> int i ; //<S2SV> # if CONFIG_ERROR_CONCEALMENT //<S2SV> int corruption_detected = 0 ; //<S2SV> # else //<S2SV> ( void ) mb_idx ; //<S2SV> # endif //<S2SV> if ( xd -> mode_info_context -> mbmi . mb_skip_coeff ) //<S2SV> { //<S2SV> vp8_reset_mb_tokens_context ( xd ) ; //<S2SV> } //<S2SV> else if ( ! vp8dx_bool_error ( xd -> current_bc ) ) //<S2SV> { //<S2SV> int eobtotal ; //<S2SV> eobtotal = vp8_decode_mb_tokens ( pbi , xd ) ; //<S2SV> xd -> mode_info_context -> mbmi . mb_skip_coeff = ( eobtotal == 0 ) ; //<S2SV> } //<S2SV> mode = xd -> mode_info_context -> mbmi . mode ; //<S2SV> if ( xd -> segmentation_enabled ) //<S2SV> vp8_mb_init_dequantizer ( pbi , xd ) ; //<S2SV> # if CONFIG_ERROR_CONCEALMENT //<S2SV> if ( pbi -> ec_active ) //<S2SV> { //<S2SV> int throw_residual ; //<S2SV> throw_residual = ( ! pbi -> independent_partitions && //<S2SV> pbi -> frame_corrupt_residual ) ; //<S2SV> throw_residual = ( throw_residual || vp8dx_bool_error ( xd -> current_bc ) ) ; //<S2SV> if ( ( mb_idx >= pbi -> mvs_corrupt_from_mb || throw_residual ) ) //<S2SV> { //<S2SV> pbi -> frame_corrupt_residual = 1 ; //<S2SV> memset ( xd -> qcoeff , 0 , sizeof ( xd -> qcoeff ) ) ; //<S2SV> vp8_conceal_corrupt_mb ( xd ) ; //<S2SV> corruption_detected = 1 ; //<S2SV> memset ( xd -> eobs , 0 , 25 ) ; //<S2SV> } //<S2SV> } //<S2SV> # endif //<S2SV> if ( xd -> mode_info_context -> mbmi . ref_frame == INTRA_FRAME ) //<S2SV> { //<S2SV> vp8_build_intra_predictors_mbuv_s ( xd , //<S2SV> xd -> recon_above [ 1 ] , //<S2SV> xd -> recon_above [ 2 ] , //<S2SV> xd -> recon_left [ 1 ] , //<S2SV> xd -> recon_left [ 2 ] , //<S2SV> xd -> recon_left_stride [ 1 ] , //<S2SV> xd -> dst . u_buffer , xd -> dst . v_buffer , //<S2SV> xd -> dst . uv_stride ) ; //<S2SV> if ( mode != B_PRED ) //<S2SV> { //<S2SV> vp8_build_intra_predictors_mby_s ( xd , //<S2SV> xd -> recon_above [ 0 ] , //<S2SV> xd -> recon_left [ 0 ] , //<S2SV> xd -> recon_left_stride [ 0 ] , //<S2SV> xd -> dst . y_buffer , //<S2SV> xd -> dst . y_stride ) ; //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> short * DQC = xd -> dequant_y1 ; //<S2SV> int dst_stride = xd -> dst . y_stride ; //<S2SV> if ( xd -> mode_info_context -> mbmi . mb_skip_coeff ) //<S2SV> memset ( xd -> eobs , 0 , 25 ) ; //<S2SV> intra_prediction_down_copy ( xd , xd -> recon_above [ 0 ] + 16 ) ; //<S2SV> for ( i = 0 ; i < 16 ; i ++ ) //<S2SV> { //<S2SV> BLOCKD * b = & xd -> block [ i ] ; //<S2SV> unsigned char * dst = xd -> dst . y_buffer + b -> offset ; //<S2SV> B_PREDICTION_MODE b_mode = //<S2SV> xd -> mode_info_context -> bmi [ i ] . as_mode ; //<S2SV> unsigned char * Above ; //<S2SV> unsigned char * yleft ; //<S2SV> int left_stride ; //<S2SV> unsigned char top_left ; //<S2SV> if ( i < 4 && pbi -> common . filter_level ) //<S2SV> Above = xd -> recon_above [ 0 ] + b -> offset ; //<S2SV> else //<S2SV> Above = dst - dst_stride ; //<S2SV> if ( i % 4 == 0 && pbi -> common . filter_level ) //<S2SV> { //<S2SV> yleft = xd -> recon_left [ 0 ] + i ; //<S2SV> left_stride = 1 ; //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> yleft = dst - 1 ; //<S2SV> left_stride = dst_stride ; //<S2SV> } //<S2SV> if ( ( i == 4 || i == 8 || i == 12 ) && pbi -> common . filter_level ) //<S2SV> top_left = * ( xd -> recon_left [ 0 ] + i - 1 ) ; //<S2SV> else //<S2SV> top_left = Above [ - 1 ] ; //<S2SV> vp8_intra4x4_predict ( Above , yleft , left_stride , //<S2SV> b_mode , dst , dst_stride , top_left ) ; //<S2SV> if ( xd -> eobs [ i ] ) //<S2SV> { //<S2SV> if ( xd -> eobs [ i ] > 1 ) //<S2SV> { //<S2SV> vp8_dequant_idct_add ( b -> qcoeff , DQC , dst , dst_stride ) ; //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> vp8_dc_only_idct_add ( b -> qcoeff [ 0 ] * DQC [ 0 ] , //<S2SV> dst , dst_stride , dst , dst_stride ) ; //<S2SV> memset ( b -> qcoeff , 0 , 2 * sizeof ( b -> qcoeff [ 0 ] ) ) ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> vp8_build_inter_predictors_mb ( xd ) ; //<S2SV> } //<S2SV> # if CONFIG_ERROR_CONCEALMENT //<S2SV> if ( corruption_detected ) //<S2SV> { //<S2SV> return ; //<S2SV> } //<S2SV> # endif //<S2SV> if ( ! xd -> mode_info_context -> mbmi . mb_skip_coeff ) //<S2SV> { //<S2SV> if ( mode != B_PRED ) //<S2SV> { //<S2SV> short * DQC = xd -> dequant_y1 ; //<S2SV> if ( mode != SPLITMV ) //<S2SV> { //<S2SV> BLOCKD * b = & xd -> block [ 24 ] ; //<S2SV> if ( xd -> eobs [ 24 ] > 1 ) //<S2SV> { //<S2SV> vp8_dequantize_b ( b , xd -> dequant_y2 ) ; //<S2SV> vp8_short_inv_walsh4x4 ( & b -> dqcoeff [ 0 ] , //<S2SV> xd -> qcoeff ) ; //<S2SV> memset ( b -> qcoeff , 0 , 16 * sizeof ( b -> qcoeff [ 0 ] ) ) ; //<S2SV> } //<S2SV> else //<S2SV> { //<S2SV> b -> dqcoeff [ 0 ] = b -> qcoeff [ 0 ] * xd -> dequant_y2 [ 0 ] ; //<S2SV> vp8_short_inv_walsh4x4_1 ( & b -> dqcoeff [ 0 ] , //<S2SV> xd -> qcoeff ) ; //<S2SV> memset ( b -> qcoeff , 0 , 2 * sizeof ( b -> qcoeff [ 0 ] ) ) ; //<S2SV> } //<S2SV> DQC = xd -> dequant_y1_dc ; //<S2SV> } //<S2SV> vp8_dequant_idct_add_y_block //<S2SV> ( xd -> qcoeff , DQC , //<S2SV> xd -> dst . y_buffer , //<S2SV> xd -> dst . y_stride , xd -> eobs ) ; //<S2SV> } //<S2SV> vp8_dequant_idct_add_uv_block //<S2SV> ( xd -> qcoeff + 16 * 16 , xd -> dequant_uv , //<S2SV> xd -> dst . u_buffer , xd -> dst . v_buffer , //<S2SV> xd -> dst . uv_stride , xd -> eobs + 16 ) ; //<S2SV> } //<S2SV> } //<S2SV> 