static void temporal_filter_iterate_c ( VP9_COMP * cpi , //<S2SV> YV12_BUFFER_CONFIG * * frames , //<S2SV> int frame_count , //<S2SV> int alt_ref_index , //<S2SV> int strength , //<S2SV> struct scale_factors * scale ) { //<S2SV> int byte ; //<S2SV> int frame ; //<S2SV> int mb_col , mb_row ; //<S2SV> unsigned int filter_weight ; //<S2SV> int mb_cols = ( frames [ alt_ref_index ] -> y_crop_width + 15 ) >> 4 ; //<S2SV> int mb_rows = ( frames [ alt_ref_index ] -> y_crop_height + 15 ) >> 4 ; //<S2SV> int mb_y_offset = 0 ; //<S2SV> int mb_uv_offset = 0 ; //<S2SV> DECLARE_ALIGNED ( 16 , unsigned int , accumulator [ 16 * 16 * 3 ] ) ; //<S2SV> DECLARE_ALIGNED ( 16 , uint16_t , count [ 16 * 16 * 3 ] ) ; //<S2SV> MACROBLOCKD * mbd = & cpi -> td . mb . e_mbd ; //<S2SV> YV12_BUFFER_CONFIG * f = frames [ alt_ref_index ] ; //<S2SV> uint8_t * dst1 , * dst2 ; //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> DECLARE_ALIGNED ( 16 , uint16_t , predictor16 [ 16 * 16 * 3 ] ) ; //<S2SV> DECLARE_ALIGNED ( 16 , uint8_t , predictor8 [ 16 * 16 * 3 ] ) ; //<S2SV> uint8_t * predictor ; //<S2SV> # else //<S2SV> DECLARE_ALIGNED ( 16 , uint8_t , predictor [ 16 * 16 * 3 ] ) ; //<S2SV> # endif //<S2SV> const int mb_uv_height = 16 >> mbd -> plane [ 1 ] . subsampling_y ; //<S2SV> const int mb_uv_width = 16 >> mbd -> plane [ 1 ] . subsampling_x ; //<S2SV> uint8_t * input_buffer [ MAX_MB_PLANE ] ; //<S2SV> int i ; //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> if ( mbd -> cur_buf -> flags & YV12_FLAG_HIGHBITDEPTH ) { //<S2SV> predictor = CONVERT_TO_BYTEPTR ( predictor16 ) ; //<S2SV> } else { //<S2SV> predictor = predictor8 ; //<S2SV> } //<S2SV> # endif //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) //<S2SV> input_buffer [ i ] = mbd -> plane [ i ] . pre [ 0 ] . buf ; //<S2SV> for ( mb_row = 0 ; mb_row < mb_rows ; mb_row ++ ) { //<S2SV> cpi -> td . mb . mv_row_min = - ( ( mb_row * 16 ) + ( 17 - 2 * VP9_INTERP_EXTEND ) ) ; //<S2SV> cpi -> td . mb . mv_row_max = ( ( mb_rows - 1 - mb_row ) * 16 ) //<S2SV> + ( 17 - 2 * VP9_INTERP_EXTEND ) ; //<S2SV> for ( mb_col = 0 ; mb_col < mb_cols ; mb_col ++ ) { //<S2SV> int i , j , k ; //<S2SV> int stride ; //<S2SV> memset ( accumulator , 0 , 16 * 16 * 3 * sizeof ( accumulator [ 0 ] ) ) ; //<S2SV> memset ( count , 0 , 16 * 16 * 3 * sizeof ( count [ 0 ] ) ) ; //<S2SV> cpi -> td . mb . mv_col_min = - ( ( mb_col * 16 ) + ( 17 - 2 * VP9_INTERP_EXTEND ) ) ; //<S2SV> cpi -> td . mb . mv_col_max = ( ( mb_cols - 1 - mb_col ) * 16 ) //<S2SV> + ( 17 - 2 * VP9_INTERP_EXTEND ) ; //<S2SV> for ( frame = 0 ; frame < frame_count ; frame ++ ) { //<S2SV> const int thresh_low = 10000 ; //<S2SV> const int thresh_high = 20000 ; //<S2SV> if ( frames [ frame ] == NULL ) //<S2SV> continue ; //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . row = 0 ; //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . col = 0 ; //<S2SV> if ( frame == alt_ref_index ) { //<S2SV> filter_weight = 2 ; //<S2SV> } else { //<S2SV> int err = temporal_filter_find_matching_mb_c ( cpi , //<S2SV> frames [ alt_ref_index ] -> y_buffer + mb_y_offset , //<S2SV> frames [ frame ] -> y_buffer + mb_y_offset , //<S2SV> frames [ frame ] -> y_stride ) ; //<S2SV> filter_weight = err < thresh_low //<S2SV> ? 2 : err < thresh_high ? 1 : 0 ; //<S2SV> } //<S2SV> if ( filter_weight != 0 ) { //<S2SV> temporal_filter_predictors_mb_c ( mbd , //<S2SV> frames [ frame ] -> y_buffer + mb_y_offset , //<S2SV> frames [ frame ] -> u_buffer + mb_uv_offset , //<S2SV> frames [ frame ] -> v_buffer + mb_uv_offset , //<S2SV> frames [ frame ] -> y_stride , //<S2SV> mb_uv_width , mb_uv_height , //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . row , //<S2SV> mbd -> mi [ 0 ] -> bmi [ 0 ] . as_mv [ 0 ] . as_mv . col , //<S2SV> predictor , scale , //<S2SV> mb_col * 16 , mb_row * 16 ) ; //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> if ( mbd -> cur_buf -> flags & YV12_FLAG_HIGHBITDEPTH ) { //<S2SV> int adj_strength = strength + 2 * ( mbd -> bd - 8 ) ; //<S2SV> vp9_highbd_temporal_filter_apply ( f -> y_buffer + mb_y_offset , //<S2SV> f -> y_stride , //<S2SV> predictor , 16 , 16 , adj_strength , //<S2SV> filter_weight , //<S2SV> accumulator , count ) ; //<S2SV> vp9_highbd_temporal_filter_apply ( f -> u_buffer + mb_uv_offset , //<S2SV> f -> uv_stride , predictor + 256 , //<S2SV> mb_uv_width , mb_uv_height , //<S2SV> adj_strength , //<S2SV> filter_weight , accumulator + 256 , //<S2SV> count + 256 ) ; //<S2SV> vp9_highbd_temporal_filter_apply ( f -> v_buffer + mb_uv_offset , //<S2SV> f -> uv_stride , predictor + 512 , //<S2SV> mb_uv_width , mb_uv_height , //<S2SV> adj_strength , filter_weight , //<S2SV> accumulator + 512 , count + 512 ) ; //<S2SV> } else { //<S2SV> vp9_temporal_filter_apply ( f -> y_buffer + mb_y_offset , f -> y_stride , //<S2SV> predictor , 16 , 16 , //<S2SV> strength , filter_weight , //<S2SV> accumulator , count ) ; //<S2SV> vp9_temporal_filter_apply ( f -> u_buffer + mb_uv_offset , f -> uv_stride , //<S2SV> predictor + 256 , //<S2SV> mb_uv_width , mb_uv_height , strength , //<S2SV> filter_weight , accumulator + 256 , //<S2SV> count + 256 ) ; //<S2SV> vp9_temporal_filter_apply ( f -> v_buffer + mb_uv_offset , f -> uv_stride , //<S2SV> predictor + 512 , //<S2SV> mb_uv_width , mb_uv_height , strength , //<S2SV> filter_weight , accumulator + 512 , //<S2SV> count + 512 ) ; //<S2SV> } //<S2SV> # else //<S2SV> vp9_temporal_filter_apply ( f -> y_buffer + mb_y_offset , f -> y_stride , //<S2SV> predictor , 16 , 16 , //<S2SV> strength , filter_weight , //<S2SV> accumulator , count ) ; //<S2SV> vp9_temporal_filter_apply ( f -> u_buffer + mb_uv_offset , f -> uv_stride , //<S2SV> predictor + 256 , //<S2SV> mb_uv_width , mb_uv_height , strength , //<S2SV> filter_weight , accumulator + 256 , //<S2SV> count + 256 ) ; //<S2SV> vp9_temporal_filter_apply ( f -> v_buffer + mb_uv_offset , f -> uv_stride , //<S2SV> predictor + 512 , //<S2SV> mb_uv_width , mb_uv_height , strength , //<S2SV> filter_weight , accumulator + 512 , //<S2SV> count + 512 ) ; //<S2SV> # endif //<S2SV> } //<S2SV> } //<S2SV> # if CONFIG_VP9_HIGHBITDEPTH //<S2SV> if ( mbd -> cur_buf -> flags & YV12_FLAG_HIGHBITDEPTH ) { //<S2SV> uint16_t * dst1_16 ; //<S2SV> uint16_t * dst2_16 ; //<S2SV> dst1 = cpi -> alt_ref_buffer . y_buffer ; //<S2SV> dst1_16 = CONVERT_TO_SHORTPTR ( dst1 ) ; //<S2SV> stride = cpi -> alt_ref_buffer . y_stride ; //<S2SV> byte = mb_y_offset ; //<S2SV> for ( i = 0 , k = 0 ; i < 16 ; i ++ ) { //<S2SV> for ( j = 0 ; j < 16 ; j ++ , k ++ ) { //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1_16 [ byte ] = ( uint16_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - 16 ; //<S2SV> } //<S2SV> dst1 = cpi -> alt_ref_buffer . u_buffer ; //<S2SV> dst2 = cpi -> alt_ref_buffer . v_buffer ; //<S2SV> dst1_16 = CONVERT_TO_SHORTPTR ( dst1 ) ; //<S2SV> dst2_16 = CONVERT_TO_SHORTPTR ( dst2 ) ; //<S2SV> stride = cpi -> alt_ref_buffer . uv_stride ; //<S2SV> byte = mb_uv_offset ; //<S2SV> for ( i = 0 , k = 256 ; i < mb_uv_height ; i ++ ) { //<S2SV> for ( j = 0 ; j < mb_uv_width ; j ++ , k ++ ) { //<S2SV> int m = k + 256 ; //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1_16 [ byte ] = ( uint16_t ) pval ; //<S2SV> pval = accumulator [ m ] + ( count [ m ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ m ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst2_16 [ byte ] = ( uint16_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - mb_uv_width ; //<S2SV> } //<S2SV> } else { //<S2SV> dst1 = cpi -> alt_ref_buffer . y_buffer ; //<S2SV> stride = cpi -> alt_ref_buffer . y_stride ; //<S2SV> byte = mb_y_offset ; //<S2SV> for ( i = 0 , k = 0 ; i < 16 ; i ++ ) { //<S2SV> for ( j = 0 ; j < 16 ; j ++ , k ++ ) { //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1 [ byte ] = ( uint8_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - 16 ; //<S2SV> } //<S2SV> dst1 = cpi -> alt_ref_buffer . u_buffer ; //<S2SV> dst2 = cpi -> alt_ref_buffer . v_buffer ; //<S2SV> stride = cpi -> alt_ref_buffer . uv_stride ; //<S2SV> byte = mb_uv_offset ; //<S2SV> for ( i = 0 , k = 256 ; i < mb_uv_height ; i ++ ) { //<S2SV> for ( j = 0 ; j < mb_uv_width ; j ++ , k ++ ) { //<S2SV> int m = k + 256 ; //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1 [ byte ] = ( uint8_t ) pval ; //<S2SV> pval = accumulator [ m ] + ( count [ m ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ m ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst2 [ byte ] = ( uint8_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - mb_uv_width ; //<S2SV> } //<S2SV> } //<S2SV> # else //<S2SV> dst1 = cpi -> alt_ref_buffer . y_buffer ; //<S2SV> stride = cpi -> alt_ref_buffer . y_stride ; //<S2SV> byte = mb_y_offset ; //<S2SV> for ( i = 0 , k = 0 ; i < 16 ; i ++ ) { //<S2SV> for ( j = 0 ; j < 16 ; j ++ , k ++ ) { //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1 [ byte ] = ( uint8_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - 16 ; //<S2SV> } //<S2SV> dst1 = cpi -> alt_ref_buffer . u_buffer ; //<S2SV> dst2 = cpi -> alt_ref_buffer . v_buffer ; //<S2SV> stride = cpi -> alt_ref_buffer . uv_stride ; //<S2SV> byte = mb_uv_offset ; //<S2SV> for ( i = 0 , k = 256 ; i < mb_uv_height ; i ++ ) { //<S2SV> for ( j = 0 ; j < mb_uv_width ; j ++ , k ++ ) { //<S2SV> int m = k + 256 ; //<S2SV> unsigned int pval = accumulator [ k ] + ( count [ k ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ k ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst1 [ byte ] = ( uint8_t ) pval ; //<S2SV> pval = accumulator [ m ] + ( count [ m ] >> 1 ) ; //<S2SV> pval *= fixed_divide [ count [ m ] ] ; //<S2SV> pval >>= 19 ; //<S2SV> dst2 [ byte ] = ( uint8_t ) pval ; //<S2SV> byte ++ ; //<S2SV> } //<S2SV> byte += stride - mb_uv_width ; //<S2SV> } //<S2SV> # endif //<S2SV> mb_y_offset += 16 ; //<S2SV> mb_uv_offset += mb_uv_width ; //<S2SV> } //<S2SV> mb_y_offset += 16 * ( f -> y_stride - mb_cols ) ; //<S2SV> mb_uv_offset += mb_uv_height * f -> uv_stride - mb_uv_width * mb_cols ; //<S2SV> } //<S2SV> for ( i = 0 ; i < MAX_MB_PLANE ; i ++ ) //<S2SV> mbd -> plane [ i ] . pre [ 0 ] . buf = input_buffer [ i ] ; //<S2SV> } //<S2SV> 