TEE_Result tee_mmu_check_access_rights ( const struct user_ta_ctx * utc , //<S2SV> uint32_t flags , uaddr_t uaddr , //<S2SV> size_t len ) //<S2SV> { //<S2SV> uaddr_t a ; //<S2SV> size_t addr_incr = MIN ( CORE_MMU_USER_CODE_SIZE , //<S2SV> CORE_MMU_USER_PARAM_SIZE ) ; //<S2SV> if ( ADD_OVERFLOW ( uaddr , len , & a ) ) //<S2SV> return TEE_ERROR_ACCESS_DENIED ; //<S2SV> if ( ( flags & TEE_MEMORY_ACCESS_NONSECURE ) && //<S2SV> ( flags & TEE_MEMORY_ACCESS_SECURE ) ) //<S2SV> return TEE_ERROR_ACCESS_DENIED ; //<S2SV> if ( ! ( flags & TEE_MEMORY_ACCESS_ANY_OWNER ) && //<S2SV> ! tee_mmu_is_vbuf_inside_ta_private ( utc , ( void * ) uaddr , len ) ) //<S2SV> return TEE_ERROR_ACCESS_DENIED ; //<S2SV> for ( a = uaddr ; a < ( uaddr + len ) ; a += addr_incr ) { //<S2SV> uint32_t attr ; //<S2SV> TEE_Result res ; //<S2SV> res = tee_mmu_user_va2pa_attr ( utc , ( void * ) a , NULL , & attr ) ; //<S2SV> if ( res != TEE_SUCCESS ) //<S2SV> return res ; //<S2SV> if ( ( flags & TEE_MEMORY_ACCESS_NONSECURE ) && //<S2SV> ( attr & TEE_MATTR_SECURE ) ) //<S2SV> return TEE_ERROR_ACCESS_DENIED ; //<S2SV> if ( ( flags & TEE_MEMORY_ACCESS_SECURE ) && //<S2SV> ! ( attr & TEE_MATTR_SECURE ) ) //<S2SV> return TEE_ERROR_ACCESS_DENIED ; //<S2SV> if ( ( flags & TEE_MEMORY_ACCESS_WRITE ) && ! ( attr & TEE_MATTR_UW ) ) //<S2SV> return TEE_ERROR_ACCESS_DENIED ; //<S2SV> if ( ( flags & TEE_MEMORY_ACCESS_READ ) && ! ( attr & TEE_MATTR_UR ) ) //<S2SV> return TEE_ERROR_ACCESS_DENIED ; //<S2SV> } //<S2SV> return TEE_SUCCESS ; //<S2SV> } //<S2SV> 