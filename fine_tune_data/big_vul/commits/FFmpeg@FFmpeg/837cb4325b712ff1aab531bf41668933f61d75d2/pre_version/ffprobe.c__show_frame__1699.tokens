static void show_frame ( WriterContext * w , AVFrame * frame , AVStream * stream , //<S2SV> AVFormatContext * fmt_ctx ) //<S2SV> { //<S2SV> AVBPrint pbuf ; //<S2SV> char val_str [ 128 ] ; //<S2SV> const char * s ; //<S2SV> int i ; //<S2SV> av_bprint_init ( & pbuf , 1 , AV_BPRINT_SIZE_UNLIMITED ) ; //<S2SV> writer_print_section_header ( w , SECTION_ID_FRAME ) ; //<S2SV> s = av_get_media_type_string ( stream -> codecpar -> codec_type ) ; //<S2SV> if ( s ) print_str ( "media_type" , s ) ; //<S2SV> else print_str_opt ( "media_type" , "unknown" ) ; //<S2SV> print_int ( "stream_index" , stream -> index ) ; //<S2SV> print_int ( "key_frame" , frame -> key_frame ) ; //<S2SV> print_ts ( "pkt_pts" , frame -> pts ) ; //<S2SV> print_time ( "pkt_pts_time" , frame -> pts , & stream -> time_base ) ; //<S2SV> print_ts ( "pkt_dts" , frame -> pkt_dts ) ; //<S2SV> print_time ( "pkt_dts_time" , frame -> pkt_dts , & stream -> time_base ) ; //<S2SV> print_ts ( "best_effort_timestamp" , frame -> best_effort_timestamp ) ; //<S2SV> print_time ( "best_effort_timestamp_time" , frame -> best_effort_timestamp , & stream -> time_base ) ; //<S2SV> print_duration_ts ( "pkt_duration" , frame -> pkt_duration ) ; //<S2SV> print_duration_time ( "pkt_duration_time" , frame -> pkt_duration , & stream -> time_base ) ; //<S2SV> if ( frame -> pkt_pos != - 1 ) print_fmt ( "pkt_pos" , "%" PRId64 , frame -> pkt_pos ) ; //<S2SV> else print_str_opt ( "pkt_pos" , "N/A" ) ; //<S2SV> if ( frame -> pkt_size != - 1 ) print_val ( "pkt_size" , frame -> pkt_size , unit_byte_str ) ; //<S2SV> else print_str_opt ( "pkt_size" , "N/A" ) ; //<S2SV> switch ( stream -> codecpar -> codec_type ) { //<S2SV> AVRational sar ; //<S2SV> case AVMEDIA_TYPE_VIDEO : //<S2SV> print_int ( "width" , frame -> width ) ; //<S2SV> print_int ( "height" , frame -> height ) ; //<S2SV> s = av_get_pix_fmt_name ( frame -> format ) ; //<S2SV> if ( s ) print_str ( "pix_fmt" , s ) ; //<S2SV> else print_str_opt ( "pix_fmt" , "unknown" ) ; //<S2SV> sar = av_guess_sample_aspect_ratio ( fmt_ctx , stream , frame ) ; //<S2SV> if ( sar . num ) { //<S2SV> print_q ( "sample_aspect_ratio" , sar , ':' ) ; //<S2SV> } else { //<S2SV> print_str_opt ( "sample_aspect_ratio" , "N/A" ) ; //<S2SV> } //<S2SV> print_fmt ( "pict_type" , "%c" , av_get_picture_type_char ( frame -> pict_type ) ) ; //<S2SV> print_int ( "coded_picture_number" , frame -> coded_picture_number ) ; //<S2SV> print_int ( "display_picture_number" , frame -> display_picture_number ) ; //<S2SV> print_int ( "interlaced_frame" , frame -> interlaced_frame ) ; //<S2SV> print_int ( "top_field_first" , frame -> top_field_first ) ; //<S2SV> print_int ( "repeat_pict" , frame -> repeat_pict ) ; //<S2SV> if ( frame -> color_range != AVCOL_RANGE_UNSPECIFIED ) //<S2SV> print_str ( "color_range" , av_color_range_name ( frame -> color_range ) ) ; //<S2SV> else //<S2SV> print_str_opt ( "color_range" , av_color_range_name ( frame -> color_range ) ) ; //<S2SV> if ( frame -> colorspace != AVCOL_SPC_UNSPECIFIED ) //<S2SV> print_str ( "color_space" , av_color_space_name ( frame -> colorspace ) ) ; //<S2SV> else //<S2SV> print_str_opt ( "color_space" , av_color_space_name ( frame -> colorspace ) ) ; //<S2SV> if ( frame -> color_primaries != AVCOL_PRI_UNSPECIFIED ) //<S2SV> print_str ( "color_primaries" , av_color_primaries_name ( frame -> color_primaries ) ) ; //<S2SV> else //<S2SV> print_str_opt ( "color_primaries" , av_color_primaries_name ( frame -> color_primaries ) ) ; //<S2SV> if ( frame -> color_trc != AVCOL_TRC_UNSPECIFIED ) //<S2SV> print_str ( "color_transfer" , av_color_transfer_name ( frame -> color_trc ) ) ; //<S2SV> else //<S2SV> print_str_opt ( "color_transfer" , av_color_transfer_name ( frame -> color_trc ) ) ; //<S2SV> if ( frame -> chroma_location != AVCHROMA_LOC_UNSPECIFIED ) //<S2SV> print_str ( "chroma_location" , av_chroma_location_name ( frame -> chroma_location ) ) ; //<S2SV> else //<S2SV> print_str_opt ( "chroma_location" , av_chroma_location_name ( frame -> chroma_location ) ) ; //<S2SV> break ; //<S2SV> case AVMEDIA_TYPE_AUDIO : //<S2SV> s = av_get_sample_fmt_name ( frame -> format ) ; //<S2SV> if ( s ) print_str ( "sample_fmt" , s ) ; //<S2SV> else print_str_opt ( "sample_fmt" , "unknown" ) ; //<S2SV> print_int ( "nb_samples" , frame -> nb_samples ) ; //<S2SV> print_int ( "channels" , frame -> channels ) ; //<S2SV> if ( frame -> channel_layout ) { //<S2SV> av_bprint_clear ( & pbuf ) ; //<S2SV> av_bprint_channel_layout ( & pbuf , frame -> channels , //<S2SV> frame -> channel_layout ) ; //<S2SV> print_str ( "channel_layout" , pbuf . str ) ; //<S2SV> } else //<S2SV> print_str_opt ( "channel_layout" , "unknown" ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( do_show_frame_tags ) //<S2SV> show_tags ( w , frame -> metadata , SECTION_ID_FRAME_TAGS ) ; //<S2SV> if ( do_show_log ) //<S2SV> show_log ( w , SECTION_ID_FRAME_LOGS , SECTION_ID_FRAME_LOG , do_show_log ) ; //<S2SV> if ( frame -> nb_side_data ) { //<S2SV> writer_print_section_header ( w , SECTION_ID_FRAME_SIDE_DATA_LIST ) ; //<S2SV> for ( i = 0 ; i < frame -> nb_side_data ; i ++ ) { //<S2SV> AVFrameSideData * sd = frame -> side_data [ i ] ; //<S2SV> const char * name ; //<S2SV> writer_print_section_header ( w , SECTION_ID_FRAME_SIDE_DATA ) ; //<S2SV> name = av_frame_side_data_name ( sd -> type ) ; //<S2SV> print_str ( "side_data_type" , name ? name : "unknown" ) ; //<S2SV> if ( sd -> type == AV_FRAME_DATA_DISPLAYMATRIX && sd -> size >= 9 * 4 ) { //<S2SV> writer_print_integers ( w , "displaymatrix" , sd -> data , 9 , "<S2SV_blank>%11d" , 3 , 4 , 1 ) ; //<S2SV> print_int ( "rotation" , av_display_rotation_get ( ( int32_t * ) sd -> data ) ) ; //<S2SV> } else if ( sd -> type == AV_FRAME_DATA_GOP_TIMECODE && sd -> size >= 8 ) { //<S2SV> char tcbuf [ AV_TIMECODE_STR_SIZE ] ; //<S2SV> av_timecode_make_mpeg_tc_string ( tcbuf , * ( int64_t * ) ( sd -> data ) ) ; //<S2SV> print_str ( "timecode" , tcbuf ) ; //<S2SV> } else if ( sd -> type == AV_FRAME_DATA_MASTERING_DISPLAY_METADATA ) { //<S2SV> AVMasteringDisplayMetadata * metadata = ( AVMasteringDisplayMetadata * ) sd -> data ; //<S2SV> if ( metadata -> has_primaries ) { //<S2SV> print_q ( "red_x" , metadata -> display_primaries [ 0 ] [ 0 ] , '/' ) ; //<S2SV> print_q ( "red_y" , metadata -> display_primaries [ 0 ] [ 1 ] , '/' ) ; //<S2SV> print_q ( "green_x" , metadata -> display_primaries [ 1 ] [ 0 ] , '/' ) ; //<S2SV> print_q ( "green_y" , metadata -> display_primaries [ 1 ] [ 1 ] , '/' ) ; //<S2SV> print_q ( "blue_x" , metadata -> display_primaries [ 2 ] [ 0 ] , '/' ) ; //<S2SV> print_q ( "blue_y" , metadata -> display_primaries [ 2 ] [ 1 ] , '/' ) ; //<S2SV> print_q ( "white_point_x" , metadata -> white_point [ 0 ] , '/' ) ; //<S2SV> print_q ( "white_point_y" , metadata -> white_point [ 1 ] , '/' ) ; //<S2SV> } //<S2SV> if ( metadata -> has_luminance ) { //<S2SV> print_q ( "min_luminance" , metadata -> min_luminance , '/' ) ; //<S2SV> print_q ( "max_luminance" , metadata -> max_luminance , '/' ) ; //<S2SV> } //<S2SV> } else if ( sd -> type == AV_FRAME_DATA_CONTENT_LIGHT_LEVEL ) { //<S2SV> AVContentLightMetadata * metadata = ( AVContentLightMetadata * ) sd -> data ; //<S2SV> print_int ( "max_content" , metadata -> MaxCLL ) ; //<S2SV> print_int ( "max_average" , metadata -> MaxFALL ) ; //<S2SV> } else if ( sd -> type == AV_FRAME_DATA_ICC_PROFILE ) { //<S2SV> AVDictionaryEntry * tag = av_dict_get ( sd -> metadata , "name" , NULL , AV_DICT_MATCH_CASE ) ; //<S2SV> if ( tag ) //<S2SV> print_str ( tag -> key , tag -> value ) ; //<S2SV> print_int ( "size" , sd -> size ) ; //<S2SV> } //<S2SV> writer_print_section_footer ( w ) ; //<S2SV> } //<S2SV> writer_print_section_footer ( w ) ; //<S2SV> } //<S2SV> writer_print_section_footer ( w ) ; //<S2SV> av_bprint_finalize ( & pbuf , NULL ) ; //<S2SV> fflush ( stdout ) ; //<S2SV> } //<S2SV> 