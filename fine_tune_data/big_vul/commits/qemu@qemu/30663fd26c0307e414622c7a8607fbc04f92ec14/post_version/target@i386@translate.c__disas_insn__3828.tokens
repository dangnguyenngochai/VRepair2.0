static target_ulong disas_insn ( CPUX86State * env , DisasContext * s , //<S2SV> target_ulong pc_start ) //<S2SV> { //<S2SV> int b , prefixes ; //<S2SV> int shift ; //<S2SV> TCGMemOp ot , aflag , dflag ; //<S2SV> int modrm , reg , rm , mod , op , opreg , val ; //<S2SV> target_ulong next_eip , tval ; //<S2SV> int rex_w , rex_r ; //<S2SV> s -> pc_start = s -> pc = pc_start ; //<S2SV> prefixes = 0 ; //<S2SV> s -> override = - 1 ; //<S2SV> rex_w = - 1 ; //<S2SV> rex_r = 0 ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> s -> rex_x = 0 ; //<S2SV> s -> rex_b = 0 ; //<S2SV> x86_64_hregs = 0 ; //<S2SV> # endif //<S2SV> s -> rip_offset = 0 ; //<S2SV> s -> vex_l = 0 ; //<S2SV> s -> vex_v = 0 ; //<S2SV> next_byte : //<S2SV> if ( s -> pc - pc_start > 14 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> b = cpu_ldub_code ( env , s -> pc ) ; //<S2SV> s -> pc ++ ; //<S2SV> switch ( b ) { //<S2SV> case 0xf3 : //<S2SV> prefixes |= PREFIX_REPZ ; //<S2SV> goto next_byte ; //<S2SV> case 0xf2 : //<S2SV> prefixes |= PREFIX_REPNZ ; //<S2SV> goto next_byte ; //<S2SV> case 0xf0 : //<S2SV> prefixes |= PREFIX_LOCK ; //<S2SV> goto next_byte ; //<S2SV> case 0x2e : //<S2SV> s -> override = R_CS ; //<S2SV> goto next_byte ; //<S2SV> case 0x36 : //<S2SV> s -> override = R_SS ; //<S2SV> goto next_byte ; //<S2SV> case 0x3e : //<S2SV> s -> override = R_DS ; //<S2SV> goto next_byte ; //<S2SV> case 0x26 : //<S2SV> s -> override = R_ES ; //<S2SV> goto next_byte ; //<S2SV> case 0x64 : //<S2SV> s -> override = R_FS ; //<S2SV> goto next_byte ; //<S2SV> case 0x65 : //<S2SV> s -> override = R_GS ; //<S2SV> goto next_byte ; //<S2SV> case 0x66 : //<S2SV> prefixes |= PREFIX_DATA ; //<S2SV> goto next_byte ; //<S2SV> case 0x67 : //<S2SV> prefixes |= PREFIX_ADR ; //<S2SV> goto next_byte ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case 0x40 ... 0x4f : //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> rex_w = ( b >> 3 ) & 1 ; //<S2SV> rex_r = ( b & 0x4 ) << 1 ; //<S2SV> s -> rex_x = ( b & 0x2 ) << 2 ; //<S2SV> REX_B ( s ) = ( b & 0x1 ) << 3 ; //<S2SV> x86_64_hregs = 1 ; //<S2SV> goto next_byte ; //<S2SV> } //<S2SV> break ; //<S2SV> # endif //<S2SV> case 0xc5 : //<S2SV> case 0xc4 : //<S2SV> if ( s -> code32 && ! s -> vm86 ) { //<S2SV> static const int pp_prefix [ 4 ] = { //<S2SV> 0 , PREFIX_DATA , PREFIX_REPZ , PREFIX_REPNZ //<S2SV> } ; //<S2SV> int vex3 , vex2 = cpu_ldub_code ( env , s -> pc ) ; //<S2SV> if ( ! CODE64 ( s ) && ( vex2 & 0xc0 ) != 0xc0 ) { //<S2SV> break ; //<S2SV> } //<S2SV> s -> pc ++ ; //<S2SV> if ( prefixes & ( PREFIX_REPZ | PREFIX_REPNZ //<S2SV> | PREFIX_LOCK | PREFIX_DATA ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> # ifdef TARGET_X86_64 //<S2SV> if ( x86_64_hregs ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> # endif //<S2SV> rex_r = ( ~ vex2 >> 4 ) & 8 ; //<S2SV> if ( b == 0xc5 ) { //<S2SV> vex3 = vex2 ; //<S2SV> b = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> } else { //<S2SV> # ifdef TARGET_X86_64 //<S2SV> s -> rex_x = ( ~ vex2 >> 3 ) & 8 ; //<S2SV> s -> rex_b = ( ~ vex2 >> 2 ) & 8 ; //<S2SV> # endif //<S2SV> vex3 = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> rex_w = ( vex3 >> 7 ) & 1 ; //<S2SV> switch ( vex2 & 0x1f ) { //<S2SV> case 0x01 : //<S2SV> b = cpu_ldub_code ( env , s -> pc ++ ) | 0x100 ; //<S2SV> break ; //<S2SV> case 0x02 : //<S2SV> b = 0x138 ; //<S2SV> break ; //<S2SV> case 0x03 : //<S2SV> b = 0x13a ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> } //<S2SV> s -> vex_v = ( ~ vex3 >> 3 ) & 0xf ; //<S2SV> s -> vex_l = ( vex3 >> 2 ) & 1 ; //<S2SV> prefixes |= pp_prefix [ vex3 & 3 ] | PREFIX_VEX ; //<S2SV> } //<S2SV> break ; //<S2SV> } //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> dflag = ( rex_w > 0 ? MO_64 : prefixes & PREFIX_DATA ? MO_16 : MO_32 ) ; //<S2SV> aflag = ( prefixes & PREFIX_ADR ? MO_32 : MO_64 ) ; //<S2SV> } else { //<S2SV> if ( s -> code32 ^ ( ( prefixes & PREFIX_DATA ) != 0 ) ) { //<S2SV> dflag = MO_32 ; //<S2SV> } else { //<S2SV> dflag = MO_16 ; //<S2SV> } //<S2SV> if ( s -> code32 ^ ( ( prefixes & PREFIX_ADR ) != 0 ) ) { //<S2SV> aflag = MO_32 ; //<S2SV> } else { //<S2SV> aflag = MO_16 ; //<S2SV> } //<S2SV> } //<S2SV> s -> prefix = prefixes ; //<S2SV> s -> aflag = aflag ; //<S2SV> s -> dflag = dflag ; //<S2SV> reswitch : //<S2SV> switch ( b ) { //<S2SV> case 0x0f : //<S2SV> b = cpu_ldub_code ( env , s -> pc ++ ) | 0x100 ; //<S2SV> goto reswitch ; //<S2SV> case 0x00 ... 0x05 : //<S2SV> case 0x08 ... 0x0d : //<S2SV> case 0x10 ... 0x15 : //<S2SV> case 0x18 ... 0x1d : //<S2SV> case 0x20 ... 0x25 : //<S2SV> case 0x28 ... 0x2d : //<S2SV> case 0x30 ... 0x35 : //<S2SV> case 0x38 ... 0x3d : //<S2SV> { //<S2SV> int op , f , val ; //<S2SV> op = ( b >> 3 ) & 7 ; //<S2SV> f = ( b >> 1 ) & 3 ; //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> switch ( f ) { //<S2SV> case 0 : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> opreg = OR_TMP0 ; //<S2SV> } else if ( op == OP_XORL && rm == reg ) { //<S2SV> xor_zero : //<S2SV> set_cc_op ( s , CC_OP_CLR ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , 0 ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T0 ) ; //<S2SV> break ; //<S2SV> } else { //<S2SV> opreg = rm ; //<S2SV> } //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , reg ) ; //<S2SV> gen_op ( s , op , ot , opreg ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , ot , cpu_T1 , cpu_A0 ) ; //<S2SV> } else if ( op == OP_XORL && rm == reg ) { //<S2SV> goto xor_zero ; //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , rm ) ; //<S2SV> } //<S2SV> gen_op ( s , op , ot , reg ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , val ) ; //<S2SV> gen_op ( s , op , ot , OR_EAX ) ; //<S2SV> break ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x82 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> case 0x80 : //<S2SV> case 0x81 : //<S2SV> case 0x83 : //<S2SV> { //<S2SV> int val ; //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> op = ( modrm >> 3 ) & 7 ; //<S2SV> if ( mod != 3 ) { //<S2SV> if ( b == 0x83 ) //<S2SV> s -> rip_offset = 1 ; //<S2SV> else //<S2SV> s -> rip_offset = insn_const_size ( ot ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> opreg = OR_TMP0 ; //<S2SV> } else { //<S2SV> opreg = rm ; //<S2SV> } //<S2SV> switch ( b ) { //<S2SV> default : //<S2SV> case 0x80 : //<S2SV> case 0x81 : //<S2SV> case 0x82 : //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> break ; //<S2SV> case 0x83 : //<S2SV> val = ( int8_t ) insn_get ( env , s , MO_8 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> tcg_gen_movi_tl ( cpu_T1 , val ) ; //<S2SV> gen_op ( s , op , ot , opreg ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x40 ... 0x47 : //<S2SV> ot = dflag ; //<S2SV> gen_inc ( s , ot , OR_EAX + ( b & 7 ) , 1 ) ; //<S2SV> break ; //<S2SV> case 0x48 ... 0x4f : //<S2SV> ot = dflag ; //<S2SV> gen_inc ( s , ot , OR_EAX + ( b & 7 ) , - 1 ) ; //<S2SV> break ; //<S2SV> case 0xf6 : //<S2SV> case 0xf7 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> op = ( modrm >> 3 ) & 7 ; //<S2SV> if ( mod != 3 ) { //<S2SV> if ( op == 0 ) { //<S2SV> s -> rip_offset = insn_const_size ( ot ) ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( ! ( s -> prefix & PREFIX_LOCK ) //<S2SV> || op != 2 ) { //<S2SV> gen_op_ld_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , rm ) ; //<S2SV> } //<S2SV> switch ( op ) { //<S2SV> case 0 : //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , val ) ; //<S2SV> gen_op_testl_T0_T1_cc ( ) ; //<S2SV> set_cc_op ( s , CC_OP_LOGICB + ot ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> if ( s -> prefix & PREFIX_LOCK ) { //<S2SV> if ( mod == 3 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_movi_tl ( cpu_T0 , ~ 0 ) ; //<S2SV> tcg_gen_atomic_xor_fetch_tl ( cpu_T0 , cpu_A0 , cpu_T0 , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> } else { //<S2SV> tcg_gen_not_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_op_st_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 3 : //<S2SV> if ( s -> prefix & PREFIX_LOCK ) { //<S2SV> TCGLabel * label1 ; //<S2SV> TCGv a0 , t0 , t1 , t2 ; //<S2SV> if ( mod == 3 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> a0 = tcg_temp_local_new ( ) ; //<S2SV> t0 = tcg_temp_local_new ( ) ; //<S2SV> label1 = gen_new_label ( ) ; //<S2SV> tcg_gen_mov_tl ( a0 , cpu_A0 ) ; //<S2SV> tcg_gen_mov_tl ( t0 , cpu_T0 ) ; //<S2SV> gen_set_label ( label1 ) ; //<S2SV> t1 = tcg_temp_new ( ) ; //<S2SV> t2 = tcg_temp_new ( ) ; //<S2SV> tcg_gen_mov_tl ( t2 , t0 ) ; //<S2SV> tcg_gen_neg_tl ( t1 , t0 ) ; //<S2SV> tcg_gen_atomic_cmpxchg_tl ( t0 , a0 , t0 , t1 , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> tcg_temp_free ( t1 ) ; //<S2SV> tcg_gen_brcond_tl ( TCG_COND_NE , t0 , t2 , label1 ) ; //<S2SV> tcg_temp_free ( t2 ) ; //<S2SV> tcg_temp_free ( a0 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_T0 , t0 ) ; //<S2SV> tcg_temp_free ( t0 ) ; //<S2SV> } else { //<S2SV> tcg_gen_neg_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_op_st_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> } //<S2SV> } //<S2SV> gen_op_update_neg_cc ( ) ; //<S2SV> set_cc_op ( s , CC_OP_SUBB + ot ) ; //<S2SV> break ; //<S2SV> case 4 : //<S2SV> switch ( ot ) { //<S2SV> case MO_8 : //<S2SV> gen_op_mov_v_reg ( MO_8 , cpu_T1 , R_EAX ) ; //<S2SV> tcg_gen_ext8u_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_ext8u_tl ( cpu_T1 , cpu_T1 ) ; //<S2SV> tcg_gen_mul_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EAX , cpu_T0 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_T0 ) ; //<S2SV> tcg_gen_andi_tl ( cpu_cc_src , cpu_T0 , 0xff00 ) ; //<S2SV> set_cc_op ( s , CC_OP_MULB ) ; //<S2SV> break ; //<S2SV> case MO_16 : //<S2SV> gen_op_mov_v_reg ( MO_16 , cpu_T1 , R_EAX ) ; //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_ext16u_tl ( cpu_T1 , cpu_T1 ) ; //<S2SV> tcg_gen_mul_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EAX , cpu_T0 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_T0 ) ; //<S2SV> tcg_gen_shri_tl ( cpu_T0 , cpu_T0 , 16 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EDX , cpu_T0 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_src , cpu_T0 ) ; //<S2SV> set_cc_op ( s , CC_OP_MULW ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case MO_32 : //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp3_i32 , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_mulu2_i32 ( cpu_tmp2_i32 , cpu_tmp3_i32 , //<S2SV> cpu_tmp2_i32 , cpu_tmp3_i32 ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_regs [ R_EAX ] , cpu_tmp2_i32 ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_regs [ R_EDX ] , cpu_tmp3_i32 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_src , cpu_regs [ R_EDX ] ) ; //<S2SV> set_cc_op ( s , CC_OP_MULL ) ; //<S2SV> break ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> tcg_gen_mulu2_i64 ( cpu_regs [ R_EAX ] , cpu_regs [ R_EDX ] , //<S2SV> cpu_T0 , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_src , cpu_regs [ R_EDX ] ) ; //<S2SV> set_cc_op ( s , CC_OP_MULQ ) ; //<S2SV> break ; //<S2SV> # endif //<S2SV> } //<S2SV> break ; //<S2SV> case 5 : //<S2SV> switch ( ot ) { //<S2SV> case MO_8 : //<S2SV> gen_op_mov_v_reg ( MO_8 , cpu_T1 , R_EAX ) ; //<S2SV> tcg_gen_ext8s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_ext8s_tl ( cpu_T1 , cpu_T1 ) ; //<S2SV> tcg_gen_mul_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EAX , cpu_T0 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_T0 ) ; //<S2SV> tcg_gen_ext8s_tl ( cpu_tmp0 , cpu_T0 ) ; //<S2SV> tcg_gen_sub_tl ( cpu_cc_src , cpu_T0 , cpu_tmp0 ) ; //<S2SV> set_cc_op ( s , CC_OP_MULB ) ; //<S2SV> break ; //<S2SV> case MO_16 : //<S2SV> gen_op_mov_v_reg ( MO_16 , cpu_T1 , R_EAX ) ; //<S2SV> tcg_gen_ext16s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_ext16s_tl ( cpu_T1 , cpu_T1 ) ; //<S2SV> tcg_gen_mul_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EAX , cpu_T0 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_T0 ) ; //<S2SV> tcg_gen_ext16s_tl ( cpu_tmp0 , cpu_T0 ) ; //<S2SV> tcg_gen_sub_tl ( cpu_cc_src , cpu_T0 , cpu_tmp0 ) ; //<S2SV> tcg_gen_shri_tl ( cpu_T0 , cpu_T0 , 16 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EDX , cpu_T0 ) ; //<S2SV> set_cc_op ( s , CC_OP_MULW ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case MO_32 : //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp3_i32 , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_muls2_i32 ( cpu_tmp2_i32 , cpu_tmp3_i32 , //<S2SV> cpu_tmp2_i32 , cpu_tmp3_i32 ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_regs [ R_EAX ] , cpu_tmp2_i32 ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_regs [ R_EDX ] , cpu_tmp3_i32 ) ; //<S2SV> tcg_gen_sari_i32 ( cpu_tmp2_i32 , cpu_tmp2_i32 , 31 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_sub_i32 ( cpu_tmp2_i32 , cpu_tmp2_i32 , cpu_tmp3_i32 ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_cc_src , cpu_tmp2_i32 ) ; //<S2SV> set_cc_op ( s , CC_OP_MULL ) ; //<S2SV> break ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> tcg_gen_muls2_i64 ( cpu_regs [ R_EAX ] , cpu_regs [ R_EDX ] , //<S2SV> cpu_T0 , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_sari_tl ( cpu_cc_src , cpu_regs [ R_EAX ] , 63 ) ; //<S2SV> tcg_gen_sub_tl ( cpu_cc_src , cpu_cc_src , cpu_regs [ R_EDX ] ) ; //<S2SV> set_cc_op ( s , CC_OP_MULQ ) ; //<S2SV> break ; //<S2SV> # endif //<S2SV> } //<S2SV> break ; //<S2SV> case 6 : //<S2SV> switch ( ot ) { //<S2SV> case MO_8 : //<S2SV> gen_helper_divb_AL ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case MO_16 : //<S2SV> gen_helper_divw_AX ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case MO_32 : //<S2SV> gen_helper_divl_EAX ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> gen_helper_divq_EAX ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> # endif //<S2SV> } //<S2SV> break ; //<S2SV> case 7 : //<S2SV> switch ( ot ) { //<S2SV> case MO_8 : //<S2SV> gen_helper_idivb_AL ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case MO_16 : //<S2SV> gen_helper_idivw_AX ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case MO_32 : //<S2SV> gen_helper_idivl_EAX ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> gen_helper_idivq_EAX ( cpu_env , cpu_T0 ) ; //<S2SV> break ; //<S2SV> # endif //<S2SV> } //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xfe : //<S2SV> case 0xff : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> op = ( modrm >> 3 ) & 7 ; //<S2SV> if ( op >= 2 && b == 0xfe ) { //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> if ( op == 2 || op == 4 ) { //<S2SV> ot = MO_64 ; //<S2SV> } else if ( op == 3 || op == 5 ) { //<S2SV> ot = dflag != MO_16 ? MO_32 + ( rex_w == 1 ) : MO_16 ; //<S2SV> } else if ( op == 6 ) { //<S2SV> ot = mo_pushpop ( s , dflag ) ; //<S2SV> } //<S2SV> } //<S2SV> if ( mod != 3 ) { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( op >= 2 && op != 3 && op != 5 ) //<S2SV> gen_op_ld_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , rm ) ; //<S2SV> } //<S2SV> switch ( op ) { //<S2SV> case 0 : //<S2SV> if ( mod != 3 ) //<S2SV> opreg = OR_TMP0 ; //<S2SV> else //<S2SV> opreg = rm ; //<S2SV> gen_inc ( s , ot , opreg , 1 ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> if ( mod != 3 ) //<S2SV> opreg = OR_TMP0 ; //<S2SV> else //<S2SV> opreg = rm ; //<S2SV> gen_inc ( s , ot , opreg , - 1 ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> } //<S2SV> next_eip = s -> pc - s -> cs_base ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , next_eip ) ; //<S2SV> gen_push_v ( s , cpu_T1 ) ; //<S2SV> gen_op_jmp_v ( cpu_T0 ) ; //<S2SV> gen_bnd_jmp ( s ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> gen_op_ld_v ( s , ot , cpu_T1 , cpu_A0 ) ; //<S2SV> gen_add_A0_im ( s , 1 << ot ) ; //<S2SV> gen_op_ld_v ( s , MO_16 , cpu_T0 , cpu_A0 ) ; //<S2SV> do_lcall : //<S2SV> if ( s -> pe && ! s -> vm86 ) { //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> gen_helper_lcall_protected ( cpu_env , cpu_tmp2_i32 , cpu_T1 , //<S2SV> tcg_const_i32 ( dflag - 1 ) , //<S2SV> tcg_const_tl ( s -> pc - s -> cs_base ) ) ; //<S2SV> } else { //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> gen_helper_lcall_real ( cpu_env , cpu_tmp2_i32 , cpu_T1 , //<S2SV> tcg_const_i32 ( dflag - 1 ) , //<S2SV> tcg_const_i32 ( s -> pc - s -> cs_base ) ) ; //<S2SV> } //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 4 : //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> } //<S2SV> gen_op_jmp_v ( cpu_T0 ) ; //<S2SV> gen_bnd_jmp ( s ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 5 : //<S2SV> gen_op_ld_v ( s , ot , cpu_T1 , cpu_A0 ) ; //<S2SV> gen_add_A0_im ( s , 1 << ot ) ; //<S2SV> gen_op_ld_v ( s , MO_16 , cpu_T0 , cpu_A0 ) ; //<S2SV> do_ljmp : //<S2SV> if ( s -> pe && ! s -> vm86 ) { //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> gen_helper_ljmp_protected ( cpu_env , cpu_tmp2_i32 , cpu_T1 , //<S2SV> tcg_const_tl ( s -> pc - s -> cs_base ) ) ; //<S2SV> } else { //<S2SV> gen_op_movl_seg_T0_vm ( R_CS ) ; //<S2SV> gen_op_jmp_v ( cpu_T1 ) ; //<S2SV> } //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 6 : //<S2SV> gen_push_v ( s , cpu_T0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x84 : //<S2SV> case 0x85 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 0 ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , reg ) ; //<S2SV> gen_op_testl_T0_T1_cc ( ) ; //<S2SV> set_cc_op ( s , CC_OP_LOGICB + ot ) ; //<S2SV> break ; //<S2SV> case 0xa8 : //<S2SV> case 0xa9 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , OR_EAX ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , val ) ; //<S2SV> gen_op_testl_T0_T1_cc ( ) ; //<S2SV> set_cc_op ( s , CC_OP_LOGICB + ot ) ; //<S2SV> break ; //<S2SV> case 0x98 : //<S2SV> switch ( dflag ) { //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> gen_op_mov_v_reg ( MO_32 , cpu_T0 , R_EAX ) ; //<S2SV> tcg_gen_ext32s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( MO_64 , R_EAX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> # endif //<S2SV> case MO_32 : //<S2SV> gen_op_mov_v_reg ( MO_16 , cpu_T0 , R_EAX ) ; //<S2SV> tcg_gen_ext16s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( MO_32 , R_EAX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case MO_16 : //<S2SV> gen_op_mov_v_reg ( MO_8 , cpu_T0 , R_EAX ) ; //<S2SV> tcg_gen_ext8s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EAX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> tcg_abort ( ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x99 : //<S2SV> switch ( dflag ) { //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> gen_op_mov_v_reg ( MO_64 , cpu_T0 , R_EAX ) ; //<S2SV> tcg_gen_sari_tl ( cpu_T0 , cpu_T0 , 63 ) ; //<S2SV> gen_op_mov_reg_v ( MO_64 , R_EDX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> # endif //<S2SV> case MO_32 : //<S2SV> gen_op_mov_v_reg ( MO_32 , cpu_T0 , R_EAX ) ; //<S2SV> tcg_gen_ext32s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_sari_tl ( cpu_T0 , cpu_T0 , 31 ) ; //<S2SV> gen_op_mov_reg_v ( MO_32 , R_EDX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case MO_16 : //<S2SV> gen_op_mov_v_reg ( MO_16 , cpu_T0 , R_EAX ) ; //<S2SV> tcg_gen_ext16s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_sari_tl ( cpu_T0 , cpu_T0 , 15 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EDX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> tcg_abort ( ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1af : //<S2SV> case 0x69 : //<S2SV> case 0x6b : //<S2SV> ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> if ( b == 0x69 ) //<S2SV> s -> rip_offset = insn_const_size ( ot ) ; //<S2SV> else if ( b == 0x6b ) //<S2SV> s -> rip_offset = 1 ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 0 ) ; //<S2SV> if ( b == 0x69 ) { //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , val ) ; //<S2SV> } else if ( b == 0x6b ) { //<S2SV> val = ( int8_t ) insn_get ( env , s , MO_8 ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , val ) ; //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , reg ) ; //<S2SV> } //<S2SV> switch ( ot ) { //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> tcg_gen_muls2_i64 ( cpu_regs [ reg ] , cpu_T1 , cpu_T0 , cpu_T1 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_regs [ reg ] ) ; //<S2SV> tcg_gen_sari_tl ( cpu_cc_src , cpu_cc_dst , 63 ) ; //<S2SV> tcg_gen_sub_tl ( cpu_cc_src , cpu_cc_src , cpu_T1 ) ; //<S2SV> break ; //<S2SV> # endif //<S2SV> case MO_32 : //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp3_i32 , cpu_T1 ) ; //<S2SV> tcg_gen_muls2_i32 ( cpu_tmp2_i32 , cpu_tmp3_i32 , //<S2SV> cpu_tmp2_i32 , cpu_tmp3_i32 ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_regs [ reg ] , cpu_tmp2_i32 ) ; //<S2SV> tcg_gen_sari_i32 ( cpu_tmp2_i32 , cpu_tmp2_i32 , 31 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_regs [ reg ] ) ; //<S2SV> tcg_gen_sub_i32 ( cpu_tmp2_i32 , cpu_tmp2_i32 , cpu_tmp3_i32 ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_cc_src , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> tcg_gen_ext16s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_ext16s_tl ( cpu_T1 , cpu_T1 ) ; //<S2SV> tcg_gen_mul_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_T0 ) ; //<S2SV> tcg_gen_ext16s_tl ( cpu_tmp0 , cpu_T0 ) ; //<S2SV> tcg_gen_sub_tl ( cpu_cc_src , cpu_T0 , cpu_tmp0 ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T0 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> set_cc_op ( s , CC_OP_MULB + ot ) ; //<S2SV> break ; //<S2SV> case 0x1c0 : //<S2SV> case 0x1c1 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , reg ) ; //<S2SV> if ( mod == 3 ) { //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , rm ) ; //<S2SV> tcg_gen_add_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T1 ) ; //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> } else { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( s -> prefix & PREFIX_LOCK ) { //<S2SV> tcg_gen_atomic_fetch_add_tl ( cpu_T1 , cpu_A0 , cpu_T0 , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> tcg_gen_add_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> } else { //<S2SV> gen_op_ld_v ( s , ot , cpu_T1 , cpu_A0 ) ; //<S2SV> tcg_gen_add_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> gen_op_st_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T1 ) ; //<S2SV> } //<S2SV> gen_op_update2_cc ( ) ; //<S2SV> set_cc_op ( s , CC_OP_ADDB + ot ) ; //<S2SV> break ; //<S2SV> case 0x1b0 : //<S2SV> case 0x1b1 : //<S2SV> { //<S2SV> TCGv oldv , newv , cmpv ; //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> oldv = tcg_temp_new ( ) ; //<S2SV> newv = tcg_temp_new ( ) ; //<S2SV> cmpv = tcg_temp_new ( ) ; //<S2SV> gen_op_mov_v_reg ( ot , newv , reg ) ; //<S2SV> tcg_gen_mov_tl ( cmpv , cpu_regs [ R_EAX ] ) ; //<S2SV> if ( s -> prefix & PREFIX_LOCK ) { //<S2SV> if ( mod == 3 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_atomic_cmpxchg_tl ( oldv , cpu_A0 , cmpv , newv , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> gen_op_mov_reg_v ( ot , R_EAX , oldv ) ; //<S2SV> } else { //<S2SV> if ( mod == 3 ) { //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> gen_op_mov_v_reg ( ot , oldv , rm ) ; //<S2SV> } else { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , ot , oldv , cpu_A0 ) ; //<S2SV> rm = 0 ; //<S2SV> } //<S2SV> gen_extu ( ot , oldv ) ; //<S2SV> gen_extu ( ot , cmpv ) ; //<S2SV> tcg_gen_movcond_tl ( TCG_COND_EQ , newv , oldv , cmpv , newv , oldv ) ; //<S2SV> if ( mod == 3 ) { //<S2SV> gen_op_mov_reg_v ( ot , R_EAX , oldv ) ; //<S2SV> gen_op_mov_reg_v ( ot , rm , newv ) ; //<S2SV> } else { //<S2SV> gen_op_st_v ( s , ot , newv , cpu_A0 ) ; //<S2SV> gen_op_mov_reg_v ( ot , R_EAX , oldv ) ; //<S2SV> } //<S2SV> } //<S2SV> tcg_gen_mov_tl ( cpu_cc_src , oldv ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_srcT , cmpv ) ; //<S2SV> tcg_gen_sub_tl ( cpu_cc_dst , cmpv , oldv ) ; //<S2SV> set_cc_op ( s , CC_OP_SUBB + ot ) ; //<S2SV> tcg_temp_free ( oldv ) ; //<S2SV> tcg_temp_free ( newv ) ; //<S2SV> tcg_temp_free ( cmpv ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1c7 : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( ( mod == 3 ) || ( ( modrm & 0x38 ) != 0x8 ) ) //<S2SV> goto illegal_op ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> if ( dflag == MO_64 ) { //<S2SV> if ( ! ( s -> cpuid_ext_features & CPUID_EXT_CX16 ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( ( s -> prefix & PREFIX_LOCK ) && parallel_cpus ) { //<S2SV> gen_helper_cmpxchg16b ( cpu_env , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_helper_cmpxchg16b_unlocked ( cpu_env , cpu_A0 ) ; //<S2SV> } //<S2SV> } else //<S2SV> # endif //<S2SV> { //<S2SV> if ( ! ( s -> cpuid_features & CPUID_CX8 ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( ( s -> prefix & PREFIX_LOCK ) && parallel_cpus ) { //<S2SV> gen_helper_cmpxchg8b ( cpu_env , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_helper_cmpxchg8b_unlocked ( cpu_env , cpu_A0 ) ; //<S2SV> } //<S2SV> } //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x50 ... 0x57 : //<S2SV> gen_op_mov_v_reg ( MO_32 , cpu_T0 , ( b & 7 ) | REX_B ( s ) ) ; //<S2SV> gen_push_v ( s , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x58 ... 0x5f : //<S2SV> ot = gen_pop_T0 ( s ) ; //<S2SV> gen_pop_update ( s , ot ) ; //<S2SV> gen_op_mov_reg_v ( ot , ( b & 7 ) | REX_B ( s ) , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x60 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_pusha ( s ) ; //<S2SV> break ; //<S2SV> case 0x61 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_popa ( s ) ; //<S2SV> break ; //<S2SV> case 0x68 : //<S2SV> case 0x6a : //<S2SV> ot = mo_pushpop ( s , dflag ) ; //<S2SV> if ( b == 0x68 ) //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> else //<S2SV> val = ( int8_t ) insn_get ( env , s , MO_8 ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , val ) ; //<S2SV> gen_push_v ( s , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x8f : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> ot = gen_pop_T0 ( s ) ; //<S2SV> if ( mod == 3 ) { //<S2SV> gen_pop_update ( s , ot ) ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> } else { //<S2SV> s -> popl_esp_hack = 1 << ot ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 1 ) ; //<S2SV> s -> popl_esp_hack = 0 ; //<S2SV> gen_pop_update ( s , ot ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xc8 : //<S2SV> { //<S2SV> int level ; //<S2SV> val = cpu_lduw_code ( env , s -> pc ) ; //<S2SV> s -> pc += 2 ; //<S2SV> level = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> gen_enter ( s , val , level ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xc9 : //<S2SV> gen_leave ( s ) ; //<S2SV> break ; //<S2SV> case 0x06 : //<S2SV> case 0x0e : //<S2SV> case 0x16 : //<S2SV> case 0x1e : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_op_movl_T0_seg ( b >> 3 ) ; //<S2SV> gen_push_v ( s , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x1a0 : //<S2SV> case 0x1a8 : //<S2SV> gen_op_movl_T0_seg ( ( b >> 3 ) & 7 ) ; //<S2SV> gen_push_v ( s , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x07 : //<S2SV> case 0x17 : //<S2SV> case 0x1f : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> reg = b >> 3 ; //<S2SV> ot = gen_pop_T0 ( s ) ; //<S2SV> gen_movl_seg_T0 ( s , reg ) ; //<S2SV> gen_pop_update ( s , ot ) ; //<S2SV> if ( s -> is_jmp ) { //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> if ( reg == R_SS ) { //<S2SV> s -> tf = 0 ; //<S2SV> gen_eob_inhibit_irq ( s , true ) ; //<S2SV> } else { //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1a1 : //<S2SV> case 0x1a9 : //<S2SV> ot = gen_pop_T0 ( s ) ; //<S2SV> gen_movl_seg_T0 ( s , ( b >> 3 ) & 7 ) ; //<S2SV> gen_pop_update ( s , ot ) ; //<S2SV> if ( s -> is_jmp ) { //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x88 : //<S2SV> case 0x89 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , reg , 1 ) ; //<S2SV> break ; //<S2SV> case 0xc6 : //<S2SV> case 0xc7 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( mod != 3 ) { //<S2SV> s -> rip_offset = insn_const_size ( ot ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> } //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , val ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_op_st_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_reg_v ( ot , ( modrm & 7 ) | REX_B ( s ) , cpu_T0 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x8a : //<S2SV> case 0x8b : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 0 ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x8e : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( modrm >> 3 ) & 7 ; //<S2SV> if ( reg >= 6 || reg == R_CS ) //<S2SV> goto illegal_op ; //<S2SV> gen_ldst_modrm ( env , s , modrm , MO_16 , OR_TMP0 , 0 ) ; //<S2SV> gen_movl_seg_T0 ( s , reg ) ; //<S2SV> if ( s -> is_jmp ) { //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> if ( reg == R_SS ) { //<S2SV> s -> tf = 0 ; //<S2SV> gen_eob_inhibit_irq ( s , true ) ; //<S2SV> } else { //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x8c : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( modrm >> 3 ) & 7 ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( reg >= 6 ) //<S2SV> goto illegal_op ; //<S2SV> gen_op_movl_T0_seg ( reg ) ; //<S2SV> ot = mod == 3 ? dflag : MO_16 ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 1 ) ; //<S2SV> break ; //<S2SV> case 0x1b6 : //<S2SV> case 0x1b7 : //<S2SV> case 0x1be : //<S2SV> case 0x1bf : //<S2SV> { //<S2SV> TCGMemOp d_ot ; //<S2SV> TCGMemOp s_ot ; //<S2SV> d_ot = dflag ; //<S2SV> ot = ( b & 1 ) + MO_8 ; //<S2SV> s_ot = b & 8 ? MO_SIGN | ot : ot ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> if ( mod == 3 ) { //<S2SV> if ( s_ot == MO_SB && byte_reg_is_xH ( rm ) ) { //<S2SV> tcg_gen_sextract_tl ( cpu_T0 , cpu_regs [ rm - 4 ] , 8 , 8 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , rm ) ; //<S2SV> switch ( s_ot ) { //<S2SV> case MO_UB : //<S2SV> tcg_gen_ext8u_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case MO_SB : //<S2SV> tcg_gen_ext8s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case MO_UW : //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case MO_SW : //<S2SV> tcg_gen_ext16s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> } //<S2SV> gen_op_mov_reg_v ( d_ot , reg , cpu_T0 ) ; //<S2SV> } else { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , s_ot , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_op_mov_reg_v ( d_ot , reg , cpu_T0 ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x8d : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( mod == 3 ) //<S2SV> goto illegal_op ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> { //<S2SV> AddressParts a = gen_lea_modrm_0 ( env , s , modrm ) ; //<S2SV> TCGv ea = gen_lea_modrm_1 ( a ) ; //<S2SV> gen_lea_v_seg ( s , s -> aflag , ea , - 1 , - 1 ) ; //<S2SV> gen_op_mov_reg_v ( dflag , reg , cpu_A0 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xa0 : //<S2SV> case 0xa1 : //<S2SV> case 0xa2 : //<S2SV> case 0xa3 : //<S2SV> { //<S2SV> target_ulong offset_addr ; //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> switch ( s -> aflag ) { //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case MO_64 : //<S2SV> offset_addr = cpu_ldq_code ( env , s -> pc ) ; //<S2SV> s -> pc += 8 ; //<S2SV> break ; //<S2SV> # endif //<S2SV> default : //<S2SV> offset_addr = insn_get ( env , s , s -> aflag ) ; //<S2SV> break ; //<S2SV> } //<S2SV> tcg_gen_movi_tl ( cpu_A0 , offset_addr ) ; //<S2SV> gen_add_A0_ds_seg ( s ) ; //<S2SV> if ( ( b & 2 ) == 0 ) { //<S2SV> gen_op_ld_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_op_mov_reg_v ( ot , R_EAX , cpu_T0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , R_EAX ) ; //<S2SV> gen_op_st_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0xd7 : //<S2SV> tcg_gen_mov_tl ( cpu_A0 , cpu_regs [ R_EBX ] ) ; //<S2SV> tcg_gen_ext8u_tl ( cpu_T0 , cpu_regs [ R_EAX ] ) ; //<S2SV> tcg_gen_add_tl ( cpu_A0 , cpu_A0 , cpu_T0 ) ; //<S2SV> gen_extu ( s -> aflag , cpu_A0 ) ; //<S2SV> gen_add_A0_ds_seg ( s ) ; //<S2SV> gen_op_ld_v ( s , MO_8 , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_op_mov_reg_v ( MO_8 , R_EAX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0xb0 ... 0xb7 : //<S2SV> val = insn_get ( env , s , MO_8 ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , val ) ; //<S2SV> gen_op_mov_reg_v ( MO_8 , ( b & 7 ) | REX_B ( s ) , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0xb8 ... 0xbf : //<S2SV> # ifdef TARGET_X86_64 //<S2SV> if ( dflag == MO_64 ) { //<S2SV> uint64_t tmp ; //<S2SV> tmp = cpu_ldq_code ( env , s -> pc ) ; //<S2SV> s -> pc += 8 ; //<S2SV> reg = ( b & 7 ) | REX_B ( s ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , tmp ) ; //<S2SV> gen_op_mov_reg_v ( MO_64 , reg , cpu_T0 ) ; //<S2SV> } else //<S2SV> # endif //<S2SV> { //<S2SV> ot = dflag ; //<S2SV> val = insn_get ( env , s , ot ) ; //<S2SV> reg = ( b & 7 ) | REX_B ( s ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , val ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T0 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x91 ... 0x97 : //<S2SV> do_xchg_reg_eax : //<S2SV> ot = dflag ; //<S2SV> reg = ( b & 7 ) | REX_B ( s ) ; //<S2SV> rm = R_EAX ; //<S2SV> goto do_xchg_reg ; //<S2SV> case 0x86 : //<S2SV> case 0x87 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( mod == 3 ) { //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> do_xchg_reg : //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , reg ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , rm ) ; //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T1 ) ; //<S2SV> } else { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , reg ) ; //<S2SV> tcg_gen_atomic_xchg_tl ( cpu_T1 , cpu_A0 , cpu_T0 , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T1 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xc4 : //<S2SV> op = R_ES ; //<S2SV> goto do_lxx ; //<S2SV> case 0xc5 : //<S2SV> op = R_DS ; //<S2SV> goto do_lxx ; //<S2SV> case 0x1b2 : //<S2SV> op = R_SS ; //<S2SV> goto do_lxx ; //<S2SV> case 0x1b4 : //<S2SV> op = R_FS ; //<S2SV> goto do_lxx ; //<S2SV> case 0x1b5 : //<S2SV> op = R_GS ; //<S2SV> do_lxx : //<S2SV> ot = dflag != MO_16 ? MO_32 : MO_16 ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( mod == 3 ) //<S2SV> goto illegal_op ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , ot , cpu_T1 , cpu_A0 ) ; //<S2SV> gen_add_A0_im ( s , 1 << ot ) ; //<S2SV> gen_op_ld_v ( s , MO_16 , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_movl_seg_T0 ( s , op ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T1 ) ; //<S2SV> if ( s -> is_jmp ) { //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xc0 : //<S2SV> case 0xc1 : //<S2SV> shift = 2 ; //<S2SV> grp2 : //<S2SV> { //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> op = ( modrm >> 3 ) & 7 ; //<S2SV> if ( mod != 3 ) { //<S2SV> if ( shift == 2 ) { //<S2SV> s -> rip_offset = 1 ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> opreg = OR_TMP0 ; //<S2SV> } else { //<S2SV> opreg = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> } //<S2SV> if ( shift == 0 ) { //<S2SV> gen_shift ( s , op , ot , opreg , OR_ECX ) ; //<S2SV> } else { //<S2SV> if ( shift == 2 ) { //<S2SV> shift = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> } //<S2SV> gen_shifti ( s , op , ot , opreg , shift ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0xd0 : //<S2SV> case 0xd1 : //<S2SV> shift = 1 ; //<S2SV> goto grp2 ; //<S2SV> case 0xd2 : //<S2SV> case 0xd3 : //<S2SV> shift = 0 ; //<S2SV> goto grp2 ; //<S2SV> case 0x1a4 : //<S2SV> op = 0 ; //<S2SV> shift = 1 ; //<S2SV> goto do_shiftd ; //<S2SV> case 0x1a5 : //<S2SV> op = 0 ; //<S2SV> shift = 0 ; //<S2SV> goto do_shiftd ; //<S2SV> case 0x1ac : //<S2SV> op = 1 ; //<S2SV> shift = 1 ; //<S2SV> goto do_shiftd ; //<S2SV> case 0x1ad : //<S2SV> op = 1 ; //<S2SV> shift = 0 ; //<S2SV> do_shiftd : //<S2SV> ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> opreg = OR_TMP0 ; //<S2SV> } else { //<S2SV> opreg = rm ; //<S2SV> } //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , reg ) ; //<S2SV> if ( shift ) { //<S2SV> TCGv imm = tcg_const_tl ( cpu_ldub_code ( env , s -> pc ++ ) ) ; //<S2SV> gen_shiftd_rm_T1 ( s , ot , opreg , op , imm ) ; //<S2SV> tcg_temp_free ( imm ) ; //<S2SV> } else { //<S2SV> gen_shiftd_rm_T1 ( s , ot , opreg , op , cpu_regs [ R_ECX ] ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xd8 ... 0xdf : //<S2SV> if ( s -> flags & ( HF_EM_MASK | HF_TS_MASK ) ) { //<S2SV> gen_exception ( s , EXCP07_PREX , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = modrm & 7 ; //<S2SV> op = ( ( b & 7 ) << 3 ) | ( ( modrm >> 3 ) & 7 ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> switch ( op ) { //<S2SV> case 0x00 ... 0x07 : //<S2SV> case 0x10 ... 0x17 : //<S2SV> case 0x20 ... 0x27 : //<S2SV> case 0x30 ... 0x37 : //<S2SV> { //<S2SV> int op1 ; //<S2SV> op1 = op & 7 ; //<S2SV> switch ( op >> 4 ) { //<S2SV> case 0 : //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> gen_helper_flds_FT0 ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> gen_helper_fildl_FT0 ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> tcg_gen_qemu_ld_i64 ( cpu_tmp1_i64 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> gen_helper_fldl_FT0 ( cpu_env , cpu_tmp1_i64 ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> default : //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LESW ) ; //<S2SV> gen_helper_fildl_FT0 ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_helper_fp_arith_ST0_FT0 ( op1 ) ; //<S2SV> if ( op1 == 3 ) { //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x08 : //<S2SV> case 0x0a : //<S2SV> case 0x0b : //<S2SV> case 0x18 ... 0x1b : //<S2SV> case 0x28 ... 0x2b : //<S2SV> case 0x38 ... 0x3b : //<S2SV> switch ( op & 7 ) { //<S2SV> case 0 : //<S2SV> switch ( op >> 4 ) { //<S2SV> case 0 : //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> gen_helper_flds_ST0 ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> gen_helper_fildl_ST0 ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> tcg_gen_qemu_ld_i64 ( cpu_tmp1_i64 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> gen_helper_fldl_ST0 ( cpu_env , cpu_tmp1_i64 ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> default : //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LESW ) ; //<S2SV> gen_helper_fildl_ST0 ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> break ; //<S2SV> case 1 : //<S2SV> switch ( op >> 4 ) { //<S2SV> case 1 : //<S2SV> gen_helper_fisttl_ST0 ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> gen_helper_fisttll_ST0 ( cpu_tmp1_i64 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i64 ( cpu_tmp1_i64 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> default : //<S2SV> gen_helper_fistt_ST0 ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUW ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> switch ( op >> 4 ) { //<S2SV> case 0 : //<S2SV> gen_helper_fsts_ST0 ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> gen_helper_fistl_ST0 ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> gen_helper_fstl_ST0 ( cpu_tmp1_i64 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i64 ( cpu_tmp1_i64 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> default : //<S2SV> gen_helper_fist_ST0 ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUW ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( ( op & 7 ) == 3 ) //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x0c : //<S2SV> gen_helper_fldenv ( cpu_env , cpu_A0 , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> break ; //<S2SV> case 0x0d : //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUW ) ; //<S2SV> gen_helper_fldcw ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> case 0x0e : //<S2SV> gen_helper_fstenv ( cpu_env , cpu_A0 , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> break ; //<S2SV> case 0x0f : //<S2SV> gen_helper_fnstcw ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUW ) ; //<S2SV> break ; //<S2SV> case 0x1d : //<S2SV> gen_helper_fldt_ST0 ( cpu_env , cpu_A0 ) ; //<S2SV> break ; //<S2SV> case 0x1f : //<S2SV> gen_helper_fstt_ST0 ( cpu_env , cpu_A0 ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x2c : //<S2SV> gen_helper_frstor ( cpu_env , cpu_A0 , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> break ; //<S2SV> case 0x2e : //<S2SV> gen_helper_fsave ( cpu_env , cpu_A0 , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> break ; //<S2SV> case 0x2f : //<S2SV> gen_helper_fnstsw ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i32 ( cpu_tmp2_i32 , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUW ) ; //<S2SV> break ; //<S2SV> case 0x3c : //<S2SV> gen_helper_fbld_ST0 ( cpu_env , cpu_A0 ) ; //<S2SV> break ; //<S2SV> case 0x3e : //<S2SV> gen_helper_fbst_ST0 ( cpu_env , cpu_A0 ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x3d : //<S2SV> tcg_gen_qemu_ld_i64 ( cpu_tmp1_i64 , cpu_A0 , s -> mem_index , MO_LEQ ) ; //<S2SV> gen_helper_fildll_ST0 ( cpu_env , cpu_tmp1_i64 ) ; //<S2SV> break ; //<S2SV> case 0x3f : //<S2SV> gen_helper_fistll_ST0 ( cpu_tmp1_i64 , cpu_env ) ; //<S2SV> tcg_gen_qemu_st_i64 ( cpu_tmp1_i64 , cpu_A0 , s -> mem_index , MO_LEQ ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> } else { //<S2SV> opreg = rm ; //<S2SV> switch ( op ) { //<S2SV> case 0x08 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fmov_ST0_STN ( cpu_env , //<S2SV> tcg_const_i32 ( ( opreg + 1 ) & 7 ) ) ; //<S2SV> break ; //<S2SV> case 0x09 : //<S2SV> case 0x29 : //<S2SV> case 0x39 : //<S2SV> gen_helper_fxchg_ST0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> break ; //<S2SV> case 0x0a : //<S2SV> switch ( rm ) { //<S2SV> case 0 : //<S2SV> gen_helper_fwait ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x0c : //<S2SV> switch ( rm ) { //<S2SV> case 0 : //<S2SV> gen_helper_fchs_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> gen_helper_fabs_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 4 : //<S2SV> gen_helper_fldz_FT0 ( cpu_env ) ; //<S2SV> gen_helper_fcom_ST0_FT0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 5 : //<S2SV> gen_helper_fxam_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x0d : //<S2SV> { //<S2SV> switch ( rm ) { //<S2SV> case 0 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fld1_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fldl2t_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fldl2e_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fldpi_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 4 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fldlg2_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 5 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fldln2_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 6 : //<S2SV> gen_helper_fpush ( cpu_env ) ; //<S2SV> gen_helper_fldz_ST0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x0e : //<S2SV> switch ( rm ) { //<S2SV> case 0 : //<S2SV> gen_helper_f2xm1 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> gen_helper_fyl2x ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> gen_helper_fptan ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> gen_helper_fpatan ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 4 : //<S2SV> gen_helper_fxtract ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 5 : //<S2SV> gen_helper_fprem1 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 6 : //<S2SV> gen_helper_fdecstp ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case 7 : //<S2SV> gen_helper_fincstp ( cpu_env ) ; //<S2SV> break ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x0f : //<S2SV> switch ( rm ) { //<S2SV> case 0 : //<S2SV> gen_helper_fprem ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> gen_helper_fyl2xp1 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> gen_helper_fsqrt ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> gen_helper_fsincos ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 5 : //<S2SV> gen_helper_fscale ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 4 : //<S2SV> gen_helper_frndint ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 6 : //<S2SV> gen_helper_fsin ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case 7 : //<S2SV> gen_helper_fcos ( cpu_env ) ; //<S2SV> break ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x00 : case 0x01 : case 0x04 ... 0x07 : //<S2SV> case 0x20 : case 0x21 : case 0x24 ... 0x27 : //<S2SV> case 0x30 : case 0x31 : case 0x34 ... 0x37 : //<S2SV> { //<S2SV> int op1 ; //<S2SV> op1 = op & 7 ; //<S2SV> if ( op >= 0x20 ) { //<S2SV> gen_helper_fp_arith_STN_ST0 ( op1 , opreg ) ; //<S2SV> if ( op >= 0x30 ) //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> } else { //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fp_arith_ST0_FT0 ( op1 ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x02 : //<S2SV> case 0x22 : //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fcom_ST0_FT0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x03 : //<S2SV> case 0x23 : //<S2SV> case 0x32 : //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fcom_ST0_FT0 ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x15 : //<S2SV> switch ( rm ) { //<S2SV> case 1 : //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( 1 ) ) ; //<S2SV> gen_helper_fucom_ST0_FT0 ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1c : //<S2SV> switch ( rm ) { //<S2SV> case 0 : //<S2SV> break ; //<S2SV> case 1 : //<S2SV> break ; //<S2SV> case 2 : //<S2SV> gen_helper_fclex ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> gen_helper_fninit ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 4 : //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1d : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_CMOV ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fucomi_ST0_FT0 ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x1e : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_CMOV ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fcomi_ST0_FT0 ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x28 : //<S2SV> gen_helper_ffree_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> break ; //<S2SV> case 0x2a : //<S2SV> gen_helper_fmov_STN_ST0 ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> break ; //<S2SV> case 0x2b : //<S2SV> case 0x0b : //<S2SV> case 0x3a : //<S2SV> case 0x3b : //<S2SV> gen_helper_fmov_STN_ST0 ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x2c : //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fucom_ST0_FT0 ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x2d : //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fucom_ST0_FT0 ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x33 : //<S2SV> switch ( rm ) { //<S2SV> case 1 : //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( 1 ) ) ; //<S2SV> gen_helper_fcom_ST0_FT0 ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x38 : //<S2SV> gen_helper_ffree_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x3c : //<S2SV> switch ( rm ) { //<S2SV> case 0 : //<S2SV> gen_helper_fnstsw ( cpu_tmp2_i32 , cpu_env ) ; //<S2SV> tcg_gen_extu_i32_tl ( cpu_T0 , cpu_tmp2_i32 ) ; //<S2SV> gen_op_mov_reg_v ( MO_16 , R_EAX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x3d : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_CMOV ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fucomi_ST0_FT0 ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x3e : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_CMOV ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_fmov_FT0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_helper_fcomi_ST0_FT0 ( cpu_env ) ; //<S2SV> gen_helper_fpop ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x10 ... 0x13 : //<S2SV> case 0x18 ... 0x1b : //<S2SV> { //<S2SV> int op1 ; //<S2SV> TCGLabel * l1 ; //<S2SV> static const uint8_t fcmov_cc [ 8 ] = { //<S2SV> ( JCC_B << 1 ) , //<S2SV> ( JCC_Z << 1 ) , //<S2SV> ( JCC_BE << 1 ) , //<S2SV> ( JCC_P << 1 ) , //<S2SV> } ; //<S2SV> if ( ! ( s -> cpuid_features & CPUID_CMOV ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> op1 = fcmov_cc [ op & 3 ] | ( ( ( op >> 3 ) & 1 ) ^ 1 ) ; //<S2SV> l1 = gen_new_label ( ) ; //<S2SV> gen_jcc1_noeob ( s , op1 , l1 ) ; //<S2SV> gen_helper_fmov_ST0_STN ( cpu_env , tcg_const_i32 ( opreg ) ) ; //<S2SV> gen_set_label ( l1 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0xa4 : //<S2SV> case 0xa5 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> if ( prefixes & ( PREFIX_REPZ | PREFIX_REPNZ ) ) { //<S2SV> gen_repz_movs ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_movs ( s , ot ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xaa : //<S2SV> case 0xab : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> if ( prefixes & ( PREFIX_REPZ | PREFIX_REPNZ ) ) { //<S2SV> gen_repz_stos ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_stos ( s , ot ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xac : //<S2SV> case 0xad : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> if ( prefixes & ( PREFIX_REPZ | PREFIX_REPNZ ) ) { //<S2SV> gen_repz_lods ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_lods ( s , ot ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xae : //<S2SV> case 0xaf : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> if ( prefixes & PREFIX_REPNZ ) { //<S2SV> gen_repz_scas ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base , 1 ) ; //<S2SV> } else if ( prefixes & PREFIX_REPZ ) { //<S2SV> gen_repz_scas ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base , 0 ) ; //<S2SV> } else { //<S2SV> gen_scas ( s , ot ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xa6 : //<S2SV> case 0xa7 : //<S2SV> ot = mo_b_d ( b , dflag ) ; //<S2SV> if ( prefixes & PREFIX_REPNZ ) { //<S2SV> gen_repz_cmps ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base , 1 ) ; //<S2SV> } else if ( prefixes & PREFIX_REPZ ) { //<S2SV> gen_repz_cmps ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base , 0 ) ; //<S2SV> } else { //<S2SV> gen_cmps ( s , ot ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x6c : //<S2SV> case 0x6d : //<S2SV> ot = mo_b_d32 ( b , dflag ) ; //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_regs [ R_EDX ] ) ; //<S2SV> gen_check_io ( s , ot , pc_start - s -> cs_base , //<S2SV> SVM_IOIO_TYPE_MASK | svm_is_rep ( prefixes ) | 4 ) ; //<S2SV> if ( prefixes & ( PREFIX_REPZ | PREFIX_REPNZ ) ) { //<S2SV> gen_repz_ins ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_ins ( s , ot ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x6e : //<S2SV> case 0x6f : //<S2SV> ot = mo_b_d32 ( b , dflag ) ; //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_regs [ R_EDX ] ) ; //<S2SV> gen_check_io ( s , ot , pc_start - s -> cs_base , //<S2SV> svm_is_rep ( prefixes ) | 4 ) ; //<S2SV> if ( prefixes & ( PREFIX_REPZ | PREFIX_REPNZ ) ) { //<S2SV> gen_repz_outs ( s , ot , pc_start - s -> cs_base , s -> pc - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_outs ( s , ot ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0xe4 : //<S2SV> case 0xe5 : //<S2SV> ot = mo_b_d32 ( b , dflag ) ; //<S2SV> val = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , val ) ; //<S2SV> gen_check_io ( s , ot , pc_start - s -> cs_base , //<S2SV> SVM_IOIO_TYPE_MASK | svm_is_rep ( prefixes ) ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_start ( ) ; //<S2SV> } //<S2SV> tcg_gen_movi_i32 ( cpu_tmp2_i32 , val ) ; //<S2SV> gen_helper_in_func ( ot , cpu_T1 , cpu_tmp2_i32 ) ; //<S2SV> gen_op_mov_reg_v ( ot , R_EAX , cpu_T1 ) ; //<S2SV> gen_bpt_io ( s , cpu_tmp2_i32 , ot ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_end ( ) ; //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xe6 : //<S2SV> case 0xe7 : //<S2SV> ot = mo_b_d32 ( b , dflag ) ; //<S2SV> val = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , val ) ; //<S2SV> gen_check_io ( s , ot , pc_start - s -> cs_base , //<S2SV> svm_is_rep ( prefixes ) ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , R_EAX ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_start ( ) ; //<S2SV> } //<S2SV> tcg_gen_movi_i32 ( cpu_tmp2_i32 , val ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp3_i32 , cpu_T1 ) ; //<S2SV> gen_helper_out_func ( ot , cpu_tmp2_i32 , cpu_tmp3_i32 ) ; //<S2SV> gen_bpt_io ( s , cpu_tmp2_i32 , ot ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_end ( ) ; //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xec : //<S2SV> case 0xed : //<S2SV> ot = mo_b_d32 ( b , dflag ) ; //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_regs [ R_EDX ] ) ; //<S2SV> gen_check_io ( s , ot , pc_start - s -> cs_base , //<S2SV> SVM_IOIO_TYPE_MASK | svm_is_rep ( prefixes ) ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_start ( ) ; //<S2SV> } //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> gen_helper_in_func ( ot , cpu_T1 , cpu_tmp2_i32 ) ; //<S2SV> gen_op_mov_reg_v ( ot , R_EAX , cpu_T1 ) ; //<S2SV> gen_bpt_io ( s , cpu_tmp2_i32 , ot ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_end ( ) ; //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xee : //<S2SV> case 0xef : //<S2SV> ot = mo_b_d32 ( b , dflag ) ; //<S2SV> tcg_gen_ext16u_tl ( cpu_T0 , cpu_regs [ R_EDX ] ) ; //<S2SV> gen_check_io ( s , ot , pc_start - s -> cs_base , //<S2SV> svm_is_rep ( prefixes ) ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T1 , R_EAX ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_start ( ) ; //<S2SV> } //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp3_i32 , cpu_T1 ) ; //<S2SV> gen_helper_out_func ( ot , cpu_tmp2_i32 , cpu_tmp3_i32 ) ; //<S2SV> gen_bpt_io ( s , cpu_tmp2_i32 , ot ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_end ( ) ; //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xc2 : //<S2SV> val = cpu_ldsw_code ( env , s -> pc ) ; //<S2SV> s -> pc += 2 ; //<S2SV> ot = gen_pop_T0 ( s ) ; //<S2SV> gen_stack_update ( s , val + ( 1 << ot ) ) ; //<S2SV> gen_op_jmp_v ( cpu_T0 ) ; //<S2SV> gen_bnd_jmp ( s ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xc3 : //<S2SV> ot = gen_pop_T0 ( s ) ; //<S2SV> gen_pop_update ( s , ot ) ; //<S2SV> gen_op_jmp_v ( cpu_T0 ) ; //<S2SV> gen_bnd_jmp ( s ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xca : //<S2SV> val = cpu_ldsw_code ( env , s -> pc ) ; //<S2SV> s -> pc += 2 ; //<S2SV> do_lret : //<S2SV> if ( s -> pe && ! s -> vm86 ) { //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_lret_protected ( cpu_env , tcg_const_i32 ( dflag - 1 ) , //<S2SV> tcg_const_i32 ( val ) ) ; //<S2SV> } else { //<S2SV> gen_stack_A0 ( s ) ; //<S2SV> gen_op_ld_v ( s , dflag , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_op_jmp_v ( cpu_T0 ) ; //<S2SV> gen_add_A0_im ( s , 1 << dflag ) ; //<S2SV> gen_op_ld_v ( s , dflag , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_op_movl_seg_T0_vm ( R_CS ) ; //<S2SV> gen_stack_update ( s , val + ( 2 << dflag ) ) ; //<S2SV> } //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xcb : //<S2SV> val = 0 ; //<S2SV> goto do_lret ; //<S2SV> case 0xcf : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_IRET ) ; //<S2SV> if ( ! s -> pe ) { //<S2SV> gen_helper_iret_real ( cpu_env , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> } else if ( s -> vm86 ) { //<S2SV> if ( s -> iopl != 3 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_helper_iret_real ( cpu_env , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> } //<S2SV> } else { //<S2SV> gen_helper_iret_protected ( cpu_env , tcg_const_i32 ( dflag - 1 ) , //<S2SV> tcg_const_i32 ( s -> pc - s -> cs_base ) ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> } //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xe8 : //<S2SV> { //<S2SV> if ( dflag != MO_16 ) { //<S2SV> tval = ( int32_t ) insn_get ( env , s , MO_32 ) ; //<S2SV> } else { //<S2SV> tval = ( int16_t ) insn_get ( env , s , MO_16 ) ; //<S2SV> } //<S2SV> next_eip = s -> pc - s -> cs_base ; //<S2SV> tval += next_eip ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tval &= 0xffff ; //<S2SV> } else if ( ! CODE64 ( s ) ) { //<S2SV> tval &= 0xffffffff ; //<S2SV> } //<S2SV> tcg_gen_movi_tl ( cpu_T0 , next_eip ) ; //<S2SV> gen_push_v ( s , cpu_T0 ) ; //<S2SV> gen_bnd_jmp ( s ) ; //<S2SV> gen_jmp ( s , tval ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x9a : //<S2SV> { //<S2SV> unsigned int selector , offset ; //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> ot = dflag ; //<S2SV> offset = insn_get ( env , s , ot ) ; //<S2SV> selector = insn_get ( env , s , MO_16 ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , selector ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , offset ) ; //<S2SV> } //<S2SV> goto do_lcall ; //<S2SV> case 0xe9 : //<S2SV> if ( dflag != MO_16 ) { //<S2SV> tval = ( int32_t ) insn_get ( env , s , MO_32 ) ; //<S2SV> } else { //<S2SV> tval = ( int16_t ) insn_get ( env , s , MO_16 ) ; //<S2SV> } //<S2SV> tval += s -> pc - s -> cs_base ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tval &= 0xffff ; //<S2SV> } else if ( ! CODE64 ( s ) ) { //<S2SV> tval &= 0xffffffff ; //<S2SV> } //<S2SV> gen_bnd_jmp ( s ) ; //<S2SV> gen_jmp ( s , tval ) ; //<S2SV> break ; //<S2SV> case 0xea : //<S2SV> { //<S2SV> unsigned int selector , offset ; //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> ot = dflag ; //<S2SV> offset = insn_get ( env , s , ot ) ; //<S2SV> selector = insn_get ( env , s , MO_16 ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T0 , selector ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , offset ) ; //<S2SV> } //<S2SV> goto do_ljmp ; //<S2SV> case 0xeb : //<S2SV> tval = ( int8_t ) insn_get ( env , s , MO_8 ) ; //<S2SV> tval += s -> pc - s -> cs_base ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tval &= 0xffff ; //<S2SV> } //<S2SV> gen_jmp ( s , tval ) ; //<S2SV> break ; //<S2SV> case 0x70 ... 0x7f : //<S2SV> tval = ( int8_t ) insn_get ( env , s , MO_8 ) ; //<S2SV> goto do_jcc ; //<S2SV> case 0x180 ... 0x18f : //<S2SV> if ( dflag != MO_16 ) { //<S2SV> tval = ( int32_t ) insn_get ( env , s , MO_32 ) ; //<S2SV> } else { //<S2SV> tval = ( int16_t ) insn_get ( env , s , MO_16 ) ; //<S2SV> } //<S2SV> do_jcc : //<S2SV> next_eip = s -> pc - s -> cs_base ; //<S2SV> tval += next_eip ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tval &= 0xffff ; //<S2SV> } //<S2SV> gen_bnd_jmp ( s ) ; //<S2SV> gen_jcc ( s , b , tval , next_eip ) ; //<S2SV> break ; //<S2SV> case 0x190 ... 0x19f : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> gen_setcc1 ( s , b , cpu_T0 ) ; //<S2SV> gen_ldst_modrm ( env , s , modrm , MO_8 , OR_TMP0 , 1 ) ; //<S2SV> break ; //<S2SV> case 0x140 ... 0x14f : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_CMOV ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> gen_cmovcc1 ( env , s , ot , b , modrm , reg ) ; //<S2SV> break ; //<S2SV> case 0x9c : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_PUSHF ) ; //<S2SV> if ( s -> vm86 && s -> iopl != 3 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_read_eflags ( cpu_T0 , cpu_env ) ; //<S2SV> gen_push_v ( s , cpu_T0 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x9d : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_POPF ) ; //<S2SV> if ( s -> vm86 && s -> iopl != 3 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> ot = gen_pop_T0 ( s ) ; //<S2SV> if ( s -> cpl == 0 ) { //<S2SV> if ( dflag != MO_16 ) { //<S2SV> gen_helper_write_eflags ( cpu_env , cpu_T0 , //<S2SV> tcg_const_i32 ( ( TF_MASK | AC_MASK | //<S2SV> ID_MASK | NT_MASK | //<S2SV> IF_MASK | //<S2SV> IOPL_MASK ) ) ) ; //<S2SV> } else { //<S2SV> gen_helper_write_eflags ( cpu_env , cpu_T0 , //<S2SV> tcg_const_i32 ( ( TF_MASK | AC_MASK | //<S2SV> ID_MASK | NT_MASK | //<S2SV> IF_MASK | IOPL_MASK ) //<S2SV> & 0xffff ) ) ; //<S2SV> } //<S2SV> } else { //<S2SV> if ( s -> cpl <= s -> iopl ) { //<S2SV> if ( dflag != MO_16 ) { //<S2SV> gen_helper_write_eflags ( cpu_env , cpu_T0 , //<S2SV> tcg_const_i32 ( ( TF_MASK | //<S2SV> AC_MASK | //<S2SV> ID_MASK | //<S2SV> NT_MASK | //<S2SV> IF_MASK ) ) ) ; //<S2SV> } else { //<S2SV> gen_helper_write_eflags ( cpu_env , cpu_T0 , //<S2SV> tcg_const_i32 ( ( TF_MASK | //<S2SV> AC_MASK | //<S2SV> ID_MASK | //<S2SV> NT_MASK | //<S2SV> IF_MASK ) //<S2SV> & 0xffff ) ) ; //<S2SV> } //<S2SV> } else { //<S2SV> if ( dflag != MO_16 ) { //<S2SV> gen_helper_write_eflags ( cpu_env , cpu_T0 , //<S2SV> tcg_const_i32 ( ( TF_MASK | AC_MASK | //<S2SV> ID_MASK | NT_MASK ) ) ) ; //<S2SV> } else { //<S2SV> gen_helper_write_eflags ( cpu_env , cpu_T0 , //<S2SV> tcg_const_i32 ( ( TF_MASK | AC_MASK | //<S2SV> ID_MASK | NT_MASK ) //<S2SV> & 0xffff ) ) ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> gen_pop_update ( s , ot ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x9e : //<S2SV> if ( CODE64 ( s ) && ! ( s -> cpuid_ext3_features & CPUID_EXT3_LAHF_LM ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_op_mov_v_reg ( MO_8 , cpu_T0 , R_AH ) ; //<S2SV> gen_compute_eflags ( s ) ; //<S2SV> tcg_gen_andi_tl ( cpu_cc_src , cpu_cc_src , CC_O ) ; //<S2SV> tcg_gen_andi_tl ( cpu_T0 , cpu_T0 , CC_S | CC_Z | CC_A | CC_P | CC_C ) ; //<S2SV> tcg_gen_or_tl ( cpu_cc_src , cpu_cc_src , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x9f : //<S2SV> if ( CODE64 ( s ) && ! ( s -> cpuid_ext3_features & CPUID_EXT3_LAHF_LM ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_compute_eflags ( s ) ; //<S2SV> tcg_gen_ori_tl ( cpu_T0 , cpu_cc_src , 0x02 ) ; //<S2SV> gen_op_mov_reg_v ( MO_8 , R_AH , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0xf5 : //<S2SV> gen_compute_eflags ( s ) ; //<S2SV> tcg_gen_xori_tl ( cpu_cc_src , cpu_cc_src , CC_C ) ; //<S2SV> break ; //<S2SV> case 0xf8 : //<S2SV> gen_compute_eflags ( s ) ; //<S2SV> tcg_gen_andi_tl ( cpu_cc_src , cpu_cc_src , ~ CC_C ) ; //<S2SV> break ; //<S2SV> case 0xf9 : //<S2SV> gen_compute_eflags ( s ) ; //<S2SV> tcg_gen_ori_tl ( cpu_cc_src , cpu_cc_src , CC_C ) ; //<S2SV> break ; //<S2SV> case 0xfc : //<S2SV> tcg_gen_movi_i32 ( cpu_tmp2_i32 , 1 ) ; //<S2SV> tcg_gen_st_i32 ( cpu_tmp2_i32 , cpu_env , offsetof ( CPUX86State , df ) ) ; //<S2SV> break ; //<S2SV> case 0xfd : //<S2SV> tcg_gen_movi_i32 ( cpu_tmp2_i32 , - 1 ) ; //<S2SV> tcg_gen_st_i32 ( cpu_tmp2_i32 , cpu_env , offsetof ( CPUX86State , df ) ) ; //<S2SV> break ; //<S2SV> case 0x1ba : //<S2SV> ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> op = ( modrm >> 3 ) & 7 ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> s -> rip_offset = 1 ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( ! ( s -> prefix & PREFIX_LOCK ) ) { //<S2SV> gen_op_ld_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , rm ) ; //<S2SV> } //<S2SV> val = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> tcg_gen_movi_tl ( cpu_T1 , val ) ; //<S2SV> if ( op < 4 ) //<S2SV> goto unknown_op ; //<S2SV> op -= 4 ; //<S2SV> goto bt_op ; //<S2SV> case 0x1a3 : //<S2SV> op = 0 ; //<S2SV> goto do_btx ; //<S2SV> case 0x1ab : //<S2SV> op = 1 ; //<S2SV> goto do_btx ; //<S2SV> case 0x1b3 : //<S2SV> op = 2 ; //<S2SV> goto do_btx ; //<S2SV> case 0x1bb : //<S2SV> op = 3 ; //<S2SV> do_btx : //<S2SV> ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> gen_op_mov_v_reg ( MO_32 , cpu_T1 , reg ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> AddressParts a = gen_lea_modrm_0 ( env , s , modrm ) ; //<S2SV> gen_exts ( ot , cpu_T1 ) ; //<S2SV> tcg_gen_sari_tl ( cpu_tmp0 , cpu_T1 , 3 + ot ) ; //<S2SV> tcg_gen_shli_tl ( cpu_tmp0 , cpu_tmp0 , ot ) ; //<S2SV> tcg_gen_add_tl ( cpu_A0 , gen_lea_modrm_1 ( a ) , cpu_tmp0 ) ; //<S2SV> gen_lea_v_seg ( s , s -> aflag , cpu_A0 , a . def_seg , s -> override ) ; //<S2SV> if ( ! ( s -> prefix & PREFIX_LOCK ) ) { //<S2SV> gen_op_ld_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , rm ) ; //<S2SV> } //<S2SV> bt_op : //<S2SV> tcg_gen_andi_tl ( cpu_T1 , cpu_T1 , ( 1 << ( 3 + ot ) ) - 1 ) ; //<S2SV> tcg_gen_movi_tl ( cpu_tmp0 , 1 ) ; //<S2SV> tcg_gen_shl_tl ( cpu_tmp0 , cpu_tmp0 , cpu_T1 ) ; //<S2SV> if ( s -> prefix & PREFIX_LOCK ) { //<S2SV> switch ( op ) { //<S2SV> case 0 : //<S2SV> gen_op_ld_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> break ; //<S2SV> case 1 : //<S2SV> tcg_gen_atomic_fetch_or_tl ( cpu_T0 , cpu_A0 , cpu_tmp0 , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> tcg_gen_not_tl ( cpu_tmp0 , cpu_tmp0 ) ; //<S2SV> tcg_gen_atomic_fetch_and_tl ( cpu_T0 , cpu_A0 , cpu_tmp0 , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case 3 : //<S2SV> tcg_gen_atomic_fetch_xor_tl ( cpu_T0 , cpu_A0 , cpu_tmp0 , //<S2SV> s -> mem_index , ot | MO_LE ) ; //<S2SV> break ; //<S2SV> } //<S2SV> tcg_gen_shr_tl ( cpu_tmp4 , cpu_T0 , cpu_T1 ) ; //<S2SV> } else { //<S2SV> tcg_gen_shr_tl ( cpu_tmp4 , cpu_T0 , cpu_T1 ) ; //<S2SV> switch ( op ) { //<S2SV> case 0 : //<S2SV> break ; //<S2SV> case 1 : //<S2SV> tcg_gen_or_tl ( cpu_T0 , cpu_T0 , cpu_tmp0 ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> tcg_gen_andc_tl ( cpu_T0 , cpu_T0 , cpu_tmp0 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case 3 : //<S2SV> tcg_gen_xor_tl ( cpu_T0 , cpu_T0 , cpu_tmp0 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( op != 0 ) { //<S2SV> if ( mod != 3 ) { //<S2SV> gen_op_st_v ( s , ot , cpu_T0 , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> switch ( s -> cc_op ) { //<S2SV> case CC_OP_MULB ... CC_OP_MULQ : //<S2SV> case CC_OP_ADDB ... CC_OP_ADDQ : //<S2SV> case CC_OP_ADCB ... CC_OP_ADCQ : //<S2SV> case CC_OP_SUBB ... CC_OP_SUBQ : //<S2SV> case CC_OP_SBBB ... CC_OP_SBBQ : //<S2SV> case CC_OP_LOGICB ... CC_OP_LOGICQ : //<S2SV> case CC_OP_INCB ... CC_OP_INCQ : //<S2SV> case CC_OP_DECB ... CC_OP_DECQ : //<S2SV> case CC_OP_SHLB ... CC_OP_SHLQ : //<S2SV> case CC_OP_SARB ... CC_OP_SARQ : //<S2SV> case CC_OP_BMILGB ... CC_OP_BMILGQ : //<S2SV> tcg_gen_mov_tl ( cpu_cc_src , cpu_tmp4 ) ; //<S2SV> set_cc_op ( s , ( ( s -> cc_op - CC_OP_MULB ) & 3 ) + CC_OP_SARB ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> gen_compute_eflags ( s ) ; //<S2SV> tcg_gen_deposit_tl ( cpu_cc_src , cpu_cc_src , cpu_tmp4 , //<S2SV> ctz32 ( CC_C ) , 1 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1bc : //<S2SV> case 0x1bd : //<S2SV> ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 0 ) ; //<S2SV> gen_extu ( ot , cpu_T0 ) ; //<S2SV> if ( ( prefixes & PREFIX_REPZ ) //<S2SV> && ( b & 1 //<S2SV> ? s -> cpuid_ext3_features & CPUID_EXT3_ABM //<S2SV> : s -> cpuid_7_0_ebx_features & CPUID_7_0_EBX_BMI1 ) ) { //<S2SV> int size = 8 << ot ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_src , cpu_T0 ) ; //<S2SV> if ( b & 1 ) { //<S2SV> tcg_gen_clzi_tl ( cpu_T0 , cpu_T0 , TARGET_LONG_BITS ) ; //<S2SV> tcg_gen_subi_tl ( cpu_T0 , cpu_T0 , TARGET_LONG_BITS - size ) ; //<S2SV> } else { //<S2SV> tcg_gen_ctzi_tl ( cpu_T0 , cpu_T0 , size ) ; //<S2SV> } //<S2SV> gen_op_update1_cc ( ) ; //<S2SV> set_cc_op ( s , CC_OP_BMILGB + ot ) ; //<S2SV> } else { //<S2SV> tcg_gen_mov_tl ( cpu_cc_dst , cpu_T0 ) ; //<S2SV> set_cc_op ( s , CC_OP_LOGICB + ot ) ; //<S2SV> if ( b & 1 ) { //<S2SV> tcg_gen_xori_tl ( cpu_T1 , cpu_regs [ reg ] , TARGET_LONG_BITS - 1 ) ; //<S2SV> tcg_gen_clz_tl ( cpu_T0 , cpu_T0 , cpu_T1 ) ; //<S2SV> tcg_gen_xori_tl ( cpu_T0 , cpu_T0 , TARGET_LONG_BITS - 1 ) ; //<S2SV> } else { //<S2SV> tcg_gen_ctz_tl ( cpu_T0 , cpu_T0 , cpu_regs [ reg ] ) ; //<S2SV> } //<S2SV> } //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0x27 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_daa ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x2f : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_das ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x37 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_aaa ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0x3f : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_helper_aas ( cpu_env ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> case 0xd4 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> val = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> if ( val == 0 ) { //<S2SV> gen_exception ( s , EXCP00_DIVZ , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_helper_aam ( cpu_env , tcg_const_i32 ( val ) ) ; //<S2SV> set_cc_op ( s , CC_OP_LOGICB ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xd5 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> val = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> gen_helper_aad ( cpu_env , tcg_const_i32 ( val ) ) ; //<S2SV> set_cc_op ( s , CC_OP_LOGICB ) ; //<S2SV> break ; //<S2SV> case 0x90 : //<S2SV> if ( prefixes & PREFIX_LOCK ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( REX_B ( s ) ) { //<S2SV> goto do_xchg_reg_eax ; //<S2SV> } //<S2SV> if ( prefixes & PREFIX_REPZ ) { //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_pause ( cpu_env , tcg_const_i32 ( s -> pc - pc_start ) ) ; //<S2SV> s -> is_jmp = DISAS_TB_JUMP ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x9b : //<S2SV> if ( ( s -> flags & ( HF_MP_MASK | HF_TS_MASK ) ) == //<S2SV> ( HF_MP_MASK | HF_TS_MASK ) ) { //<S2SV> gen_exception ( s , EXCP07_PREX , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_helper_fwait ( cpu_env ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xcc : //<S2SV> gen_interrupt ( s , EXCP03_INT3 , pc_start - s -> cs_base , s -> pc - s -> cs_base ) ; //<S2SV> break ; //<S2SV> case 0xcd : //<S2SV> val = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> if ( s -> vm86 && s -> iopl != 3 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_interrupt ( s , val , pc_start - s -> cs_base , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xce : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_into ( cpu_env , tcg_const_i32 ( s -> pc - pc_start ) ) ; //<S2SV> break ; //<S2SV> # ifdef WANT_ICEBP //<S2SV> case 0xf1 : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_ICEBP ) ; //<S2SV> # if 1 //<S2SV> gen_debug ( s , pc_start - s -> cs_base ) ; //<S2SV> # else //<S2SV> tb_flush ( CPU ( x86_env_get_cpu ( env ) ) ) ; //<S2SV> qemu_set_log ( CPU_LOG_INT | CPU_LOG_TB_IN_ASM ) ; //<S2SV> # endif //<S2SV> break ; //<S2SV> # endif //<S2SV> case 0xfa : //<S2SV> if ( ! s -> vm86 ) { //<S2SV> if ( s -> cpl <= s -> iopl ) { //<S2SV> gen_helper_cli ( cpu_env ) ; //<S2SV> } else { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } //<S2SV> } else { //<S2SV> if ( s -> iopl == 3 ) { //<S2SV> gen_helper_cli ( cpu_env ) ; //<S2SV> } else { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0xfb : //<S2SV> if ( s -> vm86 ? s -> iopl == 3 : s -> cpl <= s -> iopl ) { //<S2SV> gen_helper_sti ( cpu_env ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob_inhibit_irq ( s , true ) ; //<S2SV> } else { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x62 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( modrm >> 3 ) & 7 ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( mod == 3 ) //<S2SV> goto illegal_op ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , reg ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> if ( ot == MO_16 ) { //<S2SV> gen_helper_boundw ( cpu_env , cpu_A0 , cpu_tmp2_i32 ) ; //<S2SV> } else { //<S2SV> gen_helper_boundl ( cpu_env , cpu_A0 , cpu_tmp2_i32 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1c8 ... 0x1cf : //<S2SV> reg = ( b & 7 ) | REX_B ( s ) ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> if ( dflag == MO_64 ) { //<S2SV> gen_op_mov_v_reg ( MO_64 , cpu_T0 , reg ) ; //<S2SV> tcg_gen_bswap64_i64 ( cpu_T0 , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( MO_64 , reg , cpu_T0 ) ; //<S2SV> } else //<S2SV> # endif //<S2SV> { //<S2SV> gen_op_mov_v_reg ( MO_32 , cpu_T0 , reg ) ; //<S2SV> tcg_gen_ext32u_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> tcg_gen_bswap32_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( MO_32 , reg , cpu_T0 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0xd6 : //<S2SV> if ( CODE64 ( s ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_compute_eflags_c ( s , cpu_T0 ) ; //<S2SV> tcg_gen_neg_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( MO_8 , R_EAX , cpu_T0 ) ; //<S2SV> break ; //<S2SV> case 0xe0 : //<S2SV> case 0xe1 : //<S2SV> case 0xe2 : //<S2SV> case 0xe3 : //<S2SV> { //<S2SV> TCGLabel * l1 , * l2 , * l3 ; //<S2SV> tval = ( int8_t ) insn_get ( env , s , MO_8 ) ; //<S2SV> next_eip = s -> pc - s -> cs_base ; //<S2SV> tval += next_eip ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tval &= 0xffff ; //<S2SV> } //<S2SV> l1 = gen_new_label ( ) ; //<S2SV> l2 = gen_new_label ( ) ; //<S2SV> l3 = gen_new_label ( ) ; //<S2SV> b &= 3 ; //<S2SV> switch ( b ) { //<S2SV> case 0 : //<S2SV> case 1 : //<S2SV> gen_op_add_reg_im ( s -> aflag , R_ECX , - 1 ) ; //<S2SV> gen_op_jz_ecx ( s -> aflag , l3 ) ; //<S2SV> gen_jcc1 ( s , ( JCC_Z << 1 ) | ( b ^ 1 ) , l1 ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> gen_op_add_reg_im ( s -> aflag , R_ECX , - 1 ) ; //<S2SV> gen_op_jnz_ecx ( s -> aflag , l1 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> case 3 : //<S2SV> gen_op_jz_ecx ( s -> aflag , l1 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_set_label ( l3 ) ; //<S2SV> gen_jmp_im ( next_eip ) ; //<S2SV> tcg_gen_br ( l2 ) ; //<S2SV> gen_set_label ( l1 ) ; //<S2SV> gen_jmp_im ( tval ) ; //<S2SV> gen_set_label ( l2 ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x130 : //<S2SV> case 0x132 : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> if ( b & 2 ) { //<S2SV> gen_helper_rdmsr ( cpu_env ) ; //<S2SV> } else { //<S2SV> gen_helper_wrmsr ( cpu_env ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x131 : //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_start ( ) ; //<S2SV> } //<S2SV> gen_helper_rdtsc ( cpu_env ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_end ( ) ; //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x133 : //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_rdpmc ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0x134 : //<S2SV> if ( CODE64 ( s ) && env -> cpuid_vendor1 != CPUID_VENDOR_INTEL_1 ) //<S2SV> goto illegal_op ; //<S2SV> if ( ! s -> pe ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_helper_sysenter ( cpu_env ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x135 : //<S2SV> if ( CODE64 ( s ) && env -> cpuid_vendor1 != CPUID_VENDOR_INTEL_1 ) //<S2SV> goto illegal_op ; //<S2SV> if ( ! s -> pe ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_helper_sysexit ( cpu_env , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> break ; //<S2SV> # ifdef TARGET_X86_64 //<S2SV> case 0x105 : //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_syscall ( cpu_env , tcg_const_i32 ( s -> pc - pc_start ) ) ; //<S2SV> gen_eob_worker ( s , false , true ) ; //<S2SV> break ; //<S2SV> case 0x107 : //<S2SV> if ( ! s -> pe ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_helper_sysret ( cpu_env , tcg_const_i32 ( dflag - 1 ) ) ; //<S2SV> if ( s -> lma ) { //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> } //<S2SV> gen_eob_worker ( s , false , true ) ; //<S2SV> } //<S2SV> break ; //<S2SV> # endif //<S2SV> case 0x1a2 : //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_cpuid ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0xf4 : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_hlt ( cpu_env , tcg_const_i32 ( s -> pc - pc_start ) ) ; //<S2SV> s -> is_jmp = DISAS_TB_JUMP ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x100 : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> op = ( modrm >> 3 ) & 7 ; //<S2SV> switch ( op ) { //<S2SV> case 0 : //<S2SV> if ( ! s -> pe || s -> vm86 ) //<S2SV> goto illegal_op ; //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_LDTR_READ ) ; //<S2SV> tcg_gen_ld32u_tl ( cpu_T0 , cpu_env , //<S2SV> offsetof ( CPUX86State , ldt . selector ) ) ; //<S2SV> ot = mod == 3 ? dflag : MO_16 ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 1 ) ; //<S2SV> break ; //<S2SV> case 2 : //<S2SV> if ( ! s -> pe || s -> vm86 ) //<S2SV> goto illegal_op ; //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_LDTR_WRITE ) ; //<S2SV> gen_ldst_modrm ( env , s , modrm , MO_16 , OR_TMP0 , 0 ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> gen_helper_lldt ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 1 : //<S2SV> if ( ! s -> pe || s -> vm86 ) //<S2SV> goto illegal_op ; //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_TR_READ ) ; //<S2SV> tcg_gen_ld32u_tl ( cpu_T0 , cpu_env , //<S2SV> offsetof ( CPUX86State , tr . selector ) ) ; //<S2SV> ot = mod == 3 ? dflag : MO_16 ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 1 ) ; //<S2SV> break ; //<S2SV> case 3 : //<S2SV> if ( ! s -> pe || s -> vm86 ) //<S2SV> goto illegal_op ; //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_TR_WRITE ) ; //<S2SV> gen_ldst_modrm ( env , s , modrm , MO_16 , OR_TMP0 , 0 ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> gen_helper_ltr ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 4 : //<S2SV> case 5 : //<S2SV> if ( ! s -> pe || s -> vm86 ) //<S2SV> goto illegal_op ; //<S2SV> gen_ldst_modrm ( env , s , modrm , MO_16 , OR_TMP0 , 0 ) ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> if ( op == 4 ) { //<S2SV> gen_helper_verr ( cpu_env , cpu_T0 ) ; //<S2SV> } else { //<S2SV> gen_helper_verw ( cpu_env , cpu_T0 ) ; //<S2SV> } //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x101 : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> switch ( modrm ) { //<S2SV> CASE_MODRM_MEM_OP ( 0 ) : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_GDTR_READ ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_ld32u_tl ( cpu_T0 , //<S2SV> cpu_env , offsetof ( CPUX86State , gdt . limit ) ) ; //<S2SV> gen_op_st_v ( s , MO_16 , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_add_A0_im ( s , 2 ) ; //<S2SV> tcg_gen_ld_tl ( cpu_T0 , cpu_env , offsetof ( CPUX86State , gdt . base ) ) ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tcg_gen_andi_tl ( cpu_T0 , cpu_T0 , 0xffffff ) ; //<S2SV> } //<S2SV> gen_op_st_v ( s , CODE64 ( s ) + MO_32 , cpu_T0 , cpu_A0 ) ; //<S2SV> break ; //<S2SV> case 0xc8 : //<S2SV> if ( ! ( s -> cpuid_ext_features & CPUID_EXT_MONITOR ) || s -> cpl != 0 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> tcg_gen_mov_tl ( cpu_A0 , cpu_regs [ R_EAX ] ) ; //<S2SV> gen_extu ( s -> aflag , cpu_A0 ) ; //<S2SV> gen_add_A0_ds_seg ( s ) ; //<S2SV> gen_helper_monitor ( cpu_env , cpu_A0 ) ; //<S2SV> break ; //<S2SV> case 0xc9 : //<S2SV> if ( ! ( s -> cpuid_ext_features & CPUID_EXT_MONITOR ) || s -> cpl != 0 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_mwait ( cpu_env , tcg_const_i32 ( s -> pc - pc_start ) ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xca : //<S2SV> if ( ! ( s -> cpuid_7_0_ebx_features & CPUID_7_0_EBX_SMAP ) //<S2SV> || s -> cpl != 0 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_helper_clac ( cpu_env ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xcb : //<S2SV> if ( ! ( s -> cpuid_7_0_ebx_features & CPUID_7_0_EBX_SMAP ) //<S2SV> || s -> cpl != 0 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_helper_stac ( cpu_env ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 1 ) : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_IDTR_READ ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_ld32u_tl ( cpu_T0 , cpu_env , offsetof ( CPUX86State , idt . limit ) ) ; //<S2SV> gen_op_st_v ( s , MO_16 , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_add_A0_im ( s , 2 ) ; //<S2SV> tcg_gen_ld_tl ( cpu_T0 , cpu_env , offsetof ( CPUX86State , idt . base ) ) ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tcg_gen_andi_tl ( cpu_T0 , cpu_T0 , 0xffffff ) ; //<S2SV> } //<S2SV> gen_op_st_v ( s , CODE64 ( s ) + MO_32 , cpu_T0 , cpu_A0 ) ; //<S2SV> break ; //<S2SV> case 0xd0 : //<S2SV> if ( ( s -> cpuid_ext_features & CPUID_EXT_XSAVE ) == 0 //<S2SV> || ( s -> prefix & ( PREFIX_LOCK | PREFIX_DATA //<S2SV> | PREFIX_REPZ | PREFIX_REPNZ ) ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_regs [ R_ECX ] ) ; //<S2SV> gen_helper_xgetbv ( cpu_tmp1_i64 , cpu_env , cpu_tmp2_i32 ) ; //<S2SV> tcg_gen_extr_i64_tl ( cpu_regs [ R_EAX ] , cpu_regs [ R_EDX ] , cpu_tmp1_i64 ) ; //<S2SV> break ; //<S2SV> case 0xd1 : //<S2SV> if ( ( s -> cpuid_ext_features & CPUID_EXT_XSAVE ) == 0 //<S2SV> || ( s -> prefix & ( PREFIX_LOCK | PREFIX_DATA //<S2SV> | PREFIX_REPZ | PREFIX_REPNZ ) ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> tcg_gen_concat_tl_i64 ( cpu_tmp1_i64 , cpu_regs [ R_EAX ] , //<S2SV> cpu_regs [ R_EDX ] ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_regs [ R_ECX ] ) ; //<S2SV> gen_helper_xsetbv ( cpu_env , cpu_tmp2_i32 , cpu_tmp1_i64 ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xd8 : //<S2SV> if ( ! ( s -> flags & HF_SVME_MASK ) || ! s -> pe ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_vmrun ( cpu_env , tcg_const_i32 ( s -> aflag - 1 ) , //<S2SV> tcg_const_i32 ( s -> pc - pc_start ) ) ; //<S2SV> tcg_gen_exit_tb ( 0 ) ; //<S2SV> s -> is_jmp = DISAS_TB_JUMP ; //<S2SV> break ; //<S2SV> case 0xd9 : //<S2SV> if ( ! ( s -> flags & HF_SVME_MASK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_vmmcall ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0xda : //<S2SV> if ( ! ( s -> flags & HF_SVME_MASK ) || ! s -> pe ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_vmload ( cpu_env , tcg_const_i32 ( s -> aflag - 1 ) ) ; //<S2SV> break ; //<S2SV> case 0xdb : //<S2SV> if ( ! ( s -> flags & HF_SVME_MASK ) || ! s -> pe ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_vmsave ( cpu_env , tcg_const_i32 ( s -> aflag - 1 ) ) ; //<S2SV> break ; //<S2SV> case 0xdc : //<S2SV> if ( ( ! ( s -> flags & HF_SVME_MASK ) //<S2SV> && ! ( s -> cpuid_ext3_features & CPUID_EXT3_SKINIT ) ) //<S2SV> || ! s -> pe ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_stgi ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0xdd : //<S2SV> if ( ! ( s -> flags & HF_SVME_MASK ) || ! s -> pe ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_clgi ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0xde : //<S2SV> if ( ( ! ( s -> flags & HF_SVME_MASK ) //<S2SV> && ! ( s -> cpuid_ext3_features & CPUID_EXT3_SKINIT ) ) //<S2SV> || ! s -> pe ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_skinit ( cpu_env ) ; //<S2SV> break ; //<S2SV> case 0xdf : //<S2SV> if ( ! ( s -> flags & HF_SVME_MASK ) || ! s -> pe ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_helper_invlpga ( cpu_env , tcg_const_i32 ( s -> aflag - 1 ) ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 2 ) : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_GDTR_WRITE ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , MO_16 , cpu_T1 , cpu_A0 ) ; //<S2SV> gen_add_A0_im ( s , 2 ) ; //<S2SV> gen_op_ld_v ( s , CODE64 ( s ) + MO_32 , cpu_T0 , cpu_A0 ) ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tcg_gen_andi_tl ( cpu_T0 , cpu_T0 , 0xffffff ) ; //<S2SV> } //<S2SV> tcg_gen_st_tl ( cpu_T0 , cpu_env , offsetof ( CPUX86State , gdt . base ) ) ; //<S2SV> tcg_gen_st32_tl ( cpu_T1 , cpu_env , offsetof ( CPUX86State , gdt . limit ) ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 3 ) : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_IDTR_WRITE ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , MO_16 , cpu_T1 , cpu_A0 ) ; //<S2SV> gen_add_A0_im ( s , 2 ) ; //<S2SV> gen_op_ld_v ( s , CODE64 ( s ) + MO_32 , cpu_T0 , cpu_A0 ) ; //<S2SV> if ( dflag == MO_16 ) { //<S2SV> tcg_gen_andi_tl ( cpu_T0 , cpu_T0 , 0xffffff ) ; //<S2SV> } //<S2SV> tcg_gen_st_tl ( cpu_T0 , cpu_env , offsetof ( CPUX86State , idt . base ) ) ; //<S2SV> tcg_gen_st32_tl ( cpu_T1 , cpu_env , offsetof ( CPUX86State , idt . limit ) ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_OP ( 4 ) : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_READ_CR0 ) ; //<S2SV> tcg_gen_ld_tl ( cpu_T0 , cpu_env , offsetof ( CPUX86State , cr [ 0 ] ) ) ; //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> ot = ( mod != 3 ? MO_16 : s -> dflag ) ; //<S2SV> } else { //<S2SV> ot = MO_16 ; //<S2SV> } //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 1 ) ; //<S2SV> break ; //<S2SV> case 0xee : //<S2SV> if ( prefixes & PREFIX_LOCK ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_regs [ R_ECX ] ) ; //<S2SV> gen_helper_rdpkru ( cpu_tmp1_i64 , cpu_env , cpu_tmp2_i32 ) ; //<S2SV> tcg_gen_extr_i64_tl ( cpu_regs [ R_EAX ] , cpu_regs [ R_EDX ] , cpu_tmp1_i64 ) ; //<S2SV> break ; //<S2SV> case 0xef : //<S2SV> if ( prefixes & PREFIX_LOCK ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_concat_tl_i64 ( cpu_tmp1_i64 , cpu_regs [ R_EAX ] , //<S2SV> cpu_regs [ R_EDX ] ) ; //<S2SV> tcg_gen_trunc_tl_i32 ( cpu_tmp2_i32 , cpu_regs [ R_ECX ] ) ; //<S2SV> gen_helper_wrpkru ( cpu_env , cpu_tmp2_i32 , cpu_tmp1_i64 ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_OP ( 6 ) : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_WRITE_CR0 ) ; //<S2SV> gen_ldst_modrm ( env , s , modrm , MO_16 , OR_TMP0 , 0 ) ; //<S2SV> gen_helper_lmsw ( cpu_env , cpu_T0 ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 7 ) : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_helper_invlpg ( cpu_env , cpu_A0 ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0xf8 : //<S2SV> # ifdef TARGET_X86_64 //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> tcg_gen_mov_tl ( cpu_T0 , cpu_seg_base [ R_GS ] ) ; //<S2SV> tcg_gen_ld_tl ( cpu_seg_base [ R_GS ] , cpu_env , //<S2SV> offsetof ( CPUX86State , kernelgsbase ) ) ; //<S2SV> tcg_gen_st_tl ( cpu_T0 , cpu_env , //<S2SV> offsetof ( CPUX86State , kernelgsbase ) ) ; //<S2SV> } //<S2SV> break ; //<S2SV> } //<S2SV> # endif //<S2SV> goto illegal_op ; //<S2SV> case 0xf9 : //<S2SV> if ( ! ( s -> cpuid_ext2_features & CPUID_EXT2_RDTSCP ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_start ( ) ; //<S2SV> } //<S2SV> gen_helper_rdtscp ( cpu_env ) ; //<S2SV> if ( s -> tb -> cflags & CF_USE_ICOUNT ) { //<S2SV> gen_io_end ( ) ; //<S2SV> gen_jmp ( s , s -> pc - s -> cs_base ) ; //<S2SV> } //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x108 : //<S2SV> case 0x109 : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_svm_check_intercept ( s , pc_start , ( b & 2 ) ? SVM_EXIT_INVD : SVM_EXIT_WBINVD ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x63 : //<S2SV> # ifdef TARGET_X86_64 //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> int d_ot ; //<S2SV> d_ot = dflag ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> if ( mod == 3 ) { //<S2SV> gen_op_mov_v_reg ( MO_32 , cpu_T0 , rm ) ; //<S2SV> if ( d_ot == MO_64 ) { //<S2SV> tcg_gen_ext32s_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> } //<S2SV> gen_op_mov_reg_v ( d_ot , reg , cpu_T0 ) ; //<S2SV> } else { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , MO_32 | MO_SIGN , cpu_T0 , cpu_A0 ) ; //<S2SV> gen_op_mov_reg_v ( d_ot , reg , cpu_T0 ) ; //<S2SV> } //<S2SV> } else //<S2SV> # endif //<S2SV> { //<S2SV> TCGLabel * label1 ; //<S2SV> TCGv t0 , t1 , t2 , a0 ; //<S2SV> if ( ! s -> pe || s -> vm86 ) //<S2SV> goto illegal_op ; //<S2SV> t0 = tcg_temp_local_new ( ) ; //<S2SV> t1 = tcg_temp_local_new ( ) ; //<S2SV> t2 = tcg_temp_local_new ( ) ; //<S2SV> ot = MO_16 ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( modrm >> 3 ) & 7 ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> rm = modrm & 7 ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_op_ld_v ( s , ot , t0 , cpu_A0 ) ; //<S2SV> a0 = tcg_temp_local_new ( ) ; //<S2SV> tcg_gen_mov_tl ( a0 , cpu_A0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_v_reg ( ot , t0 , rm ) ; //<S2SV> TCGV_UNUSED ( a0 ) ; //<S2SV> } //<S2SV> gen_op_mov_v_reg ( ot , t1 , reg ) ; //<S2SV> tcg_gen_andi_tl ( cpu_tmp0 , t0 , 3 ) ; //<S2SV> tcg_gen_andi_tl ( t1 , t1 , 3 ) ; //<S2SV> tcg_gen_movi_tl ( t2 , 0 ) ; //<S2SV> label1 = gen_new_label ( ) ; //<S2SV> tcg_gen_brcond_tl ( TCG_COND_GE , cpu_tmp0 , t1 , label1 ) ; //<S2SV> tcg_gen_andi_tl ( t0 , t0 , ~ 3 ) ; //<S2SV> tcg_gen_or_tl ( t0 , t0 , t1 ) ; //<S2SV> tcg_gen_movi_tl ( t2 , CC_Z ) ; //<S2SV> gen_set_label ( label1 ) ; //<S2SV> if ( mod != 3 ) { //<S2SV> gen_op_st_v ( s , ot , t0 , a0 ) ; //<S2SV> tcg_temp_free ( a0 ) ; //<S2SV> } else { //<S2SV> gen_op_mov_reg_v ( ot , rm , t0 ) ; //<S2SV> } //<S2SV> gen_compute_eflags ( s ) ; //<S2SV> tcg_gen_andi_tl ( cpu_cc_src , cpu_cc_src , ~ CC_Z ) ; //<S2SV> tcg_gen_or_tl ( cpu_cc_src , cpu_cc_src , t2 ) ; //<S2SV> tcg_temp_free ( t0 ) ; //<S2SV> tcg_temp_free ( t1 ) ; //<S2SV> tcg_temp_free ( t2 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x102 : //<S2SV> case 0x103 : //<S2SV> { //<S2SV> TCGLabel * label1 ; //<S2SV> TCGv t0 ; //<S2SV> if ( ! s -> pe || s -> vm86 ) //<S2SV> goto illegal_op ; //<S2SV> ot = dflag != MO_16 ? MO_32 : MO_16 ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> gen_ldst_modrm ( env , s , modrm , MO_16 , OR_TMP0 , 0 ) ; //<S2SV> t0 = tcg_temp_local_new ( ) ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> if ( b == 0x102 ) { //<S2SV> gen_helper_lar ( t0 , cpu_env , cpu_T0 ) ; //<S2SV> } else { //<S2SV> gen_helper_lsl ( t0 , cpu_env , cpu_T0 ) ; //<S2SV> } //<S2SV> tcg_gen_andi_tl ( cpu_tmp0 , cpu_cc_src , CC_Z ) ; //<S2SV> label1 = gen_new_label ( ) ; //<S2SV> tcg_gen_brcondi_tl ( TCG_COND_EQ , cpu_tmp0 , 0 , label1 ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , t0 ) ; //<S2SV> gen_set_label ( label1 ) ; //<S2SV> set_cc_op ( s , CC_OP_EFLAGS ) ; //<S2SV> tcg_temp_free ( t0 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x118 : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> op = ( modrm >> 3 ) & 7 ; //<S2SV> switch ( op ) { //<S2SV> case 0 : //<S2SV> case 1 : //<S2SV> case 2 : //<S2SV> case 3 : //<S2SV> if ( mod == 3 ) //<S2SV> goto illegal_op ; //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> break ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x11a : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> if ( s -> flags & HF_MPX_EN_MASK ) { //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> if ( prefixes & PREFIX_REPZ ) { //<S2SV> if ( reg >= 4 //<S2SV> || ( prefixes & PREFIX_LOCK ) //<S2SV> || s -> aflag == MO_16 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_bndck ( env , s , modrm , TCG_COND_LTU , cpu_bndl [ reg ] ) ; //<S2SV> } else if ( prefixes & PREFIX_REPNZ ) { //<S2SV> if ( reg >= 4 //<S2SV> || ( prefixes & PREFIX_LOCK ) //<S2SV> || s -> aflag == MO_16 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> TCGv_i64 notu = tcg_temp_new_i64 ( ) ; //<S2SV> tcg_gen_not_i64 ( notu , cpu_bndu [ reg ] ) ; //<S2SV> gen_bndck ( env , s , modrm , TCG_COND_GTU , notu ) ; //<S2SV> tcg_temp_free_i64 ( notu ) ; //<S2SV> } else if ( prefixes & PREFIX_DATA ) { //<S2SV> if ( reg >= 4 || s -> aflag == MO_16 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( mod == 3 ) { //<S2SV> int reg2 = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> if ( reg2 >= 4 || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> flags & HF_MPX_IU_MASK ) { //<S2SV> tcg_gen_mov_i64 ( cpu_bndl [ reg ] , cpu_bndl [ reg2 ] ) ; //<S2SV> tcg_gen_mov_i64 ( cpu_bndu [ reg ] , cpu_bndu [ reg2 ] ) ; //<S2SV> } //<S2SV> } else { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> tcg_gen_qemu_ld_i64 ( cpu_bndl [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> tcg_gen_addi_tl ( cpu_A0 , cpu_A0 , 8 ) ; //<S2SV> tcg_gen_qemu_ld_i64 ( cpu_bndu [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> } else { //<S2SV> tcg_gen_qemu_ld_i64 ( cpu_bndl [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> tcg_gen_addi_tl ( cpu_A0 , cpu_A0 , 4 ) ; //<S2SV> tcg_gen_qemu_ld_i64 ( cpu_bndu [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> } //<S2SV> gen_set_hflag ( s , HF_MPX_IU_MASK ) ; //<S2SV> } //<S2SV> } else if ( mod != 3 ) { //<S2SV> AddressParts a = gen_lea_modrm_0 ( env , s , modrm ) ; //<S2SV> if ( reg >= 4 //<S2SV> || ( prefixes & PREFIX_LOCK ) //<S2SV> || s -> aflag == MO_16 //<S2SV> || a . base < - 1 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( a . base >= 0 ) { //<S2SV> tcg_gen_addi_tl ( cpu_A0 , cpu_regs [ a . base ] , a . disp ) ; //<S2SV> } else { //<S2SV> tcg_gen_movi_tl ( cpu_A0 , 0 ) ; //<S2SV> } //<S2SV> gen_lea_v_seg ( s , s -> aflag , cpu_A0 , a . def_seg , s -> override ) ; //<S2SV> if ( a . index >= 0 ) { //<S2SV> tcg_gen_mov_tl ( cpu_T0 , cpu_regs [ a . index ] ) ; //<S2SV> } else { //<S2SV> tcg_gen_movi_tl ( cpu_T0 , 0 ) ; //<S2SV> } //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> gen_helper_bndldx64 ( cpu_bndl [ reg ] , cpu_env , cpu_A0 , cpu_T0 ) ; //<S2SV> tcg_gen_ld_i64 ( cpu_bndu [ reg ] , cpu_env , //<S2SV> offsetof ( CPUX86State , mmx_t0 . MMX_Q ( 0 ) ) ) ; //<S2SV> } else { //<S2SV> gen_helper_bndldx32 ( cpu_bndu [ reg ] , cpu_env , cpu_A0 , cpu_T0 ) ; //<S2SV> tcg_gen_ext32u_i64 ( cpu_bndl [ reg ] , cpu_bndu [ reg ] ) ; //<S2SV> tcg_gen_shri_i64 ( cpu_bndu [ reg ] , cpu_bndu [ reg ] , 32 ) ; //<S2SV> } //<S2SV> gen_set_hflag ( s , HF_MPX_IU_MASK ) ; //<S2SV> } //<S2SV> } //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> break ; //<S2SV> case 0x11b : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> if ( s -> flags & HF_MPX_EN_MASK ) { //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> if ( mod != 3 && ( prefixes & PREFIX_REPZ ) ) { //<S2SV> if ( reg >= 4 //<S2SV> || ( prefixes & PREFIX_LOCK ) //<S2SV> || s -> aflag == MO_16 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> AddressParts a = gen_lea_modrm_0 ( env , s , modrm ) ; //<S2SV> if ( a . base >= 0 ) { //<S2SV> tcg_gen_extu_tl_i64 ( cpu_bndl [ reg ] , cpu_regs [ a . base ] ) ; //<S2SV> if ( ! CODE64 ( s ) ) { //<S2SV> tcg_gen_ext32u_i64 ( cpu_bndl [ reg ] , cpu_bndl [ reg ] ) ; //<S2SV> } //<S2SV> } else if ( a . base == - 1 ) { //<S2SV> tcg_gen_movi_i64 ( cpu_bndl [ reg ] , 0 ) ; //<S2SV> } else { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_not_tl ( cpu_A0 , gen_lea_modrm_1 ( a ) ) ; //<S2SV> if ( ! CODE64 ( s ) ) { //<S2SV> tcg_gen_ext32u_tl ( cpu_A0 , cpu_A0 ) ; //<S2SV> } //<S2SV> tcg_gen_extu_tl_i64 ( cpu_bndu [ reg ] , cpu_A0 ) ; //<S2SV> gen_set_hflag ( s , HF_MPX_IU_MASK ) ; //<S2SV> break ; //<S2SV> } else if ( prefixes & PREFIX_REPNZ ) { //<S2SV> if ( reg >= 4 //<S2SV> || ( prefixes & PREFIX_LOCK ) //<S2SV> || s -> aflag == MO_16 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_bndck ( env , s , modrm , TCG_COND_GTU , cpu_bndu [ reg ] ) ; //<S2SV> } else if ( prefixes & PREFIX_DATA ) { //<S2SV> if ( reg >= 4 || s -> aflag == MO_16 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( mod == 3 ) { //<S2SV> int reg2 = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> if ( reg2 >= 4 || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> flags & HF_MPX_IU_MASK ) { //<S2SV> tcg_gen_mov_i64 ( cpu_bndl [ reg2 ] , cpu_bndl [ reg ] ) ; //<S2SV> tcg_gen_mov_i64 ( cpu_bndu [ reg2 ] , cpu_bndu [ reg ] ) ; //<S2SV> } //<S2SV> } else { //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> tcg_gen_qemu_st_i64 ( cpu_bndl [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> tcg_gen_addi_tl ( cpu_A0 , cpu_A0 , 8 ) ; //<S2SV> tcg_gen_qemu_st_i64 ( cpu_bndu [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEQ ) ; //<S2SV> } else { //<S2SV> tcg_gen_qemu_st_i64 ( cpu_bndl [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> tcg_gen_addi_tl ( cpu_A0 , cpu_A0 , 4 ) ; //<S2SV> tcg_gen_qemu_st_i64 ( cpu_bndu [ reg ] , cpu_A0 , //<S2SV> s -> mem_index , MO_LEUL ) ; //<S2SV> } //<S2SV> } //<S2SV> } else if ( mod != 3 ) { //<S2SV> AddressParts a = gen_lea_modrm_0 ( env , s , modrm ) ; //<S2SV> if ( reg >= 4 //<S2SV> || ( prefixes & PREFIX_LOCK ) //<S2SV> || s -> aflag == MO_16 //<S2SV> || a . base < - 1 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( a . base >= 0 ) { //<S2SV> tcg_gen_addi_tl ( cpu_A0 , cpu_regs [ a . base ] , a . disp ) ; //<S2SV> } else { //<S2SV> tcg_gen_movi_tl ( cpu_A0 , 0 ) ; //<S2SV> } //<S2SV> gen_lea_v_seg ( s , s -> aflag , cpu_A0 , a . def_seg , s -> override ) ; //<S2SV> if ( a . index >= 0 ) { //<S2SV> tcg_gen_mov_tl ( cpu_T0 , cpu_regs [ a . index ] ) ; //<S2SV> } else { //<S2SV> tcg_gen_movi_tl ( cpu_T0 , 0 ) ; //<S2SV> } //<S2SV> if ( CODE64 ( s ) ) { //<S2SV> gen_helper_bndstx64 ( cpu_env , cpu_A0 , cpu_T0 , //<S2SV> cpu_bndl [ reg ] , cpu_bndu [ reg ] ) ; //<S2SV> } else { //<S2SV> gen_helper_bndstx32 ( cpu_env , cpu_A0 , cpu_T0 , //<S2SV> cpu_bndl [ reg ] , cpu_bndu [ reg ] ) ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> break ; //<S2SV> case 0x119 : case 0x11c ... 0x11f : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> break ; //<S2SV> case 0x120 : //<S2SV> case 0x122 : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> if ( CODE64 ( s ) ) //<S2SV> ot = MO_64 ; //<S2SV> else //<S2SV> ot = MO_32 ; //<S2SV> if ( ( prefixes & PREFIX_LOCK ) && ( reg == 0 ) && //<S2SV> ( s -> cpuid_ext3_features & CPUID_EXT3_CR8LEG ) ) { //<S2SV> reg = 8 ; //<S2SV> } //<S2SV> switch ( reg ) { //<S2SV> case 0 : //<S2SV> case 2 : //<S2SV> case 3 : //<S2SV> case 4 : //<S2SV> case 8 : //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( pc_start - s -> cs_base ) ; //<S2SV> if ( b & 2 ) { //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , rm ) ; //<S2SV> gen_helper_write_crN ( cpu_env , tcg_const_i32 ( reg ) , //<S2SV> cpu_T0 ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } else { //<S2SV> gen_helper_read_crN ( cpu_T0 , cpu_env , tcg_const_i32 ( reg ) ) ; //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x121 : //<S2SV> case 0x123 : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> rm = ( modrm & 7 ) | REX_B ( s ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> if ( CODE64 ( s ) ) //<S2SV> ot = MO_64 ; //<S2SV> else //<S2SV> ot = MO_32 ; //<S2SV> if ( reg >= 8 ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( b & 2 ) { //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_WRITE_DR0 + reg ) ; //<S2SV> gen_op_mov_v_reg ( ot , cpu_T0 , rm ) ; //<S2SV> tcg_gen_movi_i32 ( cpu_tmp2_i32 , reg ) ; //<S2SV> gen_helper_set_dr ( cpu_env , cpu_tmp2_i32 , cpu_T0 ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } else { //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_READ_DR0 + reg ) ; //<S2SV> tcg_gen_movi_i32 ( cpu_tmp2_i32 , reg ) ; //<S2SV> gen_helper_get_dr ( cpu_T0 , cpu_env , cpu_tmp2_i32 ) ; //<S2SV> gen_op_mov_reg_v ( ot , rm , cpu_T0 ) ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case 0x106 : //<S2SV> if ( s -> cpl != 0 ) { //<S2SV> gen_exception ( s , EXCP0D_GPF , pc_start - s -> cs_base ) ; //<S2SV> } else { //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_WRITE_CR0 ) ; //<S2SV> gen_helper_clts ( cpu_env ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x1c3 : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_SSE2 ) ) //<S2SV> goto illegal_op ; //<S2SV> ot = mo_64_32 ( dflag ) ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( mod == 3 ) //<S2SV> goto illegal_op ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , reg , 1 ) ; //<S2SV> break ; //<S2SV> case 0x1ae : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> switch ( modrm ) { //<S2SV> CASE_MODRM_MEM_OP ( 0 ) : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_FXSR ) //<S2SV> || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( ( s -> flags & HF_EM_MASK ) || ( s -> flags & HF_TS_MASK ) ) { //<S2SV> gen_exception ( s , EXCP07_PREX , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_helper_fxsave ( cpu_env , cpu_A0 ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 1 ) : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_FXSR ) //<S2SV> || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( ( s -> flags & HF_EM_MASK ) || ( s -> flags & HF_TS_MASK ) ) { //<S2SV> gen_exception ( s , EXCP07_PREX , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> gen_helper_fxrstor ( cpu_env , cpu_A0 ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 2 ) : //<S2SV> if ( ( s -> flags & HF_EM_MASK ) || ! ( s -> flags & HF_OSFXSR_MASK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> flags & HF_TS_MASK ) { //<S2SV> gen_exception ( s , EXCP07_PREX , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_qemu_ld_i32 ( cpu_tmp2_i32 , cpu_A0 , s -> mem_index , MO_LEUL ) ; //<S2SV> gen_helper_ldmxcsr ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 3 ) : //<S2SV> if ( ( s -> flags & HF_EM_MASK ) || ! ( s -> flags & HF_OSFXSR_MASK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( s -> flags & HF_TS_MASK ) { //<S2SV> gen_exception ( s , EXCP07_PREX , pc_start - s -> cs_base ) ; //<S2SV> break ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_ld32u_tl ( cpu_T0 , cpu_env , offsetof ( CPUX86State , mxcsr ) ) ; //<S2SV> gen_op_st_v ( s , MO_32 , cpu_T0 , cpu_A0 ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 4 ) : //<S2SV> if ( ( s -> cpuid_ext_features & CPUID_EXT_XSAVE ) == 0 //<S2SV> || ( prefixes & ( PREFIX_LOCK | PREFIX_DATA //<S2SV> | PREFIX_REPZ | PREFIX_REPNZ ) ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_concat_tl_i64 ( cpu_tmp1_i64 , cpu_regs [ R_EAX ] , //<S2SV> cpu_regs [ R_EDX ] ) ; //<S2SV> gen_helper_xsave ( cpu_env , cpu_A0 , cpu_tmp1_i64 ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 5 ) : //<S2SV> if ( ( s -> cpuid_ext_features & CPUID_EXT_XSAVE ) == 0 //<S2SV> || ( prefixes & ( PREFIX_LOCK | PREFIX_DATA //<S2SV> | PREFIX_REPZ | PREFIX_REPNZ ) ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_concat_tl_i64 ( cpu_tmp1_i64 , cpu_regs [ R_EAX ] , //<S2SV> cpu_regs [ R_EDX ] ) ; //<S2SV> gen_helper_xrstor ( cpu_env , cpu_A0 , cpu_tmp1_i64 ) ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 6 ) : //<S2SV> if ( prefixes & PREFIX_LOCK ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( prefixes & PREFIX_DATA ) { //<S2SV> if ( ! ( s -> cpuid_7_0_ebx_features & CPUID_7_0_EBX_CLWB ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> } else { //<S2SV> if ( ( s -> cpuid_ext_features & CPUID_EXT_XSAVE ) == 0 //<S2SV> || ( s -> cpuid_xsave_features & CPUID_XSAVE_XSAVEOPT ) == 0 //<S2SV> || ( prefixes & ( PREFIX_REPZ | PREFIX_REPNZ ) ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> gen_lea_modrm ( env , s , modrm ) ; //<S2SV> tcg_gen_concat_tl_i64 ( cpu_tmp1_i64 , cpu_regs [ R_EAX ] , //<S2SV> cpu_regs [ R_EDX ] ) ; //<S2SV> gen_helper_xsaveopt ( cpu_env , cpu_A0 , cpu_tmp1_i64 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> CASE_MODRM_MEM_OP ( 7 ) : //<S2SV> if ( prefixes & PREFIX_LOCK ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> if ( prefixes & PREFIX_DATA ) { //<S2SV> if ( ! ( s -> cpuid_7_0_ebx_features & CPUID_7_0_EBX_CLFLUSHOPT ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> } else { //<S2SV> if ( ( s -> prefix & ( PREFIX_REPZ | PREFIX_REPNZ ) ) //<S2SV> || ! ( s -> cpuid_features & CPUID_CLFLUSH ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> } //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> break ; //<S2SV> case 0xc0 ... 0xc7 : //<S2SV> case 0xc8 ... 0xc8 : //<S2SV> case 0xd0 ... 0xd7 : //<S2SV> case 0xd8 ... 0xd8 : //<S2SV> if ( CODE64 ( s ) //<S2SV> && ( prefixes & PREFIX_REPZ ) //<S2SV> && ! ( prefixes & PREFIX_LOCK ) //<S2SV> && ( s -> cpuid_7_0_ebx_features & CPUID_7_0_EBX_FSGSBASE ) ) { //<S2SV> TCGv base , treg , src , dst ; //<S2SV> tcg_gen_movi_i32 ( cpu_tmp2_i32 , CR4_FSGSBASE_MASK ) ; //<S2SV> gen_helper_cr4_testbit ( cpu_env , cpu_tmp2_i32 ) ; //<S2SV> base = cpu_seg_base [ modrm & 8 ? R_GS : R_FS ] ; //<S2SV> treg = cpu_regs [ ( modrm & 7 ) | REX_B ( s ) ] ; //<S2SV> if ( modrm & 0x10 ) { //<S2SV> dst = base , src = treg ; //<S2SV> } else { //<S2SV> dst = treg , src = base ; //<S2SV> } //<S2SV> if ( s -> dflag == MO_32 ) { //<S2SV> tcg_gen_ext32u_tl ( dst , src ) ; //<S2SV> } else { //<S2SV> tcg_gen_mov_tl ( dst , src ) ; //<S2SV> } //<S2SV> break ; //<S2SV> } //<S2SV> goto unknown_op ; //<S2SV> case 0xf8 : //<S2SV> if ( prefixes & PREFIX_DATA ) { //<S2SV> if ( ! ( s -> cpuid_7_0_ebx_features & CPUID_7_0_EBX_PCOMMIT ) //<S2SV> || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> break ; //<S2SV> } //<S2SV> case 0xf9 ... 0xff : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_SSE ) //<S2SV> || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_mb ( TCG_MO_ST_ST | TCG_BAR_SC ) ; //<S2SV> break ; //<S2SV> case 0xe8 ... 0xef : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_SSE ) //<S2SV> || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_mb ( TCG_MO_LD_LD | TCG_BAR_SC ) ; //<S2SV> break ; //<S2SV> case 0xf0 ... 0xf7 : //<S2SV> if ( ! ( s -> cpuid_features & CPUID_SSE2 ) //<S2SV> || ( prefixes & PREFIX_LOCK ) ) { //<S2SV> goto illegal_op ; //<S2SV> } //<S2SV> tcg_gen_mb ( TCG_MO_ALL | TCG_BAR_SC ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> break ; //<S2SV> case 0x10d : //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> mod = ( modrm >> 6 ) & 3 ; //<S2SV> if ( mod == 3 ) //<S2SV> goto illegal_op ; //<S2SV> gen_nop_modrm ( env , s , modrm ) ; //<S2SV> break ; //<S2SV> case 0x1aa : //<S2SV> gen_svm_check_intercept ( s , pc_start , SVM_EXIT_RSM ) ; //<S2SV> if ( ! ( s -> flags & HF_SMM_MASK ) ) //<S2SV> goto illegal_op ; //<S2SV> gen_update_cc_op ( s ) ; //<S2SV> gen_jmp_im ( s -> pc - s -> cs_base ) ; //<S2SV> gen_helper_rsm ( cpu_env ) ; //<S2SV> gen_eob ( s ) ; //<S2SV> break ; //<S2SV> case 0x1b8 : //<S2SV> if ( ( prefixes & ( PREFIX_REPZ | PREFIX_LOCK | PREFIX_REPNZ ) ) != //<S2SV> PREFIX_REPZ ) //<S2SV> goto illegal_op ; //<S2SV> if ( ! ( s -> cpuid_ext_features & CPUID_EXT_POPCNT ) ) //<S2SV> goto illegal_op ; //<S2SV> modrm = cpu_ldub_code ( env , s -> pc ++ ) ; //<S2SV> reg = ( ( modrm >> 3 ) & 7 ) | rex_r ; //<S2SV> if ( s -> prefix & PREFIX_DATA ) { //<S2SV> ot = MO_16 ; //<S2SV> } else { //<S2SV> ot = mo_64_32 ( dflag ) ; //<S2SV> } //<S2SV> gen_ldst_modrm ( env , s , modrm , ot , OR_TMP0 , 0 ) ; //<S2SV> gen_extu ( ot , cpu_T0 ) ; //<S2SV> tcg_gen_mov_tl ( cpu_cc_src , cpu_T0 ) ; //<S2SV> tcg_gen_ctpop_tl ( cpu_T0 , cpu_T0 ) ; //<S2SV> gen_op_mov_reg_v ( ot , reg , cpu_T0 ) ; //<S2SV> set_cc_op ( s , CC_OP_POPCNT ) ; //<S2SV> break ; //<S2SV> case 0x10e ... 0x10f : //<S2SV> s -> prefix &= ~ ( PREFIX_REPZ | PREFIX_REPNZ | PREFIX_DATA ) ; //<S2SV> case 0x110 ... 0x117 : //<S2SV> case 0x128 ... 0x12f : //<S2SV> case 0x138 ... 0x13a : //<S2SV> case 0x150 ... 0x179 : //<S2SV> case 0x17c ... 0x17f : //<S2SV> case 0x1c2 : //<S2SV> case 0x1c4 ... 0x1c6 : //<S2SV> case 0x1d0 ... 0x1fe : //<S2SV> gen_sse ( env , s , b , pc_start , rex_r ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto unknown_op ; //<S2SV> } //<S2SV> return s -> pc ; //<S2SV> illegal_op : //<S2SV> gen_illegal_opcode ( s ) ; //<S2SV> return s -> pc ; //<S2SV> unknown_op : //<S2SV> gen_unknown_opcode ( env , s ) ; //<S2SV> return s -> pc ; //<S2SV> } //<S2SV> 