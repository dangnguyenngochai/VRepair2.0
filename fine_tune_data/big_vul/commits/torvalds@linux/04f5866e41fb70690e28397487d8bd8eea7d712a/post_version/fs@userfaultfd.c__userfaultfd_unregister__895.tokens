static int userfaultfd_unregister ( struct userfaultfd_ctx * ctx , //<S2SV> unsigned long arg ) //<S2SV> { //<S2SV> struct mm_struct * mm = ctx -> mm ; //<S2SV> struct vm_area_struct * vma , * prev , * cur ; //<S2SV> int ret ; //<S2SV> struct uffdio_range uffdio_unregister ; //<S2SV> unsigned long new_flags ; //<S2SV> bool found ; //<S2SV> unsigned long start , end , vma_end ; //<S2SV> const void __user * buf = ( void __user * ) arg ; //<S2SV> ret = - EFAULT ; //<S2SV> if ( copy_from_user ( & uffdio_unregister , buf , sizeof ( uffdio_unregister ) ) ) //<S2SV> goto out ; //<S2SV> ret = validate_range ( mm , uffdio_unregister . start , //<S2SV> uffdio_unregister . len ) ; //<S2SV> if ( ret ) //<S2SV> goto out ; //<S2SV> start = uffdio_unregister . start ; //<S2SV> end = start + uffdio_unregister . len ; //<S2SV> ret = - ENOMEM ; //<S2SV> if ( ! mmget_not_zero ( mm ) ) //<S2SV> goto out ; //<S2SV> down_write ( & mm -> mmap_sem ) ; //<S2SV> if ( ! mmget_still_valid ( mm ) ) //<S2SV> goto out_unlock ; //<S2SV> vma = find_vma_prev ( mm , start , & prev ) ; //<S2SV> if ( ! vma ) //<S2SV> goto out_unlock ; //<S2SV> ret = - EINVAL ; //<S2SV> if ( vma -> vm_start >= end ) //<S2SV> goto out_unlock ; //<S2SV> if ( is_vm_hugetlb_page ( vma ) ) { //<S2SV> unsigned long vma_hpagesize = vma_kernel_pagesize ( vma ) ; //<S2SV> if ( start & ( vma_hpagesize - 1 ) ) //<S2SV> goto out_unlock ; //<S2SV> } //<S2SV> found = false ; //<S2SV> ret = - EINVAL ; //<S2SV> for ( cur = vma ; cur && cur -> vm_start < end ; cur = cur -> vm_next ) { //<S2SV> cond_resched ( ) ; //<S2SV> BUG_ON ( ! ! cur -> vm_userfaultfd_ctx . ctx ^ //<S2SV> ! ! ( cur -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; //<S2SV> if ( ! vma_can_userfault ( cur ) ) //<S2SV> goto out_unlock ; //<S2SV> found = true ; //<S2SV> } //<S2SV> BUG_ON ( ! found ) ; //<S2SV> if ( vma -> vm_start < start ) //<S2SV> prev = vma ; //<S2SV> ret = 0 ; //<S2SV> do { //<S2SV> cond_resched ( ) ; //<S2SV> BUG_ON ( ! vma_can_userfault ( vma ) ) ; //<S2SV> if ( ! vma -> vm_userfaultfd_ctx . ctx ) //<S2SV> goto skip ; //<S2SV> WARN_ON ( ! ( vma -> vm_flags & VM_MAYWRITE ) ) ; //<S2SV> if ( vma -> vm_start > start ) //<S2SV> start = vma -> vm_start ; //<S2SV> vma_end = min ( end , vma -> vm_end ) ; //<S2SV> if ( userfaultfd_missing ( vma ) ) { //<S2SV> struct userfaultfd_wake_range range ; //<S2SV> range . start = start ; //<S2SV> range . len = vma_end - start ; //<S2SV> wake_userfault ( vma -> vm_userfaultfd_ctx . ctx , & range ) ; //<S2SV> } //<S2SV> new_flags = vma -> vm_flags & ~ ( VM_UFFD_MISSING | VM_UFFD_WP ) ; //<S2SV> prev = vma_merge ( mm , prev , start , vma_end , new_flags , //<S2SV> vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , //<S2SV> vma_policy ( vma ) , //<S2SV> NULL_VM_UFFD_CTX ) ; //<S2SV> if ( prev ) { //<S2SV> vma = prev ; //<S2SV> goto next ; //<S2SV> } //<S2SV> if ( vma -> vm_start < start ) { //<S2SV> ret = split_vma ( mm , vma , start , 1 ) ; //<S2SV> if ( ret ) //<S2SV> break ; //<S2SV> } //<S2SV> if ( vma -> vm_end > end ) { //<S2SV> ret = split_vma ( mm , vma , end , 0 ) ; //<S2SV> if ( ret ) //<S2SV> break ; //<S2SV> } //<S2SV> next : //<S2SV> vma -> vm_flags = new_flags ; //<S2SV> vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; //<S2SV> skip : //<S2SV> prev = vma ; //<S2SV> start = vma -> vm_end ; //<S2SV> vma = vma -> vm_next ; //<S2SV> } while ( vma && vma -> vm_start < end ) ; //<S2SV> out_unlock : //<S2SV> up_write ( & mm -> mmap_sem ) ; //<S2SV> mmput ( mm ) ; //<S2SV> out : //<S2SV> return ret ; //<S2SV> } //<S2SV> 