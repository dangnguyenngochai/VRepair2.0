static int userfaultfd_release ( struct inode * inode , struct file * file ) //<S2SV> { //<S2SV> struct userfaultfd_ctx * ctx = file -> private_data ; //<S2SV> struct mm_struct * mm = ctx -> mm ; //<S2SV> struct vm_area_struct * vma , * prev ; //<S2SV> struct userfaultfd_wake_range range = { . len = 0 , } ; //<S2SV> unsigned long new_flags ; //<S2SV> WRITE_ONCE ( ctx -> released , true ) ; //<S2SV> if ( ! mmget_not_zero ( mm ) ) //<S2SV> goto wakeup ; //<S2SV> down_write ( & mm -> mmap_sem ) ; //<S2SV> prev = NULL ; //<S2SV> for ( vma = mm -> mmap ; vma ; vma = vma -> vm_next ) { //<S2SV> cond_resched ( ) ; //<S2SV> BUG_ON ( ! ! vma -> vm_userfaultfd_ctx . ctx ^ //<S2SV> ! ! ( vma -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; //<S2SV> if ( vma -> vm_userfaultfd_ctx . ctx != ctx ) { //<S2SV> prev = vma ; //<S2SV> continue ; //<S2SV> } //<S2SV> new_flags = vma -> vm_flags & ~ ( VM_UFFD_MISSING | VM_UFFD_WP ) ; //<S2SV> prev = vma_merge ( mm , prev , vma -> vm_start , vma -> vm_end , //<S2SV> new_flags , vma -> anon_vma , //<S2SV> vma -> vm_file , vma -> vm_pgoff , //<S2SV> vma_policy ( vma ) , //<S2SV> NULL_VM_UFFD_CTX ) ; //<S2SV> if ( prev ) //<S2SV> vma = prev ; //<S2SV> else //<S2SV> prev = vma ; //<S2SV> vma -> vm_flags = new_flags ; //<S2SV> vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; //<S2SV> } //<S2SV> up_write ( & mm -> mmap_sem ) ; //<S2SV> mmput ( mm ) ; //<S2SV> wakeup : //<S2SV> spin_lock ( & ctx -> fault_pending_wqh . lock ) ; //<S2SV> __wake_up_locked_key ( & ctx -> fault_pending_wqh , TASK_NORMAL , & range ) ; //<S2SV> __wake_up ( & ctx -> fault_wqh , TASK_NORMAL , 1 , & range ) ; //<S2SV> spin_unlock ( & ctx -> fault_pending_wqh . lock ) ; //<S2SV> wake_up_all ( & ctx -> event_wqh ) ; //<S2SV> wake_up_poll ( & ctx -> fd_wqh , EPOLLHUP ) ; //<S2SV> userfaultfd_ctx_put ( ctx ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> 