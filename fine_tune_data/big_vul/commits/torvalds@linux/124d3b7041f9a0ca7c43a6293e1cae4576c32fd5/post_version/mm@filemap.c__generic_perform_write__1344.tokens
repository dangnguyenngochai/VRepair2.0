static ssize_t generic_perform_write ( struct file * file , //<S2SV> struct iov_iter * i , loff_t pos ) //<S2SV> { //<S2SV> struct address_space * mapping = file -> f_mapping ; //<S2SV> const struct address_space_operations * a_ops = mapping -> a_ops ; //<S2SV> long status = 0 ; //<S2SV> ssize_t written = 0 ; //<S2SV> unsigned int flags = 0 ; //<S2SV> if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) //<S2SV> flags |= AOP_FLAG_UNINTERRUPTIBLE ; //<S2SV> do { //<S2SV> struct page * page ; //<S2SV> pgoff_t index ; //<S2SV> unsigned long offset ; //<S2SV> unsigned long bytes ; //<S2SV> size_t copied ; //<S2SV> void * fsdata ; //<S2SV> offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; //<S2SV> index = pos >> PAGE_CACHE_SHIFT ; //<S2SV> bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , //<S2SV> iov_iter_count ( i ) ) ; //<S2SV> again : //<S2SV> if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { //<S2SV> status = - EFAULT ; //<S2SV> break ; //<S2SV> } //<S2SV> status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , //<S2SV> & page , & fsdata ) ; //<S2SV> if ( unlikely ( status ) ) //<S2SV> break ; //<S2SV> pagefault_disable ( ) ; //<S2SV> copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; //<S2SV> pagefault_enable ( ) ; //<S2SV> flush_dcache_page ( page ) ; //<S2SV> status = a_ops -> write_end ( file , mapping , pos , bytes , copied , //<S2SV> page , fsdata ) ; //<S2SV> if ( unlikely ( status < 0 ) ) //<S2SV> break ; //<S2SV> copied = status ; //<S2SV> cond_resched ( ) ; //<S2SV> iov_iter_advance ( i , copied ) ; //<S2SV> if ( unlikely ( copied == 0 ) ) { //<S2SV> bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , //<S2SV> iov_iter_single_seg_count ( i ) ) ; //<S2SV> goto again ; //<S2SV> } //<S2SV> pos += copied ; //<S2SV> written += copied ; //<S2SV> balance_dirty_pages_ratelimited ( mapping ) ; //<S2SV> } while ( iov_iter_count ( i ) ) ; //<S2SV> return written ? written : status ; //<S2SV> } //<S2SV> 