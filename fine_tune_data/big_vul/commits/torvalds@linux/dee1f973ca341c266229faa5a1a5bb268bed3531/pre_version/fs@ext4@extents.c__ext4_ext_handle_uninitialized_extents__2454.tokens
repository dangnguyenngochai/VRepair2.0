static int //<S2SV> ext4_ext_handle_uninitialized_extents ( handle_t * handle , struct inode * inode , //<S2SV> struct ext4_map_blocks * map , //<S2SV> struct ext4_ext_path * path , int flags , //<S2SV> unsigned int allocated , ext4_fsblk_t newblock ) //<S2SV> { //<S2SV> int ret = 0 ; //<S2SV> int err = 0 ; //<S2SV> ext4_io_end_t * io = ext4_inode_aio ( inode ) ; //<S2SV> ext_debug ( "ext4_ext_handle_uninitialized_extents:<S2SV_blank>inode<S2SV_blank>%lu,<S2SV_blank>logical<S2SV_blank>" //<S2SV> "block<S2SV_blank>%llu,<S2SV_blank>max_blocks<S2SV_blank>%u,<S2SV_blank>flags<S2SV_blank>%x,<S2SV_blank>allocated<S2SV_blank>%u\\n" , //<S2SV> inode -> i_ino , ( unsigned long long ) map -> m_lblk , map -> m_len , //<S2SV> flags , allocated ) ; //<S2SV> ext4_ext_show_leaf ( inode , path ) ; //<S2SV> trace_ext4_ext_handle_uninitialized_extents ( inode , map , allocated , //<S2SV> newblock ) ; //<S2SV> if ( ( flags & EXT4_GET_BLOCKS_PRE_IO ) ) { //<S2SV> ret = ext4_split_unwritten_extents ( handle , inode , map , //<S2SV> path , flags ) ; //<S2SV> if ( ret <= 0 ) //<S2SV> goto out ; //<S2SV> if ( io ) //<S2SV> ext4_set_io_unwritten_flag ( inode , io ) ; //<S2SV> else //<S2SV> ext4_set_inode_state ( inode , EXT4_STATE_DIO_UNWRITTEN ) ; //<S2SV> if ( ext4_should_dioread_nolock ( inode ) ) //<S2SV> map -> m_flags |= EXT4_MAP_UNINIT ; //<S2SV> goto out ; //<S2SV> } //<S2SV> if ( ( flags & EXT4_GET_BLOCKS_CONVERT ) ) { //<S2SV> ret = ext4_convert_unwritten_extents_endio ( handle , inode , //<S2SV> path ) ; //<S2SV> if ( ret >= 0 ) { //<S2SV> ext4_update_inode_fsync_trans ( handle , inode , 1 ) ; //<S2SV> err = check_eofblocks_fl ( handle , inode , map -> m_lblk , //<S2SV> path , map -> m_len ) ; //<S2SV> } else //<S2SV> err = ret ; //<S2SV> goto out2 ; //<S2SV> } //<S2SV> if ( flags & EXT4_GET_BLOCKS_UNINIT_EXT ) //<S2SV> goto map_out ; //<S2SV> if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 ) { //<S2SV> map -> m_flags |= EXT4_MAP_UNWRITTEN ; //<S2SV> goto out1 ; //<S2SV> } //<S2SV> ret = ext4_ext_convert_to_initialized ( handle , inode , map , path ) ; //<S2SV> if ( ret >= 0 ) //<S2SV> ext4_update_inode_fsync_trans ( handle , inode , 1 ) ; //<S2SV> out : //<S2SV> if ( ret <= 0 ) { //<S2SV> err = ret ; //<S2SV> goto out2 ; //<S2SV> } else //<S2SV> allocated = ret ; //<S2SV> map -> m_flags |= EXT4_MAP_NEW ; //<S2SV> if ( allocated > map -> m_len ) { //<S2SV> unmap_underlying_metadata_blocks ( inode -> i_sb -> s_bdev , //<S2SV> newblock + map -> m_len , //<S2SV> allocated - map -> m_len ) ; //<S2SV> allocated = map -> m_len ; //<S2SV> } //<S2SV> if ( flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE ) { //<S2SV> unsigned int reserved_clusters ; //<S2SV> reserved_clusters = get_reserved_cluster_alloc ( inode , //<S2SV> map -> m_lblk , map -> m_len ) ; //<S2SV> if ( reserved_clusters ) //<S2SV> ext4_da_update_reserve_space ( inode , //<S2SV> reserved_clusters , //<S2SV> 0 ) ; //<S2SV> } //<S2SV> map_out : //<S2SV> map -> m_flags |= EXT4_MAP_MAPPED ; //<S2SV> if ( ( flags & EXT4_GET_BLOCKS_KEEP_SIZE ) == 0 ) { //<S2SV> err = check_eofblocks_fl ( handle , inode , map -> m_lblk , path , //<S2SV> map -> m_len ) ; //<S2SV> if ( err < 0 ) //<S2SV> goto out2 ; //<S2SV> } //<S2SV> out1 : //<S2SV> if ( allocated > map -> m_len ) //<S2SV> allocated = map -> m_len ; //<S2SV> ext4_ext_show_leaf ( inode , path ) ; //<S2SV> map -> m_pblk = newblock ; //<S2SV> map -> m_len = allocated ; //<S2SV> out2 : //<S2SV> if ( path ) { //<S2SV> ext4_ext_drop_refs ( path ) ; //<S2SV> kfree ( path ) ; //<S2SV> } //<S2SV> return err ? err : allocated ; //<S2SV> } //<S2SV> 