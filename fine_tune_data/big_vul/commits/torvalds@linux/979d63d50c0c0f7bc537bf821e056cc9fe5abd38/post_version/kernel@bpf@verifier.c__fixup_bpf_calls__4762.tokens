static int fixup_bpf_calls ( struct bpf_verifier_env * env ) //<S2SV> { //<S2SV> struct bpf_prog * prog = env -> prog ; //<S2SV> struct bpf_insn * insn = prog -> insnsi ; //<S2SV> const struct bpf_func_proto * fn ; //<S2SV> const int insn_cnt = prog -> len ; //<S2SV> const struct bpf_map_ops * ops ; //<S2SV> struct bpf_insn_aux_data * aux ; //<S2SV> struct bpf_insn insn_buf [ 16 ] ; //<S2SV> struct bpf_prog * new_prog ; //<S2SV> struct bpf_map * map_ptr ; //<S2SV> int i , cnt , delta = 0 ; //<S2SV> for ( i = 0 ; i < insn_cnt ; i ++ , insn ++ ) { //<S2SV> if ( insn -> code == ( BPF_ALU64 | BPF_MOD | BPF_X ) || //<S2SV> insn -> code == ( BPF_ALU64 | BPF_DIV | BPF_X ) || //<S2SV> insn -> code == ( BPF_ALU | BPF_MOD | BPF_X ) || //<S2SV> insn -> code == ( BPF_ALU | BPF_DIV | BPF_X ) ) { //<S2SV> bool is64 = BPF_CLASS ( insn -> code ) == BPF_ALU64 ; //<S2SV> struct bpf_insn mask_and_div [ ] = { //<S2SV> BPF_MOV32_REG ( insn -> src_reg , insn -> src_reg ) , //<S2SV> BPF_JMP_IMM ( BPF_JNE , insn -> src_reg , 0 , 2 ) , //<S2SV> BPF_ALU32_REG ( BPF_XOR , insn -> dst_reg , insn -> dst_reg ) , //<S2SV> BPF_JMP_IMM ( BPF_JA , 0 , 0 , 1 ) , //<S2SV> * insn , //<S2SV> } ; //<S2SV> struct bpf_insn mask_and_mod [ ] = { //<S2SV> BPF_MOV32_REG ( insn -> src_reg , insn -> src_reg ) , //<S2SV> BPF_JMP_IMM ( BPF_JEQ , insn -> src_reg , 0 , 1 ) , //<S2SV> * insn , //<S2SV> } ; //<S2SV> struct bpf_insn * patchlet ; //<S2SV> if ( insn -> code == ( BPF_ALU64 | BPF_DIV | BPF_X ) || //<S2SV> insn -> code == ( BPF_ALU | BPF_DIV | BPF_X ) ) { //<S2SV> patchlet = mask_and_div + ( is64 ? 1 : 0 ) ; //<S2SV> cnt = ARRAY_SIZE ( mask_and_div ) - ( is64 ? 1 : 0 ) ; //<S2SV> } else { //<S2SV> patchlet = mask_and_mod + ( is64 ? 1 : 0 ) ; //<S2SV> cnt = ARRAY_SIZE ( mask_and_mod ) - ( is64 ? 1 : 0 ) ; //<S2SV> } //<S2SV> new_prog = bpf_patch_insn_data ( env , i + delta , patchlet , cnt ) ; //<S2SV> if ( ! new_prog ) //<S2SV> return - ENOMEM ; //<S2SV> delta += cnt - 1 ; //<S2SV> env -> prog = prog = new_prog ; //<S2SV> insn = new_prog -> insnsi + i + delta ; //<S2SV> continue ; //<S2SV> } //<S2SV> if ( BPF_CLASS ( insn -> code ) == BPF_LD && //<S2SV> ( BPF_MODE ( insn -> code ) == BPF_ABS || //<S2SV> BPF_MODE ( insn -> code ) == BPF_IND ) ) { //<S2SV> cnt = env -> ops -> gen_ld_abs ( insn , insn_buf ) ; //<S2SV> if ( cnt == 0 || cnt >= ARRAY_SIZE ( insn_buf ) ) { //<S2SV> verbose ( env , "bpf<S2SV_blank>verifier<S2SV_blank>is<S2SV_blank>misconfigured\\n" ) ; //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> new_prog = bpf_patch_insn_data ( env , i + delta , insn_buf , cnt ) ; //<S2SV> if ( ! new_prog ) //<S2SV> return - ENOMEM ; //<S2SV> delta += cnt - 1 ; //<S2SV> env -> prog = prog = new_prog ; //<S2SV> insn = new_prog -> insnsi + i + delta ; //<S2SV> continue ; //<S2SV> } //<S2SV> if ( insn -> code == ( BPF_ALU64 | BPF_ADD | BPF_X ) || //<S2SV> insn -> code == ( BPF_ALU64 | BPF_SUB | BPF_X ) ) { //<S2SV> const u8 code_add = BPF_ALU64 | BPF_ADD | BPF_X ; //<S2SV> const u8 code_sub = BPF_ALU64 | BPF_SUB | BPF_X ; //<S2SV> struct bpf_insn insn_buf [ 16 ] ; //<S2SV> struct bpf_insn * patch = & insn_buf [ 0 ] ; //<S2SV> bool issrc , isneg ; //<S2SV> u32 off_reg ; //<S2SV> aux = & env -> insn_aux_data [ i + delta ] ; //<S2SV> if ( ! aux -> alu_state ) //<S2SV> continue ; //<S2SV> isneg = aux -> alu_state & BPF_ALU_NEG_VALUE ; //<S2SV> issrc = ( aux -> alu_state & BPF_ALU_SANITIZE ) == //<S2SV> BPF_ALU_SANITIZE_SRC ; //<S2SV> off_reg = issrc ? insn -> src_reg : insn -> dst_reg ; //<S2SV> if ( isneg ) //<S2SV> * patch ++ = BPF_ALU64_IMM ( BPF_MUL , off_reg , - 1 ) ; //<S2SV> * patch ++ = BPF_MOV32_IMM ( BPF_REG_AX , aux -> alu_limit - 1 ) ; //<S2SV> * patch ++ = BPF_ALU64_REG ( BPF_SUB , BPF_REG_AX , off_reg ) ; //<S2SV> * patch ++ = BPF_ALU64_REG ( BPF_OR , BPF_REG_AX , off_reg ) ; //<S2SV> * patch ++ = BPF_ALU64_IMM ( BPF_NEG , BPF_REG_AX , 0 ) ; //<S2SV> * patch ++ = BPF_ALU64_IMM ( BPF_ARSH , BPF_REG_AX , 63 ) ; //<S2SV> if ( issrc ) { //<S2SV> * patch ++ = BPF_ALU64_REG ( BPF_AND , BPF_REG_AX , //<S2SV> off_reg ) ; //<S2SV> insn -> src_reg = BPF_REG_AX ; //<S2SV> } else { //<S2SV> * patch ++ = BPF_ALU64_REG ( BPF_AND , off_reg , //<S2SV> BPF_REG_AX ) ; //<S2SV> } //<S2SV> if ( isneg ) //<S2SV> insn -> code = insn -> code == code_add ? //<S2SV> code_sub : code_add ; //<S2SV> * patch ++ = * insn ; //<S2SV> if ( issrc && isneg ) //<S2SV> * patch ++ = BPF_ALU64_IMM ( BPF_MUL , off_reg , - 1 ) ; //<S2SV> cnt = patch - insn_buf ; //<S2SV> new_prog = bpf_patch_insn_data ( env , i + delta , insn_buf , cnt ) ; //<S2SV> if ( ! new_prog ) //<S2SV> return - ENOMEM ; //<S2SV> delta += cnt - 1 ; //<S2SV> env -> prog = prog = new_prog ; //<S2SV> insn = new_prog -> insnsi + i + delta ; //<S2SV> continue ; //<S2SV> } //<S2SV> if ( insn -> code != ( BPF_JMP | BPF_CALL ) ) //<S2SV> continue ; //<S2SV> if ( insn -> src_reg == BPF_PSEUDO_CALL ) //<S2SV> continue ; //<S2SV> if ( insn -> imm == BPF_FUNC_get_route_realm ) //<S2SV> prog -> dst_needed = 1 ; //<S2SV> if ( insn -> imm == BPF_FUNC_get_prandom_u32 ) //<S2SV> bpf_user_rnd_init_once ( ) ; //<S2SV> if ( insn -> imm == BPF_FUNC_override_return ) //<S2SV> prog -> kprobe_override = 1 ; //<S2SV> if ( insn -> imm == BPF_FUNC_tail_call ) { //<S2SV> prog -> cb_access = 1 ; //<S2SV> env -> prog -> aux -> stack_depth = MAX_BPF_STACK ; //<S2SV> env -> prog -> aux -> max_pkt_offset = MAX_PACKET_OFF ; //<S2SV> insn -> imm = 0 ; //<S2SV> insn -> code = BPF_JMP | BPF_TAIL_CALL ; //<S2SV> aux = & env -> insn_aux_data [ i + delta ] ; //<S2SV> if ( ! bpf_map_ptr_unpriv ( aux ) ) //<S2SV> continue ; //<S2SV> if ( bpf_map_ptr_poisoned ( aux ) ) { //<S2SV> verbose ( env , "tail_call<S2SV_blank>abusing<S2SV_blank>map_ptr\\n" ) ; //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> map_ptr = BPF_MAP_PTR ( aux -> map_state ) ; //<S2SV> insn_buf [ 0 ] = BPF_JMP_IMM ( BPF_JGE , BPF_REG_3 , //<S2SV> map_ptr -> max_entries , 2 ) ; //<S2SV> insn_buf [ 1 ] = BPF_ALU32_IMM ( BPF_AND , BPF_REG_3 , //<S2SV> container_of ( map_ptr , //<S2SV> struct bpf_array , //<S2SV> map ) -> index_mask ) ; //<S2SV> insn_buf [ 2 ] = * insn ; //<S2SV> cnt = 3 ; //<S2SV> new_prog = bpf_patch_insn_data ( env , i + delta , insn_buf , cnt ) ; //<S2SV> if ( ! new_prog ) //<S2SV> return - ENOMEM ; //<S2SV> delta += cnt - 1 ; //<S2SV> env -> prog = prog = new_prog ; //<S2SV> insn = new_prog -> insnsi + i + delta ; //<S2SV> continue ; //<S2SV> } //<S2SV> if ( prog -> jit_requested && BITS_PER_LONG == 64 && //<S2SV> ( insn -> imm == BPF_FUNC_map_lookup_elem || //<S2SV> insn -> imm == BPF_FUNC_map_update_elem || //<S2SV> insn -> imm == BPF_FUNC_map_delete_elem || //<S2SV> insn -> imm == BPF_FUNC_map_push_elem || //<S2SV> insn -> imm == BPF_FUNC_map_pop_elem || //<S2SV> insn -> imm == BPF_FUNC_map_peek_elem ) ) { //<S2SV> aux = & env -> insn_aux_data [ i + delta ] ; //<S2SV> if ( bpf_map_ptr_poisoned ( aux ) ) //<S2SV> goto patch_call_imm ; //<S2SV> map_ptr = BPF_MAP_PTR ( aux -> map_state ) ; //<S2SV> ops = map_ptr -> ops ; //<S2SV> if ( insn -> imm == BPF_FUNC_map_lookup_elem && //<S2SV> ops -> map_gen_lookup ) { //<S2SV> cnt = ops -> map_gen_lookup ( map_ptr , insn_buf ) ; //<S2SV> if ( cnt == 0 || cnt >= ARRAY_SIZE ( insn_buf ) ) { //<S2SV> verbose ( env , "bpf<S2SV_blank>verifier<S2SV_blank>is<S2SV_blank>misconfigured\\n" ) ; //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> new_prog = bpf_patch_insn_data ( env , i + delta , //<S2SV> insn_buf , cnt ) ; //<S2SV> if ( ! new_prog ) //<S2SV> return - ENOMEM ; //<S2SV> delta += cnt - 1 ; //<S2SV> env -> prog = prog = new_prog ; //<S2SV> insn = new_prog -> insnsi + i + delta ; //<S2SV> continue ; //<S2SV> } //<S2SV> BUILD_BUG_ON ( ! __same_type ( ops -> map_lookup_elem , //<S2SV> ( void * ( * ) ( struct bpf_map * map , void * key ) ) NULL ) ) ; //<S2SV> BUILD_BUG_ON ( ! __same_type ( ops -> map_delete_elem , //<S2SV> ( int ( * ) ( struct bpf_map * map , void * key ) ) NULL ) ) ; //<S2SV> BUILD_BUG_ON ( ! __same_type ( ops -> map_update_elem , //<S2SV> ( int ( * ) ( struct bpf_map * map , void * key , void * value , //<S2SV> u64 flags ) ) NULL ) ) ; //<S2SV> BUILD_BUG_ON ( ! __same_type ( ops -> map_push_elem , //<S2SV> ( int ( * ) ( struct bpf_map * map , void * value , //<S2SV> u64 flags ) ) NULL ) ) ; //<S2SV> BUILD_BUG_ON ( ! __same_type ( ops -> map_pop_elem , //<S2SV> ( int ( * ) ( struct bpf_map * map , void * value ) ) NULL ) ) ; //<S2SV> BUILD_BUG_ON ( ! __same_type ( ops -> map_peek_elem , //<S2SV> ( int ( * ) ( struct bpf_map * map , void * value ) ) NULL ) ) ; //<S2SV> switch ( insn -> imm ) { //<S2SV> case BPF_FUNC_map_lookup_elem : //<S2SV> insn -> imm = BPF_CAST_CALL ( ops -> map_lookup_elem ) - //<S2SV> __bpf_call_base ; //<S2SV> continue ; //<S2SV> case BPF_FUNC_map_update_elem : //<S2SV> insn -> imm = BPF_CAST_CALL ( ops -> map_update_elem ) - //<S2SV> __bpf_call_base ; //<S2SV> continue ; //<S2SV> case BPF_FUNC_map_delete_elem : //<S2SV> insn -> imm = BPF_CAST_CALL ( ops -> map_delete_elem ) - //<S2SV> __bpf_call_base ; //<S2SV> continue ; //<S2SV> case BPF_FUNC_map_push_elem : //<S2SV> insn -> imm = BPF_CAST_CALL ( ops -> map_push_elem ) - //<S2SV> __bpf_call_base ; //<S2SV> continue ; //<S2SV> case BPF_FUNC_map_pop_elem : //<S2SV> insn -> imm = BPF_CAST_CALL ( ops -> map_pop_elem ) - //<S2SV> __bpf_call_base ; //<S2SV> continue ; //<S2SV> case BPF_FUNC_map_peek_elem : //<S2SV> insn -> imm = BPF_CAST_CALL ( ops -> map_peek_elem ) - //<S2SV> __bpf_call_base ; //<S2SV> continue ; //<S2SV> } //<S2SV> goto patch_call_imm ; //<S2SV> } //<S2SV> patch_call_imm : //<S2SV> fn = env -> ops -> get_func_proto ( insn -> imm , env -> prog ) ; //<S2SV> if ( ! fn -> func ) { //<S2SV> verbose ( env , //<S2SV> "kernel<S2SV_blank>subsystem<S2SV_blank>misconfigured<S2SV_blank>func<S2SV_blank>%s#%d\\n" , //<S2SV> func_id_name ( insn -> imm ) , insn -> imm ) ; //<S2SV> return - EFAULT ; //<S2SV> } //<S2SV> insn -> imm = fn -> func - __bpf_call_base ; //<S2SV> } //<S2SV> return 0 ; //<S2SV> } //<S2SV> 