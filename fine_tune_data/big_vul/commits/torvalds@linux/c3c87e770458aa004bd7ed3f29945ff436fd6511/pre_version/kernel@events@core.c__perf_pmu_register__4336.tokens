int perf_pmu_register ( struct pmu * pmu , const char * name , int type ) //<S2SV> { //<S2SV> int cpu , ret ; //<S2SV> mutex_lock ( & pmus_lock ) ; //<S2SV> ret = - ENOMEM ; //<S2SV> pmu -> pmu_disable_count = alloc_percpu ( int ) ; //<S2SV> if ( ! pmu -> pmu_disable_count ) //<S2SV> goto unlock ; //<S2SV> pmu -> type = - 1 ; //<S2SV> if ( ! name ) //<S2SV> goto skip_type ; //<S2SV> pmu -> name = name ; //<S2SV> if ( type < 0 ) { //<S2SV> type = idr_alloc ( & pmu_idr , pmu , PERF_TYPE_MAX , 0 , GFP_KERNEL ) ; //<S2SV> if ( type < 0 ) { //<S2SV> ret = type ; //<S2SV> goto free_pdc ; //<S2SV> } //<S2SV> } //<S2SV> pmu -> type = type ; //<S2SV> if ( pmu_bus_running ) { //<S2SV> ret = pmu_dev_alloc ( pmu ) ; //<S2SV> if ( ret ) //<S2SV> goto free_idr ; //<S2SV> } //<S2SV> skip_type : //<S2SV> pmu -> pmu_cpu_context = find_pmu_context ( pmu -> task_ctx_nr ) ; //<S2SV> if ( pmu -> pmu_cpu_context ) //<S2SV> goto got_cpu_context ; //<S2SV> ret = - ENOMEM ; //<S2SV> pmu -> pmu_cpu_context = alloc_percpu ( struct perf_cpu_context ) ; //<S2SV> if ( ! pmu -> pmu_cpu_context ) //<S2SV> goto free_dev ; //<S2SV> for_each_possible_cpu ( cpu ) { //<S2SV> struct perf_cpu_context * cpuctx ; //<S2SV> cpuctx = per_cpu_ptr ( pmu -> pmu_cpu_context , cpu ) ; //<S2SV> __perf_event_init_context ( & cpuctx -> ctx ) ; //<S2SV> lockdep_set_class ( & cpuctx -> ctx . mutex , & cpuctx_mutex ) ; //<S2SV> lockdep_set_class ( & cpuctx -> ctx . lock , & cpuctx_lock ) ; //<S2SV> cpuctx -> ctx . type = cpu_context ; //<S2SV> cpuctx -> ctx . pmu = pmu ; //<S2SV> __perf_cpu_hrtimer_init ( cpuctx , cpu ) ; //<S2SV> INIT_LIST_HEAD ( & cpuctx -> rotation_list ) ; //<S2SV> cpuctx -> unique_pmu = pmu ; //<S2SV> } //<S2SV> got_cpu_context : //<S2SV> if ( ! pmu -> start_txn ) { //<S2SV> if ( pmu -> pmu_enable ) { //<S2SV> pmu -> start_txn = perf_pmu_start_txn ; //<S2SV> pmu -> commit_txn = perf_pmu_commit_txn ; //<S2SV> pmu -> cancel_txn = perf_pmu_cancel_txn ; //<S2SV> } else { //<S2SV> pmu -> start_txn = perf_pmu_nop_void ; //<S2SV> pmu -> commit_txn = perf_pmu_nop_int ; //<S2SV> pmu -> cancel_txn = perf_pmu_nop_void ; //<S2SV> } //<S2SV> } //<S2SV> if ( ! pmu -> pmu_enable ) { //<S2SV> pmu -> pmu_enable = perf_pmu_nop_void ; //<S2SV> pmu -> pmu_disable = perf_pmu_nop_void ; //<S2SV> } //<S2SV> if ( ! pmu -> event_idx ) //<S2SV> pmu -> event_idx = perf_event_idx_default ; //<S2SV> list_add_rcu ( & pmu -> entry , & pmus ) ; //<S2SV> ret = 0 ; //<S2SV> unlock : //<S2SV> mutex_unlock ( & pmus_lock ) ; //<S2SV> return ret ; //<S2SV> free_dev : //<S2SV> device_del ( pmu -> dev ) ; //<S2SV> put_device ( pmu -> dev ) ; //<S2SV> free_idr : //<S2SV> if ( pmu -> type >= PERF_TYPE_MAX ) //<S2SV> idr_remove ( & pmu_idr , pmu -> type ) ; //<S2SV> free_pdc : //<S2SV> free_percpu ( pmu -> pmu_disable_count ) ; //<S2SV> goto unlock ; //<S2SV> } //<S2SV> 