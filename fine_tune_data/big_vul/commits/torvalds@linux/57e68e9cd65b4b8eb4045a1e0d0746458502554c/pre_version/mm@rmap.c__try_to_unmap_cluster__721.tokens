static int try_to_unmap_cluster ( unsigned long cursor , unsigned int * mapcount , //<S2SV> struct vm_area_struct * vma , struct page * check_page ) //<S2SV> { //<S2SV> struct mm_struct * mm = vma -> vm_mm ; //<S2SV> pmd_t * pmd ; //<S2SV> pte_t * pte ; //<S2SV> pte_t pteval ; //<S2SV> spinlock_t * ptl ; //<S2SV> struct page * page ; //<S2SV> unsigned long address ; //<S2SV> unsigned long mmun_start ; //<S2SV> unsigned long mmun_end ; //<S2SV> unsigned long end ; //<S2SV> int ret = SWAP_AGAIN ; //<S2SV> int locked_vma = 0 ; //<S2SV> address = ( vma -> vm_start + cursor ) & CLUSTER_MASK ; //<S2SV> end = address + CLUSTER_SIZE ; //<S2SV> if ( address < vma -> vm_start ) //<S2SV> address = vma -> vm_start ; //<S2SV> if ( end > vma -> vm_end ) //<S2SV> end = vma -> vm_end ; //<S2SV> pmd = mm_find_pmd ( mm , address ) ; //<S2SV> if ( ! pmd ) //<S2SV> return ret ; //<S2SV> mmun_start = address ; //<S2SV> mmun_end = end ; //<S2SV> mmu_notifier_invalidate_range_start ( mm , mmun_start , mmun_end ) ; //<S2SV> if ( down_read_trylock ( & vma -> vm_mm -> mmap_sem ) ) { //<S2SV> locked_vma = ( vma -> vm_flags & VM_LOCKED ) ; //<S2SV> if ( ! locked_vma ) //<S2SV> up_read ( & vma -> vm_mm -> mmap_sem ) ; //<S2SV> } //<S2SV> pte = pte_offset_map_lock ( mm , pmd , address , & ptl ) ; //<S2SV> update_hiwater_rss ( mm ) ; //<S2SV> for ( ; address < end ; pte ++ , address += PAGE_SIZE ) { //<S2SV> if ( ! pte_present ( * pte ) ) //<S2SV> continue ; //<S2SV> page = vm_normal_page ( vma , address , * pte ) ; //<S2SV> BUG_ON ( ! page || PageAnon ( page ) ) ; //<S2SV> if ( locked_vma ) { //<S2SV> mlock_vma_page ( page ) ; //<S2SV> if ( page == check_page ) //<S2SV> ret = SWAP_MLOCK ; //<S2SV> continue ; //<S2SV> } //<S2SV> if ( ptep_clear_flush_young_notify ( vma , address , pte ) ) //<S2SV> continue ; //<S2SV> flush_cache_page ( vma , address , pte_pfn ( * pte ) ) ; //<S2SV> pteval = ptep_clear_flush ( vma , address , pte ) ; //<S2SV> if ( page -> index != linear_page_index ( vma , address ) ) { //<S2SV> pte_t ptfile = pgoff_to_pte ( page -> index ) ; //<S2SV> if ( pte_soft_dirty ( pteval ) ) //<S2SV> pte_file_mksoft_dirty ( ptfile ) ; //<S2SV> set_pte_at ( mm , address , pte , ptfile ) ; //<S2SV> } //<S2SV> if ( pte_dirty ( pteval ) ) //<S2SV> set_page_dirty ( page ) ; //<S2SV> page_remove_rmap ( page ) ; //<S2SV> page_cache_release ( page ) ; //<S2SV> dec_mm_counter ( mm , MM_FILEPAGES ) ; //<S2SV> ( * mapcount ) -- ; //<S2SV> } //<S2SV> pte_unmap_unlock ( pte - 1 , ptl ) ; //<S2SV> mmu_notifier_invalidate_range_end ( mm , mmun_start , mmun_end ) ; //<S2SV> if ( locked_vma ) //<S2SV> up_read ( & vma -> vm_mm -> mmap_sem ) ; //<S2SV> return ret ; //<S2SV> } //<S2SV> 