static int adjust_scalar_min_max_vals ( struct bpf_verifier_env * env , //<S2SV> struct bpf_insn * insn , //<S2SV> struct bpf_reg_state * dst_reg , //<S2SV> struct bpf_reg_state src_reg ) //<S2SV> { //<S2SV> struct bpf_reg_state * regs = cur_regs ( env ) ; //<S2SV> u8 opcode = BPF_OP ( insn -> code ) ; //<S2SV> bool src_known , dst_known ; //<S2SV> s64 smin_val , smax_val ; //<S2SV> u64 umin_val , umax_val ; //<S2SV> u64 insn_bitness = ( BPF_CLASS ( insn -> code ) == BPF_ALU64 ) ? 64 : 32 ; //<S2SV> u32 dst = insn -> dst_reg ; //<S2SV> int ret ; //<S2SV> if ( insn_bitness == 32 ) { //<S2SV> coerce_reg_to_size ( dst_reg , 4 ) ; //<S2SV> coerce_reg_to_size ( & src_reg , 4 ) ; //<S2SV> } //<S2SV> smin_val = src_reg . smin_value ; //<S2SV> smax_val = src_reg . smax_value ; //<S2SV> umin_val = src_reg . umin_value ; //<S2SV> umax_val = src_reg . umax_value ; //<S2SV> src_known = tnum_is_const ( src_reg . var_off ) ; //<S2SV> dst_known = tnum_is_const ( dst_reg -> var_off ) ; //<S2SV> if ( ( src_known && ( smin_val != smax_val || umin_val != umax_val ) ) || //<S2SV> smin_val > smax_val || umin_val > umax_val ) { //<S2SV> __mark_reg_unknown ( dst_reg ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> if ( ! src_known && //<S2SV> opcode != BPF_ADD && opcode != BPF_SUB && opcode != BPF_AND ) { //<S2SV> __mark_reg_unknown ( dst_reg ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> switch ( opcode ) { //<S2SV> case BPF_ADD : //<S2SV> ret = sanitize_val_alu ( env , insn ) ; //<S2SV> if ( ret < 0 ) { //<S2SV> verbose ( env , "R%d<S2SV_blank>tried<S2SV_blank>to<S2SV_blank>add<S2SV_blank>from<S2SV_blank>different<S2SV_blank>pointers<S2SV_blank>or<S2SV_blank>scalars\\n" , dst ) ; //<S2SV> return ret ; //<S2SV> } //<S2SV> if ( signed_add_overflows ( dst_reg -> smin_value , smin_val ) || //<S2SV> signed_add_overflows ( dst_reg -> smax_value , smax_val ) ) { //<S2SV> dst_reg -> smin_value = S64_MIN ; //<S2SV> dst_reg -> smax_value = S64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> smin_value += smin_val ; //<S2SV> dst_reg -> smax_value += smax_val ; //<S2SV> } //<S2SV> if ( dst_reg -> umin_value + umin_val < umin_val || //<S2SV> dst_reg -> umax_value + umax_val < umax_val ) { //<S2SV> dst_reg -> umin_value = 0 ; //<S2SV> dst_reg -> umax_value = U64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> umin_value += umin_val ; //<S2SV> dst_reg -> umax_value += umax_val ; //<S2SV> } //<S2SV> dst_reg -> var_off = tnum_add ( dst_reg -> var_off , src_reg . var_off ) ; //<S2SV> break ; //<S2SV> case BPF_SUB : //<S2SV> ret = sanitize_val_alu ( env , insn ) ; //<S2SV> if ( ret < 0 ) { //<S2SV> verbose ( env , "R%d<S2SV_blank>tried<S2SV_blank>to<S2SV_blank>sub<S2SV_blank>from<S2SV_blank>different<S2SV_blank>pointers<S2SV_blank>or<S2SV_blank>scalars\\n" , dst ) ; //<S2SV> return ret ; //<S2SV> } //<S2SV> if ( signed_sub_overflows ( dst_reg -> smin_value , smax_val ) || //<S2SV> signed_sub_overflows ( dst_reg -> smax_value , smin_val ) ) { //<S2SV> dst_reg -> smin_value = S64_MIN ; //<S2SV> dst_reg -> smax_value = S64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> smin_value -= smax_val ; //<S2SV> dst_reg -> smax_value -= smin_val ; //<S2SV> } //<S2SV> if ( dst_reg -> umin_value < umax_val ) { //<S2SV> dst_reg -> umin_value = 0 ; //<S2SV> dst_reg -> umax_value = U64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> umin_value -= umax_val ; //<S2SV> dst_reg -> umax_value -= umin_val ; //<S2SV> } //<S2SV> dst_reg -> var_off = tnum_sub ( dst_reg -> var_off , src_reg . var_off ) ; //<S2SV> break ; //<S2SV> case BPF_MUL : //<S2SV> dst_reg -> var_off = tnum_mul ( dst_reg -> var_off , src_reg . var_off ) ; //<S2SV> if ( smin_val < 0 || dst_reg -> smin_value < 0 ) { //<S2SV> __mark_reg_unbounded ( dst_reg ) ; //<S2SV> __update_reg_bounds ( dst_reg ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( umax_val > U32_MAX || dst_reg -> umax_value > U32_MAX ) { //<S2SV> __mark_reg_unbounded ( dst_reg ) ; //<S2SV> __update_reg_bounds ( dst_reg ) ; //<S2SV> break ; //<S2SV> } //<S2SV> dst_reg -> umin_value *= umin_val ; //<S2SV> dst_reg -> umax_value *= umax_val ; //<S2SV> if ( dst_reg -> umax_value > S64_MAX ) { //<S2SV> dst_reg -> smin_value = S64_MIN ; //<S2SV> dst_reg -> smax_value = S64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> smin_value = dst_reg -> umin_value ; //<S2SV> dst_reg -> smax_value = dst_reg -> umax_value ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_AND : //<S2SV> if ( src_known && dst_known ) { //<S2SV> __mark_reg_known ( dst_reg , dst_reg -> var_off . value & //<S2SV> src_reg . var_off . value ) ; //<S2SV> break ; //<S2SV> } //<S2SV> dst_reg -> var_off = tnum_and ( dst_reg -> var_off , src_reg . var_off ) ; //<S2SV> dst_reg -> umin_value = dst_reg -> var_off . value ; //<S2SV> dst_reg -> umax_value = min ( dst_reg -> umax_value , umax_val ) ; //<S2SV> if ( dst_reg -> smin_value < 0 || smin_val < 0 ) { //<S2SV> dst_reg -> smin_value = S64_MIN ; //<S2SV> dst_reg -> smax_value = S64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> smin_value = dst_reg -> umin_value ; //<S2SV> dst_reg -> smax_value = dst_reg -> umax_value ; //<S2SV> } //<S2SV> __update_reg_bounds ( dst_reg ) ; //<S2SV> break ; //<S2SV> case BPF_OR : //<S2SV> if ( src_known && dst_known ) { //<S2SV> __mark_reg_known ( dst_reg , dst_reg -> var_off . value | //<S2SV> src_reg . var_off . value ) ; //<S2SV> break ; //<S2SV> } //<S2SV> dst_reg -> var_off = tnum_or ( dst_reg -> var_off , src_reg . var_off ) ; //<S2SV> dst_reg -> umin_value = max ( dst_reg -> umin_value , umin_val ) ; //<S2SV> dst_reg -> umax_value = dst_reg -> var_off . value | //<S2SV> dst_reg -> var_off . mask ; //<S2SV> if ( dst_reg -> smin_value < 0 || smin_val < 0 ) { //<S2SV> dst_reg -> smin_value = S64_MIN ; //<S2SV> dst_reg -> smax_value = S64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> smin_value = dst_reg -> umin_value ; //<S2SV> dst_reg -> smax_value = dst_reg -> umax_value ; //<S2SV> } //<S2SV> __update_reg_bounds ( dst_reg ) ; //<S2SV> break ; //<S2SV> case BPF_LSH : //<S2SV> if ( umax_val >= insn_bitness ) { //<S2SV> mark_reg_unknown ( env , regs , insn -> dst_reg ) ; //<S2SV> break ; //<S2SV> } //<S2SV> dst_reg -> smin_value = S64_MIN ; //<S2SV> dst_reg -> smax_value = S64_MAX ; //<S2SV> if ( dst_reg -> umax_value > 1ULL << ( 63 - umax_val ) ) { //<S2SV> dst_reg -> umin_value = 0 ; //<S2SV> dst_reg -> umax_value = U64_MAX ; //<S2SV> } else { //<S2SV> dst_reg -> umin_value <<= umin_val ; //<S2SV> dst_reg -> umax_value <<= umax_val ; //<S2SV> } //<S2SV> dst_reg -> var_off = tnum_lshift ( dst_reg -> var_off , umin_val ) ; //<S2SV> __update_reg_bounds ( dst_reg ) ; //<S2SV> break ; //<S2SV> case BPF_RSH : //<S2SV> if ( umax_val >= insn_bitness ) { //<S2SV> mark_reg_unknown ( env , regs , insn -> dst_reg ) ; //<S2SV> break ; //<S2SV> } //<S2SV> dst_reg -> smin_value = S64_MIN ; //<S2SV> dst_reg -> smax_value = S64_MAX ; //<S2SV> dst_reg -> var_off = tnum_rshift ( dst_reg -> var_off , umin_val ) ; //<S2SV> dst_reg -> umin_value >>= umax_val ; //<S2SV> dst_reg -> umax_value >>= umin_val ; //<S2SV> __update_reg_bounds ( dst_reg ) ; //<S2SV> break ; //<S2SV> case BPF_ARSH : //<S2SV> if ( umax_val >= insn_bitness ) { //<S2SV> mark_reg_unknown ( env , regs , insn -> dst_reg ) ; //<S2SV> break ; //<S2SV> } //<S2SV> dst_reg -> smin_value >>= umin_val ; //<S2SV> dst_reg -> smax_value >>= umin_val ; //<S2SV> dst_reg -> var_off = tnum_arshift ( dst_reg -> var_off , umin_val ) ; //<S2SV> dst_reg -> umin_value = 0 ; //<S2SV> dst_reg -> umax_value = U64_MAX ; //<S2SV> __update_reg_bounds ( dst_reg ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> mark_reg_unknown ( env , regs , insn -> dst_reg ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( BPF_CLASS ( insn -> code ) != BPF_ALU64 ) { //<S2SV> coerce_reg_to_size ( dst_reg , 4 ) ; //<S2SV> } //<S2SV> __reg_deduce_bounds ( dst_reg ) ; //<S2SV> __reg_bound_offset ( dst_reg ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> 