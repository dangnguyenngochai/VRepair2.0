int blk_init_allocated_queue ( struct request_queue * q ) //<S2SV> { //<S2SV> WARN_ON_ONCE ( q -> mq_ops ) ; //<S2SV> q -> fq = blk_alloc_flush_queue ( q , NUMA_NO_NODE , q -> cmd_size ) ; //<S2SV> if ( ! q -> fq ) //<S2SV> return - ENOMEM ; //<S2SV> if ( q -> init_rq_fn && q -> init_rq_fn ( q , q -> fq -> flush_rq , GFP_KERNEL ) ) //<S2SV> goto out_free_flush_queue ; //<S2SV> if ( blk_init_rl ( & q -> root_rl , q , GFP_KERNEL ) ) //<S2SV> goto out_exit_flush_rq ; //<S2SV> INIT_WORK ( & q -> timeout_work , blk_timeout_work ) ; //<S2SV> q -> queue_flags |= QUEUE_FLAG_DEFAULT ; //<S2SV> blk_queue_make_request ( q , blk_queue_bio ) ; //<S2SV> q -> sg_reserved_size = INT_MAX ; //<S2SV> if ( elevator_init ( q ) ) //<S2SV> goto out_exit_flush_rq ; //<S2SV> return 0 ; //<S2SV> out_exit_flush_rq : //<S2SV> if ( q -> exit_rq_fn ) //<S2SV> q -> exit_rq_fn ( q , q -> fq -> flush_rq ) ; //<S2SV> out_free_flush_queue : //<S2SV> blk_free_flush_queue ( q -> fq ) ; //<S2SV> q -> fq = NULL ; //<S2SV> return - ENOMEM ; //<S2SV> } //<S2SV> 