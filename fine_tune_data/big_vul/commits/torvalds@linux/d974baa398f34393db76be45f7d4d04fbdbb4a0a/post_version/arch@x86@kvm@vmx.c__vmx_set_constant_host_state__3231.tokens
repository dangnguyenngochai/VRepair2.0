static void vmx_set_constant_host_state ( struct vcpu_vmx * vmx ) //<S2SV> { //<S2SV> u32 low32 , high32 ; //<S2SV> unsigned long tmpl ; //<S2SV> struct desc_ptr dt ; //<S2SV> unsigned long cr4 ; //<S2SV> vmcs_writel ( HOST_CR0 , read_cr0 ( ) & ~ X86_CR0_TS ) ; //<S2SV> vmcs_writel ( HOST_CR3 , read_cr3 ( ) ) ; //<S2SV> cr4 = read_cr4 ( ) ; //<S2SV> vmcs_writel ( HOST_CR4 , cr4 ) ; //<S2SV> vmx -> host_state . vmcs_host_cr4 = cr4 ; //<S2SV> vmcs_write16 ( HOST_CS_SELECTOR , __KERNEL_CS ) ; //<S2SV> # ifdef CONFIG_X86_64 //<S2SV> vmcs_write16 ( HOST_DS_SELECTOR , 0 ) ; //<S2SV> vmcs_write16 ( HOST_ES_SELECTOR , 0 ) ; //<S2SV> # else //<S2SV> vmcs_write16 ( HOST_DS_SELECTOR , __KERNEL_DS ) ; //<S2SV> vmcs_write16 ( HOST_ES_SELECTOR , __KERNEL_DS ) ; //<S2SV> # endif //<S2SV> vmcs_write16 ( HOST_SS_SELECTOR , __KERNEL_DS ) ; //<S2SV> vmcs_write16 ( HOST_TR_SELECTOR , GDT_ENTRY_TSS * 8 ) ; //<S2SV> native_store_idt ( & dt ) ; //<S2SV> vmcs_writel ( HOST_IDTR_BASE , dt . address ) ; //<S2SV> vmx -> host_idt_base = dt . address ; //<S2SV> vmcs_writel ( HOST_RIP , vmx_return ) ; //<S2SV> rdmsr ( MSR_IA32_SYSENTER_CS , low32 , high32 ) ; //<S2SV> vmcs_write32 ( HOST_IA32_SYSENTER_CS , low32 ) ; //<S2SV> rdmsrl ( MSR_IA32_SYSENTER_EIP , tmpl ) ; //<S2SV> vmcs_writel ( HOST_IA32_SYSENTER_EIP , tmpl ) ; //<S2SV> if ( vmcs_config . vmexit_ctrl & VM_EXIT_LOAD_IA32_PAT ) { //<S2SV> rdmsr ( MSR_IA32_CR_PAT , low32 , high32 ) ; //<S2SV> vmcs_write64 ( HOST_IA32_PAT , low32 | ( ( u64 ) high32 << 32 ) ) ; //<S2SV> } //<S2SV> } //<S2SV> 