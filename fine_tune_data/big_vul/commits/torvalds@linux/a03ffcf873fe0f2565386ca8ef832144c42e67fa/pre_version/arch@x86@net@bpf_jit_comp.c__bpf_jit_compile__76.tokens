void bpf_jit_compile ( struct sk_filter * fp ) //<S2SV> { //<S2SV> u8 temp [ 64 ] ; //<S2SV> u8 * prog ; //<S2SV> unsigned int proglen , oldproglen = 0 ; //<S2SV> int ilen , i ; //<S2SV> int t_offset , f_offset ; //<S2SV> u8 t_op , f_op , seen = 0 , pass ; //<S2SV> u8 * image = NULL ; //<S2SV> u8 * func ; //<S2SV> int pc_ret0 = - 1 ; //<S2SV> unsigned int cleanup_addr ; //<S2SV> unsigned int * addrs ; //<S2SV> const struct sock_filter * filter = fp -> insns ; //<S2SV> int flen = fp -> len ; //<S2SV> if ( ! bpf_jit_enable ) //<S2SV> return ; //<S2SV> addrs = kmalloc ( flen * sizeof ( * addrs ) , GFP_KERNEL ) ; //<S2SV> if ( addrs == NULL ) //<S2SV> return ; //<S2SV> for ( proglen = 0 , i = 0 ; i < flen ; i ++ ) { //<S2SV> proglen += 64 ; //<S2SV> addrs [ i ] = proglen ; //<S2SV> } //<S2SV> cleanup_addr = proglen ; //<S2SV> for ( pass = 0 ; pass < 10 ; pass ++ ) { //<S2SV> proglen = 0 ; //<S2SV> prog = temp ; //<S2SV> if ( seen ) { //<S2SV> EMIT4 ( 0x55 , 0x48 , 0x89 , 0xe5 ) ; //<S2SV> EMIT4 ( 0x48 , 0x83 , 0xec , 96 ) ; //<S2SV> if ( seen & ( SEEN_XREG | SEEN_DATAREF ) ) //<S2SV> EMIT4 ( 0x48 , 0x89 , 0x5d , 0xf8 ) ; //<S2SV> if ( seen & SEEN_XREG ) //<S2SV> CLEAR_X ( ) ; //<S2SV> if ( seen & SEEN_DATAREF ) { //<S2SV> if ( offsetof ( struct sk_buff , len ) <= 127 ) //<S2SV> EMIT4 ( 0x44 , 0x8b , 0x4f , offsetof ( struct sk_buff , len ) ) ; //<S2SV> else { //<S2SV> EMIT3 ( 0x44 , 0x8b , 0x8f ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , len ) , 4 ) ; //<S2SV> } //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , data_len ) ) ) //<S2SV> EMIT4 ( 0x44 , 0x2b , 0x4f , offsetof ( struct sk_buff , data_len ) ) ; //<S2SV> else { //<S2SV> EMIT3 ( 0x44 , 0x2b , 0x8f ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , data_len ) , 4 ) ; //<S2SV> } //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , data ) ) ) //<S2SV> EMIT4 ( 0x4c , 0x8b , 0x47 , offsetof ( struct sk_buff , data ) ) ; //<S2SV> else { //<S2SV> EMIT3 ( 0x4c , 0x8b , 0x87 ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , data ) , 4 ) ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> switch ( filter [ 0 ] . code ) { //<S2SV> case BPF_S_RET_K : //<S2SV> case BPF_S_LD_W_LEN : //<S2SV> case BPF_S_ANC_PROTOCOL : //<S2SV> case BPF_S_ANC_IFINDEX : //<S2SV> case BPF_S_ANC_MARK : //<S2SV> case BPF_S_ANC_RXHASH : //<S2SV> case BPF_S_ANC_CPU : //<S2SV> case BPF_S_ANC_QUEUE : //<S2SV> case BPF_S_LD_W_ABS : //<S2SV> case BPF_S_LD_H_ABS : //<S2SV> case BPF_S_LD_B_ABS : //<S2SV> break ; //<S2SV> default : //<S2SV> CLEAR_A ( ) ; //<S2SV> } //<S2SV> for ( i = 0 ; i < flen ; i ++ ) { //<S2SV> unsigned int K = filter [ i ] . k ; //<S2SV> switch ( filter [ i ] . code ) { //<S2SV> case BPF_S_ALU_ADD_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x01 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_ADD_K : //<S2SV> if ( ! K ) //<S2SV> break ; //<S2SV> if ( is_imm8 ( K ) ) //<S2SV> EMIT3 ( 0x83 , 0xc0 , K ) ; //<S2SV> else //<S2SV> EMIT1_off32 ( 0x05 , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_SUB_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x29 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_SUB_K : //<S2SV> if ( ! K ) //<S2SV> break ; //<S2SV> if ( is_imm8 ( K ) ) //<S2SV> EMIT3 ( 0x83 , 0xe8 , K ) ; //<S2SV> else //<S2SV> EMIT1_off32 ( 0x2d , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_MUL_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT3 ( 0x0f , 0xaf , 0xc3 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_MUL_K : //<S2SV> if ( is_imm8 ( K ) ) //<S2SV> EMIT3 ( 0x6b , 0xc0 , K ) ; //<S2SV> else { //<S2SV> EMIT2 ( 0x69 , 0xc0 ) ; //<S2SV> EMIT ( K , 4 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_S_ALU_DIV_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x85 , 0xdb ) ; //<S2SV> if ( pc_ret0 != - 1 ) //<S2SV> EMIT_COND_JMP ( X86_JE , addrs [ pc_ret0 ] - ( addrs [ i ] - 4 ) ) ; //<S2SV> else { //<S2SV> EMIT_COND_JMP ( X86_JNE , 2 + 5 ) ; //<S2SV> CLEAR_A ( ) ; //<S2SV> EMIT1_off32 ( 0xe9 , cleanup_addr - ( addrs [ i ] - 4 ) ) ; //<S2SV> } //<S2SV> EMIT4 ( 0x31 , 0xd2 , 0xf7 , 0xf3 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_DIV_K : //<S2SV> EMIT3 ( 0x48 , 0x69 , 0xc0 ) ; //<S2SV> EMIT ( K , 4 ) ; //<S2SV> EMIT4 ( 0x48 , 0xc1 , 0xe8 , 0x20 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_AND_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x21 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_AND_K : //<S2SV> if ( K >= 0xFFFFFF00 ) { //<S2SV> EMIT2 ( 0x24 , K & 0xFF ) ; //<S2SV> } else if ( K >= 0xFFFF0000 ) { //<S2SV> EMIT2 ( 0x66 , 0x25 ) ; //<S2SV> EMIT2 ( K , 2 ) ; //<S2SV> } else { //<S2SV> EMIT1_off32 ( 0x25 , K ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_S_ALU_OR_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x09 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_OR_K : //<S2SV> if ( is_imm8 ( K ) ) //<S2SV> EMIT3 ( 0x83 , 0xc8 , K ) ; //<S2SV> else //<S2SV> EMIT1_off32 ( 0x0d , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_LSH_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT4 ( 0x89 , 0xd9 , 0xd3 , 0xe0 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_LSH_K : //<S2SV> if ( K == 0 ) //<S2SV> break ; //<S2SV> else if ( K == 1 ) //<S2SV> EMIT2 ( 0xd1 , 0xe0 ) ; //<S2SV> else //<S2SV> EMIT3 ( 0xc1 , 0xe0 , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_RSH_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT4 ( 0x89 , 0xd9 , 0xd3 , 0xe8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_RSH_K : //<S2SV> if ( K == 0 ) //<S2SV> break ; //<S2SV> else if ( K == 1 ) //<S2SV> EMIT2 ( 0xd1 , 0xe8 ) ; //<S2SV> else //<S2SV> EMIT3 ( 0xc1 , 0xe8 , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_ALU_NEG : //<S2SV> EMIT2 ( 0xf7 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_RET_K : //<S2SV> if ( ! K ) { //<S2SV> if ( pc_ret0 == - 1 ) //<S2SV> pc_ret0 = i ; //<S2SV> CLEAR_A ( ) ; //<S2SV> } else { //<S2SV> EMIT1_off32 ( 0xb8 , K ) ; //<S2SV> } //<S2SV> case BPF_S_RET_A : //<S2SV> if ( seen ) { //<S2SV> if ( i != flen - 1 ) { //<S2SV> EMIT_JMP ( cleanup_addr - addrs [ i ] ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( seen & SEEN_XREG ) //<S2SV> EMIT4 ( 0x48 , 0x8b , 0x5d , 0xf8 ) ; //<S2SV> EMIT1 ( 0xc9 ) ; //<S2SV> } //<S2SV> EMIT1 ( 0xc3 ) ; //<S2SV> break ; //<S2SV> case BPF_S_MISC_TAX : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x89 , 0xc3 ) ; //<S2SV> break ; //<S2SV> case BPF_S_MISC_TXA : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x89 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_LD_IMM : //<S2SV> if ( ! K ) //<S2SV> CLEAR_A ( ) ; //<S2SV> else //<S2SV> EMIT1_off32 ( 0xb8 , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_LDX_IMM : //<S2SV> seen |= SEEN_XREG ; //<S2SV> if ( ! K ) //<S2SV> CLEAR_X ( ) ; //<S2SV> else //<S2SV> EMIT1_off32 ( 0xbb , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_LD_MEM : //<S2SV> seen |= SEEN_MEM ; //<S2SV> EMIT3 ( 0x8b , 0x45 , 0xf0 - K * 4 ) ; //<S2SV> break ; //<S2SV> case BPF_S_LDX_MEM : //<S2SV> seen |= SEEN_XREG | SEEN_MEM ; //<S2SV> EMIT3 ( 0x8b , 0x5d , 0xf0 - K * 4 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ST : //<S2SV> seen |= SEEN_MEM ; //<S2SV> EMIT3 ( 0x89 , 0x45 , 0xf0 - K * 4 ) ; //<S2SV> break ; //<S2SV> case BPF_S_STX : //<S2SV> seen |= SEEN_XREG | SEEN_MEM ; //<S2SV> EMIT3 ( 0x89 , 0x5d , 0xf0 - K * 4 ) ; //<S2SV> break ; //<S2SV> case BPF_S_LD_W_LEN : //<S2SV> BUILD_BUG_ON ( FIELD_SIZEOF ( struct sk_buff , len ) != 4 ) ; //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , len ) ) ) //<S2SV> EMIT3 ( 0x8b , 0x47 , offsetof ( struct sk_buff , len ) ) ; //<S2SV> else { //<S2SV> EMIT2 ( 0x8b , 0x87 ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , len ) , 4 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_S_LDX_W_LEN : //<S2SV> seen |= SEEN_XREG ; //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , len ) ) ) //<S2SV> EMIT3 ( 0x8b , 0x5f , offsetof ( struct sk_buff , len ) ) ; //<S2SV> else { //<S2SV> EMIT2 ( 0x8b , 0x9f ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , len ) , 4 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_S_ANC_PROTOCOL : //<S2SV> BUILD_BUG_ON ( FIELD_SIZEOF ( struct sk_buff , protocol ) != 2 ) ; //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , protocol ) ) ) { //<S2SV> EMIT4 ( 0x0f , 0xb7 , 0x47 , offsetof ( struct sk_buff , protocol ) ) ; //<S2SV> } else { //<S2SV> EMIT3 ( 0x0f , 0xb7 , 0x87 ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , protocol ) , 4 ) ; //<S2SV> } //<S2SV> EMIT2 ( 0x86 , 0xc4 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ANC_IFINDEX : //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , dev ) ) ) { //<S2SV> EMIT4 ( 0x48 , 0x8b , 0x47 , offsetof ( struct sk_buff , dev ) ) ; //<S2SV> } else { //<S2SV> EMIT3 ( 0x48 , 0x8b , 0x87 ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , dev ) , 4 ) ; //<S2SV> } //<S2SV> EMIT3 ( 0x48 , 0x85 , 0xc0 ) ; //<S2SV> EMIT_COND_JMP ( X86_JE , cleanup_addr - ( addrs [ i ] - 6 ) ) ; //<S2SV> BUILD_BUG_ON ( FIELD_SIZEOF ( struct net_device , ifindex ) != 4 ) ; //<S2SV> EMIT2 ( 0x8b , 0x80 ) ; //<S2SV> EMIT ( offsetof ( struct net_device , ifindex ) , 4 ) ; //<S2SV> break ; //<S2SV> case BPF_S_ANC_MARK : //<S2SV> BUILD_BUG_ON ( FIELD_SIZEOF ( struct sk_buff , mark ) != 4 ) ; //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , mark ) ) ) { //<S2SV> EMIT3 ( 0x8b , 0x47 , offsetof ( struct sk_buff , mark ) ) ; //<S2SV> } else { //<S2SV> EMIT2 ( 0x8b , 0x87 ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , mark ) , 4 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_S_ANC_RXHASH : //<S2SV> BUILD_BUG_ON ( FIELD_SIZEOF ( struct sk_buff , rxhash ) != 4 ) ; //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , rxhash ) ) ) { //<S2SV> EMIT3 ( 0x8b , 0x47 , offsetof ( struct sk_buff , rxhash ) ) ; //<S2SV> } else { //<S2SV> EMIT2 ( 0x8b , 0x87 ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , rxhash ) , 4 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_S_ANC_QUEUE : //<S2SV> BUILD_BUG_ON ( FIELD_SIZEOF ( struct sk_buff , queue_mapping ) != 2 ) ; //<S2SV> if ( is_imm8 ( offsetof ( struct sk_buff , queue_mapping ) ) ) { //<S2SV> EMIT4 ( 0x0f , 0xb7 , 0x47 , offsetof ( struct sk_buff , queue_mapping ) ) ; //<S2SV> } else { //<S2SV> EMIT3 ( 0x0f , 0xb7 , 0x87 ) ; //<S2SV> EMIT ( offsetof ( struct sk_buff , queue_mapping ) , 4 ) ; //<S2SV> } //<S2SV> break ; //<S2SV> case BPF_S_ANC_CPU : //<S2SV> # ifdef CONFIG_SMP //<S2SV> EMIT4 ( 0x65 , 0x8b , 0x04 , 0x25 ) ; //<S2SV> EMIT ( ( u32 ) ( unsigned long ) & cpu_number , 4 ) ; //<S2SV> # else //<S2SV> CLEAR_A ( ) ; //<S2SV> # endif //<S2SV> break ; //<S2SV> case BPF_S_LD_W_ABS : //<S2SV> func = sk_load_word ; //<S2SV> common_load : seen |= SEEN_DATAREF ; //<S2SV> if ( ( int ) K < 0 ) //<S2SV> goto out ; //<S2SV> t_offset = func - ( image + addrs [ i ] ) ; //<S2SV> EMIT1_off32 ( 0xbe , K ) ; //<S2SV> EMIT1_off32 ( 0xe8 , t_offset ) ; //<S2SV> break ; //<S2SV> case BPF_S_LD_H_ABS : //<S2SV> func = sk_load_half ; //<S2SV> goto common_load ; //<S2SV> case BPF_S_LD_B_ABS : //<S2SV> func = sk_load_byte ; //<S2SV> goto common_load ; //<S2SV> case BPF_S_LDX_B_MSH : //<S2SV> if ( ( int ) K < 0 ) { //<S2SV> if ( pc_ret0 != - 1 ) { //<S2SV> EMIT_JMP ( addrs [ pc_ret0 ] - addrs [ i ] ) ; //<S2SV> break ; //<S2SV> } //<S2SV> CLEAR_A ( ) ; //<S2SV> EMIT_JMP ( cleanup_addr - addrs [ i ] ) ; //<S2SV> break ; //<S2SV> } //<S2SV> seen |= SEEN_DATAREF | SEEN_XREG ; //<S2SV> t_offset = sk_load_byte_msh - ( image + addrs [ i ] ) ; //<S2SV> EMIT1_off32 ( 0xbe , K ) ; //<S2SV> EMIT1_off32 ( 0xe8 , t_offset ) ; //<S2SV> break ; //<S2SV> case BPF_S_LD_W_IND : //<S2SV> func = sk_load_word_ind ; //<S2SV> common_load_ind : seen |= SEEN_DATAREF | SEEN_XREG ; //<S2SV> t_offset = func - ( image + addrs [ i ] ) ; //<S2SV> EMIT1_off32 ( 0xbe , K ) ; //<S2SV> EMIT1_off32 ( 0xe8 , t_offset ) ; //<S2SV> break ; //<S2SV> case BPF_S_LD_H_IND : //<S2SV> func = sk_load_half_ind ; //<S2SV> goto common_load_ind ; //<S2SV> case BPF_S_LD_B_IND : //<S2SV> func = sk_load_byte_ind ; //<S2SV> goto common_load_ind ; //<S2SV> case BPF_S_JMP_JA : //<S2SV> t_offset = addrs [ i + K ] - addrs [ i ] ; //<S2SV> EMIT_JMP ( t_offset ) ; //<S2SV> break ; //<S2SV> COND_SEL ( BPF_S_JMP_JGT_K , X86_JA , X86_JBE ) ; //<S2SV> COND_SEL ( BPF_S_JMP_JGE_K , X86_JAE , X86_JB ) ; //<S2SV> COND_SEL ( BPF_S_JMP_JEQ_K , X86_JE , X86_JNE ) ; //<S2SV> COND_SEL ( BPF_S_JMP_JSET_K , X86_JNE , X86_JE ) ; //<S2SV> COND_SEL ( BPF_S_JMP_JGT_X , X86_JA , X86_JBE ) ; //<S2SV> COND_SEL ( BPF_S_JMP_JGE_X , X86_JAE , X86_JB ) ; //<S2SV> COND_SEL ( BPF_S_JMP_JEQ_X , X86_JE , X86_JNE ) ; //<S2SV> COND_SEL ( BPF_S_JMP_JSET_X , X86_JNE , X86_JE ) ; //<S2SV> cond_branch : f_offset = addrs [ i + filter [ i ] . jf ] - addrs [ i ] ; //<S2SV> t_offset = addrs [ i + filter [ i ] . jt ] - addrs [ i ] ; //<S2SV> if ( filter [ i ] . jt == filter [ i ] . jf ) { //<S2SV> EMIT_JMP ( t_offset ) ; //<S2SV> break ; //<S2SV> } //<S2SV> switch ( filter [ i ] . code ) { //<S2SV> case BPF_S_JMP_JGT_X : //<S2SV> case BPF_S_JMP_JGE_X : //<S2SV> case BPF_S_JMP_JEQ_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x39 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_JMP_JSET_X : //<S2SV> seen |= SEEN_XREG ; //<S2SV> EMIT2 ( 0x85 , 0xd8 ) ; //<S2SV> break ; //<S2SV> case BPF_S_JMP_JEQ_K : //<S2SV> if ( K == 0 ) { //<S2SV> EMIT2 ( 0x85 , 0xc0 ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case BPF_S_JMP_JGT_K : //<S2SV> case BPF_S_JMP_JGE_K : //<S2SV> if ( K <= 127 ) //<S2SV> EMIT3 ( 0x83 , 0xf8 , K ) ; //<S2SV> else //<S2SV> EMIT1_off32 ( 0x3d , K ) ; //<S2SV> break ; //<S2SV> case BPF_S_JMP_JSET_K : //<S2SV> if ( K <= 0xFF ) //<S2SV> EMIT2 ( 0xa8 , K ) ; //<S2SV> else if ( ! ( K & 0xFFFF00FF ) ) //<S2SV> EMIT3 ( 0xf6 , 0xc4 , K >> 8 ) ; //<S2SV> else if ( K <= 0xFFFF ) { //<S2SV> EMIT2 ( 0x66 , 0xa9 ) ; //<S2SV> EMIT ( K , 2 ) ; //<S2SV> } else { //<S2SV> EMIT1_off32 ( 0xa9 , K ) ; //<S2SV> } //<S2SV> break ; //<S2SV> } //<S2SV> if ( filter [ i ] . jt != 0 ) { //<S2SV> if ( filter [ i ] . jf ) //<S2SV> t_offset += is_near ( f_offset ) ? 2 : 6 ; //<S2SV> EMIT_COND_JMP ( t_op , t_offset ) ; //<S2SV> if ( filter [ i ] . jf ) //<S2SV> EMIT_JMP ( f_offset ) ; //<S2SV> break ; //<S2SV> } //<S2SV> EMIT_COND_JMP ( f_op , f_offset ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto out ; //<S2SV> } //<S2SV> ilen = prog - temp ; //<S2SV> if ( image ) { //<S2SV> if ( unlikely ( proglen + ilen > oldproglen ) ) { //<S2SV> pr_err ( "bpb_jit_compile<S2SV_blank>fatal<S2SV_blank>error\\n" ) ; //<S2SV> kfree ( addrs ) ; //<S2SV> module_free ( NULL , image ) ; //<S2SV> return ; //<S2SV> } //<S2SV> memcpy ( image + proglen , temp , ilen ) ; //<S2SV> } //<S2SV> proglen += ilen ; //<S2SV> addrs [ i ] = proglen ; //<S2SV> prog = temp ; //<S2SV> } //<S2SV> cleanup_addr = proglen - 1 ; //<S2SV> if ( seen ) //<S2SV> cleanup_addr -= 1 ; //<S2SV> if ( seen & SEEN_XREG ) //<S2SV> cleanup_addr -= 4 ; //<S2SV> if ( image ) { //<S2SV> WARN_ON ( proglen != oldproglen ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( proglen == oldproglen ) { //<S2SV> image = module_alloc ( max_t ( unsigned int , //<S2SV> proglen , //<S2SV> sizeof ( struct work_struct ) ) ) ; //<S2SV> if ( ! image ) //<S2SV> goto out ; //<S2SV> } //<S2SV> oldproglen = proglen ; //<S2SV> } //<S2SV> if ( bpf_jit_enable > 1 ) //<S2SV> pr_err ( "flen=%d<S2SV_blank>proglen=%u<S2SV_blank>pass=%d<S2SV_blank>image=%p\\n" , //<S2SV> flen , proglen , pass , image ) ; //<S2SV> if ( image ) { //<S2SV> if ( bpf_jit_enable > 1 ) //<S2SV> print_hex_dump ( KERN_ERR , "JIT<S2SV_blank>code:<S2SV_blank>" , DUMP_PREFIX_ADDRESS , //<S2SV> 16 , 1 , image , proglen , false ) ; //<S2SV> bpf_flush_icache ( image , image + proglen ) ; //<S2SV> fp -> bpf_func = ( void * ) image ; //<S2SV> } //<S2SV> out : //<S2SV> kfree ( addrs ) ; //<S2SV> return ; //<S2SV> } //<S2SV> 