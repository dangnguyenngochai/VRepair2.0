int x86_decode_insn ( struct x86_emulate_ctxt * ctxt , void * insn , int insn_len ) //<S2SV> { //<S2SV> int rc = X86EMUL_CONTINUE ; //<S2SV> int mode = ctxt -> mode ; //<S2SV> int def_op_bytes , def_ad_bytes , goffset , simd_prefix ; //<S2SV> bool op_prefix = false ; //<S2SV> bool has_seg_override = false ; //<S2SV> struct opcode opcode ; //<S2SV> ctxt -> memop . type = OP_NONE ; //<S2SV> ctxt -> memopp = NULL ; //<S2SV> ctxt -> _eip = ctxt -> eip ; //<S2SV> ctxt -> fetch . ptr = ctxt -> fetch . data ; //<S2SV> ctxt -> fetch . end = ctxt -> fetch . data + insn_len ; //<S2SV> ctxt -> opcode_len = 1 ; //<S2SV> if ( insn_len > 0 ) //<S2SV> memcpy ( ctxt -> fetch . data , insn , insn_len ) ; //<S2SV> else { //<S2SV> rc = __do_insn_fetch_bytes ( ctxt , 1 ) ; //<S2SV> if ( rc != X86EMUL_CONTINUE ) //<S2SV> return rc ; //<S2SV> } //<S2SV> switch ( mode ) { //<S2SV> case X86EMUL_MODE_REAL : //<S2SV> case X86EMUL_MODE_VM86 : //<S2SV> case X86EMUL_MODE_PROT16 : //<S2SV> def_op_bytes = def_ad_bytes = 2 ; //<S2SV> break ; //<S2SV> case X86EMUL_MODE_PROT32 : //<S2SV> def_op_bytes = def_ad_bytes = 4 ; //<S2SV> break ; //<S2SV> # ifdef CONFIG_X86_64 //<S2SV> case X86EMUL_MODE_PROT64 : //<S2SV> def_op_bytes = 4 ; //<S2SV> def_ad_bytes = 8 ; //<S2SV> break ; //<S2SV> # endif //<S2SV> default : //<S2SV> return EMULATION_FAILED ; //<S2SV> } //<S2SV> ctxt -> op_bytes = def_op_bytes ; //<S2SV> ctxt -> ad_bytes = def_ad_bytes ; //<S2SV> for ( ; ; ) { //<S2SV> switch ( ctxt -> b = insn_fetch ( u8 , ctxt ) ) { //<S2SV> case 0x66 : //<S2SV> op_prefix = true ; //<S2SV> ctxt -> op_bytes = def_op_bytes ^ 6 ; //<S2SV> break ; //<S2SV> case 0x67 : //<S2SV> if ( mode == X86EMUL_MODE_PROT64 ) //<S2SV> ctxt -> ad_bytes = def_ad_bytes ^ 12 ; //<S2SV> else //<S2SV> ctxt -> ad_bytes = def_ad_bytes ^ 6 ; //<S2SV> break ; //<S2SV> case 0x26 : //<S2SV> case 0x2e : //<S2SV> case 0x36 : //<S2SV> case 0x3e : //<S2SV> has_seg_override = true ; //<S2SV> ctxt -> seg_override = ( ctxt -> b >> 3 ) & 3 ; //<S2SV> break ; //<S2SV> case 0x64 : //<S2SV> case 0x65 : //<S2SV> has_seg_override = true ; //<S2SV> ctxt -> seg_override = ctxt -> b & 7 ; //<S2SV> break ; //<S2SV> case 0x40 ... 0x4f : //<S2SV> if ( mode != X86EMUL_MODE_PROT64 ) //<S2SV> goto done_prefixes ; //<S2SV> ctxt -> rex_prefix = ctxt -> b ; //<S2SV> continue ; //<S2SV> case 0xf0 : //<S2SV> ctxt -> lock_prefix = 1 ; //<S2SV> break ; //<S2SV> case 0xf2 : //<S2SV> case 0xf3 : //<S2SV> ctxt -> rep_prefix = ctxt -> b ; //<S2SV> break ; //<S2SV> default : //<S2SV> goto done_prefixes ; //<S2SV> } //<S2SV> ctxt -> rex_prefix = 0 ; //<S2SV> } //<S2SV> done_prefixes : //<S2SV> if ( ctxt -> rex_prefix & 8 ) //<S2SV> ctxt -> op_bytes = 8 ; //<S2SV> opcode = opcode_table [ ctxt -> b ] ; //<S2SV> if ( ctxt -> b == 0x0f ) { //<S2SV> ctxt -> opcode_len = 2 ; //<S2SV> ctxt -> b = insn_fetch ( u8 , ctxt ) ; //<S2SV> opcode = twobyte_table [ ctxt -> b ] ; //<S2SV> if ( ctxt -> b == 0x38 ) { //<S2SV> ctxt -> opcode_len = 3 ; //<S2SV> ctxt -> b = insn_fetch ( u8 , ctxt ) ; //<S2SV> opcode = opcode_map_0f_38 [ ctxt -> b ] ; //<S2SV> } //<S2SV> } //<S2SV> ctxt -> d = opcode . flags ; //<S2SV> if ( ctxt -> d & ModRM ) //<S2SV> ctxt -> modrm = insn_fetch ( u8 , ctxt ) ; //<S2SV> if ( ctxt -> opcode_len == 1 && ( ctxt -> b == 0xc5 || ctxt -> b == 0xc4 ) && //<S2SV> ( mode == X86EMUL_MODE_PROT64 || //<S2SV> ( mode >= X86EMUL_MODE_PROT16 && ( ctxt -> modrm & 0x80 ) ) ) ) { //<S2SV> ctxt -> d = NotImpl ; //<S2SV> } //<S2SV> while ( ctxt -> d & GroupMask ) { //<S2SV> switch ( ctxt -> d & GroupMask ) { //<S2SV> case Group : //<S2SV> goffset = ( ctxt -> modrm >> 3 ) & 7 ; //<S2SV> opcode = opcode . u . group [ goffset ] ; //<S2SV> break ; //<S2SV> case GroupDual : //<S2SV> goffset = ( ctxt -> modrm >> 3 ) & 7 ; //<S2SV> if ( ( ctxt -> modrm >> 6 ) == 3 ) //<S2SV> opcode = opcode . u . gdual -> mod3 [ goffset ] ; //<S2SV> else //<S2SV> opcode = opcode . u . gdual -> mod012 [ goffset ] ; //<S2SV> break ; //<S2SV> case RMExt : //<S2SV> goffset = ctxt -> modrm & 7 ; //<S2SV> opcode = opcode . u . group [ goffset ] ; //<S2SV> break ; //<S2SV> case Prefix : //<S2SV> if ( ctxt -> rep_prefix && op_prefix ) //<S2SV> return EMULATION_FAILED ; //<S2SV> simd_prefix = op_prefix ? 0x66 : ctxt -> rep_prefix ; //<S2SV> switch ( simd_prefix ) { //<S2SV> case 0x00 : opcode = opcode . u . gprefix -> pfx_no ; break ; //<S2SV> case 0x66 : opcode = opcode . u . gprefix -> pfx_66 ; break ; //<S2SV> case 0xf2 : opcode = opcode . u . gprefix -> pfx_f2 ; break ; //<S2SV> case 0xf3 : opcode = opcode . u . gprefix -> pfx_f3 ; break ; //<S2SV> } //<S2SV> break ; //<S2SV> case Escape : //<S2SV> if ( ctxt -> modrm > 0xbf ) //<S2SV> opcode = opcode . u . esc -> high [ ctxt -> modrm - 0xc0 ] ; //<S2SV> else //<S2SV> opcode = opcode . u . esc -> op [ ( ctxt -> modrm >> 3 ) & 7 ] ; //<S2SV> break ; //<S2SV> default : //<S2SV> return EMULATION_FAILED ; //<S2SV> } //<S2SV> ctxt -> d &= ~ ( u64 ) GroupMask ; //<S2SV> ctxt -> d |= opcode . flags ; //<S2SV> } //<S2SV> if ( ctxt -> d == 0 ) //<S2SV> return EMULATION_FAILED ; //<S2SV> ctxt -> execute = opcode . u . execute ; //<S2SV> if ( unlikely ( ctxt -> ud ) && likely ( ! ( ctxt -> d & EmulateOnUD ) ) ) //<S2SV> return EMULATION_FAILED ; //<S2SV> if ( unlikely ( ctxt -> d & //<S2SV> ( NotImpl | Stack | Op3264 | Sse | Mmx | Intercept | CheckPerm ) ) ) { //<S2SV> ctxt -> check_perm = opcode . check_perm ; //<S2SV> ctxt -> intercept = opcode . intercept ; //<S2SV> if ( ctxt -> d & NotImpl ) //<S2SV> return EMULATION_FAILED ; //<S2SV> if ( mode == X86EMUL_MODE_PROT64 && ( ctxt -> d & Stack ) ) //<S2SV> ctxt -> op_bytes = 8 ; //<S2SV> if ( ctxt -> d & Op3264 ) { //<S2SV> if ( mode == X86EMUL_MODE_PROT64 ) //<S2SV> ctxt -> op_bytes = 8 ; //<S2SV> else //<S2SV> ctxt -> op_bytes = 4 ; //<S2SV> } //<S2SV> if ( ctxt -> d & Sse ) //<S2SV> ctxt -> op_bytes = 16 ; //<S2SV> else if ( ctxt -> d & Mmx ) //<S2SV> ctxt -> op_bytes = 8 ; //<S2SV> } //<S2SV> if ( ctxt -> d & ModRM ) { //<S2SV> rc = decode_modrm ( ctxt , & ctxt -> memop ) ; //<S2SV> if ( ! has_seg_override ) { //<S2SV> has_seg_override = true ; //<S2SV> ctxt -> seg_override = ctxt -> modrm_seg ; //<S2SV> } //<S2SV> } else if ( ctxt -> d & MemAbs ) //<S2SV> rc = decode_abs ( ctxt , & ctxt -> memop ) ; //<S2SV> if ( rc != X86EMUL_CONTINUE ) //<S2SV> goto done ; //<S2SV> if ( ! has_seg_override ) //<S2SV> ctxt -> seg_override = VCPU_SREG_DS ; //<S2SV> ctxt -> memop . addr . mem . seg = ctxt -> seg_override ; //<S2SV> rc = decode_operand ( ctxt , & ctxt -> src , ( ctxt -> d >> SrcShift ) & OpMask ) ; //<S2SV> if ( rc != X86EMUL_CONTINUE ) //<S2SV> goto done ; //<S2SV> rc = decode_operand ( ctxt , & ctxt -> src2 , ( ctxt -> d >> Src2Shift ) & OpMask ) ; //<S2SV> if ( rc != X86EMUL_CONTINUE ) //<S2SV> goto done ; //<S2SV> rc = decode_operand ( ctxt , & ctxt -> dst , ( ctxt -> d >> DstShift ) & OpMask ) ; //<S2SV> done : //<S2SV> if ( ctxt -> rip_relative ) //<S2SV> ctxt -> memopp -> addr . mem . ea += ctxt -> _eip ; //<S2SV> return ( rc != X86EMUL_CONTINUE ) ? EMULATION_FAILED : EMULATION_OK ; //<S2SV> } //<S2SV> 