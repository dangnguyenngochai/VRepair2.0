static void //<S2SV> ext4_xattr_release_block ( handle_t * handle , struct inode * inode , //<S2SV> struct buffer_head * bh ) //<S2SV> { //<S2SV> int error = 0 ; //<S2SV> BUFFER_TRACE ( bh , "get_write_access" ) ; //<S2SV> error = ext4_journal_get_write_access ( handle , bh ) ; //<S2SV> if ( error ) //<S2SV> goto out ; //<S2SV> lock_buffer ( bh ) ; //<S2SV> if ( BHDR ( bh ) -> h_refcount == cpu_to_le32 ( 1 ) ) { //<S2SV> __u32 hash = le32_to_cpu ( BHDR ( bh ) -> h_hash ) ; //<S2SV> ea_bdebug ( bh , "refcount<S2SV_blank>now=0;<S2SV_blank>freeing" ) ; //<S2SV> mb2_cache_entry_delete_block ( EXT4_GET_MB_CACHE ( inode ) , hash , //<S2SV> bh -> b_blocknr ) ; //<S2SV> get_bh ( bh ) ; //<S2SV> unlock_buffer ( bh ) ; //<S2SV> ext4_free_blocks ( handle , inode , bh , 0 , 1 , //<S2SV> EXT4_FREE_BLOCKS_METADATA | //<S2SV> EXT4_FREE_BLOCKS_FORGET ) ; //<S2SV> } else { //<S2SV> le32_add_cpu ( & BHDR ( bh ) -> h_refcount , - 1 ) ; //<S2SV> if ( ext4_handle_valid ( handle ) ) //<S2SV> error = ext4_handle_dirty_xattr_block ( handle , inode , //<S2SV> bh ) ; //<S2SV> unlock_buffer ( bh ) ; //<S2SV> if ( ! ext4_handle_valid ( handle ) ) //<S2SV> error = ext4_handle_dirty_xattr_block ( handle , inode , //<S2SV> bh ) ; //<S2SV> if ( IS_SYNC ( inode ) ) //<S2SV> ext4_handle_sync ( handle ) ; //<S2SV> dquot_free_block ( inode , EXT4_C2B ( EXT4_SB ( inode -> i_sb ) , 1 ) ) ; //<S2SV> ea_bdebug ( bh , "refcount<S2SV_blank>now=%d;<S2SV_blank>releasing" , //<S2SV> le32_to_cpu ( BHDR ( bh ) -> h_refcount ) ) ; //<S2SV> } //<S2SV> out : //<S2SV> ext4_std_error ( inode -> i_sb , error ) ; //<S2SV> return ; //<S2SV> } //<S2SV> 