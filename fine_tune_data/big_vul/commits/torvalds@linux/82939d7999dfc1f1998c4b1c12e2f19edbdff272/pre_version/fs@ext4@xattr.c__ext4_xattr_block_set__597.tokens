static int //<S2SV> ext4_xattr_block_set ( handle_t * handle , struct inode * inode , //<S2SV> struct ext4_xattr_info * i , //<S2SV> struct ext4_xattr_block_find * bs ) //<S2SV> { //<S2SV> struct super_block * sb = inode -> i_sb ; //<S2SV> struct buffer_head * new_bh = NULL ; //<S2SV> struct ext4_xattr_search * s = & bs -> s ; //<S2SV> struct mb_cache_entry * ce = NULL ; //<S2SV> int error = 0 ; //<S2SV> struct mb_cache * ext4_mb_cache = EXT4_GET_MB_CACHE ( inode ) ; //<S2SV> # define header ( x ) ( ( struct ext4_xattr_header * ) ( x ) ) //<S2SV> if ( i -> value && i -> value_len > sb -> s_blocksize ) //<S2SV> return - ENOSPC ; //<S2SV> if ( s -> base ) { //<S2SV> ce = mb_cache_entry_get ( ext4_mb_cache , bs -> bh -> b_bdev , //<S2SV> bs -> bh -> b_blocknr ) ; //<S2SV> BUFFER_TRACE ( bs -> bh , "get_write_access" ) ; //<S2SV> error = ext4_journal_get_write_access ( handle , bs -> bh ) ; //<S2SV> if ( error ) //<S2SV> goto cleanup ; //<S2SV> lock_buffer ( bs -> bh ) ; //<S2SV> if ( header ( s -> base ) -> h_refcount == cpu_to_le32 ( 1 ) ) { //<S2SV> if ( ce ) { //<S2SV> mb_cache_entry_free ( ce ) ; //<S2SV> ce = NULL ; //<S2SV> } //<S2SV> ea_bdebug ( bs -> bh , "modifying<S2SV_blank>in-place" ) ; //<S2SV> error = ext4_xattr_set_entry ( i , s ) ; //<S2SV> if ( ! error ) { //<S2SV> if ( ! IS_LAST_ENTRY ( s -> first ) ) //<S2SV> ext4_xattr_rehash ( header ( s -> base ) , //<S2SV> s -> here ) ; //<S2SV> ext4_xattr_cache_insert ( ext4_mb_cache , //<S2SV> bs -> bh ) ; //<S2SV> } //<S2SV> unlock_buffer ( bs -> bh ) ; //<S2SV> if ( error == - EFSCORRUPTED ) //<S2SV> goto bad_block ; //<S2SV> if ( ! error ) //<S2SV> error = ext4_handle_dirty_xattr_block ( handle , //<S2SV> inode , //<S2SV> bs -> bh ) ; //<S2SV> if ( error ) //<S2SV> goto cleanup ; //<S2SV> goto inserted ; //<S2SV> } else { //<S2SV> int offset = ( char * ) s -> here - bs -> bh -> b_data ; //<S2SV> unlock_buffer ( bs -> bh ) ; //<S2SV> if ( ce ) { //<S2SV> mb_cache_entry_release ( ce ) ; //<S2SV> ce = NULL ; //<S2SV> } //<S2SV> ea_bdebug ( bs -> bh , "cloning" ) ; //<S2SV> s -> base = kmalloc ( bs -> bh -> b_size , GFP_NOFS ) ; //<S2SV> error = - ENOMEM ; //<S2SV> if ( s -> base == NULL ) //<S2SV> goto cleanup ; //<S2SV> memcpy ( s -> base , BHDR ( bs -> bh ) , bs -> bh -> b_size ) ; //<S2SV> s -> first = ENTRY ( header ( s -> base ) + 1 ) ; //<S2SV> header ( s -> base ) -> h_refcount = cpu_to_le32 ( 1 ) ; //<S2SV> s -> here = ENTRY ( s -> base + offset ) ; //<S2SV> s -> end = s -> base + bs -> bh -> b_size ; //<S2SV> } //<S2SV> } else { //<S2SV> s -> base = kzalloc ( sb -> s_blocksize , GFP_NOFS ) ; //<S2SV> error = - ENOMEM ; //<S2SV> if ( s -> base == NULL ) //<S2SV> goto cleanup ; //<S2SV> header ( s -> base ) -> h_magic = cpu_to_le32 ( EXT4_XATTR_MAGIC ) ; //<S2SV> header ( s -> base ) -> h_blocks = cpu_to_le32 ( 1 ) ; //<S2SV> header ( s -> base ) -> h_refcount = cpu_to_le32 ( 1 ) ; //<S2SV> s -> first = ENTRY ( header ( s -> base ) + 1 ) ; //<S2SV> s -> here = ENTRY ( header ( s -> base ) + 1 ) ; //<S2SV> s -> end = s -> base + sb -> s_blocksize ; //<S2SV> } //<S2SV> error = ext4_xattr_set_entry ( i , s ) ; //<S2SV> if ( error == - EFSCORRUPTED ) //<S2SV> goto bad_block ; //<S2SV> if ( error ) //<S2SV> goto cleanup ; //<S2SV> if ( ! IS_LAST_ENTRY ( s -> first ) ) //<S2SV> ext4_xattr_rehash ( header ( s -> base ) , s -> here ) ; //<S2SV> inserted : //<S2SV> if ( ! IS_LAST_ENTRY ( s -> first ) ) { //<S2SV> new_bh = ext4_xattr_cache_find ( inode , header ( s -> base ) , & ce ) ; //<S2SV> if ( new_bh ) { //<S2SV> if ( new_bh == bs -> bh ) //<S2SV> ea_bdebug ( new_bh , "keeping" ) ; //<S2SV> else { //<S2SV> error = dquot_alloc_block ( inode , //<S2SV> EXT4_C2B ( EXT4_SB ( sb ) , 1 ) ) ; //<S2SV> if ( error ) //<S2SV> goto cleanup ; //<S2SV> BUFFER_TRACE ( new_bh , "get_write_access" ) ; //<S2SV> error = ext4_journal_get_write_access ( handle , //<S2SV> new_bh ) ; //<S2SV> if ( error ) //<S2SV> goto cleanup_dquot ; //<S2SV> lock_buffer ( new_bh ) ; //<S2SV> le32_add_cpu ( & BHDR ( new_bh ) -> h_refcount , 1 ) ; //<S2SV> ea_bdebug ( new_bh , "reusing;<S2SV_blank>refcount<S2SV_blank>now=%d" , //<S2SV> le32_to_cpu ( BHDR ( new_bh ) -> h_refcount ) ) ; //<S2SV> unlock_buffer ( new_bh ) ; //<S2SV> error = ext4_handle_dirty_xattr_block ( handle , //<S2SV> inode , //<S2SV> new_bh ) ; //<S2SV> if ( error ) //<S2SV> goto cleanup_dquot ; //<S2SV> } //<S2SV> mb_cache_entry_release ( ce ) ; //<S2SV> ce = NULL ; //<S2SV> } else if ( bs -> bh && s -> base == bs -> bh -> b_data ) { //<S2SV> ea_bdebug ( bs -> bh , "keeping<S2SV_blank>this<S2SV_blank>block" ) ; //<S2SV> new_bh = bs -> bh ; //<S2SV> get_bh ( new_bh ) ; //<S2SV> } else { //<S2SV> ext4_fsblk_t goal , block ; //<S2SV> goal = ext4_group_first_block_no ( sb , //<S2SV> EXT4_I ( inode ) -> i_block_group ) ; //<S2SV> if ( ! ( ext4_test_inode_flag ( inode , EXT4_INODE_EXTENTS ) ) ) //<S2SV> goal = goal & EXT4_MAX_BLOCK_FILE_PHYS ; //<S2SV> block = ext4_new_meta_blocks ( handle , inode , goal , 0 , //<S2SV> NULL , & error ) ; //<S2SV> if ( error ) //<S2SV> goto cleanup ; //<S2SV> if ( ! ( ext4_test_inode_flag ( inode , EXT4_INODE_EXTENTS ) ) ) //<S2SV> BUG_ON ( block > EXT4_MAX_BLOCK_FILE_PHYS ) ; //<S2SV> ea_idebug ( inode , "creating<S2SV_blank>block<S2SV_blank>%llu" , //<S2SV> ( unsigned long long ) block ) ; //<S2SV> new_bh = sb_getblk ( sb , block ) ; //<S2SV> if ( unlikely ( ! new_bh ) ) { //<S2SV> error = - ENOMEM ; //<S2SV> getblk_failed : //<S2SV> ext4_free_blocks ( handle , inode , NULL , block , 1 , //<S2SV> EXT4_FREE_BLOCKS_METADATA ) ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> lock_buffer ( new_bh ) ; //<S2SV> error = ext4_journal_get_create_access ( handle , new_bh ) ; //<S2SV> if ( error ) { //<S2SV> unlock_buffer ( new_bh ) ; //<S2SV> error = - EIO ; //<S2SV> goto getblk_failed ; //<S2SV> } //<S2SV> memcpy ( new_bh -> b_data , s -> base , new_bh -> b_size ) ; //<S2SV> set_buffer_uptodate ( new_bh ) ; //<S2SV> unlock_buffer ( new_bh ) ; //<S2SV> ext4_xattr_cache_insert ( ext4_mb_cache , new_bh ) ; //<S2SV> error = ext4_handle_dirty_xattr_block ( handle , //<S2SV> inode , new_bh ) ; //<S2SV> if ( error ) //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> } //<S2SV> EXT4_I ( inode ) -> i_file_acl = new_bh ? new_bh -> b_blocknr : 0 ; //<S2SV> if ( bs -> bh && bs -> bh != new_bh ) //<S2SV> ext4_xattr_release_block ( handle , inode , bs -> bh ) ; //<S2SV> error = 0 ; //<S2SV> cleanup : //<S2SV> if ( ce ) //<S2SV> mb_cache_entry_release ( ce ) ; //<S2SV> brelse ( new_bh ) ; //<S2SV> if ( ! ( bs -> bh && s -> base == bs -> bh -> b_data ) ) //<S2SV> kfree ( s -> base ) ; //<S2SV> return error ; //<S2SV> cleanup_dquot : //<S2SV> dquot_free_block ( inode , EXT4_C2B ( EXT4_SB ( sb ) , 1 ) ) ; //<S2SV> goto cleanup ; //<S2SV> bad_block : //<S2SV> EXT4_ERROR_INODE ( inode , "bad<S2SV_blank>block<S2SV_blank>%llu" , //<S2SV> EXT4_I ( inode ) -> i_file_acl ) ; //<S2SV> goto cleanup ; //<S2SV> # undef header //<S2SV> } //<S2SV> 