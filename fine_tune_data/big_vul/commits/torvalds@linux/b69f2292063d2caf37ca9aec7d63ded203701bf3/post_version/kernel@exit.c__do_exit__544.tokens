NORET_TYPE void do_exit ( long code ) //<S2SV> { //<S2SV> struct task_struct * tsk = current ; //<S2SV> int group_dead ; //<S2SV> profile_task_exit ( tsk ) ; //<S2SV> WARN_ON ( atomic_read ( & tsk -> fs_excl ) ) ; //<S2SV> if ( unlikely ( in_interrupt ( ) ) ) //<S2SV> panic ( "Aiee,<S2SV_blank>killing<S2SV_blank>interrupt<S2SV_blank>handler!" ) ; //<S2SV> if ( unlikely ( ! tsk -> pid ) ) //<S2SV> panic ( "Attempted<S2SV_blank>to<S2SV_blank>kill<S2SV_blank>the<S2SV_blank>idle<S2SV_blank>task!" ) ; //<S2SV> tracehook_report_exit ( & code ) ; //<S2SV> validate_creds_for_do_exit ( tsk ) ; //<S2SV> if ( unlikely ( tsk -> flags & PF_EXITING ) ) { //<S2SV> printk ( KERN_ALERT //<S2SV> "Fixing<S2SV_blank>recursive<S2SV_blank>fault<S2SV_blank>but<S2SV_blank>reboot<S2SV_blank>is<S2SV_blank>needed!\\n" ) ; //<S2SV> tsk -> flags |= PF_EXITPIDONE ; //<S2SV> set_current_state ( TASK_UNINTERRUPTIBLE ) ; //<S2SV> schedule ( ) ; //<S2SV> } //<S2SV> exit_irq_thread ( ) ; //<S2SV> exit_signals ( tsk ) ; //<S2SV> smp_mb ( ) ; //<S2SV> spin_unlock_wait ( & tsk -> pi_lock ) ; //<S2SV> if ( unlikely ( in_atomic ( ) ) ) //<S2SV> printk ( KERN_INFO "note:<S2SV_blank>%s[%d]<S2SV_blank>exited<S2SV_blank>with<S2SV_blank>preempt_count<S2SV_blank>%d\\n" , //<S2SV> current -> comm , task_pid_nr ( current ) , //<S2SV> preempt_count ( ) ) ; //<S2SV> acct_update_integrals ( tsk ) ; //<S2SV> group_dead = atomic_dec_and_test ( & tsk -> signal -> live ) ; //<S2SV> if ( group_dead ) { //<S2SV> hrtimer_cancel ( & tsk -> signal -> real_timer ) ; //<S2SV> exit_itimers ( tsk -> signal ) ; //<S2SV> if ( tsk -> mm ) //<S2SV> setmax_mm_hiwater_rss ( & tsk -> signal -> maxrss , tsk -> mm ) ; //<S2SV> } //<S2SV> acct_collect ( code , group_dead ) ; //<S2SV> if ( group_dead ) //<S2SV> tty_audit_exit ( ) ; //<S2SV> if ( unlikely ( tsk -> audit_context ) ) //<S2SV> audit_free ( tsk ) ; //<S2SV> tsk -> exit_code = code ; //<S2SV> taskstats_exit ( tsk , group_dead ) ; //<S2SV> exit_mm ( tsk ) ; //<S2SV> if ( group_dead ) //<S2SV> acct_process ( ) ; //<S2SV> trace_sched_process_exit ( tsk ) ; //<S2SV> exit_sem ( tsk ) ; //<S2SV> exit_files ( tsk ) ; //<S2SV> exit_fs ( tsk ) ; //<S2SV> check_stack_usage ( ) ; //<S2SV> exit_thread ( ) ; //<S2SV> cgroup_exit ( tsk , 1 ) ; //<S2SV> if ( group_dead && tsk -> signal -> leader ) //<S2SV> disassociate_ctty ( 1 ) ; //<S2SV> module_put ( task_thread_info ( tsk ) -> exec_domain -> module ) ; //<S2SV> proc_exit_connector ( tsk ) ; //<S2SV> perf_event_exit_task ( tsk ) ; //<S2SV> exit_notify ( tsk , group_dead ) ; //<S2SV> # ifdef CONFIG_NUMA //<S2SV> mpol_put ( tsk -> mempolicy ) ; //<S2SV> tsk -> mempolicy = NULL ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_FUTEX //<S2SV> if ( unlikely ( current -> pi_state_cache ) ) //<S2SV> kfree ( current -> pi_state_cache ) ; //<S2SV> # endif //<S2SV> debug_check_no_locks_held ( tsk ) ; //<S2SV> tsk -> flags |= PF_EXITPIDONE ; //<S2SV> if ( tsk -> io_context ) //<S2SV> exit_io_context ( tsk ) ; //<S2SV> if ( tsk -> splice_pipe ) //<S2SV> __free_pipe_info ( tsk -> splice_pipe ) ; //<S2SV> validate_creds_for_do_exit ( tsk ) ; //<S2SV> preempt_disable ( ) ; //<S2SV> exit_rcu ( ) ; //<S2SV> tsk -> state = TASK_DEAD ; //<S2SV> schedule ( ) ; //<S2SV> BUG ( ) ; //<S2SV> for ( ; ; ) //<S2SV> cpu_relax ( ) ; //<S2SV> } //<S2SV> 