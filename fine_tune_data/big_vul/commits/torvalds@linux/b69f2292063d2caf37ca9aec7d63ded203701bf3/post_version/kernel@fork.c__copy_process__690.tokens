static struct task_struct * copy_process ( unsigned long clone_flags , //<S2SV> unsigned long stack_start , //<S2SV> struct pt_regs * regs , //<S2SV> unsigned long stack_size , //<S2SV> int __user * child_tidptr , //<S2SV> struct pid * pid , //<S2SV> int trace ) //<S2SV> { //<S2SV> int retval ; //<S2SV> struct task_struct * p ; //<S2SV> int cgroup_callbacks_done = 0 ; //<S2SV> if ( ( clone_flags & ( CLONE_NEWNS | CLONE_FS ) ) == ( CLONE_NEWNS | CLONE_FS ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & CLONE_THREAD ) && ! ( clone_flags & CLONE_SIGHAND ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & CLONE_SIGHAND ) && ! ( clone_flags & CLONE_VM ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & CLONE_PARENT ) && //<S2SV> current -> signal -> flags & SIGNAL_UNKILLABLE ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> retval = security_task_create ( clone_flags ) ; //<S2SV> if ( retval ) //<S2SV> goto fork_out ; //<S2SV> retval = - ENOMEM ; //<S2SV> p = dup_task_struct ( current ) ; //<S2SV> if ( ! p ) //<S2SV> goto fork_out ; //<S2SV> ftrace_graph_init_task ( p ) ; //<S2SV> rt_mutex_init_task ( p ) ; //<S2SV> # ifdef CONFIG_PROVE_LOCKING //<S2SV> DEBUG_LOCKS_WARN_ON ( ! p -> hardirqs_enabled ) ; //<S2SV> DEBUG_LOCKS_WARN_ON ( ! p -> softirqs_enabled ) ; //<S2SV> # endif //<S2SV> retval = - EAGAIN ; //<S2SV> if ( atomic_read ( & p -> real_cred -> user -> processes ) >= //<S2SV> p -> signal -> rlim [ RLIMIT_NPROC ] . rlim_cur ) { //<S2SV> if ( ! capable ( CAP_SYS_ADMIN ) && ! capable ( CAP_SYS_RESOURCE ) && //<S2SV> p -> real_cred -> user != INIT_USER ) //<S2SV> goto bad_fork_free ; //<S2SV> } //<S2SV> retval = copy_creds ( p , clone_flags ) ; //<S2SV> if ( retval < 0 ) //<S2SV> goto bad_fork_free ; //<S2SV> retval = - EAGAIN ; //<S2SV> if ( nr_threads >= max_threads ) //<S2SV> goto bad_fork_cleanup_count ; //<S2SV> if ( ! try_module_get ( task_thread_info ( p ) -> exec_domain -> module ) ) //<S2SV> goto bad_fork_cleanup_count ; //<S2SV> p -> did_exec = 0 ; //<S2SV> delayacct_tsk_init ( p ) ; //<S2SV> copy_flags ( clone_flags , p ) ; //<S2SV> INIT_LIST_HEAD ( & p -> children ) ; //<S2SV> INIT_LIST_HEAD ( & p -> sibling ) ; //<S2SV> rcu_copy_process ( p ) ; //<S2SV> p -> vfork_done = NULL ; //<S2SV> spin_lock_init ( & p -> alloc_lock ) ; //<S2SV> init_sigpending ( & p -> pending ) ; //<S2SV> p -> utime = cputime_zero ; //<S2SV> p -> stime = cputime_zero ; //<S2SV> p -> gtime = cputime_zero ; //<S2SV> p -> utimescaled = cputime_zero ; //<S2SV> p -> stimescaled = cputime_zero ; //<S2SV> p -> prev_utime = cputime_zero ; //<S2SV> p -> prev_stime = cputime_zero ; //<S2SV> p -> default_timer_slack_ns = current -> timer_slack_ns ; //<S2SV> task_io_accounting_init ( & p -> ioac ) ; //<S2SV> acct_clear_integrals ( p ) ; //<S2SV> posix_cpu_timers_init ( p ) ; //<S2SV> p -> lock_depth = - 1 ; //<S2SV> do_posix_clock_monotonic_gettime ( & p -> start_time ) ; //<S2SV> p -> real_start_time = p -> start_time ; //<S2SV> monotonic_to_bootbased ( & p -> real_start_time ) ; //<S2SV> p -> io_context = NULL ; //<S2SV> p -> audit_context = NULL ; //<S2SV> cgroup_fork ( p ) ; //<S2SV> # ifdef CONFIG_NUMA //<S2SV> p -> mempolicy = mpol_dup ( p -> mempolicy ) ; //<S2SV> if ( IS_ERR ( p -> mempolicy ) ) { //<S2SV> retval = PTR_ERR ( p -> mempolicy ) ; //<S2SV> p -> mempolicy = NULL ; //<S2SV> goto bad_fork_cleanup_cgroup ; //<S2SV> } //<S2SV> mpol_fix_fork_child_flag ( p ) ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_TRACE_IRQFLAGS //<S2SV> p -> irq_events = 0 ; //<S2SV> # ifdef __ARCH_WANT_INTERRUPTS_ON_CTXSW //<S2SV> p -> hardirqs_enabled = 1 ; //<S2SV> # else //<S2SV> p -> hardirqs_enabled = 0 ; //<S2SV> # endif //<S2SV> p -> hardirq_enable_ip = 0 ; //<S2SV> p -> hardirq_enable_event = 0 ; //<S2SV> p -> hardirq_disable_ip = _THIS_IP_ ; //<S2SV> p -> hardirq_disable_event = 0 ; //<S2SV> p -> softirqs_enabled = 1 ; //<S2SV> p -> softirq_enable_ip = _THIS_IP_ ; //<S2SV> p -> softirq_enable_event = 0 ; //<S2SV> p -> softirq_disable_ip = 0 ; //<S2SV> p -> softirq_disable_event = 0 ; //<S2SV> p -> hardirq_context = 0 ; //<S2SV> p -> softirq_context = 0 ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_LOCKDEP //<S2SV> p -> lockdep_depth = 0 ; //<S2SV> p -> curr_chain_key = 0 ; //<S2SV> p -> lockdep_recursion = 0 ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_DEBUG_MUTEXES //<S2SV> p -> blocked_on = NULL ; //<S2SV> # endif //<S2SV> p -> bts = NULL ; //<S2SV> p -> stack_start = stack_start ; //<S2SV> sched_fork ( p , clone_flags ) ; //<S2SV> retval = perf_event_init_task ( p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_policy ; //<S2SV> if ( ( retval = audit_alloc ( p ) ) ) //<S2SV> goto bad_fork_cleanup_policy ; //<S2SV> if ( ( retval = copy_semundo ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_audit ; //<S2SV> if ( ( retval = copy_files ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_semundo ; //<S2SV> if ( ( retval = copy_fs ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_files ; //<S2SV> if ( ( retval = copy_sighand ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_fs ; //<S2SV> if ( ( retval = copy_signal ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_sighand ; //<S2SV> if ( ( retval = copy_mm ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_signal ; //<S2SV> if ( ( retval = copy_namespaces ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_mm ; //<S2SV> if ( ( retval = copy_io ( clone_flags , p ) ) ) //<S2SV> goto bad_fork_cleanup_namespaces ; //<S2SV> retval = copy_thread ( clone_flags , stack_start , stack_size , p , regs ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_io ; //<S2SV> if ( pid != & init_struct_pid ) { //<S2SV> retval = - ENOMEM ; //<S2SV> pid = alloc_pid ( p -> nsproxy -> pid_ns ) ; //<S2SV> if ( ! pid ) //<S2SV> goto bad_fork_cleanup_io ; //<S2SV> if ( clone_flags & CLONE_NEWPID ) { //<S2SV> retval = pid_ns_prepare_proc ( p -> nsproxy -> pid_ns ) ; //<S2SV> if ( retval < 0 ) //<S2SV> goto bad_fork_free_pid ; //<S2SV> } //<S2SV> } //<S2SV> p -> pid = pid_nr ( pid ) ; //<S2SV> p -> tgid = p -> pid ; //<S2SV> if ( clone_flags & CLONE_THREAD ) //<S2SV> p -> tgid = current -> tgid ; //<S2SV> if ( current -> nsproxy != p -> nsproxy ) { //<S2SV> retval = ns_cgroup_clone ( p , pid ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_free_pid ; //<S2SV> } //<S2SV> p -> set_child_tid = ( clone_flags & CLONE_CHILD_SETTID ) ? child_tidptr : NULL ; //<S2SV> p -> clear_child_tid = ( clone_flags & CLONE_CHILD_CLEARTID ) ? child_tidptr : NULL ; //<S2SV> # ifdef CONFIG_FUTEX //<S2SV> p -> robust_list = NULL ; //<S2SV> # ifdef CONFIG_COMPAT //<S2SV> p -> compat_robust_list = NULL ; //<S2SV> # endif //<S2SV> INIT_LIST_HEAD ( & p -> pi_state_list ) ; //<S2SV> p -> pi_state_cache = NULL ; //<S2SV> # endif //<S2SV> if ( ( clone_flags & ( CLONE_VM | CLONE_VFORK ) ) == CLONE_VM ) //<S2SV> p -> sas_ss_sp = p -> sas_ss_size = 0 ; //<S2SV> clear_tsk_thread_flag ( p , TIF_SYSCALL_TRACE ) ; //<S2SV> # ifdef TIF_SYSCALL_EMU //<S2SV> clear_tsk_thread_flag ( p , TIF_SYSCALL_EMU ) ; //<S2SV> # endif //<S2SV> clear_all_latency_tracing ( p ) ; //<S2SV> p -> exit_signal = ( clone_flags & CLONE_THREAD ) ? - 1 : ( clone_flags & CSIGNAL ) ; //<S2SV> p -> pdeath_signal = 0 ; //<S2SV> p -> exit_state = 0 ; //<S2SV> p -> group_leader = p ; //<S2SV> INIT_LIST_HEAD ( & p -> thread_group ) ; //<S2SV> cgroup_fork_callbacks ( p ) ; //<S2SV> cgroup_callbacks_done = 1 ; //<S2SV> write_lock_irq ( & tasklist_lock ) ; //<S2SV> p -> cpus_allowed = current -> cpus_allowed ; //<S2SV> p -> rt . nr_cpus_allowed = current -> rt . nr_cpus_allowed ; //<S2SV> if ( unlikely ( ! cpu_isset ( task_cpu ( p ) , p -> cpus_allowed ) || //<S2SV> ! cpu_online ( task_cpu ( p ) ) ) ) //<S2SV> set_task_cpu ( p , smp_processor_id ( ) ) ; //<S2SV> if ( clone_flags & ( CLONE_PARENT | CLONE_THREAD ) ) { //<S2SV> p -> real_parent = current -> real_parent ; //<S2SV> p -> parent_exec_id = current -> parent_exec_id ; //<S2SV> } else { //<S2SV> p -> real_parent = current ; //<S2SV> p -> parent_exec_id = current -> self_exec_id ; //<S2SV> } //<S2SV> spin_lock ( & current -> sighand -> siglock ) ; //<S2SV> recalc_sigpending ( ) ; //<S2SV> if ( signal_pending ( current ) ) { //<S2SV> spin_unlock ( & current -> sighand -> siglock ) ; //<S2SV> write_unlock_irq ( & tasklist_lock ) ; //<S2SV> retval = - ERESTARTNOINTR ; //<S2SV> goto bad_fork_free_pid ; //<S2SV> } //<S2SV> if ( clone_flags & CLONE_THREAD ) { //<S2SV> atomic_inc ( & current -> signal -> count ) ; //<S2SV> atomic_inc ( & current -> signal -> live ) ; //<S2SV> p -> group_leader = current -> group_leader ; //<S2SV> list_add_tail_rcu ( & p -> thread_group , & p -> group_leader -> thread_group ) ; //<S2SV> } //<S2SV> if ( likely ( p -> pid ) ) { //<S2SV> list_add_tail ( & p -> sibling , & p -> real_parent -> children ) ; //<S2SV> tracehook_finish_clone ( p , clone_flags , trace ) ; //<S2SV> if ( thread_group_leader ( p ) ) { //<S2SV> if ( clone_flags & CLONE_NEWPID ) //<S2SV> p -> nsproxy -> pid_ns -> child_reaper = p ; //<S2SV> p -> signal -> leader_pid = pid ; //<S2SV> tty_kref_put ( p -> signal -> tty ) ; //<S2SV> p -> signal -> tty = tty_kref_get ( current -> signal -> tty ) ; //<S2SV> attach_pid ( p , PIDTYPE_PGID , task_pgrp ( current ) ) ; //<S2SV> attach_pid ( p , PIDTYPE_SID , task_session ( current ) ) ; //<S2SV> list_add_tail_rcu ( & p -> tasks , & init_task . tasks ) ; //<S2SV> __get_cpu_var ( process_counts ) ++ ; //<S2SV> } //<S2SV> attach_pid ( p , PIDTYPE_PID , pid ) ; //<S2SV> nr_threads ++ ; //<S2SV> } //<S2SV> total_forks ++ ; //<S2SV> spin_unlock ( & current -> sighand -> siglock ) ; //<S2SV> write_unlock_irq ( & tasklist_lock ) ; //<S2SV> proc_fork_connector ( p ) ; //<S2SV> cgroup_post_fork ( p ) ; //<S2SV> perf_event_fork ( p ) ; //<S2SV> return p ; //<S2SV> bad_fork_free_pid : //<S2SV> if ( pid != & init_struct_pid ) //<S2SV> free_pid ( pid ) ; //<S2SV> bad_fork_cleanup_io : //<S2SV> if ( p -> io_context ) //<S2SV> exit_io_context ( p ) ; //<S2SV> bad_fork_cleanup_namespaces : //<S2SV> exit_task_namespaces ( p ) ; //<S2SV> bad_fork_cleanup_mm : //<S2SV> if ( p -> mm ) //<S2SV> mmput ( p -> mm ) ; //<S2SV> bad_fork_cleanup_signal : //<S2SV> if ( ! ( clone_flags & CLONE_THREAD ) ) //<S2SV> __cleanup_signal ( p -> signal ) ; //<S2SV> bad_fork_cleanup_sighand : //<S2SV> __cleanup_sighand ( p -> sighand ) ; //<S2SV> bad_fork_cleanup_fs : //<S2SV> exit_fs ( p ) ; //<S2SV> bad_fork_cleanup_files : //<S2SV> exit_files ( p ) ; //<S2SV> bad_fork_cleanup_semundo : //<S2SV> exit_sem ( p ) ; //<S2SV> bad_fork_cleanup_audit : //<S2SV> audit_free ( p ) ; //<S2SV> bad_fork_cleanup_policy : //<S2SV> perf_event_free_task ( p ) ; //<S2SV> # ifdef CONFIG_NUMA //<S2SV> mpol_put ( p -> mempolicy ) ; //<S2SV> bad_fork_cleanup_cgroup : //<S2SV> # endif //<S2SV> cgroup_exit ( p , cgroup_callbacks_done ) ; //<S2SV> delayacct_tsk_free ( p ) ; //<S2SV> module_put ( task_thread_info ( p ) -> exec_domain -> module ) ; //<S2SV> bad_fork_cleanup_count : //<S2SV> atomic_dec ( & p -> cred -> user -> processes ) ; //<S2SV> exit_creds ( p ) ; //<S2SV> bad_fork_free : //<S2SV> free_task ( p ) ; //<S2SV> fork_out : //<S2SV> return ERR_PTR ( retval ) ; //<S2SV> } //<S2SV> 