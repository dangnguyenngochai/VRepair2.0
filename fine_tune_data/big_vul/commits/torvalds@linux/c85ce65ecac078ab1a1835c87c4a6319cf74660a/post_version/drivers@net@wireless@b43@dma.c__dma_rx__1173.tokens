static void dma_rx ( struct b43_dmaring * ring , int * slot ) //<S2SV> { //<S2SV> const struct b43_dma_ops * ops = ring -> ops ; //<S2SV> struct b43_dmadesc_generic * desc ; //<S2SV> struct b43_dmadesc_meta * meta ; //<S2SV> struct b43_rxhdr_fw4 * rxhdr ; //<S2SV> struct sk_buff * skb ; //<S2SV> u16 len ; //<S2SV> int err ; //<S2SV> dma_addr_t dmaaddr ; //<S2SV> desc = ops -> idx2desc ( ring , * slot , & meta ) ; //<S2SV> sync_descbuffer_for_cpu ( ring , meta -> dmaaddr , ring -> rx_buffersize ) ; //<S2SV> skb = meta -> skb ; //<S2SV> rxhdr = ( struct b43_rxhdr_fw4 * ) skb -> data ; //<S2SV> len = le16_to_cpu ( rxhdr -> frame_len ) ; //<S2SV> if ( len == 0 ) { //<S2SV> int i = 0 ; //<S2SV> do { //<S2SV> udelay ( 2 ) ; //<S2SV> barrier ( ) ; //<S2SV> len = le16_to_cpu ( rxhdr -> frame_len ) ; //<S2SV> } while ( len == 0 && i ++ < 5 ) ; //<S2SV> if ( unlikely ( len == 0 ) ) { //<S2SV> dmaaddr = meta -> dmaaddr ; //<S2SV> goto drop_recycle_buffer ; //<S2SV> } //<S2SV> } //<S2SV> if ( unlikely ( b43_rx_buffer_is_poisoned ( ring , skb ) ) ) { //<S2SV> b43dbg ( ring -> dev -> wl , "DMA<S2SV_blank>RX:<S2SV_blank>Dropping<S2SV_blank>poisoned<S2SV_blank>buffer.\\n" ) ; //<S2SV> dmaaddr = meta -> dmaaddr ; //<S2SV> goto drop_recycle_buffer ; //<S2SV> } //<S2SV> if ( unlikely ( len + ring -> frameoffset > ring -> rx_buffersize ) ) { //<S2SV> int cnt = 0 ; //<S2SV> s32 tmp = len ; //<S2SV> while ( 1 ) { //<S2SV> desc = ops -> idx2desc ( ring , * slot , & meta ) ; //<S2SV> b43_poison_rx_buffer ( ring , meta -> skb ) ; //<S2SV> sync_descbuffer_for_device ( ring , meta -> dmaaddr , //<S2SV> ring -> rx_buffersize ) ; //<S2SV> * slot = next_slot ( ring , * slot ) ; //<S2SV> cnt ++ ; //<S2SV> tmp -= ring -> rx_buffersize ; //<S2SV> if ( tmp <= 0 ) //<S2SV> break ; //<S2SV> } //<S2SV> b43err ( ring -> dev -> wl , "DMA<S2SV_blank>RX<S2SV_blank>buffer<S2SV_blank>too<S2SV_blank>small<S2SV_blank>" //<S2SV> "(len:<S2SV_blank>%u,<S2SV_blank>buffer:<S2SV_blank>%u,<S2SV_blank>nr-dropped:<S2SV_blank>%d)\\n" , //<S2SV> len , ring -> rx_buffersize , cnt ) ; //<S2SV> goto drop ; //<S2SV> } //<S2SV> dmaaddr = meta -> dmaaddr ; //<S2SV> err = setup_rx_descbuffer ( ring , desc , meta , GFP_ATOMIC ) ; //<S2SV> if ( unlikely ( err ) ) { //<S2SV> b43dbg ( ring -> dev -> wl , "DMA<S2SV_blank>RX:<S2SV_blank>setup_rx_descbuffer()<S2SV_blank>failed\\n" ) ; //<S2SV> goto drop_recycle_buffer ; //<S2SV> } //<S2SV> unmap_descbuffer ( ring , dmaaddr , ring -> rx_buffersize , 0 ) ; //<S2SV> skb_put ( skb , len + ring -> frameoffset ) ; //<S2SV> skb_pull ( skb , ring -> frameoffset ) ; //<S2SV> b43_rx ( ring -> dev , skb , rxhdr ) ; //<S2SV> drop : //<S2SV> return ; //<S2SV> drop_recycle_buffer : //<S2SV> b43_poison_rx_buffer ( ring , skb ) ; //<S2SV> sync_descbuffer_for_device ( ring , dmaaddr , ring -> rx_buffersize ) ; //<S2SV> } //<S2SV> 