static int llc_ui_recvmsg ( struct kiocb * iocb , struct socket * sock , //<S2SV> struct msghdr * msg , size_t len , int flags ) //<S2SV> { //<S2SV> struct sockaddr_llc * uaddr = ( struct sockaddr_llc * ) msg -> msg_name ; //<S2SV> const int nonblock = flags & MSG_DONTWAIT ; //<S2SV> struct sk_buff * skb = NULL ; //<S2SV> struct sock * sk = sock -> sk ; //<S2SV> struct llc_sock * llc = llc_sk ( sk ) ; //<S2SV> unsigned long cpu_flags ; //<S2SV> size_t copied = 0 ; //<S2SV> u32 peek_seq = 0 ; //<S2SV> u32 * seq ; //<S2SV> unsigned long used ; //<S2SV> int target ; //<S2SV> long timeo ; //<S2SV> msg -> msg_namelen = 0 ; //<S2SV> lock_sock ( sk ) ; //<S2SV> copied = - ENOTCONN ; //<S2SV> if ( unlikely ( sk -> sk_type == SOCK_STREAM && sk -> sk_state == TCP_LISTEN ) ) //<S2SV> goto out ; //<S2SV> timeo = sock_rcvtimeo ( sk , nonblock ) ; //<S2SV> seq = & llc -> copied_seq ; //<S2SV> if ( flags & MSG_PEEK ) { //<S2SV> peek_seq = llc -> copied_seq ; //<S2SV> seq = & peek_seq ; //<S2SV> } //<S2SV> target = sock_rcvlowat ( sk , flags & MSG_WAITALL , len ) ; //<S2SV> copied = 0 ; //<S2SV> do { //<S2SV> u32 offset ; //<S2SV> if ( signal_pending ( current ) ) { //<S2SV> if ( copied ) //<S2SV> break ; //<S2SV> copied = timeo ? sock_intr_errno ( timeo ) : - EAGAIN ; //<S2SV> break ; //<S2SV> } //<S2SV> skb = skb_peek ( & sk -> sk_receive_queue ) ; //<S2SV> if ( skb ) { //<S2SV> offset = * seq ; //<S2SV> goto found_ok_skb ; //<S2SV> } //<S2SV> if ( copied >= target && ! sk -> sk_backlog . tail ) //<S2SV> break ; //<S2SV> if ( copied ) { //<S2SV> if ( sk -> sk_err || //<S2SV> sk -> sk_state == TCP_CLOSE || //<S2SV> ( sk -> sk_shutdown & RCV_SHUTDOWN ) || //<S2SV> ! timeo || //<S2SV> ( flags & MSG_PEEK ) ) //<S2SV> break ; //<S2SV> } else { //<S2SV> if ( sock_flag ( sk , SOCK_DONE ) ) //<S2SV> break ; //<S2SV> if ( sk -> sk_err ) { //<S2SV> copied = sock_error ( sk ) ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( sk -> sk_shutdown & RCV_SHUTDOWN ) //<S2SV> break ; //<S2SV> if ( sk -> sk_type == SOCK_STREAM && sk -> sk_state == TCP_CLOSE ) { //<S2SV> if ( ! sock_flag ( sk , SOCK_DONE ) ) { //<S2SV> copied = - ENOTCONN ; //<S2SV> break ; //<S2SV> } //<S2SV> break ; //<S2SV> } //<S2SV> if ( ! timeo ) { //<S2SV> copied = - EAGAIN ; //<S2SV> break ; //<S2SV> } //<S2SV> } //<S2SV> if ( copied >= target ) { //<S2SV> release_sock ( sk ) ; //<S2SV> lock_sock ( sk ) ; //<S2SV> } else //<S2SV> sk_wait_data ( sk , & timeo ) ; //<S2SV> if ( ( flags & MSG_PEEK ) && peek_seq != llc -> copied_seq ) { //<S2SV> net_dbg_ratelimited ( "LLC(%s:%d):<S2SV_blank>Application<S2SV_blank>bug,<S2SV_blank>race<S2SV_blank>in<S2SV_blank>MSG_PEEK\\n" , //<S2SV> current -> comm , //<S2SV> task_pid_nr ( current ) ) ; //<S2SV> peek_seq = llc -> copied_seq ; //<S2SV> } //<S2SV> continue ; //<S2SV> found_ok_skb : //<S2SV> used = skb -> len - offset ; //<S2SV> if ( len < used ) //<S2SV> used = len ; //<S2SV> if ( ! ( flags & MSG_TRUNC ) ) { //<S2SV> int rc = skb_copy_datagram_iovec ( skb , offset , //<S2SV> msg -> msg_iov , used ) ; //<S2SV> if ( rc ) { //<S2SV> if ( ! copied ) //<S2SV> copied = - EFAULT ; //<S2SV> break ; //<S2SV> } //<S2SV> } //<S2SV> * seq += used ; //<S2SV> copied += used ; //<S2SV> len -= used ; //<S2SV> if ( sk -> sk_type != SOCK_STREAM ) //<S2SV> goto copy_uaddr ; //<S2SV> if ( ! ( flags & MSG_PEEK ) ) { //<S2SV> spin_lock_irqsave ( & sk -> sk_receive_queue . lock , cpu_flags ) ; //<S2SV> sk_eat_skb ( sk , skb , false ) ; //<S2SV> spin_unlock_irqrestore ( & sk -> sk_receive_queue . lock , cpu_flags ) ; //<S2SV> * seq = 0 ; //<S2SV> } //<S2SV> if ( used + offset < skb -> len ) //<S2SV> continue ; //<S2SV> } while ( len > 0 ) ; //<S2SV> out : //<S2SV> release_sock ( sk ) ; //<S2SV> return copied ; //<S2SV> copy_uaddr : //<S2SV> if ( uaddr != NULL && skb != NULL ) { //<S2SV> memcpy ( uaddr , llc_ui_skb_cb ( skb ) , sizeof ( * uaddr ) ) ; //<S2SV> msg -> msg_namelen = sizeof ( * uaddr ) ; //<S2SV> } //<S2SV> if ( llc_sk ( sk ) -> cmsg_flags ) //<S2SV> llc_cmsg_rcv ( msg , skb ) ; //<S2SV> if ( ! ( flags & MSG_PEEK ) ) { //<S2SV> spin_lock_irqsave ( & sk -> sk_receive_queue . lock , cpu_flags ) ; //<S2SV> sk_eat_skb ( sk , skb , false ) ; //<S2SV> spin_unlock_irqrestore ( & sk -> sk_receive_queue . lock , cpu_flags ) ; //<S2SV> * seq = 0 ; //<S2SV> } //<S2SV> goto out ; //<S2SV> } //<S2SV> 