static void recalculate_apic_map ( struct kvm * kvm ) //<S2SV> { //<S2SV> struct kvm_apic_map * new , * old = NULL ; //<S2SV> struct kvm_vcpu * vcpu ; //<S2SV> int i ; //<S2SV> new = kzalloc ( sizeof ( struct kvm_apic_map ) , GFP_KERNEL ) ; //<S2SV> mutex_lock ( & kvm -> arch . apic_map_lock ) ; //<S2SV> if ( ! new ) //<S2SV> goto out ; //<S2SV> new -> ldr_bits = 8 ; //<S2SV> new -> cid_shift = 8 ; //<S2SV> new -> cid_mask = 0 ; //<S2SV> new -> lid_mask = 0xff ; //<S2SV> kvm_for_each_vcpu ( i , vcpu , kvm ) { //<S2SV> struct kvm_lapic * apic = vcpu -> arch . apic ; //<S2SV> u16 cid , lid ; //<S2SV> u32 ldr ; //<S2SV> if ( ! kvm_apic_present ( vcpu ) ) //<S2SV> continue ; //<S2SV> if ( apic_x2apic_mode ( apic ) ) { //<S2SV> new -> ldr_bits = 32 ; //<S2SV> new -> cid_shift = 16 ; //<S2SV> new -> cid_mask = new -> lid_mask = 0xffff ; //<S2SV> } else if ( kvm_apic_sw_enabled ( apic ) && //<S2SV> ! new -> cid_mask && //<S2SV> kvm_apic_get_reg ( apic , APIC_DFR ) == APIC_DFR_CLUSTER ) { //<S2SV> new -> cid_shift = 4 ; //<S2SV> new -> cid_mask = 0xf ; //<S2SV> new -> lid_mask = 0xf ; //<S2SV> } //<S2SV> new -> phys_map [ kvm_apic_id ( apic ) ] = apic ; //<S2SV> ldr = kvm_apic_get_reg ( apic , APIC_LDR ) ; //<S2SV> cid = apic_cluster_id ( new , ldr ) ; //<S2SV> lid = apic_logical_id ( new , ldr ) ; //<S2SV> if ( lid ) //<S2SV> new -> logical_map [ cid ] [ ffs ( lid ) - 1 ] = apic ; //<S2SV> } //<S2SV> out : //<S2SV> old = rcu_dereference_protected ( kvm -> arch . apic_map , //<S2SV> lockdep_is_held ( & kvm -> arch . apic_map_lock ) ) ; //<S2SV> rcu_assign_pointer ( kvm -> arch . apic_map , new ) ; //<S2SV> mutex_unlock ( & kvm -> arch . apic_map_lock ) ; //<S2SV> if ( old ) //<S2SV> kfree_rcu ( old , rcu ) ; //<S2SV> kvm_vcpu_request_scan_ioapic ( kvm ) ; //<S2SV> } //<S2SV> 