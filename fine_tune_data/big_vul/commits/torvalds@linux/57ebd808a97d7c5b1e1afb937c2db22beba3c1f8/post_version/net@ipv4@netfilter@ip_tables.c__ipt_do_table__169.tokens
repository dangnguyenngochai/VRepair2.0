unsigned int //<S2SV> ipt_do_table ( struct sk_buff * skb , //<S2SV> const struct nf_hook_state * state , //<S2SV> struct xt_table * table ) //<S2SV> { //<S2SV> unsigned int hook = state -> hook ; //<S2SV> static const char nulldevname [ IFNAMSIZ ] __attribute__ ( ( aligned ( sizeof ( long ) ) ) ) ; //<S2SV> const struct iphdr * ip ; //<S2SV> unsigned int verdict = NF_DROP ; //<S2SV> const char * indev , * outdev ; //<S2SV> const void * table_base ; //<S2SV> struct ipt_entry * e , * * jumpstack ; //<S2SV> unsigned int stackidx , cpu ; //<S2SV> const struct xt_table_info * private ; //<S2SV> struct xt_action_param acpar ; //<S2SV> unsigned int addend ; //<S2SV> stackidx = 0 ; //<S2SV> ip = ip_hdr ( skb ) ; //<S2SV> indev = state -> in ? state -> in -> name : nulldevname ; //<S2SV> outdev = state -> out ? state -> out -> name : nulldevname ; //<S2SV> acpar . fragoff = ntohs ( ip -> frag_off ) & IP_OFFSET ; //<S2SV> acpar . thoff = ip_hdrlen ( skb ) ; //<S2SV> acpar . hotdrop = false ; //<S2SV> acpar . state = state ; //<S2SV> WARN_ON ( ! ( table -> valid_hooks & ( 1 << hook ) ) ) ; //<S2SV> local_bh_disable ( ) ; //<S2SV> addend = xt_write_recseq_begin ( ) ; //<S2SV> private = READ_ONCE ( table -> private ) ; //<S2SV> cpu = smp_processor_id ( ) ; //<S2SV> table_base = private -> entries ; //<S2SV> jumpstack = ( struct ipt_entry * * ) private -> jumpstack [ cpu ] ; //<S2SV> if ( static_key_false ( & xt_tee_enabled ) ) //<S2SV> jumpstack += private -> stacksize * __this_cpu_read ( nf_skb_duplicated ) ; //<S2SV> e = get_entry ( table_base , private -> hook_entry [ hook ] ) ; //<S2SV> do { //<S2SV> const struct xt_entry_target * t ; //<S2SV> const struct xt_entry_match * ematch ; //<S2SV> struct xt_counters * counter ; //<S2SV> WARN_ON ( ! e ) ; //<S2SV> if ( ! ip_packet_match ( ip , indev , outdev , //<S2SV> & e -> ip , acpar . fragoff ) ) { //<S2SV> no_match : //<S2SV> e = ipt_next_entry ( e ) ; //<S2SV> continue ; //<S2SV> } //<S2SV> xt_ematch_foreach ( ematch , e ) { //<S2SV> acpar . match = ematch -> u . kernel . match ; //<S2SV> acpar . matchinfo = ematch -> data ; //<S2SV> if ( ! acpar . match -> match ( skb , & acpar ) ) //<S2SV> goto no_match ; //<S2SV> } //<S2SV> counter = xt_get_this_cpu_counter ( & e -> counters ) ; //<S2SV> ADD_COUNTER ( * counter , skb -> len , 1 ) ; //<S2SV> t = ipt_get_target ( e ) ; //<S2SV> WARN_ON ( ! t -> u . kernel . target ) ; //<S2SV> # if IS_ENABLED ( CONFIG_NETFILTER_XT_TARGET_TRACE ) //<S2SV> if ( unlikely ( skb -> nf_trace ) ) //<S2SV> trace_packet ( state -> net , skb , hook , state -> in , //<S2SV> state -> out , table -> name , private , e ) ; //<S2SV> # endif //<S2SV> if ( ! t -> u . kernel . target -> target ) { //<S2SV> int v ; //<S2SV> v = ( ( struct xt_standard_target * ) t ) -> verdict ; //<S2SV> if ( v < 0 ) { //<S2SV> if ( v != XT_RETURN ) { //<S2SV> verdict = ( unsigned int ) ( - v ) - 1 ; //<S2SV> break ; //<S2SV> } //<S2SV> if ( stackidx == 0 ) { //<S2SV> e = get_entry ( table_base , //<S2SV> private -> underflow [ hook ] ) ; //<S2SV> } else { //<S2SV> e = jumpstack [ -- stackidx ] ; //<S2SV> e = ipt_next_entry ( e ) ; //<S2SV> } //<S2SV> continue ; //<S2SV> } //<S2SV> if ( table_base + v != ipt_next_entry ( e ) && //<S2SV> ! ( e -> ip . flags & IPT_F_GOTO ) ) { //<S2SV> if ( unlikely ( stackidx >= private -> stacksize ) ) { //<S2SV> verdict = NF_DROP ; //<S2SV> break ; //<S2SV> } //<S2SV> jumpstack [ stackidx ++ ] = e ; //<S2SV> } //<S2SV> e = get_entry ( table_base , v ) ; //<S2SV> continue ; //<S2SV> } //<S2SV> acpar . target = t -> u . kernel . target ; //<S2SV> acpar . targinfo = t -> data ; //<S2SV> verdict = t -> u . kernel . target -> target ( skb , & acpar ) ; //<S2SV> if ( verdict == XT_CONTINUE ) { //<S2SV> ip = ip_hdr ( skb ) ; //<S2SV> e = ipt_next_entry ( e ) ; //<S2SV> } else { //<S2SV> break ; //<S2SV> } //<S2SV> } while ( ! acpar . hotdrop ) ; //<S2SV> xt_write_recseq_end ( addend ) ; //<S2SV> local_bh_enable ( ) ; //<S2SV> if ( acpar . hotdrop ) //<S2SV> return NF_DROP ; //<S2SV> else return verdict ; //<S2SV> } //<S2SV> 