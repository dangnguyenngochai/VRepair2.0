static int em_sysexit ( struct x86_emulate_ctxt * ctxt ) //<S2SV> { //<S2SV> const struct x86_emulate_ops * ops = ctxt -> ops ; //<S2SV> struct desc_struct cs , ss ; //<S2SV> u64 msr_data ; //<S2SV> int usermode ; //<S2SV> u16 cs_sel = 0 , ss_sel = 0 ; //<S2SV> if ( ctxt -> mode == X86EMUL_MODE_REAL || //<S2SV> ctxt -> mode == X86EMUL_MODE_VM86 ) //<S2SV> return emulate_gp ( ctxt , 0 ) ; //<S2SV> setup_syscalls_segments ( ctxt , & cs , & ss ) ; //<S2SV> if ( ( ctxt -> rex_prefix & 0x8 ) != 0x0 ) //<S2SV> usermode = X86EMUL_MODE_PROT64 ; //<S2SV> else //<S2SV> usermode = X86EMUL_MODE_PROT32 ; //<S2SV> cs . dpl = 3 ; //<S2SV> ss . dpl = 3 ; //<S2SV> ops -> get_msr ( ctxt , MSR_IA32_SYSENTER_CS , & msr_data ) ; //<S2SV> switch ( usermode ) { //<S2SV> case X86EMUL_MODE_PROT32 : //<S2SV> cs_sel = ( u16 ) ( msr_data + 16 ) ; //<S2SV> if ( ( msr_data & 0xfffc ) == 0x0 ) //<S2SV> return emulate_gp ( ctxt , 0 ) ; //<S2SV> ss_sel = ( u16 ) ( msr_data + 24 ) ; //<S2SV> break ; //<S2SV> case X86EMUL_MODE_PROT64 : //<S2SV> cs_sel = ( u16 ) ( msr_data + 32 ) ; //<S2SV> if ( msr_data == 0x0 ) //<S2SV> return emulate_gp ( ctxt , 0 ) ; //<S2SV> ss_sel = cs_sel + 8 ; //<S2SV> cs . d = 0 ; //<S2SV> cs . l = 1 ; //<S2SV> break ; //<S2SV> } //<S2SV> cs_sel |= SELECTOR_RPL_MASK ; //<S2SV> ss_sel |= SELECTOR_RPL_MASK ; //<S2SV> ops -> set_segment ( ctxt , cs_sel , & cs , 0 , VCPU_SREG_CS ) ; //<S2SV> ops -> set_segment ( ctxt , ss_sel , & ss , 0 , VCPU_SREG_SS ) ; //<S2SV> ctxt -> _eip = reg_read ( ctxt , VCPU_REGS_RDX ) ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RSP ) = reg_read ( ctxt , VCPU_REGS_RCX ) ; //<S2SV> return X86EMUL_CONTINUE ; //<S2SV> } //<S2SV> 