static int load_state_from_tss32 ( struct x86_emulate_ctxt * ctxt , //<S2SV> struct tss_segment_32 * tss ) //<S2SV> { //<S2SV> int ret ; //<S2SV> u8 cpl ; //<S2SV> if ( ctxt -> ops -> set_cr ( ctxt , 3 , tss -> cr3 ) ) //<S2SV> return emulate_gp ( ctxt , 0 ) ; //<S2SV> ctxt -> _eip = tss -> eip ; //<S2SV> ctxt -> eflags = tss -> eflags | 2 ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RAX ) = tss -> eax ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RCX ) = tss -> ecx ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RDX ) = tss -> edx ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RBX ) = tss -> ebx ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RSP ) = tss -> esp ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RBP ) = tss -> ebp ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RSI ) = tss -> esi ; //<S2SV> * reg_write ( ctxt , VCPU_REGS_RDI ) = tss -> edi ; //<S2SV> set_segment_selector ( ctxt , tss -> ldt_selector , VCPU_SREG_LDTR ) ; //<S2SV> set_segment_selector ( ctxt , tss -> es , VCPU_SREG_ES ) ; //<S2SV> set_segment_selector ( ctxt , tss -> cs , VCPU_SREG_CS ) ; //<S2SV> set_segment_selector ( ctxt , tss -> ss , VCPU_SREG_SS ) ; //<S2SV> set_segment_selector ( ctxt , tss -> ds , VCPU_SREG_DS ) ; //<S2SV> set_segment_selector ( ctxt , tss -> fs , VCPU_SREG_FS ) ; //<S2SV> set_segment_selector ( ctxt , tss -> gs , VCPU_SREG_GS ) ; //<S2SV> if ( ctxt -> eflags & X86_EFLAGS_VM ) { //<S2SV> ctxt -> mode = X86EMUL_MODE_VM86 ; //<S2SV> cpl = 3 ; //<S2SV> } else { //<S2SV> ctxt -> mode = X86EMUL_MODE_PROT32 ; //<S2SV> cpl = tss -> cs & 3 ; //<S2SV> } //<S2SV> ret = __load_segment_descriptor ( ctxt , tss -> ldt_selector , VCPU_SREG_LDTR , //<S2SV> cpl , true , NULL ) ; //<S2SV> if ( ret != X86EMUL_CONTINUE ) //<S2SV> return ret ; //<S2SV> ret = __load_segment_descriptor ( ctxt , tss -> es , VCPU_SREG_ES , cpl , //<S2SV> true , NULL ) ; //<S2SV> if ( ret != X86EMUL_CONTINUE ) //<S2SV> return ret ; //<S2SV> ret = __load_segment_descriptor ( ctxt , tss -> cs , VCPU_SREG_CS , cpl , //<S2SV> true , NULL ) ; //<S2SV> if ( ret != X86EMUL_CONTINUE ) //<S2SV> return ret ; //<S2SV> ret = __load_segment_descriptor ( ctxt , tss -> ss , VCPU_SREG_SS , cpl , //<S2SV> true , NULL ) ; //<S2SV> if ( ret != X86EMUL_CONTINUE ) //<S2SV> return ret ; //<S2SV> ret = __load_segment_descriptor ( ctxt , tss -> ds , VCPU_SREG_DS , cpl , //<S2SV> true , NULL ) ; //<S2SV> if ( ret != X86EMUL_CONTINUE ) //<S2SV> return ret ; //<S2SV> ret = __load_segment_descriptor ( ctxt , tss -> fs , VCPU_SREG_FS , cpl , //<S2SV> true , NULL ) ; //<S2SV> if ( ret != X86EMUL_CONTINUE ) //<S2SV> return ret ; //<S2SV> ret = __load_segment_descriptor ( ctxt , tss -> gs , VCPU_SREG_GS , cpl , //<S2SV> true , NULL ) ; //<S2SV> if ( ret != X86EMUL_CONTINUE ) //<S2SV> return ret ; //<S2SV> return X86EMUL_CONTINUE ; //<S2SV> } //<S2SV> 