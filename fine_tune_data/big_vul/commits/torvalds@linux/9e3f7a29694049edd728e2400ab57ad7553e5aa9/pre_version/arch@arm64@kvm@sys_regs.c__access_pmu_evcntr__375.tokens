static bool access_pmu_evcntr ( struct kvm_vcpu * vcpu , //<S2SV> struct sys_reg_params * p , //<S2SV> const struct sys_reg_desc * r ) //<S2SV> { //<S2SV> u64 idx ; //<S2SV> if ( ! kvm_arm_pmu_v3_ready ( vcpu ) ) //<S2SV> return trap_raz_wi ( vcpu , p , r ) ; //<S2SV> if ( r -> CRn == 9 && r -> CRm == 13 ) { //<S2SV> if ( r -> Op2 == 2 ) { //<S2SV> if ( pmu_access_event_counter_el0_disabled ( vcpu ) ) //<S2SV> return false ; //<S2SV> idx = vcpu_sys_reg ( vcpu , PMSELR_EL0 ) //<S2SV> & ARMV8_PMU_COUNTER_MASK ; //<S2SV> } else if ( r -> Op2 == 0 ) { //<S2SV> if ( pmu_access_cycle_counter_el0_disabled ( vcpu ) ) //<S2SV> return false ; //<S2SV> idx = ARMV8_PMU_CYCLE_IDX ; //<S2SV> } else { //<S2SV> BUG ( ) ; //<S2SV> } //<S2SV> } else if ( r -> CRn == 14 && ( r -> CRm & 12 ) == 8 ) { //<S2SV> if ( pmu_access_event_counter_el0_disabled ( vcpu ) ) //<S2SV> return false ; //<S2SV> idx = ( ( r -> CRm & 3 ) << 3 ) | ( r -> Op2 & 7 ) ; //<S2SV> } else { //<S2SV> BUG ( ) ; //<S2SV> } //<S2SV> if ( ! pmu_counter_idx_valid ( vcpu , idx ) ) //<S2SV> return false ; //<S2SV> if ( p -> is_write ) { //<S2SV> if ( pmu_access_el0_disabled ( vcpu ) ) //<S2SV> return false ; //<S2SV> kvm_pmu_set_counter_value ( vcpu , idx , p -> regval ) ; //<S2SV> } else { //<S2SV> p -> regval = kvm_pmu_get_counter_value ( vcpu , idx ) ; //<S2SV> } //<S2SV> return true ; //<S2SV> } //<S2SV> 