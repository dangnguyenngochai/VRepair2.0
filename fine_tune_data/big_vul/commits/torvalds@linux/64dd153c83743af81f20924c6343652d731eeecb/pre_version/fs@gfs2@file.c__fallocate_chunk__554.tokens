static int fallocate_chunk ( struct inode * inode , loff_t offset , loff_t len , //<S2SV> int mode ) //<S2SV> { //<S2SV> struct gfs2_inode * ip = GFS2_I ( inode ) ; //<S2SV> struct buffer_head * dibh ; //<S2SV> int error ; //<S2SV> u64 start = offset >> PAGE_CACHE_SHIFT ; //<S2SV> unsigned int start_offset = offset & ~ PAGE_CACHE_MASK ; //<S2SV> u64 end = ( offset + len - 1 ) >> PAGE_CACHE_SHIFT ; //<S2SV> pgoff_t curr ; //<S2SV> struct page * page ; //<S2SV> unsigned int end_offset = ( offset + len ) & ~ PAGE_CACHE_MASK ; //<S2SV> unsigned int from , to ; //<S2SV> if ( ! end_offset ) //<S2SV> end_offset = PAGE_CACHE_SIZE ; //<S2SV> error = gfs2_meta_inode_buffer ( ip , & dibh ) ; //<S2SV> if ( unlikely ( error ) ) //<S2SV> goto out ; //<S2SV> gfs2_trans_add_bh ( ip -> i_gl , dibh , 1 ) ; //<S2SV> if ( gfs2_is_stuffed ( ip ) ) { //<S2SV> error = gfs2_unstuff_dinode ( ip , NULL ) ; //<S2SV> if ( unlikely ( error ) ) //<S2SV> goto out ; //<S2SV> } //<S2SV> curr = start ; //<S2SV> offset = start << PAGE_CACHE_SHIFT ; //<S2SV> from = start_offset ; //<S2SV> to = PAGE_CACHE_SIZE ; //<S2SV> while ( curr <= end ) { //<S2SV> page = grab_cache_page_write_begin ( inode -> i_mapping , curr , //<S2SV> AOP_FLAG_NOFS ) ; //<S2SV> if ( unlikely ( ! page ) ) { //<S2SV> error = - ENOMEM ; //<S2SV> goto out ; //<S2SV> } //<S2SV> if ( curr == end ) //<S2SV> to = end_offset ; //<S2SV> error = write_empty_blocks ( page , from , to , mode ) ; //<S2SV> if ( ! error && offset + to > inode -> i_size && //<S2SV> ! ( mode & FALLOC_FL_KEEP_SIZE ) ) { //<S2SV> i_size_write ( inode , offset + to ) ; //<S2SV> } //<S2SV> unlock_page ( page ) ; //<S2SV> page_cache_release ( page ) ; //<S2SV> if ( error ) //<S2SV> goto out ; //<S2SV> curr ++ ; //<S2SV> offset += PAGE_CACHE_SIZE ; //<S2SV> from = 0 ; //<S2SV> } //<S2SV> mark_inode_dirty ( inode ) ; //<S2SV> brelse ( dibh ) ; //<S2SV> out : //<S2SV> return error ; //<S2SV> } //<S2SV> 