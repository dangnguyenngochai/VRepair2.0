static void perf_event_interrupt ( struct pt_regs * regs ) //<S2SV> { //<S2SV> int i ; //<S2SV> struct cpu_hw_events * cpuhw = & __get_cpu_var ( cpu_hw_events ) ; //<S2SV> struct perf_event * event ; //<S2SV> unsigned long val ; //<S2SV> int found = 0 ; //<S2SV> int nmi ; //<S2SV> if ( cpuhw -> n_limited ) //<S2SV> freeze_limited_counters ( cpuhw , mfspr ( SPRN_PMC5 ) , //<S2SV> mfspr ( SPRN_PMC6 ) ) ; //<S2SV> perf_read_regs ( regs ) ; //<S2SV> nmi = perf_intr_is_nmi ( regs ) ; //<S2SV> if ( nmi ) //<S2SV> nmi_enter ( ) ; //<S2SV> else //<S2SV> irq_enter ( ) ; //<S2SV> for ( i = 0 ; i < cpuhw -> n_events ; ++ i ) { //<S2SV> event = cpuhw -> event [ i ] ; //<S2SV> if ( ! event -> hw . idx || is_limited_pmc ( event -> hw . idx ) ) //<S2SV> continue ; //<S2SV> val = read_pmc ( event -> hw . idx ) ; //<S2SV> if ( ( int ) val < 0 ) { //<S2SV> found = 1 ; //<S2SV> record_and_restart ( event , val , regs , nmi ) ; //<S2SV> } //<S2SV> } //<S2SV> if ( ! found ) { //<S2SV> for ( i = 0 ; i < ppmu -> n_counter ; ++ i ) { //<S2SV> if ( is_limited_pmc ( i + 1 ) ) //<S2SV> continue ; //<S2SV> val = read_pmc ( i + 1 ) ; //<S2SV> if ( pmc_overflow ( val ) ) //<S2SV> write_pmc ( i + 1 , 0 ) ; //<S2SV> } //<S2SV> } //<S2SV> write_mmcr0 ( cpuhw , cpuhw -> mmcr [ 0 ] ) ; //<S2SV> if ( nmi ) //<S2SV> nmi_exit ( ) ; //<S2SV> else //<S2SV> irq_exit ( ) ; //<S2SV> } //<S2SV> 