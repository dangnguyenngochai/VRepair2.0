static struct vm_area_struct * vma_to_resize ( unsigned long addr , //<S2SV> unsigned long old_len , unsigned long new_len , unsigned long * p ) //<S2SV> { //<S2SV> struct mm_struct * mm = current -> mm ; //<S2SV> struct vm_area_struct * vma = find_vma ( mm , addr ) ; //<S2SV> if ( ! vma || vma -> vm_start > addr ) //<S2SV> goto Efault ; //<S2SV> if ( is_vm_hugetlb_page ( vma ) ) //<S2SV> goto Einval ; //<S2SV> if ( old_len > vma -> vm_end - addr ) //<S2SV> goto Efault ; //<S2SV> if ( vma -> vm_flags & ( VM_DONTEXPAND | VM_PFNMAP ) ) { //<S2SV> if ( new_len > old_len ) //<S2SV> goto Efault ; //<S2SV> } //<S2SV> if ( vma -> vm_flags & VM_LOCKED ) { //<S2SV> unsigned long locked , lock_limit ; //<S2SV> locked = mm -> locked_vm << PAGE_SHIFT ; //<S2SV> lock_limit = rlimit ( RLIMIT_MEMLOCK ) ; //<S2SV> locked += new_len - old_len ; //<S2SV> if ( locked > lock_limit && ! capable ( CAP_IPC_LOCK ) ) //<S2SV> goto Eagain ; //<S2SV> } //<S2SV> if ( ! may_expand_vm ( mm , ( new_len - old_len ) >> PAGE_SHIFT ) ) //<S2SV> goto Enomem ; //<S2SV> if ( vma -> vm_flags & VM_ACCOUNT ) { //<S2SV> unsigned long charged = ( new_len - old_len ) >> PAGE_SHIFT ; //<S2SV> if ( security_vm_enough_memory ( charged ) ) //<S2SV> goto Efault ; //<S2SV> * p = charged ; //<S2SV> } //<S2SV> return vma ; //<S2SV> Efault : //<S2SV> return ERR_PTR ( - EFAULT ) ; //<S2SV> Einval : //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> Enomem : //<S2SV> return ERR_PTR ( - ENOMEM ) ; //<S2SV> Eagain : //<S2SV> return ERR_PTR ( - EAGAIN ) ; //<S2SV> } //<S2SV> 