static int create_qp_common ( struct mlx5_ib_dev * dev , struct ib_pd * pd , //<S2SV> struct ib_qp_init_attr * init_attr , //<S2SV> struct ib_udata * udata , struct mlx5_ib_qp * qp ) //<S2SV> { //<S2SV> struct mlx5_ib_resources * devr = & dev -> devr ; //<S2SV> int inlen = MLX5_ST_SZ_BYTES ( create_qp_in ) ; //<S2SV> struct mlx5_core_dev * mdev = dev -> mdev ; //<S2SV> struct mlx5_ib_create_qp_resp resp ; //<S2SV> struct mlx5_ib_cq * send_cq ; //<S2SV> struct mlx5_ib_cq * recv_cq ; //<S2SV> unsigned long flags ; //<S2SV> u32 uidx = MLX5_IB_DEFAULT_UIDX ; //<S2SV> struct mlx5_ib_create_qp ucmd ; //<S2SV> struct mlx5_ib_qp_base * base ; //<S2SV> int mlx5_st ; //<S2SV> void * qpc ; //<S2SV> u32 * in ; //<S2SV> int err ; //<S2SV> mutex_init ( & qp -> mutex ) ; //<S2SV> spin_lock_init ( & qp -> sq . lock ) ; //<S2SV> spin_lock_init ( & qp -> rq . lock ) ; //<S2SV> mlx5_st = to_mlx5_st ( init_attr -> qp_type ) ; //<S2SV> if ( mlx5_st < 0 ) //<S2SV> return - EINVAL ; //<S2SV> if ( init_attr -> rwq_ind_tbl ) { //<S2SV> if ( ! udata ) //<S2SV> return - ENOSYS ; //<S2SV> err = create_rss_raw_qp_tir ( dev , qp , pd , init_attr , udata ) ; //<S2SV> return err ; //<S2SV> } //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK ) { //<S2SV> if ( ! MLX5_CAP_GEN ( mdev , block_lb_mc ) ) { //<S2SV> mlx5_ib_dbg ( dev , "block<S2SV_blank>multicast<S2SV_blank>loopback<S2SV_blank>isn\'t<S2SV_blank>supported\\n" ) ; //<S2SV> return - EINVAL ; //<S2SV> } else { //<S2SV> qp -> flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK ; //<S2SV> } //<S2SV> } //<S2SV> if ( init_attr -> create_flags & //<S2SV> ( IB_QP_CREATE_CROSS_CHANNEL | //<S2SV> IB_QP_CREATE_MANAGED_SEND | //<S2SV> IB_QP_CREATE_MANAGED_RECV ) ) { //<S2SV> if ( ! MLX5_CAP_GEN ( mdev , cd ) ) { //<S2SV> mlx5_ib_dbg ( dev , "cross-channel<S2SV_blank>isn\'t<S2SV_blank>supported\\n" ) ; //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_CROSS_CHANNEL ) //<S2SV> qp -> flags |= MLX5_IB_QP_CROSS_CHANNEL ; //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_MANAGED_SEND ) //<S2SV> qp -> flags |= MLX5_IB_QP_MANAGED_SEND ; //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_MANAGED_RECV ) //<S2SV> qp -> flags |= MLX5_IB_QP_MANAGED_RECV ; //<S2SV> } //<S2SV> if ( init_attr -> qp_type == IB_QPT_UD && //<S2SV> ( init_attr -> create_flags & IB_QP_CREATE_IPOIB_UD_LSO ) ) //<S2SV> if ( ! MLX5_CAP_GEN ( mdev , ipoib_basic_offloads ) ) { //<S2SV> mlx5_ib_dbg ( dev , "ipoib<S2SV_blank>UD<S2SV_blank>lso<S2SV_blank>qp<S2SV_blank>isn\'t<S2SV_blank>supported\\n" ) ; //<S2SV> return - EOPNOTSUPP ; //<S2SV> } //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_SCATTER_FCS ) { //<S2SV> if ( init_attr -> qp_type != IB_QPT_RAW_PACKET ) { //<S2SV> mlx5_ib_dbg ( dev , "Scatter<S2SV_blank>FCS<S2SV_blank>is<S2SV_blank>supported<S2SV_blank>only<S2SV_blank>for<S2SV_blank>Raw<S2SV_blank>Packet<S2SV_blank>QPs" ) ; //<S2SV> return - EOPNOTSUPP ; //<S2SV> } //<S2SV> if ( ! MLX5_CAP_GEN ( dev -> mdev , eth_net_offloads ) || //<S2SV> ! MLX5_CAP_ETH ( dev -> mdev , scatter_fcs ) ) { //<S2SV> mlx5_ib_dbg ( dev , "Scatter<S2SV_blank>FCS<S2SV_blank>isn\'t<S2SV_blank>supported\\n" ) ; //<S2SV> return - EOPNOTSUPP ; //<S2SV> } //<S2SV> qp -> flags |= MLX5_IB_QP_CAP_SCATTER_FCS ; //<S2SV> } //<S2SV> if ( init_attr -> sq_sig_type == IB_SIGNAL_ALL_WR ) //<S2SV> qp -> sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE ; //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_CVLAN_STRIPPING ) { //<S2SV> if ( ! ( MLX5_CAP_GEN ( dev -> mdev , eth_net_offloads ) && //<S2SV> MLX5_CAP_ETH ( dev -> mdev , vlan_cap ) ) || //<S2SV> ( init_attr -> qp_type != IB_QPT_RAW_PACKET ) ) //<S2SV> return - EOPNOTSUPP ; //<S2SV> qp -> flags |= MLX5_IB_QP_CVLAN_STRIPPING ; //<S2SV> } //<S2SV> if ( pd && pd -> uobject ) { //<S2SV> if ( ib_copy_from_udata ( & ucmd , udata , sizeof ( ucmd ) ) ) { //<S2SV> mlx5_ib_dbg ( dev , "copy<S2SV_blank>failed\\n" ) ; //<S2SV> return - EFAULT ; //<S2SV> } //<S2SV> err = get_qp_user_index ( to_mucontext ( pd -> uobject -> context ) , //<S2SV> & ucmd , udata -> inlen , & uidx ) ; //<S2SV> if ( err ) //<S2SV> return err ; //<S2SV> qp -> wq_sig = ! ! ( ucmd . flags & MLX5_QP_FLAG_SIGNATURE ) ; //<S2SV> qp -> scat_cqe = ! ! ( ucmd . flags & MLX5_QP_FLAG_SCATTER_CQE ) ; //<S2SV> if ( ucmd . flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS ) { //<S2SV> if ( init_attr -> qp_type != IB_QPT_RAW_PACKET || //<S2SV> ! tunnel_offload_supported ( mdev ) ) { //<S2SV> mlx5_ib_dbg ( dev , "Tunnel<S2SV_blank>offload<S2SV_blank>isn\'t<S2SV_blank>supported\\n" ) ; //<S2SV> return - EOPNOTSUPP ; //<S2SV> } //<S2SV> qp -> tunnel_offload_en = true ; //<S2SV> } //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_SOURCE_QPN ) { //<S2SV> if ( init_attr -> qp_type != IB_QPT_UD || //<S2SV> ( MLX5_CAP_GEN ( dev -> mdev , port_type ) != //<S2SV> MLX5_CAP_PORT_TYPE_IB ) || //<S2SV> ! mlx5_get_flow_namespace ( dev -> mdev , MLX5_FLOW_NAMESPACE_BYPASS ) ) { //<S2SV> mlx5_ib_dbg ( dev , "Source<S2SV_blank>QP<S2SV_blank>option<S2SV_blank>isn\'t<S2SV_blank>supported\\n" ) ; //<S2SV> return - EOPNOTSUPP ; //<S2SV> } //<S2SV> qp -> flags |= MLX5_IB_QP_UNDERLAY ; //<S2SV> qp -> underlay_qpn = init_attr -> source_qpn ; //<S2SV> } //<S2SV> } else { //<S2SV> qp -> wq_sig = ! ! wq_signature ; //<S2SV> } //<S2SV> base = ( init_attr -> qp_type == IB_QPT_RAW_PACKET || //<S2SV> qp -> flags & MLX5_IB_QP_UNDERLAY ) ? //<S2SV> & qp -> raw_packet_qp . rq . base : //<S2SV> & qp -> trans_qp . base ; //<S2SV> qp -> has_rq = qp_has_rq ( init_attr ) ; //<S2SV> err = set_rq_size ( dev , & init_attr -> cap , qp -> has_rq , //<S2SV> qp , ( pd && pd -> uobject ) ? & ucmd : NULL ) ; //<S2SV> if ( err ) { //<S2SV> mlx5_ib_dbg ( dev , "err<S2SV_blank>%d\\n" , err ) ; //<S2SV> return err ; //<S2SV> } //<S2SV> if ( pd ) { //<S2SV> if ( pd -> uobject ) { //<S2SV> __u32 max_wqes = //<S2SV> 1 << MLX5_CAP_GEN ( mdev , log_max_qp_sz ) ; //<S2SV> mlx5_ib_dbg ( dev , "requested<S2SV_blank>sq_wqe_count<S2SV_blank>(%d)\\n" , ucmd . sq_wqe_count ) ; //<S2SV> if ( ucmd . rq_wqe_shift != qp -> rq . wqe_shift || //<S2SV> ucmd . rq_wqe_count != qp -> rq . wqe_cnt ) { //<S2SV> mlx5_ib_dbg ( dev , "invalid<S2SV_blank>rq<S2SV_blank>params\\n" ) ; //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> if ( ucmd . sq_wqe_count > max_wqes ) { //<S2SV> mlx5_ib_dbg ( dev , "requested<S2SV_blank>sq_wqe_count<S2SV_blank>(%d)<S2SV_blank>><S2SV_blank>max<S2SV_blank>allowed<S2SV_blank>(%d)\\n" , //<S2SV> ucmd . sq_wqe_count , max_wqes ) ; //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> if ( init_attr -> create_flags & //<S2SV> mlx5_ib_create_qp_sqpn_qp1 ( ) ) { //<S2SV> mlx5_ib_dbg ( dev , "user-space<S2SV_blank>is<S2SV_blank>not<S2SV_blank>allowed<S2SV_blank>to<S2SV_blank>create<S2SV_blank>UD<S2SV_blank>QPs<S2SV_blank>spoofing<S2SV_blank>as<S2SV_blank>QP1\\n" ) ; //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> err = create_user_qp ( dev , pd , qp , udata , init_attr , & in , //<S2SV> & resp , & inlen , base ) ; //<S2SV> if ( err ) //<S2SV> mlx5_ib_dbg ( dev , "err<S2SV_blank>%d\\n" , err ) ; //<S2SV> } else { //<S2SV> err = create_kernel_qp ( dev , init_attr , qp , & in , & inlen , //<S2SV> base ) ; //<S2SV> if ( err ) //<S2SV> mlx5_ib_dbg ( dev , "err<S2SV_blank>%d\\n" , err ) ; //<S2SV> } //<S2SV> if ( err ) //<S2SV> return err ; //<S2SV> } else { //<S2SV> in = kvzalloc ( inlen , GFP_KERNEL ) ; //<S2SV> if ( ! in ) //<S2SV> return - ENOMEM ; //<S2SV> qp -> create_type = MLX5_QP_EMPTY ; //<S2SV> } //<S2SV> if ( is_sqp ( init_attr -> qp_type ) ) //<S2SV> qp -> port = init_attr -> port_num ; //<S2SV> qpc = MLX5_ADDR_OF ( create_qp_in , in , qpc ) ; //<S2SV> MLX5_SET ( qpc , qpc , st , mlx5_st ) ; //<S2SV> MLX5_SET ( qpc , qpc , pm_state , MLX5_QP_PM_MIGRATED ) ; //<S2SV> if ( init_attr -> qp_type != MLX5_IB_QPT_REG_UMR ) //<S2SV> MLX5_SET ( qpc , qpc , pd , to_mpd ( pd ? pd : devr -> p0 ) -> pdn ) ; //<S2SV> else //<S2SV> MLX5_SET ( qpc , qpc , latency_sensitive , 1 ) ; //<S2SV> if ( qp -> wq_sig ) //<S2SV> MLX5_SET ( qpc , qpc , wq_signature , 1 ) ; //<S2SV> if ( qp -> flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK ) //<S2SV> MLX5_SET ( qpc , qpc , block_lb_mc , 1 ) ; //<S2SV> if ( qp -> flags & MLX5_IB_QP_CROSS_CHANNEL ) //<S2SV> MLX5_SET ( qpc , qpc , cd_master , 1 ) ; //<S2SV> if ( qp -> flags & MLX5_IB_QP_MANAGED_SEND ) //<S2SV> MLX5_SET ( qpc , qpc , cd_slave_send , 1 ) ; //<S2SV> if ( qp -> flags & MLX5_IB_QP_MANAGED_RECV ) //<S2SV> MLX5_SET ( qpc , qpc , cd_slave_receive , 1 ) ; //<S2SV> if ( qp -> scat_cqe && is_connected ( init_attr -> qp_type ) ) { //<S2SV> int rcqe_sz ; //<S2SV> int scqe_sz ; //<S2SV> rcqe_sz = mlx5_ib_get_cqe_size ( dev , init_attr -> recv_cq ) ; //<S2SV> scqe_sz = mlx5_ib_get_cqe_size ( dev , init_attr -> send_cq ) ; //<S2SV> if ( rcqe_sz == 128 ) //<S2SV> MLX5_SET ( qpc , qpc , cs_res , MLX5_RES_SCAT_DATA64_CQE ) ; //<S2SV> else //<S2SV> MLX5_SET ( qpc , qpc , cs_res , MLX5_RES_SCAT_DATA32_CQE ) ; //<S2SV> if ( init_attr -> sq_sig_type == IB_SIGNAL_ALL_WR ) { //<S2SV> if ( scqe_sz == 128 ) //<S2SV> MLX5_SET ( qpc , qpc , cs_req , MLX5_REQ_SCAT_DATA64_CQE ) ; //<S2SV> else //<S2SV> MLX5_SET ( qpc , qpc , cs_req , MLX5_REQ_SCAT_DATA32_CQE ) ; //<S2SV> } //<S2SV> } //<S2SV> if ( qp -> rq . wqe_cnt ) { //<S2SV> MLX5_SET ( qpc , qpc , log_rq_stride , qp -> rq . wqe_shift - 4 ) ; //<S2SV> MLX5_SET ( qpc , qpc , log_rq_size , ilog2 ( qp -> rq . wqe_cnt ) ) ; //<S2SV> } //<S2SV> MLX5_SET ( qpc , qpc , rq_type , get_rx_type ( qp , init_attr ) ) ; //<S2SV> if ( qp -> sq . wqe_cnt ) { //<S2SV> MLX5_SET ( qpc , qpc , log_sq_size , ilog2 ( qp -> sq . wqe_cnt ) ) ; //<S2SV> } else { //<S2SV> MLX5_SET ( qpc , qpc , no_sq , 1 ) ; //<S2SV> if ( init_attr -> srq && //<S2SV> init_attr -> srq -> srq_type == IB_SRQT_TM ) //<S2SV> MLX5_SET ( qpc , qpc , offload_type , //<S2SV> MLX5_QPC_OFFLOAD_TYPE_RNDV ) ; //<S2SV> } //<S2SV> switch ( init_attr -> qp_type ) { //<S2SV> case IB_QPT_XRC_TGT : //<S2SV> MLX5_SET ( qpc , qpc , cqn_rcv , to_mcq ( devr -> c0 ) -> mcq . cqn ) ; //<S2SV> MLX5_SET ( qpc , qpc , cqn_snd , to_mcq ( devr -> c0 ) -> mcq . cqn ) ; //<S2SV> MLX5_SET ( qpc , qpc , srqn_rmpn_xrqn , to_msrq ( devr -> s0 ) -> msrq . srqn ) ; //<S2SV> MLX5_SET ( qpc , qpc , xrcd , to_mxrcd ( init_attr -> xrcd ) -> xrcdn ) ; //<S2SV> break ; //<S2SV> case IB_QPT_XRC_INI : //<S2SV> MLX5_SET ( qpc , qpc , cqn_rcv , to_mcq ( devr -> c0 ) -> mcq . cqn ) ; //<S2SV> MLX5_SET ( qpc , qpc , xrcd , to_mxrcd ( devr -> x1 ) -> xrcdn ) ; //<S2SV> MLX5_SET ( qpc , qpc , srqn_rmpn_xrqn , to_msrq ( devr -> s0 ) -> msrq . srqn ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> if ( init_attr -> srq ) { //<S2SV> MLX5_SET ( qpc , qpc , xrcd , to_mxrcd ( devr -> x0 ) -> xrcdn ) ; //<S2SV> MLX5_SET ( qpc , qpc , srqn_rmpn_xrqn , to_msrq ( init_attr -> srq ) -> msrq . srqn ) ; //<S2SV> } else { //<S2SV> MLX5_SET ( qpc , qpc , xrcd , to_mxrcd ( devr -> x1 ) -> xrcdn ) ; //<S2SV> MLX5_SET ( qpc , qpc , srqn_rmpn_xrqn , to_msrq ( devr -> s1 ) -> msrq . srqn ) ; //<S2SV> } //<S2SV> } //<S2SV> if ( init_attr -> send_cq ) //<S2SV> MLX5_SET ( qpc , qpc , cqn_snd , to_mcq ( init_attr -> send_cq ) -> mcq . cqn ) ; //<S2SV> if ( init_attr -> recv_cq ) //<S2SV> MLX5_SET ( qpc , qpc , cqn_rcv , to_mcq ( init_attr -> recv_cq ) -> mcq . cqn ) ; //<S2SV> MLX5_SET64 ( qpc , qpc , dbr_addr , qp -> db . dma ) ; //<S2SV> if ( MLX5_CAP_GEN ( mdev , cqe_version ) == MLX5_CQE_VERSION_V1 ) //<S2SV> MLX5_SET ( qpc , qpc , user_index , uidx ) ; //<S2SV> if ( init_attr -> qp_type == IB_QPT_UD && //<S2SV> ( init_attr -> create_flags & IB_QP_CREATE_IPOIB_UD_LSO ) ) { //<S2SV> MLX5_SET ( qpc , qpc , ulp_stateless_offload_mode , 1 ) ; //<S2SV> qp -> flags |= MLX5_IB_QP_LSO ; //<S2SV> } //<S2SV> if ( init_attr -> create_flags & IB_QP_CREATE_PCI_WRITE_END_PADDING ) { //<S2SV> if ( ! MLX5_CAP_GEN ( dev -> mdev , end_pad ) ) { //<S2SV> mlx5_ib_dbg ( dev , "scatter<S2SV_blank>end<S2SV_blank>padding<S2SV_blank>is<S2SV_blank>not<S2SV_blank>supported\\n" ) ; //<S2SV> err = - EOPNOTSUPP ; //<S2SV> goto err ; //<S2SV> } else if ( init_attr -> qp_type != IB_QPT_RAW_PACKET ) { //<S2SV> MLX5_SET ( qpc , qpc , end_padding_mode , //<S2SV> MLX5_WQ_END_PAD_MODE_ALIGN ) ; //<S2SV> } else { //<S2SV> qp -> flags |= MLX5_IB_QP_PCI_WRITE_END_PADDING ; //<S2SV> } //<S2SV> } //<S2SV> if ( inlen < 0 ) { //<S2SV> err = - EINVAL ; //<S2SV> goto err ; //<S2SV> } //<S2SV> if ( init_attr -> qp_type == IB_QPT_RAW_PACKET || //<S2SV> qp -> flags & MLX5_IB_QP_UNDERLAY ) { //<S2SV> qp -> raw_packet_qp . sq . ubuffer . buf_addr = ucmd . sq_buf_addr ; //<S2SV> raw_packet_qp_copy_info ( qp , & qp -> raw_packet_qp ) ; //<S2SV> err = create_raw_packet_qp ( dev , qp , in , inlen , pd ) ; //<S2SV> } else { //<S2SV> err = mlx5_core_create_qp ( dev -> mdev , & base -> mqp , in , inlen ) ; //<S2SV> } //<S2SV> if ( err ) { //<S2SV> mlx5_ib_dbg ( dev , "create<S2SV_blank>qp<S2SV_blank>failed\\n" ) ; //<S2SV> goto err_create ; //<S2SV> } //<S2SV> kvfree ( in ) ; //<S2SV> base -> container_mibqp = qp ; //<S2SV> base -> mqp . event = mlx5_ib_qp_event ; //<S2SV> get_cqs ( init_attr -> qp_type , init_attr -> send_cq , init_attr -> recv_cq , //<S2SV> & send_cq , & recv_cq ) ; //<S2SV> spin_lock_irqsave ( & dev -> reset_flow_resource_lock , flags ) ; //<S2SV> mlx5_ib_lock_cqs ( send_cq , recv_cq ) ; //<S2SV> list_add_tail ( & qp -> qps_list , & dev -> qp_list ) ; //<S2SV> if ( send_cq ) //<S2SV> list_add_tail ( & qp -> cq_send_list , & send_cq -> list_send_qp ) ; //<S2SV> if ( recv_cq ) //<S2SV> list_add_tail ( & qp -> cq_recv_list , & recv_cq -> list_recv_qp ) ; //<S2SV> mlx5_ib_unlock_cqs ( send_cq , recv_cq ) ; //<S2SV> spin_unlock_irqrestore ( & dev -> reset_flow_resource_lock , flags ) ; //<S2SV> return 0 ; //<S2SV> err_create : //<S2SV> if ( qp -> create_type == MLX5_QP_USER ) //<S2SV> destroy_qp_user ( dev , pd , qp , base ) ; //<S2SV> else if ( qp -> create_type == MLX5_QP_KERNEL ) //<S2SV> destroy_qp_kernel ( dev , qp ) ; //<S2SV> err : //<S2SV> kvfree ( in ) ; //<S2SV> return err ; //<S2SV> } //<S2SV> 