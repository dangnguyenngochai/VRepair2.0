static int em_syscall ( struct x86_emulate_ctxt * ctxt ) //<S2SV> { //<S2SV> struct x86_emulate_ops * ops = ctxt -> ops ; //<S2SV> struct desc_struct cs , ss ; //<S2SV> u64 msr_data ; //<S2SV> u16 cs_sel , ss_sel ; //<S2SV> u64 efer = 0 ; //<S2SV> if ( ctxt -> mode == X86EMUL_MODE_REAL || //<S2SV> ctxt -> mode == X86EMUL_MODE_VM86 ) //<S2SV> return emulate_ud ( ctxt ) ; //<S2SV> if ( ! ( em_syscall_is_enabled ( ctxt ) ) ) //<S2SV> return emulate_ud ( ctxt ) ; //<S2SV> ops -> get_msr ( ctxt , MSR_EFER , & efer ) ; //<S2SV> setup_syscalls_segments ( ctxt , & cs , & ss ) ; //<S2SV> if ( ! ( efer & EFER_SCE ) ) //<S2SV> return emulate_ud ( ctxt ) ; //<S2SV> ops -> get_msr ( ctxt , MSR_STAR , & msr_data ) ; //<S2SV> msr_data >>= 32 ; //<S2SV> cs_sel = ( u16 ) ( msr_data & 0xfffc ) ; //<S2SV> ss_sel = ( u16 ) ( msr_data + 8 ) ; //<S2SV> if ( efer & EFER_LMA ) { //<S2SV> cs . d = 0 ; //<S2SV> cs . l = 1 ; //<S2SV> } //<S2SV> ops -> set_segment ( ctxt , cs_sel , & cs , 0 , VCPU_SREG_CS ) ; //<S2SV> ops -> set_segment ( ctxt , ss_sel , & ss , 0 , VCPU_SREG_SS ) ; //<S2SV> ctxt -> regs [ VCPU_REGS_RCX ] = ctxt -> _eip ; //<S2SV> if ( efer & EFER_LMA ) { //<S2SV> # ifdef CONFIG_X86_64 //<S2SV> ctxt -> regs [ VCPU_REGS_R11 ] = ctxt -> eflags & ~ EFLG_RF ; //<S2SV> ops -> get_msr ( ctxt , //<S2SV> ctxt -> mode == X86EMUL_MODE_PROT64 ? //<S2SV> MSR_LSTAR : MSR_CSTAR , & msr_data ) ; //<S2SV> ctxt -> _eip = msr_data ; //<S2SV> ops -> get_msr ( ctxt , MSR_SYSCALL_MASK , & msr_data ) ; //<S2SV> ctxt -> eflags &= ~ ( msr_data | EFLG_RF ) ; //<S2SV> # endif //<S2SV> } else { //<S2SV> ops -> get_msr ( ctxt , MSR_STAR , & msr_data ) ; //<S2SV> ctxt -> _eip = ( u32 ) msr_data ; //<S2SV> ctxt -> eflags &= ~ ( EFLG_VM | EFLG_IF | EFLG_RF ) ; //<S2SV> } //<S2SV> return X86EMUL_CONTINUE ; //<S2SV> } //<S2SV> 