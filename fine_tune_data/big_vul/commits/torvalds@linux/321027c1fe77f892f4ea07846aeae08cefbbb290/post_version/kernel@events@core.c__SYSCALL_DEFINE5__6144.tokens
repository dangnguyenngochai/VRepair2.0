SYSCALL_DEFINE5 ( perf_event_open , //<S2SV> struct perf_event_attr __user * , attr_uptr , //<S2SV> pid_t , pid , int , cpu , int , group_fd , unsigned long , flags ) //<S2SV> { //<S2SV> struct perf_event * group_leader = NULL , * output_event = NULL ; //<S2SV> struct perf_event * event , * sibling ; //<S2SV> struct perf_event_attr attr ; //<S2SV> struct perf_event_context * ctx , * uninitialized_var ( gctx ) ; //<S2SV> struct file * event_file = NULL ; //<S2SV> struct fd group = { NULL , 0 } ; //<S2SV> struct task_struct * task = NULL ; //<S2SV> struct pmu * pmu ; //<S2SV> int event_fd ; //<S2SV> int move_group = 0 ; //<S2SV> int err ; //<S2SV> int f_flags = O_RDWR ; //<S2SV> int cgroup_fd = - 1 ; //<S2SV> if ( flags & ~ PERF_FLAG_ALL ) //<S2SV> return - EINVAL ; //<S2SV> err = perf_copy_attr ( attr_uptr , & attr ) ; //<S2SV> if ( err ) //<S2SV> return err ; //<S2SV> if ( ! attr . exclude_kernel ) { //<S2SV> if ( perf_paranoid_kernel ( ) && ! capable ( CAP_SYS_ADMIN ) ) //<S2SV> return - EACCES ; //<S2SV> } //<S2SV> if ( attr . freq ) { //<S2SV> if ( attr . sample_freq > sysctl_perf_event_sample_rate ) //<S2SV> return - EINVAL ; //<S2SV> } else { //<S2SV> if ( attr . sample_period & ( 1ULL << 63 ) ) //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> if ( ! attr . sample_max_stack ) //<S2SV> attr . sample_max_stack = sysctl_perf_event_max_stack ; //<S2SV> if ( ( flags & PERF_FLAG_PID_CGROUP ) && ( pid == - 1 || cpu == - 1 ) ) //<S2SV> return - EINVAL ; //<S2SV> if ( flags & PERF_FLAG_FD_CLOEXEC ) //<S2SV> f_flags |= O_CLOEXEC ; //<S2SV> event_fd = get_unused_fd_flags ( f_flags ) ; //<S2SV> if ( event_fd < 0 ) //<S2SV> return event_fd ; //<S2SV> if ( group_fd != - 1 ) { //<S2SV> err = perf_fget_light ( group_fd , & group ) ; //<S2SV> if ( err ) //<S2SV> goto err_fd ; //<S2SV> group_leader = group . file -> private_data ; //<S2SV> if ( flags & PERF_FLAG_FD_OUTPUT ) //<S2SV> output_event = group_leader ; //<S2SV> if ( flags & PERF_FLAG_FD_NO_GROUP ) //<S2SV> group_leader = NULL ; //<S2SV> } //<S2SV> if ( pid != - 1 && ! ( flags & PERF_FLAG_PID_CGROUP ) ) { //<S2SV> task = find_lively_task_by_vpid ( pid ) ; //<S2SV> if ( IS_ERR ( task ) ) { //<S2SV> err = PTR_ERR ( task ) ; //<S2SV> goto err_group_fd ; //<S2SV> } //<S2SV> } //<S2SV> if ( task && group_leader && //<S2SV> group_leader -> attr . inherit != attr . inherit ) { //<S2SV> err = - EINVAL ; //<S2SV> goto err_task ; //<S2SV> } //<S2SV> get_online_cpus ( ) ; //<S2SV> if ( task ) { //<S2SV> err = mutex_lock_interruptible ( & task -> signal -> cred_guard_mutex ) ; //<S2SV> if ( err ) //<S2SV> goto err_cpus ; //<S2SV> err = - EACCES ; //<S2SV> if ( ! ptrace_may_access ( task , PTRACE_MODE_READ_REALCREDS ) ) //<S2SV> goto err_cred ; //<S2SV> } //<S2SV> if ( flags & PERF_FLAG_PID_CGROUP ) //<S2SV> cgroup_fd = pid ; //<S2SV> event = perf_event_alloc ( & attr , cpu , task , group_leader , NULL , //<S2SV> NULL , NULL , cgroup_fd ) ; //<S2SV> if ( IS_ERR ( event ) ) { //<S2SV> err = PTR_ERR ( event ) ; //<S2SV> goto err_cred ; //<S2SV> } //<S2SV> if ( is_sampling_event ( event ) ) { //<S2SV> if ( event -> pmu -> capabilities & PERF_PMU_CAP_NO_INTERRUPT ) { //<S2SV> err = - EOPNOTSUPP ; //<S2SV> goto err_alloc ; //<S2SV> } //<S2SV> } //<S2SV> pmu = event -> pmu ; //<S2SV> if ( attr . use_clockid ) { //<S2SV> err = perf_event_set_clock ( event , attr . clockid ) ; //<S2SV> if ( err ) //<S2SV> goto err_alloc ; //<S2SV> } //<S2SV> if ( pmu -> task_ctx_nr == perf_sw_context ) //<S2SV> event -> event_caps |= PERF_EV_CAP_SOFTWARE ; //<S2SV> if ( group_leader && //<S2SV> ( is_software_event ( event ) != is_software_event ( group_leader ) ) ) { //<S2SV> if ( is_software_event ( event ) ) { //<S2SV> pmu = group_leader -> pmu ; //<S2SV> } else if ( is_software_event ( group_leader ) && //<S2SV> ( group_leader -> group_caps & PERF_EV_CAP_SOFTWARE ) ) { //<S2SV> move_group = 1 ; //<S2SV> } //<S2SV> } //<S2SV> ctx = find_get_context ( pmu , task , event ) ; //<S2SV> if ( IS_ERR ( ctx ) ) { //<S2SV> err = PTR_ERR ( ctx ) ; //<S2SV> goto err_alloc ; //<S2SV> } //<S2SV> if ( ( pmu -> capabilities & PERF_PMU_CAP_EXCLUSIVE ) && group_leader ) { //<S2SV> err = - EBUSY ; //<S2SV> goto err_context ; //<S2SV> } //<S2SV> if ( group_leader ) { //<S2SV> err = - EINVAL ; //<S2SV> if ( group_leader -> group_leader != group_leader ) //<S2SV> goto err_context ; //<S2SV> if ( group_leader -> clock != event -> clock ) //<S2SV> goto err_context ; //<S2SV> if ( move_group ) { //<S2SV> if ( group_leader -> ctx -> task != ctx -> task ) //<S2SV> goto err_context ; //<S2SV> if ( group_leader -> cpu != event -> cpu ) //<S2SV> goto err_context ; //<S2SV> } else { //<S2SV> if ( group_leader -> ctx != ctx ) //<S2SV> goto err_context ; //<S2SV> } //<S2SV> if ( attr . exclusive || attr . pinned ) //<S2SV> goto err_context ; //<S2SV> } //<S2SV> if ( output_event ) { //<S2SV> err = perf_event_set_output ( event , output_event ) ; //<S2SV> if ( err ) //<S2SV> goto err_context ; //<S2SV> } //<S2SV> event_file = anon_inode_getfile ( "[perf_event]" , & perf_fops , event , //<S2SV> f_flags ) ; //<S2SV> if ( IS_ERR ( event_file ) ) { //<S2SV> err = PTR_ERR ( event_file ) ; //<S2SV> event_file = NULL ; //<S2SV> goto err_context ; //<S2SV> } //<S2SV> if ( move_group ) { //<S2SV> gctx = __perf_event_ctx_lock_double ( group_leader , ctx ) ; //<S2SV> if ( gctx -> task == TASK_TOMBSTONE ) { //<S2SV> err = - ESRCH ; //<S2SV> goto err_locked ; //<S2SV> } //<S2SV> if ( ! ( group_leader -> group_caps & PERF_EV_CAP_SOFTWARE ) ) { //<S2SV> if ( gctx != ctx ) { //<S2SV> err = - EINVAL ; //<S2SV> goto err_locked ; //<S2SV> } else { //<S2SV> perf_event_ctx_unlock ( group_leader , gctx ) ; //<S2SV> move_group = 0 ; //<S2SV> } //<S2SV> } //<S2SV> } else { //<S2SV> mutex_lock ( & ctx -> mutex ) ; //<S2SV> } //<S2SV> if ( ctx -> task == TASK_TOMBSTONE ) { //<S2SV> err = - ESRCH ; //<S2SV> goto err_locked ; //<S2SV> } //<S2SV> if ( ! perf_event_validate_size ( event ) ) { //<S2SV> err = - E2BIG ; //<S2SV> goto err_locked ; //<S2SV> } //<S2SV> if ( ! exclusive_event_installable ( event , ctx ) ) { //<S2SV> WARN_ON_ONCE ( move_group ) ; //<S2SV> err = - EBUSY ; //<S2SV> goto err_locked ; //<S2SV> } //<S2SV> WARN_ON_ONCE ( ctx -> parent_ctx ) ; //<S2SV> if ( move_group ) { //<S2SV> perf_remove_from_context ( group_leader , 0 ) ; //<S2SV> list_for_each_entry ( sibling , & group_leader -> sibling_list , //<S2SV> group_entry ) { //<S2SV> perf_remove_from_context ( sibling , 0 ) ; //<S2SV> put_ctx ( gctx ) ; //<S2SV> } //<S2SV> synchronize_rcu ( ) ; //<S2SV> list_for_each_entry ( sibling , & group_leader -> sibling_list , //<S2SV> group_entry ) { //<S2SV> perf_event__state_init ( sibling ) ; //<S2SV> perf_install_in_context ( ctx , sibling , sibling -> cpu ) ; //<S2SV> get_ctx ( ctx ) ; //<S2SV> } //<S2SV> perf_event__state_init ( group_leader ) ; //<S2SV> perf_install_in_context ( ctx , group_leader , group_leader -> cpu ) ; //<S2SV> get_ctx ( ctx ) ; //<S2SV> put_ctx ( gctx ) ; //<S2SV> } //<S2SV> perf_event__header_size ( event ) ; //<S2SV> perf_event__id_header_size ( event ) ; //<S2SV> event -> owner = current ; //<S2SV> perf_install_in_context ( ctx , event , event -> cpu ) ; //<S2SV> perf_unpin_context ( ctx ) ; //<S2SV> if ( move_group ) //<S2SV> perf_event_ctx_unlock ( group_leader , gctx ) ; //<S2SV> mutex_unlock ( & ctx -> mutex ) ; //<S2SV> if ( task ) { //<S2SV> mutex_unlock ( & task -> signal -> cred_guard_mutex ) ; //<S2SV> put_task_struct ( task ) ; //<S2SV> } //<S2SV> put_online_cpus ( ) ; //<S2SV> mutex_lock ( & current -> perf_event_mutex ) ; //<S2SV> list_add_tail ( & event -> owner_entry , & current -> perf_event_list ) ; //<S2SV> mutex_unlock ( & current -> perf_event_mutex ) ; //<S2SV> fdput ( group ) ; //<S2SV> fd_install ( event_fd , event_file ) ; //<S2SV> return event_fd ; //<S2SV> err_locked : //<S2SV> if ( move_group ) //<S2SV> perf_event_ctx_unlock ( group_leader , gctx ) ; //<S2SV> mutex_unlock ( & ctx -> mutex ) ; //<S2SV> fput ( event_file ) ; //<S2SV> err_context : //<S2SV> perf_unpin_context ( ctx ) ; //<S2SV> put_ctx ( ctx ) ; //<S2SV> err_alloc : //<S2SV> if ( ! event_file ) //<S2SV> free_event ( event ) ; //<S2SV> err_cred : //<S2SV> if ( task ) //<S2SV> mutex_unlock ( & task -> signal -> cred_guard_mutex ) ; //<S2SV> err_cpus : //<S2SV> put_online_cpus ( ) ; //<S2SV> err_task : //<S2SV> if ( task ) //<S2SV> put_task_struct ( task ) ; //<S2SV> err_group_fd : //<S2SV> fdput ( group ) ; //<S2SV> err_fd : //<S2SV> put_unused_fd ( event_fd ) ; //<S2SV> return err ; //<S2SV> } //<S2SV> 