static int tpacket_rcv ( struct sk_buff * skb , struct net_device * dev , //<S2SV> struct packet_type * pt , struct net_device * orig_dev ) //<S2SV> { //<S2SV> struct sock * sk ; //<S2SV> struct packet_sock * po ; //<S2SV> struct sockaddr_ll * sll ; //<S2SV> union tpacket_uhdr h ; //<S2SV> u8 * skb_head = skb -> data ; //<S2SV> int skb_len = skb -> len ; //<S2SV> unsigned int snaplen , res ; //<S2SV> unsigned long status = TP_STATUS_USER ; //<S2SV> unsigned short macoff , netoff , hdrlen ; //<S2SV> struct sk_buff * copy_skb = NULL ; //<S2SV> struct timespec ts ; //<S2SV> __u32 ts_status ; //<S2SV> bool is_drop_n_account = false ; //<S2SV> BUILD_BUG_ON ( TPACKET_ALIGN ( sizeof ( * h . h2 ) ) != 32 ) ; //<S2SV> BUILD_BUG_ON ( TPACKET_ALIGN ( sizeof ( * h . h3 ) ) != 48 ) ; //<S2SV> if ( skb -> pkt_type == PACKET_LOOPBACK ) //<S2SV> goto drop ; //<S2SV> sk = pt -> af_packet_priv ; //<S2SV> po = pkt_sk ( sk ) ; //<S2SV> if ( ! net_eq ( dev_net ( dev ) , sock_net ( sk ) ) ) //<S2SV> goto drop ; //<S2SV> if ( dev -> header_ops ) { //<S2SV> if ( sk -> sk_type != SOCK_DGRAM ) //<S2SV> skb_push ( skb , skb -> data - skb_mac_header ( skb ) ) ; //<S2SV> else if ( skb -> pkt_type == PACKET_OUTGOING ) { //<S2SV> skb_pull ( skb , skb_network_offset ( skb ) ) ; //<S2SV> } //<S2SV> } //<S2SV> snaplen = skb -> len ; //<S2SV> res = run_filter ( skb , sk , snaplen ) ; //<S2SV> if ( ! res ) //<S2SV> goto drop_n_restore ; //<S2SV> if ( skb -> ip_summed == CHECKSUM_PARTIAL ) //<S2SV> status |= TP_STATUS_CSUMNOTREADY ; //<S2SV> else if ( skb -> pkt_type != PACKET_OUTGOING && //<S2SV> ( skb -> ip_summed == CHECKSUM_COMPLETE || //<S2SV> skb_csum_unnecessary ( skb ) ) ) //<S2SV> status |= TP_STATUS_CSUM_VALID ; //<S2SV> if ( snaplen > res ) //<S2SV> snaplen = res ; //<S2SV> if ( sk -> sk_type == SOCK_DGRAM ) { //<S2SV> macoff = netoff = TPACKET_ALIGN ( po -> tp_hdrlen ) + 16 + //<S2SV> po -> tp_reserve ; //<S2SV> } else { //<S2SV> unsigned int maclen = skb_network_offset ( skb ) ; //<S2SV> netoff = TPACKET_ALIGN ( po -> tp_hdrlen + //<S2SV> ( maclen < 16 ? 16 : maclen ) ) + //<S2SV> po -> tp_reserve ; //<S2SV> if ( po -> has_vnet_hdr ) //<S2SV> netoff += sizeof ( struct virtio_net_hdr ) ; //<S2SV> macoff = netoff - maclen ; //<S2SV> } //<S2SV> if ( po -> tp_version <= TPACKET_V2 ) { //<S2SV> if ( macoff + snaplen > po -> rx_ring . frame_size ) { //<S2SV> if ( po -> copy_thresh && //<S2SV> atomic_read ( & sk -> sk_rmem_alloc ) < sk -> sk_rcvbuf ) { //<S2SV> if ( skb_shared ( skb ) ) { //<S2SV> copy_skb = skb_clone ( skb , GFP_ATOMIC ) ; //<S2SV> } else { //<S2SV> copy_skb = skb_get ( skb ) ; //<S2SV> skb_head = skb -> data ; //<S2SV> } //<S2SV> if ( copy_skb ) //<S2SV> skb_set_owner_r ( copy_skb , sk ) ; //<S2SV> } //<S2SV> snaplen = po -> rx_ring . frame_size - macoff ; //<S2SV> if ( ( int ) snaplen < 0 ) //<S2SV> snaplen = 0 ; //<S2SV> } //<S2SV> } else if ( unlikely ( macoff + snaplen > //<S2SV> GET_PBDQC_FROM_RB ( & po -> rx_ring ) -> max_frame_len ) ) { //<S2SV> u32 nval ; //<S2SV> nval = GET_PBDQC_FROM_RB ( & po -> rx_ring ) -> max_frame_len - macoff ; //<S2SV> pr_err_once ( "tpacket_rcv:<S2SV_blank>packet<S2SV_blank>too<S2SV_blank>big,<S2SV_blank>clamped<S2SV_blank>from<S2SV_blank>%u<S2SV_blank>to<S2SV_blank>%u.<S2SV_blank>macoff=%u\\n" , //<S2SV> snaplen , nval , macoff ) ; //<S2SV> snaplen = nval ; //<S2SV> if ( unlikely ( ( int ) snaplen < 0 ) ) { //<S2SV> snaplen = 0 ; //<S2SV> macoff = GET_PBDQC_FROM_RB ( & po -> rx_ring ) -> max_frame_len ; //<S2SV> } //<S2SV> } //<S2SV> spin_lock ( & sk -> sk_receive_queue . lock ) ; //<S2SV> h . raw = packet_current_rx_frame ( po , skb , //<S2SV> TP_STATUS_KERNEL , ( macoff + snaplen ) ) ; //<S2SV> if ( ! h . raw ) //<S2SV> goto drop_n_account ; //<S2SV> if ( po -> tp_version <= TPACKET_V2 ) { //<S2SV> packet_increment_rx_head ( po , & po -> rx_ring ) ; //<S2SV> if ( po -> stats . stats1 . tp_drops ) //<S2SV> status |= TP_STATUS_LOSING ; //<S2SV> } //<S2SV> po -> stats . stats1 . tp_packets ++ ; //<S2SV> if ( copy_skb ) { //<S2SV> status |= TP_STATUS_COPY ; //<S2SV> __skb_queue_tail ( & sk -> sk_receive_queue , copy_skb ) ; //<S2SV> } //<S2SV> spin_unlock ( & sk -> sk_receive_queue . lock ) ; //<S2SV> if ( po -> has_vnet_hdr ) { //<S2SV> if ( virtio_net_hdr_from_skb ( skb , h . raw + macoff - //<S2SV> sizeof ( struct virtio_net_hdr ) , //<S2SV> vio_le ( ) , true ) ) { //<S2SV> spin_lock ( & sk -> sk_receive_queue . lock ) ; //<S2SV> goto drop_n_account ; //<S2SV> } //<S2SV> } //<S2SV> skb_copy_bits ( skb , 0 , h . raw + macoff , snaplen ) ; //<S2SV> if ( ! ( ts_status = tpacket_get_timestamp ( skb , & ts , po -> tp_tstamp ) ) ) //<S2SV> getnstimeofday ( & ts ) ; //<S2SV> status |= ts_status ; //<S2SV> switch ( po -> tp_version ) { //<S2SV> case TPACKET_V1 : //<S2SV> h . h1 -> tp_len = skb -> len ; //<S2SV> h . h1 -> tp_snaplen = snaplen ; //<S2SV> h . h1 -> tp_mac = macoff ; //<S2SV> h . h1 -> tp_net = netoff ; //<S2SV> h . h1 -> tp_sec = ts . tv_sec ; //<S2SV> h . h1 -> tp_usec = ts . tv_nsec / NSEC_PER_USEC ; //<S2SV> hdrlen = sizeof ( * h . h1 ) ; //<S2SV> break ; //<S2SV> case TPACKET_V2 : //<S2SV> h . h2 -> tp_len = skb -> len ; //<S2SV> h . h2 -> tp_snaplen = snaplen ; //<S2SV> h . h2 -> tp_mac = macoff ; //<S2SV> h . h2 -> tp_net = netoff ; //<S2SV> h . h2 -> tp_sec = ts . tv_sec ; //<S2SV> h . h2 -> tp_nsec = ts . tv_nsec ; //<S2SV> if ( skb_vlan_tag_present ( skb ) ) { //<S2SV> h . h2 -> tp_vlan_tci = skb_vlan_tag_get ( skb ) ; //<S2SV> h . h2 -> tp_vlan_tpid = ntohs ( skb -> vlan_proto ) ; //<S2SV> status |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID ; //<S2SV> } else { //<S2SV> h . h2 -> tp_vlan_tci = 0 ; //<S2SV> h . h2 -> tp_vlan_tpid = 0 ; //<S2SV> } //<S2SV> memset ( h . h2 -> tp_padding , 0 , sizeof ( h . h2 -> tp_padding ) ) ; //<S2SV> hdrlen = sizeof ( * h . h2 ) ; //<S2SV> break ; //<S2SV> case TPACKET_V3 : //<S2SV> h . h3 -> tp_status |= status ; //<S2SV> h . h3 -> tp_len = skb -> len ; //<S2SV> h . h3 -> tp_snaplen = snaplen ; //<S2SV> h . h3 -> tp_mac = macoff ; //<S2SV> h . h3 -> tp_net = netoff ; //<S2SV> h . h3 -> tp_sec = ts . tv_sec ; //<S2SV> h . h3 -> tp_nsec = ts . tv_nsec ; //<S2SV> memset ( h . h3 -> tp_padding , 0 , sizeof ( h . h3 -> tp_padding ) ) ; //<S2SV> hdrlen = sizeof ( * h . h3 ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> BUG ( ) ; //<S2SV> } //<S2SV> sll = h . raw + TPACKET_ALIGN ( hdrlen ) ; //<S2SV> sll -> sll_halen = dev_parse_header ( skb , sll -> sll_addr ) ; //<S2SV> sll -> sll_family = AF_PACKET ; //<S2SV> sll -> sll_hatype = dev -> type ; //<S2SV> sll -> sll_protocol = skb -> protocol ; //<S2SV> sll -> sll_pkttype = skb -> pkt_type ; //<S2SV> if ( unlikely ( po -> origdev ) ) //<S2SV> sll -> sll_ifindex = orig_dev -> ifindex ; //<S2SV> else //<S2SV> sll -> sll_ifindex = dev -> ifindex ; //<S2SV> smp_mb ( ) ; //<S2SV> # if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1 //<S2SV> if ( po -> tp_version <= TPACKET_V2 ) { //<S2SV> u8 * start , * end ; //<S2SV> end = ( u8 * ) PAGE_ALIGN ( ( unsigned long ) h . raw + //<S2SV> macoff + snaplen ) ; //<S2SV> for ( start = h . raw ; start < end ; start += PAGE_SIZE ) //<S2SV> flush_dcache_page ( pgv_to_page ( start ) ) ; //<S2SV> } //<S2SV> smp_wmb ( ) ; //<S2SV> # endif //<S2SV> if ( po -> tp_version <= TPACKET_V2 ) { //<S2SV> __packet_set_status ( po , h . raw , status ) ; //<S2SV> sk -> sk_data_ready ( sk ) ; //<S2SV> } else { //<S2SV> prb_clear_blk_fill_status ( & po -> rx_ring ) ; //<S2SV> } //<S2SV> drop_n_restore : //<S2SV> if ( skb_head != skb -> data && skb_shared ( skb ) ) { //<S2SV> skb -> data = skb_head ; //<S2SV> skb -> len = skb_len ; //<S2SV> } //<S2SV> drop : //<S2SV> if ( ! is_drop_n_account ) //<S2SV> consume_skb ( skb ) ; //<S2SV> else //<S2SV> kfree_skb ( skb ) ; //<S2SV> return 0 ; //<S2SV> drop_n_account : //<S2SV> is_drop_n_account = true ; //<S2SV> po -> stats . stats1 . tp_drops ++ ; //<S2SV> spin_unlock ( & sk -> sk_receive_queue . lock ) ; //<S2SV> sk -> sk_data_ready ( sk ) ; //<S2SV> kfree_skb ( copy_skb ) ; //<S2SV> goto drop_n_restore ; //<S2SV> } //<S2SV> 