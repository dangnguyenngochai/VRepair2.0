static long //<S2SV> sg_ioctl ( struct file * filp , unsigned int cmd_in , unsigned long arg ) //<S2SV> { //<S2SV> void __user * p = ( void __user * ) arg ; //<S2SV> int __user * ip = p ; //<S2SV> int result , val , read_only ; //<S2SV> Sg_device * sdp ; //<S2SV> Sg_fd * sfp ; //<S2SV> Sg_request * srp ; //<S2SV> unsigned long iflags ; //<S2SV> if ( ( ! ( sfp = ( Sg_fd * ) filp -> private_data ) ) || ( ! ( sdp = sfp -> parentdp ) ) ) //<S2SV> return - ENXIO ; //<S2SV> SCSI_LOG_TIMEOUT ( 3 , sg_printk ( KERN_INFO , sdp , //<S2SV> "sg_ioctl:<S2SV_blank>cmd=0x%x\\n" , ( int ) cmd_in ) ) ; //<S2SV> read_only = ( O_RDWR != ( filp -> f_flags & O_ACCMODE ) ) ; //<S2SV> switch ( cmd_in ) { //<S2SV> case SG_IO : //<S2SV> if ( atomic_read ( & sdp -> detaching ) ) //<S2SV> return - ENODEV ; //<S2SV> if ( ! scsi_block_when_processing_errors ( sdp -> device ) ) //<S2SV> return - ENXIO ; //<S2SV> if ( ! access_ok ( VERIFY_WRITE , p , SZ_SG_IO_HDR ) ) //<S2SV> return - EFAULT ; //<S2SV> result = sg_new_write ( sfp , filp , p , SZ_SG_IO_HDR , //<S2SV> 1 , read_only , 1 , & srp ) ; //<S2SV> if ( result < 0 ) //<S2SV> return result ; //<S2SV> result = wait_event_interruptible ( sfp -> read_wait , //<S2SV> ( srp_done ( sfp , srp ) || atomic_read ( & sdp -> detaching ) ) ) ; //<S2SV> if ( atomic_read ( & sdp -> detaching ) ) //<S2SV> return - ENODEV ; //<S2SV> write_lock_irq ( & sfp -> rq_list_lock ) ; //<S2SV> if ( srp -> done ) { //<S2SV> srp -> done = 2 ; //<S2SV> write_unlock_irq ( & sfp -> rq_list_lock ) ; //<S2SV> result = sg_new_read ( sfp , p , SZ_SG_IO_HDR , srp ) ; //<S2SV> return ( result < 0 ) ? result : 0 ; //<S2SV> } //<S2SV> srp -> orphan = 1 ; //<S2SV> write_unlock_irq ( & sfp -> rq_list_lock ) ; //<S2SV> return result ; //<S2SV> case SG_SET_TIMEOUT : //<S2SV> result = get_user ( val , ip ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> if ( val < 0 ) //<S2SV> return - EIO ; //<S2SV> if ( val >= mult_frac ( ( s64 ) INT_MAX , USER_HZ , HZ ) ) //<S2SV> val = min_t ( s64 , mult_frac ( ( s64 ) INT_MAX , USER_HZ , HZ ) , //<S2SV> INT_MAX ) ; //<S2SV> sfp -> timeout_user = val ; //<S2SV> sfp -> timeout = mult_frac ( val , HZ , USER_HZ ) ; //<S2SV> return 0 ; //<S2SV> case SG_GET_TIMEOUT : //<S2SV> return sfp -> timeout_user ; //<S2SV> case SG_SET_FORCE_LOW_DMA : //<S2SV> return 0 ; //<S2SV> case SG_GET_LOW_DMA : //<S2SV> return put_user ( ( int ) sdp -> device -> host -> unchecked_isa_dma , ip ) ; //<S2SV> case SG_GET_SCSI_ID : //<S2SV> if ( ! access_ok ( VERIFY_WRITE , p , sizeof ( sg_scsi_id_t ) ) ) //<S2SV> return - EFAULT ; //<S2SV> else { //<S2SV> sg_scsi_id_t __user * sg_idp = p ; //<S2SV> if ( atomic_read ( & sdp -> detaching ) ) //<S2SV> return - ENODEV ; //<S2SV> __put_user ( ( int ) sdp -> device -> host -> host_no , //<S2SV> & sg_idp -> host_no ) ; //<S2SV> __put_user ( ( int ) sdp -> device -> channel , //<S2SV> & sg_idp -> channel ) ; //<S2SV> __put_user ( ( int ) sdp -> device -> id , & sg_idp -> scsi_id ) ; //<S2SV> __put_user ( ( int ) sdp -> device -> lun , & sg_idp -> lun ) ; //<S2SV> __put_user ( ( int ) sdp -> device -> type , & sg_idp -> scsi_type ) ; //<S2SV> __put_user ( ( short ) sdp -> device -> host -> cmd_per_lun , //<S2SV> & sg_idp -> h_cmd_per_lun ) ; //<S2SV> __put_user ( ( short ) sdp -> device -> queue_depth , //<S2SV> & sg_idp -> d_queue_depth ) ; //<S2SV> __put_user ( 0 , & sg_idp -> unused [ 0 ] ) ; //<S2SV> __put_user ( 0 , & sg_idp -> unused [ 1 ] ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> case SG_SET_FORCE_PACK_ID : //<S2SV> result = get_user ( val , ip ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> sfp -> force_packid = val ? 1 : 0 ; //<S2SV> return 0 ; //<S2SV> case SG_GET_PACK_ID : //<S2SV> if ( ! access_ok ( VERIFY_WRITE , ip , sizeof ( int ) ) ) //<S2SV> return - EFAULT ; //<S2SV> read_lock_irqsave ( & sfp -> rq_list_lock , iflags ) ; //<S2SV> list_for_each_entry ( srp , & sfp -> rq_list , entry ) { //<S2SV> if ( ( 1 == srp -> done ) && ( ! srp -> sg_io_owned ) ) { //<S2SV> read_unlock_irqrestore ( & sfp -> rq_list_lock , //<S2SV> iflags ) ; //<S2SV> __put_user ( srp -> header . pack_id , ip ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> } //<S2SV> read_unlock_irqrestore ( & sfp -> rq_list_lock , iflags ) ; //<S2SV> __put_user ( - 1 , ip ) ; //<S2SV> return 0 ; //<S2SV> case SG_GET_NUM_WAITING : //<S2SV> read_lock_irqsave ( & sfp -> rq_list_lock , iflags ) ; //<S2SV> val = 0 ; //<S2SV> list_for_each_entry ( srp , & sfp -> rq_list , entry ) { //<S2SV> if ( ( 1 == srp -> done ) && ( ! srp -> sg_io_owned ) ) //<S2SV> ++ val ; //<S2SV> } //<S2SV> read_unlock_irqrestore ( & sfp -> rq_list_lock , iflags ) ; //<S2SV> return put_user ( val , ip ) ; //<S2SV> case SG_GET_SG_TABLESIZE : //<S2SV> return put_user ( sdp -> sg_tablesize , ip ) ; //<S2SV> case SG_SET_RESERVED_SIZE : //<S2SV> result = get_user ( val , ip ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> if ( val < 0 ) //<S2SV> return - EINVAL ; //<S2SV> val = min_t ( int , val , //<S2SV> max_sectors_bytes ( sdp -> device -> request_queue ) ) ; //<S2SV> mutex_lock ( & sfp -> f_mutex ) ; //<S2SV> if ( val != sfp -> reserve . bufflen ) { //<S2SV> if ( sfp -> mmap_called || //<S2SV> sfp -> res_in_use ) { //<S2SV> mutex_unlock ( & sfp -> f_mutex ) ; //<S2SV> return - EBUSY ; //<S2SV> } //<S2SV> sg_remove_scat ( sfp , & sfp -> reserve ) ; //<S2SV> sg_build_reserve ( sfp , val ) ; //<S2SV> } //<S2SV> mutex_unlock ( & sfp -> f_mutex ) ; //<S2SV> return 0 ; //<S2SV> case SG_GET_RESERVED_SIZE : //<S2SV> val = min_t ( int , sfp -> reserve . bufflen , //<S2SV> max_sectors_bytes ( sdp -> device -> request_queue ) ) ; //<S2SV> return put_user ( val , ip ) ; //<S2SV> case SG_SET_COMMAND_Q : //<S2SV> result = get_user ( val , ip ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> sfp -> cmd_q = val ? 1 : 0 ; //<S2SV> return 0 ; //<S2SV> case SG_GET_COMMAND_Q : //<S2SV> return put_user ( ( int ) sfp -> cmd_q , ip ) ; //<S2SV> case SG_SET_KEEP_ORPHAN : //<S2SV> result = get_user ( val , ip ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> sfp -> keep_orphan = val ; //<S2SV> return 0 ; //<S2SV> case SG_GET_KEEP_ORPHAN : //<S2SV> return put_user ( ( int ) sfp -> keep_orphan , ip ) ; //<S2SV> case SG_NEXT_CMD_LEN : //<S2SV> result = get_user ( val , ip ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> if ( val > SG_MAX_CDB_SIZE ) //<S2SV> return - ENOMEM ; //<S2SV> sfp -> next_cmd_len = ( val > 0 ) ? val : 0 ; //<S2SV> return 0 ; //<S2SV> case SG_GET_VERSION_NUM : //<S2SV> return put_user ( sg_version_num , ip ) ; //<S2SV> case SG_GET_ACCESS_COUNT : //<S2SV> val = ( sdp -> device ? 1 : 0 ) ; //<S2SV> return put_user ( val , ip ) ; //<S2SV> case SG_GET_REQUEST_TABLE : //<S2SV> if ( ! access_ok ( VERIFY_WRITE , p , SZ_SG_REQ_INFO * SG_MAX_QUEUE ) ) //<S2SV> return - EFAULT ; //<S2SV> else { //<S2SV> sg_req_info_t * rinfo ; //<S2SV> rinfo = kzalloc ( SZ_SG_REQ_INFO * SG_MAX_QUEUE , //<S2SV> GFP_KERNEL ) ; //<S2SV> if ( ! rinfo ) //<S2SV> return - ENOMEM ; //<S2SV> read_lock_irqsave ( & sfp -> rq_list_lock , iflags ) ; //<S2SV> sg_fill_request_table ( sfp , rinfo ) ; //<S2SV> read_unlock_irqrestore ( & sfp -> rq_list_lock , iflags ) ; //<S2SV> result = __copy_to_user ( p , rinfo , //<S2SV> SZ_SG_REQ_INFO * SG_MAX_QUEUE ) ; //<S2SV> result = result ? - EFAULT : 0 ; //<S2SV> kfree ( rinfo ) ; //<S2SV> return result ; //<S2SV> } //<S2SV> case SG_EMULATED_HOST : //<S2SV> if ( atomic_read ( & sdp -> detaching ) ) //<S2SV> return - ENODEV ; //<S2SV> return put_user ( sdp -> device -> host -> hostt -> emulated , ip ) ; //<S2SV> case SCSI_IOCTL_SEND_COMMAND : //<S2SV> if ( atomic_read ( & sdp -> detaching ) ) //<S2SV> return - ENODEV ; //<S2SV> if ( read_only ) { //<S2SV> unsigned char opcode = WRITE_6 ; //<S2SV> Scsi_Ioctl_Command __user * siocp = p ; //<S2SV> if ( copy_from_user ( & opcode , siocp -> data , 1 ) ) //<S2SV> return - EFAULT ; //<S2SV> if ( sg_allow_access ( filp , & opcode ) ) //<S2SV> return - EPERM ; //<S2SV> } //<S2SV> return sg_scsi_ioctl ( sdp -> device -> request_queue , NULL , filp -> f_mode , p ) ; //<S2SV> case SG_SET_DEBUG : //<S2SV> result = get_user ( val , ip ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> sdp -> sgdebug = ( char ) val ; //<S2SV> return 0 ; //<S2SV> case BLKSECTGET : //<S2SV> return put_user ( max_sectors_bytes ( sdp -> device -> request_queue ) , //<S2SV> ip ) ; //<S2SV> case BLKTRACESETUP : //<S2SV> return blk_trace_setup ( sdp -> device -> request_queue , //<S2SV> sdp -> disk -> disk_name , //<S2SV> MKDEV ( SCSI_GENERIC_MAJOR , sdp -> index ) , //<S2SV> NULL , p ) ; //<S2SV> case BLKTRACESTART : //<S2SV> return blk_trace_startstop ( sdp -> device -> request_queue , 1 ) ; //<S2SV> case BLKTRACESTOP : //<S2SV> return blk_trace_startstop ( sdp -> device -> request_queue , 0 ) ; //<S2SV> case BLKTRACETEARDOWN : //<S2SV> return blk_trace_remove ( sdp -> device -> request_queue ) ; //<S2SV> case SCSI_IOCTL_GET_IDLUN : //<S2SV> case SCSI_IOCTL_GET_BUS_NUMBER : //<S2SV> case SCSI_IOCTL_PROBE_HOST : //<S2SV> case SG_GET_TRANSFORM : //<S2SV> case SG_SCSI_RESET : //<S2SV> if ( atomic_read ( & sdp -> detaching ) ) //<S2SV> return - ENODEV ; //<S2SV> break ; //<S2SV> default : //<S2SV> if ( read_only ) //<S2SV> return - EPERM ; //<S2SV> break ; //<S2SV> } //<S2SV> result = scsi_ioctl_block_when_processing_errors ( sdp -> device , //<S2SV> cmd_in , filp -> f_flags & O_NDELAY ) ; //<S2SV> if ( result ) //<S2SV> return result ; //<S2SV> return scsi_ioctl ( sdp -> device , cmd_in , p ) ; //<S2SV> } //<S2SV> 