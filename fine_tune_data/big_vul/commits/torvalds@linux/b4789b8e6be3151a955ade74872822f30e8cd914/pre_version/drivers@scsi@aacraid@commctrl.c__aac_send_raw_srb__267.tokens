static int aac_send_raw_srb ( struct aac_dev * dev , void __user * arg ) //<S2SV> { //<S2SV> struct fib * srbfib ; //<S2SV> int status ; //<S2SV> struct aac_srb * srbcmd = NULL ; //<S2SV> struct user_aac_srb * user_srbcmd = NULL ; //<S2SV> struct user_aac_srb __user * user_srb = arg ; //<S2SV> struct aac_srb_reply __user * user_reply ; //<S2SV> struct aac_srb_reply * reply ; //<S2SV> u32 fibsize = 0 ; //<S2SV> u32 flags = 0 ; //<S2SV> s32 rcode = 0 ; //<S2SV> u32 data_dir ; //<S2SV> void __user * sg_user [ 32 ] ; //<S2SV> void * sg_list [ 32 ] ; //<S2SV> u32 sg_indx = 0 ; //<S2SV> u32 byte_count = 0 ; //<S2SV> u32 actual_fibsize64 , actual_fibsize = 0 ; //<S2SV> int i ; //<S2SV> if ( dev -> in_reset ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>send<S2SV_blank>raw<S2SV_blank>srb<S2SV_blank>-EBUSY\\n" ) ) ; //<S2SV> return - EBUSY ; //<S2SV> } //<S2SV> if ( ! capable ( CAP_SYS_ADMIN ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>No<S2SV_blank>permission<S2SV_blank>to<S2SV_blank>send<S2SV_blank>raw<S2SV_blank>srb\\n" ) ) ; //<S2SV> return - EPERM ; //<S2SV> } //<S2SV> if ( ! ( srbfib = aac_fib_alloc ( dev ) ) ) { //<S2SV> return - ENOMEM ; //<S2SV> } //<S2SV> aac_fib_init ( srbfib ) ; //<S2SV> srbfib -> hw_fib_va -> header . XferState &= ~ cpu_to_le32 ( FastResponseCapable ) ; //<S2SV> srbcmd = ( struct aac_srb * ) fib_data ( srbfib ) ; //<S2SV> memset ( sg_list , 0 , sizeof ( sg_list ) ) ; //<S2SV> if ( copy_from_user ( & fibsize , & user_srb -> count , sizeof ( u32 ) ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>data<S2SV_blank>size<S2SV_blank>from<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> if ( fibsize > ( dev -> max_fib_size - sizeof ( struct aac_fibhdr ) ) ) { //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> user_srbcmd = kmalloc ( fibsize , GFP_KERNEL ) ; //<S2SV> if ( ! user_srbcmd ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>make<S2SV_blank>a<S2SV_blank>copy<S2SV_blank>of<S2SV_blank>the<S2SV_blank>srb\\n" ) ) ; //<S2SV> rcode = - ENOMEM ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> if ( copy_from_user ( user_srbcmd , user_srb , fibsize ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>srb<S2SV_blank>from<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> user_reply = arg + fibsize ; //<S2SV> flags = user_srbcmd -> flags ; //<S2SV> srbcmd -> function = cpu_to_le32 ( SRBF_ExecuteScsi ) ; //<S2SV> srbcmd -> channel = cpu_to_le32 ( user_srbcmd -> channel ) ; //<S2SV> srbcmd -> id = cpu_to_le32 ( user_srbcmd -> id ) ; //<S2SV> srbcmd -> lun = cpu_to_le32 ( user_srbcmd -> lun ) ; //<S2SV> srbcmd -> timeout = cpu_to_le32 ( user_srbcmd -> timeout ) ; //<S2SV> srbcmd -> flags = cpu_to_le32 ( flags ) ; //<S2SV> srbcmd -> retry_limit = 0 ; //<S2SV> srbcmd -> cdb_size = cpu_to_le32 ( user_srbcmd -> cdb_size ) ; //<S2SV> memcpy ( srbcmd -> cdb , user_srbcmd -> cdb , sizeof ( srbcmd -> cdb ) ) ; //<S2SV> switch ( flags & ( SRB_DataIn | SRB_DataOut ) ) { //<S2SV> case SRB_DataOut : //<S2SV> data_dir = DMA_TO_DEVICE ; //<S2SV> break ; //<S2SV> case ( SRB_DataIn | SRB_DataOut ) : //<S2SV> data_dir = DMA_BIDIRECTIONAL ; //<S2SV> break ; //<S2SV> case SRB_DataIn : //<S2SV> data_dir = DMA_FROM_DEVICE ; //<S2SV> break ; //<S2SV> default : //<S2SV> data_dir = DMA_NONE ; //<S2SV> } //<S2SV> if ( user_srbcmd -> sg . count > ARRAY_SIZE ( sg_list ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>too<S2SV_blank>many<S2SV_blank>sg<S2SV_blank>entries<S2SV_blank>%d\\n" , //<S2SV> le32_to_cpu ( srbcmd -> sg . count ) ) ) ; //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> actual_fibsize = sizeof ( struct aac_srb ) - sizeof ( struct sgentry ) + //<S2SV> ( ( user_srbcmd -> sg . count & 0xff ) * sizeof ( struct sgentry ) ) ; //<S2SV> actual_fibsize64 = actual_fibsize + ( user_srbcmd -> sg . count & 0xff ) * //<S2SV> ( sizeof ( struct sgentry64 ) - sizeof ( struct sgentry ) ) ; //<S2SV> if ( ( actual_fibsize != fibsize ) && ( actual_fibsize64 != fibsize ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Bad<S2SV_blank>Size<S2SV_blank>specified<S2SV_blank>in<S2SV_blank>" //<S2SV> "Raw<S2SV_blank>SRB<S2SV_blank>command<S2SV_blank>calculated<S2SV_blank>fibsize=%lu;%lu<S2SV_blank>" //<S2SV> "user_srbcmd->sg.count=%d<S2SV_blank>aac_srb=%lu<S2SV_blank>sgentry=%lu;%lu<S2SV_blank>" //<S2SV> "issued<S2SV_blank>fibsize=%d\\n" , //<S2SV> actual_fibsize , actual_fibsize64 , user_srbcmd -> sg . count , //<S2SV> sizeof ( struct aac_srb ) , sizeof ( struct sgentry ) , //<S2SV> sizeof ( struct sgentry64 ) , fibsize ) ) ; //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> if ( ( data_dir == DMA_NONE ) && user_srbcmd -> sg . count ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>SG<S2SV_blank>with<S2SV_blank>no<S2SV_blank>direction<S2SV_blank>specified<S2SV_blank>in<S2SV_blank>Raw<S2SV_blank>SRB<S2SV_blank>command\\n" ) ) ; //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> byte_count = 0 ; //<S2SV> if ( dev -> adapter_info . options & AAC_OPT_SGMAP_HOST64 ) { //<S2SV> struct user_sgmap64 * upsg = ( struct user_sgmap64 * ) & user_srbcmd -> sg ; //<S2SV> struct sgmap64 * psg = ( struct sgmap64 * ) & srbcmd -> sg ; //<S2SV> if ( actual_fibsize64 == fibsize ) { //<S2SV> actual_fibsize = actual_fibsize64 ; //<S2SV> for ( i = 0 ; i < upsg -> count ; i ++ ) { //<S2SV> u64 addr ; //<S2SV> void * p ; //<S2SV> if ( upsg -> sg [ i ] . count > //<S2SV> ( ( dev -> adapter_info . options & //<S2SV> AAC_OPT_NEW_COMM ) ? //<S2SV> ( dev -> scsi_host_ptr -> max_sectors << 9 ) : //<S2SV> 65536 ) ) { //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> p = kmalloc ( upsg -> sg [ i ] . count , GFP_KERNEL | __GFP_DMA ) ; //<S2SV> if ( ! p ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>allocate<S2SV_blank>SG<S2SV_blank>buffer<S2SV_blank>-<S2SV_blank>size<S2SV_blank>=<S2SV_blank>%d<S2SV_blank>buffer<S2SV_blank>number<S2SV_blank>%d<S2SV_blank>of<S2SV_blank>%d\\n" , //<S2SV> upsg -> sg [ i ] . count , i , upsg -> count ) ) ; //<S2SV> rcode = - ENOMEM ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> addr = ( u64 ) upsg -> sg [ i ] . addr [ 0 ] ; //<S2SV> addr += ( ( u64 ) upsg -> sg [ i ] . addr [ 1 ] ) << 32 ; //<S2SV> sg_user [ i ] = ( void __user * ) ( uintptr_t ) addr ; //<S2SV> sg_list [ i ] = p ; //<S2SV> sg_indx = i ; //<S2SV> if ( flags & SRB_DataOut ) { //<S2SV> if ( copy_from_user ( p , sg_user [ i ] , upsg -> sg [ i ] . count ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>sg<S2SV_blank>data<S2SV_blank>from<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> } //<S2SV> addr = pci_map_single ( dev -> pdev , p , upsg -> sg [ i ] . count , data_dir ) ; //<S2SV> psg -> sg [ i ] . addr [ 0 ] = cpu_to_le32 ( addr & 0xffffffff ) ; //<S2SV> psg -> sg [ i ] . addr [ 1 ] = cpu_to_le32 ( addr >> 32 ) ; //<S2SV> byte_count += upsg -> sg [ i ] . count ; //<S2SV> psg -> sg [ i ] . count = cpu_to_le32 ( upsg -> sg [ i ] . count ) ; //<S2SV> } //<S2SV> } else { //<S2SV> struct user_sgmap * usg ; //<S2SV> usg = kmalloc ( actual_fibsize - sizeof ( struct aac_srb ) //<S2SV> + sizeof ( struct sgmap ) , GFP_KERNEL ) ; //<S2SV> if ( ! usg ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Allocation<S2SV_blank>error<S2SV_blank>in<S2SV_blank>Raw<S2SV_blank>SRB<S2SV_blank>command\\n" ) ) ; //<S2SV> rcode = - ENOMEM ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> memcpy ( usg , upsg , actual_fibsize - sizeof ( struct aac_srb ) //<S2SV> + sizeof ( struct sgmap ) ) ; //<S2SV> actual_fibsize = actual_fibsize64 ; //<S2SV> for ( i = 0 ; i < usg -> count ; i ++ ) { //<S2SV> u64 addr ; //<S2SV> void * p ; //<S2SV> if ( usg -> sg [ i ] . count > //<S2SV> ( ( dev -> adapter_info . options & //<S2SV> AAC_OPT_NEW_COMM ) ? //<S2SV> ( dev -> scsi_host_ptr -> max_sectors << 9 ) : //<S2SV> 65536 ) ) { //<S2SV> kfree ( usg ) ; //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> p = kmalloc ( usg -> sg [ i ] . count , GFP_KERNEL | __GFP_DMA ) ; //<S2SV> if ( ! p ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>allocate<S2SV_blank>SG<S2SV_blank>buffer<S2SV_blank>-<S2SV_blank>size<S2SV_blank>=<S2SV_blank>%d<S2SV_blank>buffer<S2SV_blank>number<S2SV_blank>%d<S2SV_blank>of<S2SV_blank>%d\\n" , //<S2SV> usg -> sg [ i ] . count , i , usg -> count ) ) ; //<S2SV> kfree ( usg ) ; //<S2SV> rcode = - ENOMEM ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> sg_user [ i ] = ( void __user * ) ( uintptr_t ) usg -> sg [ i ] . addr ; //<S2SV> sg_list [ i ] = p ; //<S2SV> sg_indx = i ; //<S2SV> if ( flags & SRB_DataOut ) { //<S2SV> if ( copy_from_user ( p , sg_user [ i ] , upsg -> sg [ i ] . count ) ) { //<S2SV> kfree ( usg ) ; //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>sg<S2SV_blank>data<S2SV_blank>from<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> } //<S2SV> addr = pci_map_single ( dev -> pdev , p , usg -> sg [ i ] . count , data_dir ) ; //<S2SV> psg -> sg [ i ] . addr [ 0 ] = cpu_to_le32 ( addr & 0xffffffff ) ; //<S2SV> psg -> sg [ i ] . addr [ 1 ] = cpu_to_le32 ( addr >> 32 ) ; //<S2SV> byte_count += usg -> sg [ i ] . count ; //<S2SV> psg -> sg [ i ] . count = cpu_to_le32 ( usg -> sg [ i ] . count ) ; //<S2SV> } //<S2SV> kfree ( usg ) ; //<S2SV> } //<S2SV> srbcmd -> count = cpu_to_le32 ( byte_count ) ; //<S2SV> psg -> count = cpu_to_le32 ( sg_indx + 1 ) ; //<S2SV> status = aac_fib_send ( ScsiPortCommand64 , srbfib , actual_fibsize , FsaNormal , 1 , 1 , NULL , NULL ) ; //<S2SV> } else { //<S2SV> struct user_sgmap * upsg = & user_srbcmd -> sg ; //<S2SV> struct sgmap * psg = & srbcmd -> sg ; //<S2SV> if ( actual_fibsize64 == fibsize ) { //<S2SV> struct user_sgmap64 * usg = ( struct user_sgmap64 * ) upsg ; //<S2SV> for ( i = 0 ; i < upsg -> count ; i ++ ) { //<S2SV> uintptr_t addr ; //<S2SV> void * p ; //<S2SV> if ( usg -> sg [ i ] . count > //<S2SV> ( ( dev -> adapter_info . options & //<S2SV> AAC_OPT_NEW_COMM ) ? //<S2SV> ( dev -> scsi_host_ptr -> max_sectors << 9 ) : //<S2SV> 65536 ) ) { //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> p = kmalloc ( usg -> sg [ i ] . count , GFP_KERNEL | __GFP_DMA ) ; //<S2SV> if ( ! p ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>allocate<S2SV_blank>SG<S2SV_blank>buffer<S2SV_blank>-<S2SV_blank>size<S2SV_blank>=<S2SV_blank>%d<S2SV_blank>buffer<S2SV_blank>number<S2SV_blank>%d<S2SV_blank>of<S2SV_blank>%d\\n" , //<S2SV> usg -> sg [ i ] . count , i , usg -> count ) ) ; //<S2SV> rcode = - ENOMEM ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> addr = ( u64 ) usg -> sg [ i ] . addr [ 0 ] ; //<S2SV> addr += ( ( u64 ) usg -> sg [ i ] . addr [ 1 ] ) << 32 ; //<S2SV> sg_user [ i ] = ( void __user * ) addr ; //<S2SV> sg_list [ i ] = p ; //<S2SV> sg_indx = i ; //<S2SV> if ( flags & SRB_DataOut ) { //<S2SV> if ( copy_from_user ( p , sg_user [ i ] , usg -> sg [ i ] . count ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>sg<S2SV_blank>data<S2SV_blank>from<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> } //<S2SV> addr = pci_map_single ( dev -> pdev , p , usg -> sg [ i ] . count , data_dir ) ; //<S2SV> psg -> sg [ i ] . addr = cpu_to_le32 ( addr & 0xffffffff ) ; //<S2SV> byte_count += usg -> sg [ i ] . count ; //<S2SV> psg -> sg [ i ] . count = cpu_to_le32 ( usg -> sg [ i ] . count ) ; //<S2SV> } //<S2SV> } else { //<S2SV> for ( i = 0 ; i < upsg -> count ; i ++ ) { //<S2SV> dma_addr_t addr ; //<S2SV> void * p ; //<S2SV> if ( upsg -> sg [ i ] . count > //<S2SV> ( ( dev -> adapter_info . options & //<S2SV> AAC_OPT_NEW_COMM ) ? //<S2SV> ( dev -> scsi_host_ptr -> max_sectors << 9 ) : //<S2SV> 65536 ) ) { //<S2SV> rcode = - EINVAL ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> p = kmalloc ( upsg -> sg [ i ] . count , GFP_KERNEL ) ; //<S2SV> if ( ! p ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>allocate<S2SV_blank>SG<S2SV_blank>buffer<S2SV_blank>-<S2SV_blank>size<S2SV_blank>=<S2SV_blank>%d<S2SV_blank>buffer<S2SV_blank>number<S2SV_blank>%d<S2SV_blank>of<S2SV_blank>%d\\n" , //<S2SV> upsg -> sg [ i ] . count , i , upsg -> count ) ) ; //<S2SV> rcode = - ENOMEM ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> sg_user [ i ] = ( void __user * ) ( uintptr_t ) upsg -> sg [ i ] . addr ; //<S2SV> sg_list [ i ] = p ; //<S2SV> sg_indx = i ; //<S2SV> if ( flags & SRB_DataOut ) { //<S2SV> if ( copy_from_user ( p , sg_user [ i ] , //<S2SV> upsg -> sg [ i ] . count ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>sg<S2SV_blank>data<S2SV_blank>from<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> } //<S2SV> addr = pci_map_single ( dev -> pdev , p , //<S2SV> upsg -> sg [ i ] . count , data_dir ) ; //<S2SV> psg -> sg [ i ] . addr = cpu_to_le32 ( addr ) ; //<S2SV> byte_count += upsg -> sg [ i ] . count ; //<S2SV> psg -> sg [ i ] . count = cpu_to_le32 ( upsg -> sg [ i ] . count ) ; //<S2SV> } //<S2SV> } //<S2SV> srbcmd -> count = cpu_to_le32 ( byte_count ) ; //<S2SV> psg -> count = cpu_to_le32 ( sg_indx + 1 ) ; //<S2SV> status = aac_fib_send ( ScsiPortCommand , srbfib , actual_fibsize , FsaNormal , 1 , 1 , NULL , NULL ) ; //<S2SV> } //<S2SV> if ( status == - ERESTARTSYS ) { //<S2SV> rcode = - ERESTARTSYS ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> if ( status != 0 ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>send<S2SV_blank>raw<S2SV_blank>srb<S2SV_blank>fib<S2SV_blank>to<S2SV_blank>hba\\n" ) ) ; //<S2SV> rcode = - ENXIO ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> if ( flags & SRB_DataIn ) { //<S2SV> for ( i = 0 ; i <= sg_indx ; i ++ ) { //<S2SV> byte_count = le32_to_cpu ( //<S2SV> ( dev -> adapter_info . options & AAC_OPT_SGMAP_HOST64 ) //<S2SV> ? ( ( struct sgmap64 * ) & srbcmd -> sg ) -> sg [ i ] . count //<S2SV> : srbcmd -> sg . sg [ i ] . count ) ; //<S2SV> if ( copy_to_user ( sg_user [ i ] , sg_list [ i ] , byte_count ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>sg<S2SV_blank>data<S2SV_blank>to<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> } //<S2SV> } //<S2SV> reply = ( struct aac_srb_reply * ) fib_data ( srbfib ) ; //<S2SV> if ( copy_to_user ( user_reply , reply , sizeof ( struct aac_srb_reply ) ) ) { //<S2SV> dprintk ( ( KERN_DEBUG "aacraid:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>copy<S2SV_blank>reply<S2SV_blank>to<S2SV_blank>user\\n" ) ) ; //<S2SV> rcode = - EFAULT ; //<S2SV> goto cleanup ; //<S2SV> } //<S2SV> cleanup : //<S2SV> kfree ( user_srbcmd ) ; //<S2SV> for ( i = 0 ; i <= sg_indx ; i ++ ) { //<S2SV> kfree ( sg_list [ i ] ) ; //<S2SV> } //<S2SV> if ( rcode != - ERESTARTSYS ) { //<S2SV> aac_fib_complete ( srbfib ) ; //<S2SV> aac_fib_free ( srbfib ) ; //<S2SV> } //<S2SV> return rcode ; //<S2SV> } //<S2SV> 