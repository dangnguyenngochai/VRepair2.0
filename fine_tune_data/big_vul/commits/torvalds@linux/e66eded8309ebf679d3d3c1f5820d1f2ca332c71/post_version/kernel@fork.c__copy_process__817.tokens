static struct task_struct * copy_process ( unsigned long clone_flags , //<S2SV> unsigned long stack_start , //<S2SV> unsigned long stack_size , //<S2SV> int __user * child_tidptr , //<S2SV> struct pid * pid , //<S2SV> int trace ) //<S2SV> { //<S2SV> int retval ; //<S2SV> struct task_struct * p ; //<S2SV> if ( ( clone_flags & ( CLONE_NEWNS | CLONE_FS ) ) == ( CLONE_NEWNS | CLONE_FS ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & ( CLONE_NEWUSER | CLONE_FS ) ) == ( CLONE_NEWUSER | CLONE_FS ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & CLONE_THREAD ) && ! ( clone_flags & CLONE_SIGHAND ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & CLONE_SIGHAND ) && ! ( clone_flags & CLONE_VM ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & CLONE_PARENT ) && //<S2SV> current -> signal -> flags & SIGNAL_UNKILLABLE ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> if ( ( clone_flags & ( CLONE_VM | CLONE_NEWPID ) ) && //<S2SV> ( task_active_pid_ns ( current ) != current -> nsproxy -> pid_ns ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> retval = security_task_create ( clone_flags ) ; //<S2SV> if ( retval ) //<S2SV> goto fork_out ; //<S2SV> retval = - ENOMEM ; //<S2SV> p = dup_task_struct ( current ) ; //<S2SV> if ( ! p ) //<S2SV> goto fork_out ; //<S2SV> ftrace_graph_init_task ( p ) ; //<S2SV> get_seccomp_filter ( p ) ; //<S2SV> rt_mutex_init_task ( p ) ; //<S2SV> # ifdef CONFIG_PROVE_LOCKING //<S2SV> DEBUG_LOCKS_WARN_ON ( ! p -> hardirqs_enabled ) ; //<S2SV> DEBUG_LOCKS_WARN_ON ( ! p -> softirqs_enabled ) ; //<S2SV> # endif //<S2SV> retval = - EAGAIN ; //<S2SV> if ( atomic_read ( & p -> real_cred -> user -> processes ) >= //<S2SV> task_rlimit ( p , RLIMIT_NPROC ) ) { //<S2SV> if ( ! capable ( CAP_SYS_ADMIN ) && ! capable ( CAP_SYS_RESOURCE ) && //<S2SV> p -> real_cred -> user != INIT_USER ) //<S2SV> goto bad_fork_free ; //<S2SV> } //<S2SV> current -> flags &= ~ PF_NPROC_EXCEEDED ; //<S2SV> retval = copy_creds ( p , clone_flags ) ; //<S2SV> if ( retval < 0 ) //<S2SV> goto bad_fork_free ; //<S2SV> retval = - EAGAIN ; //<S2SV> if ( nr_threads >= max_threads ) //<S2SV> goto bad_fork_cleanup_count ; //<S2SV> if ( ! try_module_get ( task_thread_info ( p ) -> exec_domain -> module ) ) //<S2SV> goto bad_fork_cleanup_count ; //<S2SV> p -> did_exec = 0 ; //<S2SV> delayacct_tsk_init ( p ) ; //<S2SV> copy_flags ( clone_flags , p ) ; //<S2SV> INIT_LIST_HEAD ( & p -> children ) ; //<S2SV> INIT_LIST_HEAD ( & p -> sibling ) ; //<S2SV> rcu_copy_process ( p ) ; //<S2SV> p -> vfork_done = NULL ; //<S2SV> spin_lock_init ( & p -> alloc_lock ) ; //<S2SV> init_sigpending ( & p -> pending ) ; //<S2SV> p -> utime = p -> stime = p -> gtime = 0 ; //<S2SV> p -> utimescaled = p -> stimescaled = 0 ; //<S2SV> # ifndef CONFIG_VIRT_CPU_ACCOUNTING //<S2SV> p -> prev_cputime . utime = p -> prev_cputime . stime = 0 ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN //<S2SV> seqlock_init ( & p -> vtime_seqlock ) ; //<S2SV> p -> vtime_snap = 0 ; //<S2SV> p -> vtime_snap_whence = VTIME_SLEEPING ; //<S2SV> # endif //<S2SV> # if defined ( SPLIT_RSS_COUNTING ) //<S2SV> memset ( & p -> rss_stat , 0 , sizeof ( p -> rss_stat ) ) ; //<S2SV> # endif //<S2SV> p -> default_timer_slack_ns = current -> timer_slack_ns ; //<S2SV> task_io_accounting_init ( & p -> ioac ) ; //<S2SV> acct_clear_integrals ( p ) ; //<S2SV> posix_cpu_timers_init ( p ) ; //<S2SV> do_posix_clock_monotonic_gettime ( & p -> start_time ) ; //<S2SV> p -> real_start_time = p -> start_time ; //<S2SV> monotonic_to_bootbased ( & p -> real_start_time ) ; //<S2SV> p -> io_context = NULL ; //<S2SV> p -> audit_context = NULL ; //<S2SV> if ( clone_flags & CLONE_THREAD ) //<S2SV> threadgroup_change_begin ( current ) ; //<S2SV> cgroup_fork ( p ) ; //<S2SV> # ifdef CONFIG_NUMA //<S2SV> p -> mempolicy = mpol_dup ( p -> mempolicy ) ; //<S2SV> if ( IS_ERR ( p -> mempolicy ) ) { //<S2SV> retval = PTR_ERR ( p -> mempolicy ) ; //<S2SV> p -> mempolicy = NULL ; //<S2SV> goto bad_fork_cleanup_cgroup ; //<S2SV> } //<S2SV> mpol_fix_fork_child_flag ( p ) ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_CPUSETS //<S2SV> p -> cpuset_mem_spread_rotor = NUMA_NO_NODE ; //<S2SV> p -> cpuset_slab_spread_rotor = NUMA_NO_NODE ; //<S2SV> seqcount_init ( & p -> mems_allowed_seq ) ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_TRACE_IRQFLAGS //<S2SV> p -> irq_events = 0 ; //<S2SV> p -> hardirqs_enabled = 0 ; //<S2SV> p -> hardirq_enable_ip = 0 ; //<S2SV> p -> hardirq_enable_event = 0 ; //<S2SV> p -> hardirq_disable_ip = _THIS_IP_ ; //<S2SV> p -> hardirq_disable_event = 0 ; //<S2SV> p -> softirqs_enabled = 1 ; //<S2SV> p -> softirq_enable_ip = _THIS_IP_ ; //<S2SV> p -> softirq_enable_event = 0 ; //<S2SV> p -> softirq_disable_ip = 0 ; //<S2SV> p -> softirq_disable_event = 0 ; //<S2SV> p -> hardirq_context = 0 ; //<S2SV> p -> softirq_context = 0 ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_LOCKDEP //<S2SV> p -> lockdep_depth = 0 ; //<S2SV> p -> curr_chain_key = 0 ; //<S2SV> p -> lockdep_recursion = 0 ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_DEBUG_MUTEXES //<S2SV> p -> blocked_on = NULL ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_MEMCG //<S2SV> p -> memcg_batch . do_batch = 0 ; //<S2SV> p -> memcg_batch . memcg = NULL ; //<S2SV> # endif //<S2SV> sched_fork ( p ) ; //<S2SV> retval = perf_event_init_task ( p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_policy ; //<S2SV> retval = audit_alloc ( p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_policy ; //<S2SV> retval = copy_semundo ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_audit ; //<S2SV> retval = copy_files ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_semundo ; //<S2SV> retval = copy_fs ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_files ; //<S2SV> retval = copy_sighand ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_fs ; //<S2SV> retval = copy_signal ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_sighand ; //<S2SV> retval = copy_mm ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_signal ; //<S2SV> retval = copy_namespaces ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_mm ; //<S2SV> retval = copy_io ( clone_flags , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_namespaces ; //<S2SV> retval = copy_thread ( clone_flags , stack_start , stack_size , p ) ; //<S2SV> if ( retval ) //<S2SV> goto bad_fork_cleanup_io ; //<S2SV> if ( pid != & init_struct_pid ) { //<S2SV> retval = - ENOMEM ; //<S2SV> pid = alloc_pid ( p -> nsproxy -> pid_ns ) ; //<S2SV> if ( ! pid ) //<S2SV> goto bad_fork_cleanup_io ; //<S2SV> } //<S2SV> p -> pid = pid_nr ( pid ) ; //<S2SV> p -> tgid = p -> pid ; //<S2SV> if ( clone_flags & CLONE_THREAD ) //<S2SV> p -> tgid = current -> tgid ; //<S2SV> p -> set_child_tid = ( clone_flags & CLONE_CHILD_SETTID ) ? child_tidptr : NULL ; //<S2SV> p -> clear_child_tid = ( clone_flags & CLONE_CHILD_CLEARTID ) ? child_tidptr : NULL ; //<S2SV> # ifdef CONFIG_BLOCK //<S2SV> p -> plug = NULL ; //<S2SV> # endif //<S2SV> # ifdef CONFIG_FUTEX //<S2SV> p -> robust_list = NULL ; //<S2SV> # ifdef CONFIG_COMPAT //<S2SV> p -> compat_robust_list = NULL ; //<S2SV> # endif //<S2SV> INIT_LIST_HEAD ( & p -> pi_state_list ) ; //<S2SV> p -> pi_state_cache = NULL ; //<S2SV> # endif //<S2SV> uprobe_copy_process ( p ) ; //<S2SV> if ( ( clone_flags & ( CLONE_VM | CLONE_VFORK ) ) == CLONE_VM ) //<S2SV> p -> sas_ss_sp = p -> sas_ss_size = 0 ; //<S2SV> user_disable_single_step ( p ) ; //<S2SV> clear_tsk_thread_flag ( p , TIF_SYSCALL_TRACE ) ; //<S2SV> # ifdef TIF_SYSCALL_EMU //<S2SV> clear_tsk_thread_flag ( p , TIF_SYSCALL_EMU ) ; //<S2SV> # endif //<S2SV> clear_all_latency_tracing ( p ) ; //<S2SV> if ( clone_flags & CLONE_THREAD ) //<S2SV> p -> exit_signal = - 1 ; //<S2SV> else if ( clone_flags & CLONE_PARENT ) //<S2SV> p -> exit_signal = current -> group_leader -> exit_signal ; //<S2SV> else //<S2SV> p -> exit_signal = ( clone_flags & CSIGNAL ) ; //<S2SV> p -> pdeath_signal = 0 ; //<S2SV> p -> exit_state = 0 ; //<S2SV> p -> nr_dirtied = 0 ; //<S2SV> p -> nr_dirtied_pause = 128 >> ( PAGE_SHIFT - 10 ) ; //<S2SV> p -> dirty_paused_when = 0 ; //<S2SV> p -> group_leader = p ; //<S2SV> INIT_LIST_HEAD ( & p -> thread_group ) ; //<S2SV> p -> task_works = NULL ; //<S2SV> write_lock_irq ( & tasklist_lock ) ; //<S2SV> if ( clone_flags & ( CLONE_PARENT | CLONE_THREAD ) ) { //<S2SV> p -> real_parent = current -> real_parent ; //<S2SV> p -> parent_exec_id = current -> parent_exec_id ; //<S2SV> } else { //<S2SV> p -> real_parent = current ; //<S2SV> p -> parent_exec_id = current -> self_exec_id ; //<S2SV> } //<S2SV> spin_lock ( & current -> sighand -> siglock ) ; //<S2SV> recalc_sigpending ( ) ; //<S2SV> if ( signal_pending ( current ) ) { //<S2SV> spin_unlock ( & current -> sighand -> siglock ) ; //<S2SV> write_unlock_irq ( & tasklist_lock ) ; //<S2SV> retval = - ERESTARTNOINTR ; //<S2SV> goto bad_fork_free_pid ; //<S2SV> } //<S2SV> if ( clone_flags & CLONE_THREAD ) { //<S2SV> current -> signal -> nr_threads ++ ; //<S2SV> atomic_inc ( & current -> signal -> live ) ; //<S2SV> atomic_inc ( & current -> signal -> sigcnt ) ; //<S2SV> p -> group_leader = current -> group_leader ; //<S2SV> list_add_tail_rcu ( & p -> thread_group , & p -> group_leader -> thread_group ) ; //<S2SV> } //<S2SV> if ( likely ( p -> pid ) ) { //<S2SV> ptrace_init_task ( p , ( clone_flags & CLONE_PTRACE ) || trace ) ; //<S2SV> if ( thread_group_leader ( p ) ) { //<S2SV> if ( is_child_reaper ( pid ) ) { //<S2SV> ns_of_pid ( pid ) -> child_reaper = p ; //<S2SV> p -> signal -> flags |= SIGNAL_UNKILLABLE ; //<S2SV> } //<S2SV> p -> signal -> leader_pid = pid ; //<S2SV> p -> signal -> tty = tty_kref_get ( current -> signal -> tty ) ; //<S2SV> attach_pid ( p , PIDTYPE_PGID , task_pgrp ( current ) ) ; //<S2SV> attach_pid ( p , PIDTYPE_SID , task_session ( current ) ) ; //<S2SV> list_add_tail ( & p -> sibling , & p -> real_parent -> children ) ; //<S2SV> list_add_tail_rcu ( & p -> tasks , & init_task . tasks ) ; //<S2SV> __this_cpu_inc ( process_counts ) ; //<S2SV> } //<S2SV> attach_pid ( p , PIDTYPE_PID , pid ) ; //<S2SV> nr_threads ++ ; //<S2SV> } //<S2SV> total_forks ++ ; //<S2SV> spin_unlock ( & current -> sighand -> siglock ) ; //<S2SV> write_unlock_irq ( & tasklist_lock ) ; //<S2SV> proc_fork_connector ( p ) ; //<S2SV> cgroup_post_fork ( p ) ; //<S2SV> if ( clone_flags & CLONE_THREAD ) //<S2SV> threadgroup_change_end ( current ) ; //<S2SV> perf_event_fork ( p ) ; //<S2SV> trace_task_newtask ( p , clone_flags ) ; //<S2SV> return p ; //<S2SV> bad_fork_free_pid : //<S2SV> if ( pid != & init_struct_pid ) //<S2SV> free_pid ( pid ) ; //<S2SV> bad_fork_cleanup_io : //<S2SV> if ( p -> io_context ) //<S2SV> exit_io_context ( p ) ; //<S2SV> bad_fork_cleanup_namespaces : //<S2SV> exit_task_namespaces ( p ) ; //<S2SV> bad_fork_cleanup_mm : //<S2SV> if ( p -> mm ) //<S2SV> mmput ( p -> mm ) ; //<S2SV> bad_fork_cleanup_signal : //<S2SV> if ( ! ( clone_flags & CLONE_THREAD ) ) //<S2SV> free_signal_struct ( p -> signal ) ; //<S2SV> bad_fork_cleanup_sighand : //<S2SV> __cleanup_sighand ( p -> sighand ) ; //<S2SV> bad_fork_cleanup_fs : //<S2SV> exit_fs ( p ) ; //<S2SV> bad_fork_cleanup_files : //<S2SV> exit_files ( p ) ; //<S2SV> bad_fork_cleanup_semundo : //<S2SV> exit_sem ( p ) ; //<S2SV> bad_fork_cleanup_audit : //<S2SV> audit_free ( p ) ; //<S2SV> bad_fork_cleanup_policy : //<S2SV> perf_event_free_task ( p ) ; //<S2SV> # ifdef CONFIG_NUMA //<S2SV> mpol_put ( p -> mempolicy ) ; //<S2SV> bad_fork_cleanup_cgroup : //<S2SV> # endif //<S2SV> if ( clone_flags & CLONE_THREAD ) //<S2SV> threadgroup_change_end ( current ) ; //<S2SV> cgroup_exit ( p , 0 ) ; //<S2SV> delayacct_tsk_free ( p ) ; //<S2SV> module_put ( task_thread_info ( p ) -> exec_domain -> module ) ; //<S2SV> bad_fork_cleanup_count : //<S2SV> atomic_dec ( & p -> cred -> user -> processes ) ; //<S2SV> exit_creds ( p ) ; //<S2SV> bad_fork_free : //<S2SV> free_task ( p ) ; //<S2SV> fork_out : //<S2SV> return ERR_PTR ( retval ) ; //<S2SV> } //<S2SV> 