int __kvm_set_memory_region ( struct kvm * kvm , //<S2SV> struct kvm_userspace_memory_region * mem , //<S2SV> int user_alloc ) //<S2SV> { //<S2SV> int r ; //<S2SV> gfn_t base_gfn ; //<S2SV> unsigned long npages ; //<S2SV> unsigned long i ; //<S2SV> struct kvm_memory_slot * memslot ; //<S2SV> struct kvm_memory_slot old , new ; //<S2SV> struct kvm_memslots * slots , * old_memslots ; //<S2SV> r = check_memory_region_flags ( mem ) ; //<S2SV> if ( r ) //<S2SV> goto out ; //<S2SV> r = - EINVAL ; //<S2SV> if ( mem -> memory_size & ( PAGE_SIZE - 1 ) ) //<S2SV> goto out ; //<S2SV> if ( mem -> guest_phys_addr & ( PAGE_SIZE - 1 ) ) //<S2SV> goto out ; //<S2SV> if ( user_alloc && //<S2SV> ( ( mem -> userspace_addr & ( PAGE_SIZE - 1 ) ) || //<S2SV> ! access_ok ( VERIFY_WRITE , //<S2SV> ( void __user * ) ( unsigned long ) mem -> userspace_addr , //<S2SV> mem -> memory_size ) ) ) //<S2SV> goto out ; //<S2SV> if ( mem -> slot >= KVM_MEM_SLOTS_NUM ) //<S2SV> goto out ; //<S2SV> if ( mem -> guest_phys_addr + mem -> memory_size < mem -> guest_phys_addr ) //<S2SV> goto out ; //<S2SV> memslot = id_to_memslot ( kvm -> memslots , mem -> slot ) ; //<S2SV> base_gfn = mem -> guest_phys_addr >> PAGE_SHIFT ; //<S2SV> npages = mem -> memory_size >> PAGE_SHIFT ; //<S2SV> r = - EINVAL ; //<S2SV> if ( npages > KVM_MEM_MAX_NR_PAGES ) //<S2SV> goto out ; //<S2SV> if ( ! npages ) //<S2SV> mem -> flags &= ~ KVM_MEM_LOG_DIRTY_PAGES ; //<S2SV> new = old = * memslot ; //<S2SV> new . id = mem -> slot ; //<S2SV> new . base_gfn = base_gfn ; //<S2SV> new . npages = npages ; //<S2SV> new . flags = mem -> flags ; //<S2SV> r = - EINVAL ; //<S2SV> if ( npages && old . npages && npages != old . npages ) //<S2SV> goto out_free ; //<S2SV> r = - EEXIST ; //<S2SV> for ( i = 0 ; i < KVM_MEMORY_SLOTS ; ++ i ) { //<S2SV> struct kvm_memory_slot * s = & kvm -> memslots -> memslots [ i ] ; //<S2SV> if ( s == memslot || ! s -> npages ) //<S2SV> continue ; //<S2SV> if ( ! ( ( base_gfn + npages <= s -> base_gfn ) || //<S2SV> ( base_gfn >= s -> base_gfn + s -> npages ) ) ) //<S2SV> goto out_free ; //<S2SV> } //<S2SV> if ( ! ( new . flags & KVM_MEM_LOG_DIRTY_PAGES ) ) //<S2SV> new . dirty_bitmap = NULL ; //<S2SV> r = - ENOMEM ; //<S2SV> if ( npages && ! old . npages ) { //<S2SV> new . user_alloc = user_alloc ; //<S2SV> new . userspace_addr = mem -> userspace_addr ; //<S2SV> if ( kvm_arch_create_memslot ( & new , npages ) ) //<S2SV> goto out_free ; //<S2SV> } //<S2SV> if ( ( new . flags & KVM_MEM_LOG_DIRTY_PAGES ) && ! new . dirty_bitmap ) { //<S2SV> if ( kvm_create_dirty_bitmap ( & new ) < 0 ) //<S2SV> goto out_free ; //<S2SV> } //<S2SV> if ( ! npages ) { //<S2SV> struct kvm_memory_slot * slot ; //<S2SV> r = - ENOMEM ; //<S2SV> slots = kmemdup ( kvm -> memslots , sizeof ( struct kvm_memslots ) , //<S2SV> GFP_KERNEL ) ; //<S2SV> if ( ! slots ) //<S2SV> goto out_free ; //<S2SV> slot = id_to_memslot ( slots , mem -> slot ) ; //<S2SV> slot -> flags |= KVM_MEMSLOT_INVALID ; //<S2SV> update_memslots ( slots , NULL ) ; //<S2SV> old_memslots = kvm -> memslots ; //<S2SV> rcu_assign_pointer ( kvm -> memslots , slots ) ; //<S2SV> synchronize_srcu_expedited ( & kvm -> srcu ) ; //<S2SV> kvm_arch_flush_shadow_memslot ( kvm , slot ) ; //<S2SV> kfree ( old_memslots ) ; //<S2SV> } //<S2SV> r = kvm_arch_prepare_memory_region ( kvm , & new , old , mem , user_alloc ) ; //<S2SV> if ( r ) //<S2SV> goto out_free ; //<S2SV> if ( npages ) { //<S2SV> r = kvm_iommu_map_pages ( kvm , & new ) ; //<S2SV> if ( r ) //<S2SV> goto out_free ; //<S2SV> } else //<S2SV> kvm_iommu_unmap_pages ( kvm , & old ) ; //<S2SV> r = - ENOMEM ; //<S2SV> slots = kmemdup ( kvm -> memslots , sizeof ( struct kvm_memslots ) , //<S2SV> GFP_KERNEL ) ; //<S2SV> if ( ! slots ) //<S2SV> goto out_free ; //<S2SV> if ( ! npages ) { //<S2SV> new . dirty_bitmap = NULL ; //<S2SV> memset ( & new . arch , 0 , sizeof ( new . arch ) ) ; //<S2SV> } //<S2SV> update_memslots ( slots , & new ) ; //<S2SV> old_memslots = kvm -> memslots ; //<S2SV> rcu_assign_pointer ( kvm -> memslots , slots ) ; //<S2SV> synchronize_srcu_expedited ( & kvm -> srcu ) ; //<S2SV> kvm_arch_commit_memory_region ( kvm , mem , old , user_alloc ) ; //<S2SV> if ( npages && old . base_gfn != mem -> guest_phys_addr >> PAGE_SHIFT ) //<S2SV> kvm_arch_flush_shadow_all ( kvm ) ; //<S2SV> kvm_free_physmem_slot ( & old , & new ) ; //<S2SV> kfree ( old_memslots ) ; //<S2SV> return 0 ; //<S2SV> out_free : //<S2SV> kvm_free_physmem_slot ( & new , & old ) ; //<S2SV> out : //<S2SV> return r ; //<S2SV> } //<S2SV> 