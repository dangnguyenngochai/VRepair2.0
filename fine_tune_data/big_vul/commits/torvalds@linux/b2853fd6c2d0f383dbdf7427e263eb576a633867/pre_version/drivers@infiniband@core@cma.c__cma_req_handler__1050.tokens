static int cma_req_handler ( struct ib_cm_id * cm_id , struct ib_cm_event * ib_event ) //<S2SV> { //<S2SV> struct rdma_id_private * listen_id , * conn_id ; //<S2SV> struct rdma_cm_event event ; //<S2SV> int offset , ret ; //<S2SV> u8 smac [ ETH_ALEN ] ; //<S2SV> u8 alt_smac [ ETH_ALEN ] ; //<S2SV> u8 * psmac = smac ; //<S2SV> u8 * palt_smac = alt_smac ; //<S2SV> int is_iboe = ( ( rdma_node_get_transport ( cm_id -> device -> node_type ) == //<S2SV> RDMA_TRANSPORT_IB ) && //<S2SV> ( rdma_port_get_link_layer ( cm_id -> device , //<S2SV> ib_event -> param . req_rcvd . port ) == //<S2SV> IB_LINK_LAYER_ETHERNET ) ) ; //<S2SV> listen_id = cm_id -> context ; //<S2SV> if ( ! cma_check_req_qp_type ( & listen_id -> id , ib_event ) ) //<S2SV> return - EINVAL ; //<S2SV> if ( cma_disable_callback ( listen_id , RDMA_CM_LISTEN ) ) //<S2SV> return - ECONNABORTED ; //<S2SV> memset ( & event , 0 , sizeof event ) ; //<S2SV> offset = cma_user_data_offset ( listen_id ) ; //<S2SV> event . event = RDMA_CM_EVENT_CONNECT_REQUEST ; //<S2SV> if ( ib_event -> event == IB_CM_SIDR_REQ_RECEIVED ) { //<S2SV> conn_id = cma_new_udp_id ( & listen_id -> id , ib_event ) ; //<S2SV> event . param . ud . private_data = ib_event -> private_data + offset ; //<S2SV> event . param . ud . private_data_len = //<S2SV> IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE - offset ; //<S2SV> } else { //<S2SV> conn_id = cma_new_conn_id ( & listen_id -> id , ib_event ) ; //<S2SV> cma_set_req_event_data ( & event , & ib_event -> param . req_rcvd , //<S2SV> ib_event -> private_data , offset ) ; //<S2SV> } //<S2SV> if ( ! conn_id ) { //<S2SV> ret = - ENOMEM ; //<S2SV> goto err1 ; //<S2SV> } //<S2SV> mutex_lock_nested ( & conn_id -> handler_mutex , SINGLE_DEPTH_NESTING ) ; //<S2SV> ret = cma_acquire_dev ( conn_id , listen_id ) ; //<S2SV> if ( ret ) //<S2SV> goto err2 ; //<S2SV> conn_id -> cm_id . ib = cm_id ; //<S2SV> cm_id -> context = conn_id ; //<S2SV> cm_id -> cm_handler = cma_ib_handler ; //<S2SV> atomic_inc ( & conn_id -> refcount ) ; //<S2SV> ret = conn_id -> id . event_handler ( & conn_id -> id , & event ) ; //<S2SV> if ( ret ) //<S2SV> goto err3 ; //<S2SV> if ( is_iboe ) { //<S2SV> if ( ib_event -> param . req_rcvd . primary_path != NULL ) //<S2SV> rdma_addr_find_smac_by_sgid ( //<S2SV> & ib_event -> param . req_rcvd . primary_path -> sgid , //<S2SV> psmac , NULL ) ; //<S2SV> else //<S2SV> psmac = NULL ; //<S2SV> if ( ib_event -> param . req_rcvd . alternate_path != NULL ) //<S2SV> rdma_addr_find_smac_by_sgid ( //<S2SV> & ib_event -> param . req_rcvd . alternate_path -> sgid , //<S2SV> palt_smac , NULL ) ; //<S2SV> else //<S2SV> palt_smac = NULL ; //<S2SV> } //<S2SV> mutex_lock ( & lock ) ; //<S2SV> if ( is_iboe ) //<S2SV> ib_update_cm_av ( cm_id , psmac , palt_smac ) ; //<S2SV> if ( cma_comp ( conn_id , RDMA_CM_CONNECT ) && //<S2SV> ( conn_id -> id . qp_type != IB_QPT_UD ) ) //<S2SV> ib_send_cm_mra ( cm_id , CMA_CM_MRA_SETTING , NULL , 0 ) ; //<S2SV> mutex_unlock ( & lock ) ; //<S2SV> mutex_unlock ( & conn_id -> handler_mutex ) ; //<S2SV> mutex_unlock ( & listen_id -> handler_mutex ) ; //<S2SV> cma_deref_id ( conn_id ) ; //<S2SV> return 0 ; //<S2SV> err3 : //<S2SV> cma_deref_id ( conn_id ) ; //<S2SV> conn_id -> cm_id . ib = NULL ; //<S2SV> err2 : //<S2SV> cma_exch ( conn_id , RDMA_CM_DESTROYING ) ; //<S2SV> mutex_unlock ( & conn_id -> handler_mutex ) ; //<S2SV> err1 : //<S2SV> mutex_unlock ( & listen_id -> handler_mutex ) ; //<S2SV> if ( conn_id ) //<S2SV> rdma_destroy_id ( & conn_id -> id ) ; //<S2SV> return ret ; //<S2SV> } //<S2SV> 