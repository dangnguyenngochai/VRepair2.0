struct sk_buff * skb_segment ( struct sk_buff * head_skb , //<S2SV> netdev_features_t features ) //<S2SV> { //<S2SV> struct sk_buff * segs = NULL ; //<S2SV> struct sk_buff * tail = NULL ; //<S2SV> struct sk_buff * list_skb = skb_shinfo ( head_skb ) -> frag_list ; //<S2SV> skb_frag_t * frag = skb_shinfo ( head_skb ) -> frags ; //<S2SV> unsigned int mss = skb_shinfo ( head_skb ) -> gso_size ; //<S2SV> unsigned int doffset = head_skb -> data - skb_mac_header ( head_skb ) ; //<S2SV> struct sk_buff * frag_skb = head_skb ; //<S2SV> unsigned int offset = doffset ; //<S2SV> unsigned int tnl_hlen = skb_tnl_header_len ( head_skb ) ; //<S2SV> unsigned int headroom ; //<S2SV> unsigned int len ; //<S2SV> __be16 proto ; //<S2SV> bool csum ; //<S2SV> int sg = ! ! ( features & NETIF_F_SG ) ; //<S2SV> int nfrags = skb_shinfo ( head_skb ) -> nr_frags ; //<S2SV> int err = - ENOMEM ; //<S2SV> int i = 0 ; //<S2SV> int pos ; //<S2SV> proto = skb_network_protocol ( head_skb ) ; //<S2SV> if ( unlikely ( ! proto ) ) //<S2SV> return ERR_PTR ( - EINVAL ) ; //<S2SV> csum = ! ! can_checksum_protocol ( features , proto ) ; //<S2SV> __skb_push ( head_skb , doffset ) ; //<S2SV> headroom = skb_headroom ( head_skb ) ; //<S2SV> pos = skb_headlen ( head_skb ) ; //<S2SV> do { //<S2SV> struct sk_buff * nskb ; //<S2SV> skb_frag_t * nskb_frag ; //<S2SV> int hsize ; //<S2SV> int size ; //<S2SV> len = head_skb -> len - offset ; //<S2SV> if ( len > mss ) //<S2SV> len = mss ; //<S2SV> hsize = skb_headlen ( head_skb ) - offset ; //<S2SV> if ( hsize < 0 ) //<S2SV> hsize = 0 ; //<S2SV> if ( hsize > len || ! sg ) //<S2SV> hsize = len ; //<S2SV> if ( ! hsize && i >= nfrags && skb_headlen ( list_skb ) && //<S2SV> ( skb_headlen ( list_skb ) == len || sg ) ) { //<S2SV> BUG_ON ( skb_headlen ( list_skb ) > len ) ; //<S2SV> i = 0 ; //<S2SV> nfrags = skb_shinfo ( list_skb ) -> nr_frags ; //<S2SV> frag = skb_shinfo ( list_skb ) -> frags ; //<S2SV> frag_skb = list_skb ; //<S2SV> pos += skb_headlen ( list_skb ) ; //<S2SV> while ( pos < offset + len ) { //<S2SV> BUG_ON ( i >= nfrags ) ; //<S2SV> size = skb_frag_size ( frag ) ; //<S2SV> if ( pos + size > offset + len ) //<S2SV> break ; //<S2SV> i ++ ; //<S2SV> pos += size ; //<S2SV> frag ++ ; //<S2SV> } //<S2SV> nskb = skb_clone ( list_skb , GFP_ATOMIC ) ; //<S2SV> list_skb = list_skb -> next ; //<S2SV> if ( unlikely ( ! nskb ) ) //<S2SV> goto err ; //<S2SV> if ( unlikely ( pskb_trim ( nskb , len ) ) ) { //<S2SV> kfree_skb ( nskb ) ; //<S2SV> goto err ; //<S2SV> } //<S2SV> hsize = skb_end_offset ( nskb ) ; //<S2SV> if ( skb_cow_head ( nskb , doffset + headroom ) ) { //<S2SV> kfree_skb ( nskb ) ; //<S2SV> goto err ; //<S2SV> } //<S2SV> nskb -> truesize += skb_end_offset ( nskb ) - hsize ; //<S2SV> skb_release_head_state ( nskb ) ; //<S2SV> __skb_push ( nskb , doffset ) ; //<S2SV> } else { //<S2SV> nskb = __alloc_skb ( hsize + doffset + headroom , //<S2SV> GFP_ATOMIC , skb_alloc_rx_flag ( head_skb ) , //<S2SV> NUMA_NO_NODE ) ; //<S2SV> if ( unlikely ( ! nskb ) ) //<S2SV> goto err ; //<S2SV> skb_reserve ( nskb , headroom ) ; //<S2SV> __skb_put ( nskb , doffset ) ; //<S2SV> } //<S2SV> if ( segs ) //<S2SV> tail -> next = nskb ; //<S2SV> else //<S2SV> segs = nskb ; //<S2SV> tail = nskb ; //<S2SV> __copy_skb_header ( nskb , head_skb ) ; //<S2SV> nskb -> mac_len = head_skb -> mac_len ; //<S2SV> skb_headers_offset_update ( nskb , skb_headroom ( nskb ) - headroom ) ; //<S2SV> skb_copy_from_linear_data_offset ( head_skb , - tnl_hlen , //<S2SV> nskb -> data - tnl_hlen , //<S2SV> doffset + tnl_hlen ) ; //<S2SV> if ( nskb -> len == len + doffset ) //<S2SV> goto perform_csum_check ; //<S2SV> if ( ! sg ) { //<S2SV> nskb -> ip_summed = CHECKSUM_NONE ; //<S2SV> nskb -> csum = skb_copy_and_csum_bits ( head_skb , offset , //<S2SV> skb_put ( nskb , len ) , //<S2SV> len , 0 ) ; //<S2SV> continue ; //<S2SV> } //<S2SV> nskb_frag = skb_shinfo ( nskb ) -> frags ; //<S2SV> skb_copy_from_linear_data_offset ( head_skb , offset , //<S2SV> skb_put ( nskb , hsize ) , hsize ) ; //<S2SV> skb_shinfo ( nskb ) -> tx_flags = skb_shinfo ( head_skb ) -> tx_flags & //<S2SV> SKBTX_SHARED_FRAG ; //<S2SV> while ( pos < offset + len ) { //<S2SV> if ( i >= nfrags ) { //<S2SV> BUG_ON ( skb_headlen ( list_skb ) ) ; //<S2SV> i = 0 ; //<S2SV> nfrags = skb_shinfo ( list_skb ) -> nr_frags ; //<S2SV> frag = skb_shinfo ( list_skb ) -> frags ; //<S2SV> frag_skb = list_skb ; //<S2SV> BUG_ON ( ! nfrags ) ; //<S2SV> list_skb = list_skb -> next ; //<S2SV> } //<S2SV> if ( unlikely ( skb_shinfo ( nskb ) -> nr_frags >= //<S2SV> MAX_SKB_FRAGS ) ) { //<S2SV> net_warn_ratelimited ( //<S2SV> "skb_segment:<S2SV_blank>too<S2SV_blank>many<S2SV_blank>frags:<S2SV_blank>%u<S2SV_blank>%u\\n" , //<S2SV> pos , mss ) ; //<S2SV> goto err ; //<S2SV> } //<S2SV> if ( unlikely ( skb_orphan_frags ( frag_skb , GFP_ATOMIC ) ) ) //<S2SV> goto err ; //<S2SV> * nskb_frag = * frag ; //<S2SV> __skb_frag_ref ( nskb_frag ) ; //<S2SV> size = skb_frag_size ( nskb_frag ) ; //<S2SV> if ( pos < offset ) { //<S2SV> nskb_frag -> page_offset += offset - pos ; //<S2SV> skb_frag_size_sub ( nskb_frag , offset - pos ) ; //<S2SV> } //<S2SV> skb_shinfo ( nskb ) -> nr_frags ++ ; //<S2SV> if ( pos + size <= offset + len ) { //<S2SV> i ++ ; //<S2SV> frag ++ ; //<S2SV> pos += size ; //<S2SV> } else { //<S2SV> skb_frag_size_sub ( nskb_frag , pos + size - ( offset + len ) ) ; //<S2SV> goto skip_fraglist ; //<S2SV> } //<S2SV> nskb_frag ++ ; //<S2SV> } //<S2SV> skip_fraglist : //<S2SV> nskb -> data_len = len - hsize ; //<S2SV> nskb -> len += nskb -> data_len ; //<S2SV> nskb -> truesize += nskb -> data_len ; //<S2SV> perform_csum_check : //<S2SV> if ( ! csum ) { //<S2SV> nskb -> csum = skb_checksum ( nskb , doffset , //<S2SV> nskb -> len - doffset , 0 ) ; //<S2SV> nskb -> ip_summed = CHECKSUM_NONE ; //<S2SV> } //<S2SV> } while ( ( offset += len ) < head_skb -> len ) ; //<S2SV> return segs ; //<S2SV> err : //<S2SV> kfree_skb_list ( segs ) ; //<S2SV> return ERR_PTR ( err ) ; //<S2SV> } //<S2SV> 