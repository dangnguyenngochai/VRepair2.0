static int kvm_vm_ioctl_assign_device ( struct kvm * kvm , //<S2SV> struct kvm_assigned_pci_dev * assigned_dev ) //<S2SV> { //<S2SV> int r = 0 , idx ; //<S2SV> struct kvm_assigned_dev_kernel * match ; //<S2SV> struct pci_dev * dev ; //<S2SV> u8 header_type ; //<S2SV> if ( ! ( assigned_dev -> flags & KVM_DEV_ASSIGN_ENABLE_IOMMU ) ) //<S2SV> return - EINVAL ; //<S2SV> mutex_lock ( & kvm -> lock ) ; //<S2SV> idx = srcu_read_lock ( & kvm -> srcu ) ; //<S2SV> match = kvm_find_assigned_dev ( & kvm -> arch . assigned_dev_head , //<S2SV> assigned_dev -> assigned_dev_id ) ; //<S2SV> if ( match ) { //<S2SV> r = - EEXIST ; //<S2SV> goto out ; //<S2SV> } //<S2SV> match = kzalloc ( sizeof ( struct kvm_assigned_dev_kernel ) , GFP_KERNEL ) ; //<S2SV> if ( match == NULL ) { //<S2SV> printk ( KERN_INFO "%s:<S2SV_blank>Couldn\'t<S2SV_blank>allocate<S2SV_blank>memory\\n" , //<S2SV> __func__ ) ; //<S2SV> r = - ENOMEM ; //<S2SV> goto out ; //<S2SV> } //<S2SV> dev = pci_get_domain_bus_and_slot ( assigned_dev -> segnr , //<S2SV> assigned_dev -> busnr , //<S2SV> assigned_dev -> devfn ) ; //<S2SV> if ( ! dev ) { //<S2SV> printk ( KERN_INFO "%s:<S2SV_blank>host<S2SV_blank>device<S2SV_blank>not<S2SV_blank>found\\n" , __func__ ) ; //<S2SV> r = - EINVAL ; //<S2SV> goto out_free ; //<S2SV> } //<S2SV> pci_read_config_byte ( dev , PCI_HEADER_TYPE , & header_type ) ; //<S2SV> if ( ( header_type & PCI_HEADER_TYPE ) != PCI_HEADER_TYPE_NORMAL ) { //<S2SV> r = - EPERM ; //<S2SV> goto out_put ; //<S2SV> } //<S2SV> r = probe_sysfs_permissions ( dev ) ; //<S2SV> if ( r ) //<S2SV> goto out_put ; //<S2SV> if ( pci_enable_device ( dev ) ) { //<S2SV> printk ( KERN_INFO "%s:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>enable<S2SV_blank>PCI<S2SV_blank>device\\n" , __func__ ) ; //<S2SV> r = - EBUSY ; //<S2SV> goto out_put ; //<S2SV> } //<S2SV> r = pci_request_regions ( dev , "kvm_assigned_device" ) ; //<S2SV> if ( r ) { //<S2SV> printk ( KERN_INFO "%s:<S2SV_blank>Could<S2SV_blank>not<S2SV_blank>get<S2SV_blank>access<S2SV_blank>to<S2SV_blank>device<S2SV_blank>regions\\n" , //<S2SV> __func__ ) ; //<S2SV> goto out_disable ; //<S2SV> } //<S2SV> pci_reset_function ( dev ) ; //<S2SV> pci_save_state ( dev ) ; //<S2SV> match -> pci_saved_state = pci_store_saved_state ( dev ) ; //<S2SV> if ( ! match -> pci_saved_state ) //<S2SV> printk ( KERN_DEBUG "%s:<S2SV_blank>Couldn\'t<S2SV_blank>store<S2SV_blank>%s<S2SV_blank>saved<S2SV_blank>state\\n" , //<S2SV> __func__ , dev_name ( & dev -> dev ) ) ; //<S2SV> match -> assigned_dev_id = assigned_dev -> assigned_dev_id ; //<S2SV> match -> host_segnr = assigned_dev -> segnr ; //<S2SV> match -> host_busnr = assigned_dev -> busnr ; //<S2SV> match -> host_devfn = assigned_dev -> devfn ; //<S2SV> match -> flags = assigned_dev -> flags ; //<S2SV> match -> dev = dev ; //<S2SV> spin_lock_init ( & match -> intx_lock ) ; //<S2SV> match -> irq_source_id = - 1 ; //<S2SV> match -> kvm = kvm ; //<S2SV> match -> ack_notifier . irq_acked = kvm_assigned_dev_ack_irq ; //<S2SV> list_add ( & match -> list , & kvm -> arch . assigned_dev_head ) ; //<S2SV> if ( ! kvm -> arch . iommu_domain ) { //<S2SV> r = kvm_iommu_map_guest ( kvm ) ; //<S2SV> if ( r ) //<S2SV> goto out_list_del ; //<S2SV> } //<S2SV> r = kvm_assign_device ( kvm , match ) ; //<S2SV> if ( r ) //<S2SV> goto out_list_del ; //<S2SV> out : //<S2SV> srcu_read_unlock ( & kvm -> srcu , idx ) ; //<S2SV> mutex_unlock ( & kvm -> lock ) ; //<S2SV> return r ; //<S2SV> out_list_del : //<S2SV> if ( pci_load_and_free_saved_state ( dev , & match -> pci_saved_state ) ) //<S2SV> printk ( KERN_INFO "%s:<S2SV_blank>Couldn\'t<S2SV_blank>reload<S2SV_blank>%s<S2SV_blank>saved<S2SV_blank>state\\n" , //<S2SV> __func__ , dev_name ( & dev -> dev ) ) ; //<S2SV> list_del ( & match -> list ) ; //<S2SV> pci_release_regions ( dev ) ; //<S2SV> out_disable : //<S2SV> pci_disable_device ( dev ) ; //<S2SV> out_put : //<S2SV> pci_dev_put ( dev ) ; //<S2SV> out_free : //<S2SV> kfree ( match ) ; //<S2SV> srcu_read_unlock ( & kvm -> srcu , idx ) ; //<S2SV> mutex_unlock ( & kvm -> lock ) ; //<S2SV> return r ; //<S2SV> } //<S2SV> 