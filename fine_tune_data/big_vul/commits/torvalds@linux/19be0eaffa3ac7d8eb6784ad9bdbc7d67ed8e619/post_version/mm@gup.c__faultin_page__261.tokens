static int faultin_page ( struct task_struct * tsk , struct vm_area_struct * vma , //<S2SV> unsigned long address , unsigned int * flags , int * nonblocking ) //<S2SV> { //<S2SV> unsigned int fault_flags = 0 ; //<S2SV> int ret ; //<S2SV> if ( ( * flags & ( FOLL_POPULATE | FOLL_MLOCK ) ) == FOLL_MLOCK ) //<S2SV> return - ENOENT ; //<S2SV> if ( ( * flags & FOLL_POPULATE ) && //<S2SV> ( stack_guard_page_start ( vma , address ) || //<S2SV> stack_guard_page_end ( vma , address + PAGE_SIZE ) ) ) //<S2SV> return - ENOENT ; //<S2SV> if ( * flags & FOLL_WRITE ) //<S2SV> fault_flags |= FAULT_FLAG_WRITE ; //<S2SV> if ( * flags & FOLL_REMOTE ) //<S2SV> fault_flags |= FAULT_FLAG_REMOTE ; //<S2SV> if ( nonblocking ) //<S2SV> fault_flags |= FAULT_FLAG_ALLOW_RETRY ; //<S2SV> if ( * flags & FOLL_NOWAIT ) //<S2SV> fault_flags |= FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_RETRY_NOWAIT ; //<S2SV> if ( * flags & FOLL_TRIED ) { //<S2SV> VM_WARN_ON_ONCE ( fault_flags & FAULT_FLAG_ALLOW_RETRY ) ; //<S2SV> fault_flags |= FAULT_FLAG_TRIED ; //<S2SV> } //<S2SV> ret = handle_mm_fault ( vma , address , fault_flags ) ; //<S2SV> if ( ret & VM_FAULT_ERROR ) { //<S2SV> if ( ret & VM_FAULT_OOM ) //<S2SV> return - ENOMEM ; //<S2SV> if ( ret & ( VM_FAULT_HWPOISON | VM_FAULT_HWPOISON_LARGE ) ) //<S2SV> return * flags & FOLL_HWPOISON ? - EHWPOISON : - EFAULT ; //<S2SV> if ( ret & ( VM_FAULT_SIGBUS | VM_FAULT_SIGSEGV ) ) //<S2SV> return - EFAULT ; //<S2SV> BUG ( ) ; //<S2SV> } //<S2SV> if ( tsk ) { //<S2SV> if ( ret & VM_FAULT_MAJOR ) //<S2SV> tsk -> maj_flt ++ ; //<S2SV> else //<S2SV> tsk -> min_flt ++ ; //<S2SV> } //<S2SV> if ( ret & VM_FAULT_RETRY ) { //<S2SV> if ( nonblocking ) //<S2SV> * nonblocking = 0 ; //<S2SV> return - EBUSY ; //<S2SV> } //<S2SV> if ( ( ret & VM_FAULT_WRITE ) && ! ( vma -> vm_flags & VM_WRITE ) ) //<S2SV> * flags |= FOLL_COW ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> 