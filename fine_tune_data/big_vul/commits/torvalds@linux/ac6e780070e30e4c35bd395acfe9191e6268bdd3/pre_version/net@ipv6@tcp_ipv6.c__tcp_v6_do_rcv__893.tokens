static int tcp_v6_do_rcv ( struct sock * sk , struct sk_buff * skb ) //<S2SV> { //<S2SV> struct ipv6_pinfo * np = inet6_sk ( sk ) ; //<S2SV> struct tcp_sock * tp ; //<S2SV> struct sk_buff * opt_skb = NULL ; //<S2SV> if ( skb -> protocol == htons ( ETH_P_IP ) ) //<S2SV> return tcp_v4_do_rcv ( sk , skb ) ; //<S2SV> if ( sk_filter ( sk , skb ) ) //<S2SV> goto discard ; //<S2SV> if ( np -> rxopt . all ) //<S2SV> opt_skb = skb_clone ( skb , sk_gfp_mask ( sk , GFP_ATOMIC ) ) ; //<S2SV> if ( sk -> sk_state == TCP_ESTABLISHED ) { //<S2SV> struct dst_entry * dst = sk -> sk_rx_dst ; //<S2SV> sock_rps_save_rxhash ( sk , skb ) ; //<S2SV> sk_mark_napi_id ( sk , skb ) ; //<S2SV> if ( dst ) { //<S2SV> if ( inet_sk ( sk ) -> rx_dst_ifindex != skb -> skb_iif || //<S2SV> dst -> ops -> check ( dst , np -> rx_dst_cookie ) == NULL ) { //<S2SV> dst_release ( dst ) ; //<S2SV> sk -> sk_rx_dst = NULL ; //<S2SV> } //<S2SV> } //<S2SV> tcp_rcv_established ( sk , skb , tcp_hdr ( skb ) , skb -> len ) ; //<S2SV> if ( opt_skb ) //<S2SV> goto ipv6_pktoptions ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> if ( tcp_checksum_complete ( skb ) ) //<S2SV> goto csum_err ; //<S2SV> if ( sk -> sk_state == TCP_LISTEN ) { //<S2SV> struct sock * nsk = tcp_v6_cookie_check ( sk , skb ) ; //<S2SV> if ( ! nsk ) //<S2SV> goto discard ; //<S2SV> if ( nsk != sk ) { //<S2SV> sock_rps_save_rxhash ( nsk , skb ) ; //<S2SV> sk_mark_napi_id ( nsk , skb ) ; //<S2SV> if ( tcp_child_process ( sk , nsk , skb ) ) //<S2SV> goto reset ; //<S2SV> if ( opt_skb ) //<S2SV> __kfree_skb ( opt_skb ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> } else //<S2SV> sock_rps_save_rxhash ( sk , skb ) ; //<S2SV> if ( tcp_rcv_state_process ( sk , skb ) ) //<S2SV> goto reset ; //<S2SV> if ( opt_skb ) //<S2SV> goto ipv6_pktoptions ; //<S2SV> return 0 ; //<S2SV> reset : //<S2SV> tcp_v6_send_reset ( sk , skb ) ; //<S2SV> discard : //<S2SV> if ( opt_skb ) //<S2SV> __kfree_skb ( opt_skb ) ; //<S2SV> kfree_skb ( skb ) ; //<S2SV> return 0 ; //<S2SV> csum_err : //<S2SV> TCP_INC_STATS ( sock_net ( sk ) , TCP_MIB_CSUMERRORS ) ; //<S2SV> TCP_INC_STATS ( sock_net ( sk ) , TCP_MIB_INERRS ) ; //<S2SV> goto discard ; //<S2SV> ipv6_pktoptions : //<S2SV> tp = tcp_sk ( sk ) ; //<S2SV> if ( TCP_SKB_CB ( opt_skb ) -> end_seq == tp -> rcv_nxt && //<S2SV> ! ( ( 1 << sk -> sk_state ) & ( TCPF_CLOSE | TCPF_LISTEN ) ) ) { //<S2SV> if ( np -> rxopt . bits . rxinfo || np -> rxopt . bits . rxoinfo ) //<S2SV> np -> mcast_oif = tcp_v6_iif ( opt_skb ) ; //<S2SV> if ( np -> rxopt . bits . rxhlim || np -> rxopt . bits . rxohlim ) //<S2SV> np -> mcast_hops = ipv6_hdr ( opt_skb ) -> hop_limit ; //<S2SV> if ( np -> rxopt . bits . rxflow || np -> rxopt . bits . rxtclass ) //<S2SV> np -> rcv_flowinfo = ip6_flowinfo ( ipv6_hdr ( opt_skb ) ) ; //<S2SV> if ( np -> repflow ) //<S2SV> np -> flow_label = ip6_flowlabel ( ipv6_hdr ( opt_skb ) ) ; //<S2SV> if ( ipv6_opt_accepted ( sk , opt_skb , & TCP_SKB_CB ( opt_skb ) -> header . h6 ) ) { //<S2SV> skb_set_owner_r ( opt_skb , sk ) ; //<S2SV> tcp_v6_restore_cb ( opt_skb ) ; //<S2SV> opt_skb = xchg ( & np -> pktoptions , opt_skb ) ; //<S2SV> } else { //<S2SV> __kfree_skb ( opt_skb ) ; //<S2SV> opt_skb = xchg ( & np -> pktoptions , NULL ) ; //<S2SV> } //<S2SV> } //<S2SV> kfree_skb ( opt_skb ) ; //<S2SV> return 0 ; //<S2SV> } //<S2SV> 