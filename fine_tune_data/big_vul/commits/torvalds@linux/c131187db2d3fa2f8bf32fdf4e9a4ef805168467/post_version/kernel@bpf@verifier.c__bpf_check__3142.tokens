int bpf_check ( struct bpf_prog * * prog , union bpf_attr * attr ) //<S2SV> { //<S2SV> struct bpf_verifier_env * env ; //<S2SV> struct bpf_verifer_log * log ; //<S2SV> int ret = - EINVAL ; //<S2SV> if ( ARRAY_SIZE ( bpf_verifier_ops ) == 0 ) //<S2SV> return - EINVAL ; //<S2SV> env = kzalloc ( sizeof ( struct bpf_verifier_env ) , GFP_KERNEL ) ; //<S2SV> if ( ! env ) //<S2SV> return - ENOMEM ; //<S2SV> log = & env -> log ; //<S2SV> env -> insn_aux_data = vzalloc ( sizeof ( struct bpf_insn_aux_data ) * //<S2SV> ( * prog ) -> len ) ; //<S2SV> ret = - ENOMEM ; //<S2SV> if ( ! env -> insn_aux_data ) //<S2SV> goto err_free_env ; //<S2SV> env -> prog = * prog ; //<S2SV> env -> ops = bpf_verifier_ops [ env -> prog -> type ] ; //<S2SV> mutex_lock ( & bpf_verifier_lock ) ; //<S2SV> if ( attr -> log_level || attr -> log_buf || attr -> log_size ) { //<S2SV> log -> level = attr -> log_level ; //<S2SV> log -> ubuf = ( char __user * ) ( unsigned long ) attr -> log_buf ; //<S2SV> log -> len_total = attr -> log_size ; //<S2SV> ret = - EINVAL ; //<S2SV> if ( log -> len_total < 128 || log -> len_total > UINT_MAX >> 8 || //<S2SV> ! log -> level || ! log -> ubuf ) //<S2SV> goto err_unlock ; //<S2SV> } //<S2SV> env -> strict_alignment = ! ! ( attr -> prog_flags & BPF_F_STRICT_ALIGNMENT ) ; //<S2SV> if ( ! IS_ENABLED ( CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS ) ) //<S2SV> env -> strict_alignment = true ; //<S2SV> if ( env -> prog -> aux -> offload ) { //<S2SV> ret = bpf_prog_offload_verifier_prep ( env ) ; //<S2SV> if ( ret ) //<S2SV> goto err_unlock ; //<S2SV> } //<S2SV> ret = replace_map_fd_with_map_ptr ( env ) ; //<S2SV> if ( ret < 0 ) //<S2SV> goto skip_full_check ; //<S2SV> env -> explored_states = kcalloc ( env -> prog -> len , //<S2SV> sizeof ( struct bpf_verifier_state_list * ) , //<S2SV> GFP_USER ) ; //<S2SV> ret = - ENOMEM ; //<S2SV> if ( ! env -> explored_states ) //<S2SV> goto skip_full_check ; //<S2SV> ret = check_cfg ( env ) ; //<S2SV> if ( ret < 0 ) //<S2SV> goto skip_full_check ; //<S2SV> env -> allow_ptr_leaks = capable ( CAP_SYS_ADMIN ) ; //<S2SV> ret = do_check ( env ) ; //<S2SV> if ( env -> cur_state ) { //<S2SV> free_verifier_state ( env -> cur_state , true ) ; //<S2SV> env -> cur_state = NULL ; //<S2SV> } //<S2SV> skip_full_check : //<S2SV> while ( ! pop_stack ( env , NULL , NULL ) ) ; //<S2SV> free_states ( env ) ; //<S2SV> if ( ret == 0 ) //<S2SV> sanitize_dead_code ( env ) ; //<S2SV> if ( ret == 0 ) //<S2SV> ret = convert_ctx_accesses ( env ) ; //<S2SV> if ( ret == 0 ) //<S2SV> ret = fixup_bpf_calls ( env ) ; //<S2SV> if ( log -> level && bpf_verifier_log_full ( log ) ) //<S2SV> ret = - ENOSPC ; //<S2SV> if ( log -> level && ! log -> ubuf ) { //<S2SV> ret = - EFAULT ; //<S2SV> goto err_release_maps ; //<S2SV> } //<S2SV> if ( ret == 0 && env -> used_map_cnt ) { //<S2SV> env -> prog -> aux -> used_maps = kmalloc_array ( env -> used_map_cnt , //<S2SV> sizeof ( env -> used_maps [ 0 ] ) , //<S2SV> GFP_KERNEL ) ; //<S2SV> if ( ! env -> prog -> aux -> used_maps ) { //<S2SV> ret = - ENOMEM ; //<S2SV> goto err_release_maps ; //<S2SV> } //<S2SV> memcpy ( env -> prog -> aux -> used_maps , env -> used_maps , //<S2SV> sizeof ( env -> used_maps [ 0 ] ) * env -> used_map_cnt ) ; //<S2SV> env -> prog -> aux -> used_map_cnt = env -> used_map_cnt ; //<S2SV> convert_pseudo_ld_imm64 ( env ) ; //<S2SV> } //<S2SV> err_release_maps : //<S2SV> if ( ! env -> prog -> aux -> used_maps ) //<S2SV> release_maps ( env ) ; //<S2SV> * prog = env -> prog ; //<S2SV> err_unlock : //<S2SV> mutex_unlock ( & bpf_verifier_lock ) ; //<S2SV> vfree ( env -> insn_aux_data ) ; //<S2SV> err_free_env : //<S2SV> kfree ( env ) ; //<S2SV> return ret ; //<S2SV> } //<S2SV> 