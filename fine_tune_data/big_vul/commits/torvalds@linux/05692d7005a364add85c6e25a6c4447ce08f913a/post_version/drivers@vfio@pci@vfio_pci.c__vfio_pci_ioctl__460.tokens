static long vfio_pci_ioctl ( void * device_data , //<S2SV> unsigned int cmd , unsigned long arg ) //<S2SV> { //<S2SV> struct vfio_pci_device * vdev = device_data ; //<S2SV> unsigned long minsz ; //<S2SV> if ( cmd == VFIO_DEVICE_GET_INFO ) { //<S2SV> struct vfio_device_info info ; //<S2SV> minsz = offsetofend ( struct vfio_device_info , num_irqs ) ; //<S2SV> if ( copy_from_user ( & info , ( void __user * ) arg , minsz ) ) //<S2SV> return - EFAULT ; //<S2SV> if ( info . argsz < minsz ) //<S2SV> return - EINVAL ; //<S2SV> info . flags = VFIO_DEVICE_FLAGS_PCI ; //<S2SV> if ( vdev -> reset_works ) //<S2SV> info . flags |= VFIO_DEVICE_FLAGS_RESET ; //<S2SV> info . num_regions = VFIO_PCI_NUM_REGIONS + vdev -> num_regions ; //<S2SV> info . num_irqs = VFIO_PCI_NUM_IRQS ; //<S2SV> return copy_to_user ( ( void __user * ) arg , & info , minsz ) ? //<S2SV> - EFAULT : 0 ; //<S2SV> } else if ( cmd == VFIO_DEVICE_GET_REGION_INFO ) { //<S2SV> struct pci_dev * pdev = vdev -> pdev ; //<S2SV> struct vfio_region_info info ; //<S2SV> struct vfio_info_cap caps = { . buf = NULL , . size = 0 } ; //<S2SV> int i , ret ; //<S2SV> minsz = offsetofend ( struct vfio_region_info , offset ) ; //<S2SV> if ( copy_from_user ( & info , ( void __user * ) arg , minsz ) ) //<S2SV> return - EFAULT ; //<S2SV> if ( info . argsz < minsz ) //<S2SV> return - EINVAL ; //<S2SV> switch ( info . index ) { //<S2SV> case VFIO_PCI_CONFIG_REGION_INDEX : //<S2SV> info . offset = VFIO_PCI_INDEX_TO_OFFSET ( info . index ) ; //<S2SV> info . size = pdev -> cfg_size ; //<S2SV> info . flags = VFIO_REGION_INFO_FLAG_READ | //<S2SV> VFIO_REGION_INFO_FLAG_WRITE ; //<S2SV> break ; //<S2SV> case VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX : //<S2SV> info . offset = VFIO_PCI_INDEX_TO_OFFSET ( info . index ) ; //<S2SV> info . size = pci_resource_len ( pdev , info . index ) ; //<S2SV> if ( ! info . size ) { //<S2SV> info . flags = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> info . flags = VFIO_REGION_INFO_FLAG_READ | //<S2SV> VFIO_REGION_INFO_FLAG_WRITE ; //<S2SV> if ( vdev -> bar_mmap_supported [ info . index ] ) { //<S2SV> info . flags |= VFIO_REGION_INFO_FLAG_MMAP ; //<S2SV> if ( info . index == vdev -> msix_bar ) { //<S2SV> ret = msix_sparse_mmap_cap ( vdev , & caps ) ; //<S2SV> if ( ret ) //<S2SV> return ret ; //<S2SV> } //<S2SV> } //<S2SV> break ; //<S2SV> case VFIO_PCI_ROM_REGION_INDEX : //<S2SV> { //<S2SV> void __iomem * io ; //<S2SV> size_t size ; //<S2SV> info . offset = VFIO_PCI_INDEX_TO_OFFSET ( info . index ) ; //<S2SV> info . flags = 0 ; //<S2SV> info . size = pci_resource_len ( pdev , info . index ) ; //<S2SV> if ( ! info . size ) { //<S2SV> if ( pdev -> resource [ PCI_ROM_RESOURCE ] . flags & //<S2SV> IORESOURCE_ROM_SHADOW ) //<S2SV> info . size = 0x20000 ; //<S2SV> else //<S2SV> break ; //<S2SV> } //<S2SV> io = pci_map_rom ( pdev , & size ) ; //<S2SV> if ( ! io || ! size ) { //<S2SV> info . size = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> pci_unmap_rom ( pdev , io ) ; //<S2SV> info . flags = VFIO_REGION_INFO_FLAG_READ ; //<S2SV> break ; //<S2SV> } //<S2SV> case VFIO_PCI_VGA_REGION_INDEX : //<S2SV> if ( ! vdev -> has_vga ) //<S2SV> return - EINVAL ; //<S2SV> info . offset = VFIO_PCI_INDEX_TO_OFFSET ( info . index ) ; //<S2SV> info . size = 0xc0000 ; //<S2SV> info . flags = VFIO_REGION_INFO_FLAG_READ | //<S2SV> VFIO_REGION_INFO_FLAG_WRITE ; //<S2SV> break ; //<S2SV> default : //<S2SV> if ( info . index >= //<S2SV> VFIO_PCI_NUM_REGIONS + vdev -> num_regions ) //<S2SV> return - EINVAL ; //<S2SV> i = info . index - VFIO_PCI_NUM_REGIONS ; //<S2SV> info . offset = VFIO_PCI_INDEX_TO_OFFSET ( info . index ) ; //<S2SV> info . size = vdev -> region [ i ] . size ; //<S2SV> info . flags = vdev -> region [ i ] . flags ; //<S2SV> ret = region_type_cap ( vdev , & caps , //<S2SV> vdev -> region [ i ] . type , //<S2SV> vdev -> region [ i ] . subtype ) ; //<S2SV> if ( ret ) //<S2SV> return ret ; //<S2SV> } //<S2SV> if ( caps . size ) { //<S2SV> info . flags |= VFIO_REGION_INFO_FLAG_CAPS ; //<S2SV> if ( info . argsz < sizeof ( info ) + caps . size ) { //<S2SV> info . argsz = sizeof ( info ) + caps . size ; //<S2SV> info . cap_offset = 0 ; //<S2SV> } else { //<S2SV> vfio_info_cap_shift ( & caps , sizeof ( info ) ) ; //<S2SV> if ( copy_to_user ( ( void __user * ) arg + //<S2SV> sizeof ( info ) , caps . buf , //<S2SV> caps . size ) ) { //<S2SV> kfree ( caps . buf ) ; //<S2SV> return - EFAULT ; //<S2SV> } //<S2SV> info . cap_offset = sizeof ( info ) ; //<S2SV> } //<S2SV> kfree ( caps . buf ) ; //<S2SV> } //<S2SV> return copy_to_user ( ( void __user * ) arg , & info , minsz ) ? //<S2SV> - EFAULT : 0 ; //<S2SV> } else if ( cmd == VFIO_DEVICE_GET_IRQ_INFO ) { //<S2SV> struct vfio_irq_info info ; //<S2SV> minsz = offsetofend ( struct vfio_irq_info , count ) ; //<S2SV> if ( copy_from_user ( & info , ( void __user * ) arg , minsz ) ) //<S2SV> return - EFAULT ; //<S2SV> if ( info . argsz < minsz || info . index >= VFIO_PCI_NUM_IRQS ) //<S2SV> return - EINVAL ; //<S2SV> switch ( info . index ) { //<S2SV> case VFIO_PCI_INTX_IRQ_INDEX ... VFIO_PCI_MSIX_IRQ_INDEX : //<S2SV> case VFIO_PCI_REQ_IRQ_INDEX : //<S2SV> break ; //<S2SV> case VFIO_PCI_ERR_IRQ_INDEX : //<S2SV> if ( pci_is_pcie ( vdev -> pdev ) ) //<S2SV> break ; //<S2SV> default : //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> info . flags = VFIO_IRQ_INFO_EVENTFD ; //<S2SV> info . count = vfio_pci_get_irq_count ( vdev , info . index ) ; //<S2SV> if ( info . index == VFIO_PCI_INTX_IRQ_INDEX ) //<S2SV> info . flags |= ( VFIO_IRQ_INFO_MASKABLE | //<S2SV> VFIO_IRQ_INFO_AUTOMASKED ) ; //<S2SV> else //<S2SV> info . flags |= VFIO_IRQ_INFO_NORESIZE ; //<S2SV> return copy_to_user ( ( void __user * ) arg , & info , minsz ) ? //<S2SV> - EFAULT : 0 ; //<S2SV> } else if ( cmd == VFIO_DEVICE_SET_IRQS ) { //<S2SV> struct vfio_irq_set hdr ; //<S2SV> size_t size ; //<S2SV> u8 * data = NULL ; //<S2SV> int max , ret = 0 ; //<S2SV> minsz = offsetofend ( struct vfio_irq_set , count ) ; //<S2SV> if ( copy_from_user ( & hdr , ( void __user * ) arg , minsz ) ) //<S2SV> return - EFAULT ; //<S2SV> if ( hdr . argsz < minsz || hdr . index >= VFIO_PCI_NUM_IRQS || //<S2SV> hdr . count >= ( U32_MAX - hdr . start ) || //<S2SV> hdr . flags & ~ ( VFIO_IRQ_SET_DATA_TYPE_MASK | //<S2SV> VFIO_IRQ_SET_ACTION_TYPE_MASK ) ) //<S2SV> return - EINVAL ; //<S2SV> max = vfio_pci_get_irq_count ( vdev , hdr . index ) ; //<S2SV> if ( hdr . start >= max || hdr . start + hdr . count > max ) //<S2SV> return - EINVAL ; //<S2SV> switch ( hdr . flags & VFIO_IRQ_SET_DATA_TYPE_MASK ) { //<S2SV> case VFIO_IRQ_SET_DATA_NONE : //<S2SV> size = 0 ; //<S2SV> break ; //<S2SV> case VFIO_IRQ_SET_DATA_BOOL : //<S2SV> size = sizeof ( uint8_t ) ; //<S2SV> break ; //<S2SV> case VFIO_IRQ_SET_DATA_EVENTFD : //<S2SV> size = sizeof ( int32_t ) ; //<S2SV> break ; //<S2SV> default : //<S2SV> return - EINVAL ; //<S2SV> } //<S2SV> if ( size ) { //<S2SV> if ( hdr . argsz - minsz < hdr . count * size ) //<S2SV> return - EINVAL ; //<S2SV> data = memdup_user ( ( void __user * ) ( arg + minsz ) , //<S2SV> hdr . count * size ) ; //<S2SV> if ( IS_ERR ( data ) ) //<S2SV> return PTR_ERR ( data ) ; //<S2SV> } //<S2SV> mutex_lock ( & vdev -> igate ) ; //<S2SV> ret = vfio_pci_set_irqs_ioctl ( vdev , hdr . flags , hdr . index , //<S2SV> hdr . start , hdr . count , data ) ; //<S2SV> mutex_unlock ( & vdev -> igate ) ; //<S2SV> kfree ( data ) ; //<S2SV> return ret ; //<S2SV> } else if ( cmd == VFIO_DEVICE_RESET ) { //<S2SV> return vdev -> reset_works ? //<S2SV> pci_try_reset_function ( vdev -> pdev ) : - EINVAL ; //<S2SV> } else if ( cmd == VFIO_DEVICE_GET_PCI_HOT_RESET_INFO ) { //<S2SV> struct vfio_pci_hot_reset_info hdr ; //<S2SV> struct vfio_pci_fill_info fill = { 0 } ; //<S2SV> struct vfio_pci_dependent_device * devices = NULL ; //<S2SV> bool slot = false ; //<S2SV> int ret = 0 ; //<S2SV> minsz = offsetofend ( struct vfio_pci_hot_reset_info , count ) ; //<S2SV> if ( copy_from_user ( & hdr , ( void __user * ) arg , minsz ) ) //<S2SV> return - EFAULT ; //<S2SV> if ( hdr . argsz < minsz ) //<S2SV> return - EINVAL ; //<S2SV> hdr . flags = 0 ; //<S2SV> if ( ! pci_probe_reset_slot ( vdev -> pdev -> slot ) ) //<S2SV> slot = true ; //<S2SV> else if ( pci_probe_reset_bus ( vdev -> pdev -> bus ) ) //<S2SV> return - ENODEV ; //<S2SV> ret = vfio_pci_for_each_slot_or_bus ( vdev -> pdev , //<S2SV> vfio_pci_count_devs , //<S2SV> & fill . max , slot ) ; //<S2SV> if ( ret ) //<S2SV> return ret ; //<S2SV> WARN_ON ( ! fill . max ) ; //<S2SV> if ( hdr . argsz < sizeof ( hdr ) + ( fill . max * sizeof ( * devices ) ) ) { //<S2SV> ret = - ENOSPC ; //<S2SV> hdr . count = fill . max ; //<S2SV> goto reset_info_exit ; //<S2SV> } //<S2SV> devices = kcalloc ( fill . max , sizeof ( * devices ) , GFP_KERNEL ) ; //<S2SV> if ( ! devices ) //<S2SV> return - ENOMEM ; //<S2SV> fill . devices = devices ; //<S2SV> ret = vfio_pci_for_each_slot_or_bus ( vdev -> pdev , //<S2SV> vfio_pci_fill_devs , //<S2SV> & fill , slot ) ; //<S2SV> if ( ! ret ) //<S2SV> hdr . count = fill . cur ; //<S2SV> reset_info_exit : //<S2SV> if ( copy_to_user ( ( void __user * ) arg , & hdr , minsz ) ) //<S2SV> ret = - EFAULT ; //<S2SV> if ( ! ret ) { //<S2SV> if ( copy_to_user ( ( void __user * ) ( arg + minsz ) , devices , //<S2SV> hdr . count * sizeof ( * devices ) ) ) //<S2SV> ret = - EFAULT ; //<S2SV> } //<S2SV> kfree ( devices ) ; //<S2SV> return ret ; //<S2SV> } else if ( cmd == VFIO_DEVICE_PCI_HOT_RESET ) { //<S2SV> struct vfio_pci_hot_reset hdr ; //<S2SV> int32_t * group_fds ; //<S2SV> struct vfio_pci_group_entry * groups ; //<S2SV> struct vfio_pci_group_info info ; //<S2SV> bool slot = false ; //<S2SV> int i , count = 0 , ret = 0 ; //<S2SV> minsz = offsetofend ( struct vfio_pci_hot_reset , count ) ; //<S2SV> if ( copy_from_user ( & hdr , ( void __user * ) arg , minsz ) ) //<S2SV> return - EFAULT ; //<S2SV> if ( hdr . argsz < minsz || hdr . flags ) //<S2SV> return - EINVAL ; //<S2SV> if ( ! pci_probe_reset_slot ( vdev -> pdev -> slot ) ) //<S2SV> slot = true ; //<S2SV> else if ( pci_probe_reset_bus ( vdev -> pdev -> bus ) ) //<S2SV> return - ENODEV ; //<S2SV> ret = vfio_pci_for_each_slot_or_bus ( vdev -> pdev , //<S2SV> vfio_pci_count_devs , //<S2SV> & count , slot ) ; //<S2SV> if ( ret ) //<S2SV> return ret ; //<S2SV> if ( ! hdr . count || hdr . count > count ) //<S2SV> return - EINVAL ; //<S2SV> group_fds = kcalloc ( hdr . count , sizeof ( * group_fds ) , GFP_KERNEL ) ; //<S2SV> groups = kcalloc ( hdr . count , sizeof ( * groups ) , GFP_KERNEL ) ; //<S2SV> if ( ! group_fds || ! groups ) { //<S2SV> kfree ( group_fds ) ; //<S2SV> kfree ( groups ) ; //<S2SV> return - ENOMEM ; //<S2SV> } //<S2SV> if ( copy_from_user ( group_fds , ( void __user * ) ( arg + minsz ) , //<S2SV> hdr . count * sizeof ( * group_fds ) ) ) { //<S2SV> kfree ( group_fds ) ; //<S2SV> kfree ( groups ) ; //<S2SV> return - EFAULT ; //<S2SV> } //<S2SV> for ( i = 0 ; i < hdr . count ; i ++ ) { //<S2SV> struct vfio_group * group ; //<S2SV> struct fd f = fdget ( group_fds [ i ] ) ; //<S2SV> if ( ! f . file ) { //<S2SV> ret = - EBADF ; //<S2SV> break ; //<S2SV> } //<S2SV> group = vfio_group_get_external_user ( f . file ) ; //<S2SV> fdput ( f ) ; //<S2SV> if ( IS_ERR ( group ) ) { //<S2SV> ret = PTR_ERR ( group ) ; //<S2SV> break ; //<S2SV> } //<S2SV> groups [ i ] . group = group ; //<S2SV> groups [ i ] . id = vfio_external_user_iommu_id ( group ) ; //<S2SV> } //<S2SV> kfree ( group_fds ) ; //<S2SV> if ( ret ) //<S2SV> goto hot_reset_release ; //<S2SV> info . count = hdr . count ; //<S2SV> info . groups = groups ; //<S2SV> ret = vfio_pci_for_each_slot_or_bus ( vdev -> pdev , //<S2SV> vfio_pci_validate_devs , //<S2SV> & info , slot ) ; //<S2SV> if ( ! ret ) //<S2SV> ret = slot ? pci_try_reset_slot ( vdev -> pdev -> slot ) : //<S2SV> pci_try_reset_bus ( vdev -> pdev -> bus ) ; //<S2SV> hot_reset_release : //<S2SV> for ( i -- ; i >= 0 ; i -- ) //<S2SV> vfio_group_put_external_user ( groups [ i ] . group ) ; //<S2SV> kfree ( groups ) ; //<S2SV> return ret ; //<S2SV> } //<S2SV> return - ENOTTY ; //<S2SV> } //<S2SV> 