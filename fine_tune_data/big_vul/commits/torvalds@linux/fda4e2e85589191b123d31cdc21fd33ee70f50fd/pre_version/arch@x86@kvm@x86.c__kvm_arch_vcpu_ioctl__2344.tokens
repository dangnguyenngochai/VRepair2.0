long kvm_arch_vcpu_ioctl ( struct file * filp , //<S2SV> unsigned int ioctl , unsigned long arg ) //<S2SV> { //<S2SV> struct kvm_vcpu * vcpu = filp -> private_data ; //<S2SV> void __user * argp = ( void __user * ) arg ; //<S2SV> int r ; //<S2SV> union { //<S2SV> struct kvm_lapic_state * lapic ; //<S2SV> struct kvm_xsave * xsave ; //<S2SV> struct kvm_xcrs * xcrs ; //<S2SV> void * buffer ; //<S2SV> } u ; //<S2SV> u . buffer = NULL ; //<S2SV> switch ( ioctl ) { //<S2SV> case KVM_GET_LAPIC : { //<S2SV> r = - EINVAL ; //<S2SV> if ( ! vcpu -> arch . apic ) //<S2SV> goto out ; //<S2SV> u . lapic = kzalloc ( sizeof ( struct kvm_lapic_state ) , GFP_KERNEL ) ; //<S2SV> r = - ENOMEM ; //<S2SV> if ( ! u . lapic ) //<S2SV> goto out ; //<S2SV> r = kvm_vcpu_ioctl_get_lapic ( vcpu , u . lapic ) ; //<S2SV> if ( r ) //<S2SV> goto out ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_to_user ( argp , u . lapic , sizeof ( struct kvm_lapic_state ) ) ) //<S2SV> goto out ; //<S2SV> r = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_LAPIC : { //<S2SV> r = - EINVAL ; //<S2SV> if ( ! vcpu -> arch . apic ) //<S2SV> goto out ; //<S2SV> u . lapic = memdup_user ( argp , sizeof ( * u . lapic ) ) ; //<S2SV> if ( IS_ERR ( u . lapic ) ) //<S2SV> return PTR_ERR ( u . lapic ) ; //<S2SV> r = kvm_vcpu_ioctl_set_lapic ( vcpu , u . lapic ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_INTERRUPT : { //<S2SV> struct kvm_interrupt irq ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & irq , argp , sizeof irq ) ) //<S2SV> goto out ; //<S2SV> r = kvm_vcpu_ioctl_interrupt ( vcpu , & irq ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_NMI : { //<S2SV> r = kvm_vcpu_ioctl_nmi ( vcpu ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_CPUID : { //<S2SV> struct kvm_cpuid __user * cpuid_arg = argp ; //<S2SV> struct kvm_cpuid cpuid ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & cpuid , cpuid_arg , sizeof cpuid ) ) //<S2SV> goto out ; //<S2SV> r = kvm_vcpu_ioctl_set_cpuid ( vcpu , & cpuid , cpuid_arg -> entries ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_CPUID2 : { //<S2SV> struct kvm_cpuid2 __user * cpuid_arg = argp ; //<S2SV> struct kvm_cpuid2 cpuid ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & cpuid , cpuid_arg , sizeof cpuid ) ) //<S2SV> goto out ; //<S2SV> r = kvm_vcpu_ioctl_set_cpuid2 ( vcpu , & cpuid , //<S2SV> cpuid_arg -> entries ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_GET_CPUID2 : { //<S2SV> struct kvm_cpuid2 __user * cpuid_arg = argp ; //<S2SV> struct kvm_cpuid2 cpuid ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & cpuid , cpuid_arg , sizeof cpuid ) ) //<S2SV> goto out ; //<S2SV> r = kvm_vcpu_ioctl_get_cpuid2 ( vcpu , & cpuid , //<S2SV> cpuid_arg -> entries ) ; //<S2SV> if ( r ) //<S2SV> goto out ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_to_user ( cpuid_arg , & cpuid , sizeof cpuid ) ) //<S2SV> goto out ; //<S2SV> r = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_GET_MSRS : //<S2SV> r = msr_io ( vcpu , argp , kvm_get_msr , 1 ) ; //<S2SV> break ; //<S2SV> case KVM_SET_MSRS : //<S2SV> r = msr_io ( vcpu , argp , do_set_msr , 0 ) ; //<S2SV> break ; //<S2SV> case KVM_TPR_ACCESS_REPORTING : { //<S2SV> struct kvm_tpr_access_ctl tac ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & tac , argp , sizeof tac ) ) //<S2SV> goto out ; //<S2SV> r = vcpu_ioctl_tpr_access_reporting ( vcpu , & tac ) ; //<S2SV> if ( r ) //<S2SV> goto out ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_to_user ( argp , & tac , sizeof tac ) ) //<S2SV> goto out ; //<S2SV> r = 0 ; //<S2SV> break ; //<S2SV> } ; //<S2SV> case KVM_SET_VAPIC_ADDR : { //<S2SV> struct kvm_vapic_addr va ; //<S2SV> r = - EINVAL ; //<S2SV> if ( ! irqchip_in_kernel ( vcpu -> kvm ) ) //<S2SV> goto out ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & va , argp , sizeof va ) ) //<S2SV> goto out ; //<S2SV> r = 0 ; //<S2SV> kvm_lapic_set_vapic_addr ( vcpu , va . vapic_addr ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_X86_SETUP_MCE : { //<S2SV> u64 mcg_cap ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & mcg_cap , argp , sizeof mcg_cap ) ) //<S2SV> goto out ; //<S2SV> r = kvm_vcpu_ioctl_x86_setup_mce ( vcpu , mcg_cap ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_X86_SET_MCE : { //<S2SV> struct kvm_x86_mce mce ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & mce , argp , sizeof mce ) ) //<S2SV> goto out ; //<S2SV> r = kvm_vcpu_ioctl_x86_set_mce ( vcpu , & mce ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_GET_VCPU_EVENTS : { //<S2SV> struct kvm_vcpu_events events ; //<S2SV> kvm_vcpu_ioctl_x86_get_vcpu_events ( vcpu , & events ) ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_to_user ( argp , & events , sizeof ( struct kvm_vcpu_events ) ) ) //<S2SV> break ; //<S2SV> r = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_VCPU_EVENTS : { //<S2SV> struct kvm_vcpu_events events ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & events , argp , sizeof ( struct kvm_vcpu_events ) ) ) //<S2SV> break ; //<S2SV> r = kvm_vcpu_ioctl_x86_set_vcpu_events ( vcpu , & events ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_GET_DEBUGREGS : { //<S2SV> struct kvm_debugregs dbgregs ; //<S2SV> kvm_vcpu_ioctl_x86_get_debugregs ( vcpu , & dbgregs ) ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_to_user ( argp , & dbgregs , //<S2SV> sizeof ( struct kvm_debugregs ) ) ) //<S2SV> break ; //<S2SV> r = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_DEBUGREGS : { //<S2SV> struct kvm_debugregs dbgregs ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_from_user ( & dbgregs , argp , //<S2SV> sizeof ( struct kvm_debugregs ) ) ) //<S2SV> break ; //<S2SV> r = kvm_vcpu_ioctl_x86_set_debugregs ( vcpu , & dbgregs ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_GET_XSAVE : { //<S2SV> u . xsave = kzalloc ( sizeof ( struct kvm_xsave ) , GFP_KERNEL ) ; //<S2SV> r = - ENOMEM ; //<S2SV> if ( ! u . xsave ) //<S2SV> break ; //<S2SV> kvm_vcpu_ioctl_x86_get_xsave ( vcpu , u . xsave ) ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_to_user ( argp , u . xsave , sizeof ( struct kvm_xsave ) ) ) //<S2SV> break ; //<S2SV> r = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_XSAVE : { //<S2SV> u . xsave = memdup_user ( argp , sizeof ( * u . xsave ) ) ; //<S2SV> if ( IS_ERR ( u . xsave ) ) //<S2SV> return PTR_ERR ( u . xsave ) ; //<S2SV> r = kvm_vcpu_ioctl_x86_set_xsave ( vcpu , u . xsave ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_GET_XCRS : { //<S2SV> u . xcrs = kzalloc ( sizeof ( struct kvm_xcrs ) , GFP_KERNEL ) ; //<S2SV> r = - ENOMEM ; //<S2SV> if ( ! u . xcrs ) //<S2SV> break ; //<S2SV> kvm_vcpu_ioctl_x86_get_xcrs ( vcpu , u . xcrs ) ; //<S2SV> r = - EFAULT ; //<S2SV> if ( copy_to_user ( argp , u . xcrs , //<S2SV> sizeof ( struct kvm_xcrs ) ) ) //<S2SV> break ; //<S2SV> r = 0 ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_XCRS : { //<S2SV> u . xcrs = memdup_user ( argp , sizeof ( * u . xcrs ) ) ; //<S2SV> if ( IS_ERR ( u . xcrs ) ) //<S2SV> return PTR_ERR ( u . xcrs ) ; //<S2SV> r = kvm_vcpu_ioctl_x86_set_xcrs ( vcpu , u . xcrs ) ; //<S2SV> break ; //<S2SV> } //<S2SV> case KVM_SET_TSC_KHZ : { //<S2SV> u32 user_tsc_khz ; //<S2SV> r = - EINVAL ; //<S2SV> user_tsc_khz = ( u32 ) arg ; //<S2SV> if ( user_tsc_khz >= kvm_max_guest_tsc_khz ) //<S2SV> goto out ; //<S2SV> if ( user_tsc_khz == 0 ) //<S2SV> user_tsc_khz = tsc_khz ; //<S2SV> kvm_set_tsc_khz ( vcpu , user_tsc_khz ) ; //<S2SV> r = 0 ; //<S2SV> goto out ; //<S2SV> } //<S2SV> case KVM_GET_TSC_KHZ : { //<S2SV> r = vcpu -> arch . virtual_tsc_khz ; //<S2SV> goto out ; //<S2SV> } //<S2SV> case KVM_KVMCLOCK_CTRL : { //<S2SV> r = kvm_set_guest_paused ( vcpu ) ; //<S2SV> goto out ; //<S2SV> } //<S2SV> default : //<S2SV> r = - EINVAL ; //<S2SV> } //<S2SV> out : //<S2SV> kfree ( u . buffer ) ; //<S2SV> return r ; //<S2SV> } //<S2SV> 