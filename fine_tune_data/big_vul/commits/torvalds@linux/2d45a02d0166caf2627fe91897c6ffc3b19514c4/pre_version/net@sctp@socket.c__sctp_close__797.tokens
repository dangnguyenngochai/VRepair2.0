static void sctp_close ( struct sock * sk , long timeout ) //<S2SV> { //<S2SV> struct net * net = sock_net ( sk ) ; //<S2SV> struct sctp_endpoint * ep ; //<S2SV> struct sctp_association * asoc ; //<S2SV> struct list_head * pos , * temp ; //<S2SV> unsigned int data_was_unread ; //<S2SV> pr_debug ( "%s:<S2SV_blank>sk:%p,<S2SV_blank>timeout:%ld\\n" , __func__ , sk , timeout ) ; //<S2SV> lock_sock ( sk ) ; //<S2SV> sk -> sk_shutdown = SHUTDOWN_MASK ; //<S2SV> sk -> sk_state = SCTP_SS_CLOSING ; //<S2SV> ep = sctp_sk ( sk ) -> ep ; //<S2SV> data_was_unread = sctp_queue_purge_ulpevents ( & sk -> sk_receive_queue ) ; //<S2SV> data_was_unread += sctp_queue_purge_ulpevents ( & sctp_sk ( sk ) -> pd_lobby ) ; //<S2SV> list_for_each_safe ( pos , temp , & ep -> asocs ) { //<S2SV> asoc = list_entry ( pos , struct sctp_association , asocs ) ; //<S2SV> if ( sctp_style ( sk , TCP ) ) { //<S2SV> if ( sctp_state ( asoc , CLOSED ) ) { //<S2SV> sctp_unhash_established ( asoc ) ; //<S2SV> sctp_association_free ( asoc ) ; //<S2SV> continue ; //<S2SV> } //<S2SV> } //<S2SV> if ( data_was_unread || ! skb_queue_empty ( & asoc -> ulpq . lobby ) || //<S2SV> ! skb_queue_empty ( & asoc -> ulpq . reasm ) || //<S2SV> ( sock_flag ( sk , SOCK_LINGER ) && ! sk -> sk_lingertime ) ) { //<S2SV> struct sctp_chunk * chunk ; //<S2SV> chunk = sctp_make_abort_user ( asoc , NULL , 0 ) ; //<S2SV> if ( chunk ) //<S2SV> sctp_primitive_ABORT ( net , asoc , chunk ) ; //<S2SV> } else //<S2SV> sctp_primitive_SHUTDOWN ( net , asoc , NULL ) ; //<S2SV> } //<S2SV> if ( sctp_style ( sk , TCP ) && timeout ) //<S2SV> sctp_wait_for_close ( sk , timeout ) ; //<S2SV> release_sock ( sk ) ; //<S2SV> local_bh_disable ( ) ; //<S2SV> bh_lock_sock ( sk ) ; //<S2SV> sock_hold ( sk ) ; //<S2SV> sk_common_release ( sk ) ; //<S2SV> bh_unlock_sock ( sk ) ; //<S2SV> local_bh_enable ( ) ; //<S2SV> sock_put ( sk ) ; //<S2SV> SCTP_DBG_OBJCNT_DEC ( sock ) ; //<S2SV> } //<S2SV> 