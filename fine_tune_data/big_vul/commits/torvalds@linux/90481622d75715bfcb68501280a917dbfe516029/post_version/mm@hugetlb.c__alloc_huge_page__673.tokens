static struct page * alloc_huge_page ( struct vm_area_struct * vma , //<S2SV> unsigned long addr , int avoid_reserve ) //<S2SV> { //<S2SV> struct hugepage_subpool * spool = subpool_vma ( vma ) ; //<S2SV> struct hstate * h = hstate_vma ( vma ) ; //<S2SV> struct page * page ; //<S2SV> long chg ; //<S2SV> chg = vma_needs_reservation ( h , vma , addr ) ; //<S2SV> if ( chg < 0 ) //<S2SV> return ERR_PTR ( - VM_FAULT_OOM ) ; //<S2SV> if ( chg ) //<S2SV> if ( hugepage_subpool_get_pages ( spool , chg ) ) //<S2SV> return ERR_PTR ( - VM_FAULT_SIGBUS ) ; //<S2SV> spin_lock ( & hugetlb_lock ) ; //<S2SV> page = dequeue_huge_page_vma ( h , vma , addr , avoid_reserve ) ; //<S2SV> spin_unlock ( & hugetlb_lock ) ; //<S2SV> if ( ! page ) { //<S2SV> page = alloc_buddy_huge_page ( h , NUMA_NO_NODE ) ; //<S2SV> if ( ! page ) { //<S2SV> hugepage_subpool_put_pages ( spool , chg ) ; //<S2SV> return ERR_PTR ( - VM_FAULT_SIGBUS ) ; //<S2SV> } //<S2SV> } //<S2SV> set_page_private ( page , ( unsigned long ) spool ) ; //<S2SV> vma_commit_reservation ( h , vma , addr ) ; //<S2SV> return page ; //<S2SV> } //<S2SV> 