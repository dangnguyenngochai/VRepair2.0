static struct page * alloc_huge_page ( struct vm_area_struct * vma , //<S2SV> unsigned long addr , int avoid_reserve ) //<S2SV> { //<S2SV> struct hstate * h = hstate_vma ( vma ) ; //<S2SV> struct page * page ; //<S2SV> struct address_space * mapping = vma -> vm_file -> f_mapping ; //<S2SV> struct inode * inode = mapping -> host ; //<S2SV> long chg ; //<S2SV> chg = vma_needs_reservation ( h , vma , addr ) ; //<S2SV> if ( chg < 0 ) //<S2SV> return ERR_PTR ( - VM_FAULT_OOM ) ; //<S2SV> if ( chg ) //<S2SV> if ( hugetlb_get_quota ( inode -> i_mapping , chg ) ) //<S2SV> return ERR_PTR ( - VM_FAULT_SIGBUS ) ; //<S2SV> spin_lock ( & hugetlb_lock ) ; //<S2SV> page = dequeue_huge_page_vma ( h , vma , addr , avoid_reserve ) ; //<S2SV> spin_unlock ( & hugetlb_lock ) ; //<S2SV> if ( ! page ) { //<S2SV> page = alloc_buddy_huge_page ( h , NUMA_NO_NODE ) ; //<S2SV> if ( ! page ) { //<S2SV> hugetlb_put_quota ( inode -> i_mapping , chg ) ; //<S2SV> return ERR_PTR ( - VM_FAULT_SIGBUS ) ; //<S2SV> } //<S2SV> } //<S2SV> set_page_private ( page , ( unsigned long ) mapping ) ; //<S2SV> vma_commit_reservation ( h , vma , addr ) ; //<S2SV> return page ; //<S2SV> } //<S2SV> 