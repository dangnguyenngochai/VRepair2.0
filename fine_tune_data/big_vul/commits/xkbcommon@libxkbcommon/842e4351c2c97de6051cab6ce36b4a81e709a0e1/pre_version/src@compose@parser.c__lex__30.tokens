static enum rules_token //<S2SV> lex ( struct scanner * s , union lvalue * val ) //<S2SV> { //<S2SV> skip_more_whitespace_and_comments : //<S2SV> while ( is_space ( peek ( s ) ) ) //<S2SV> if ( next ( s ) == '\\n' ) //<S2SV> return TOK_END_OF_LINE ; //<S2SV> if ( chr ( s , '#' ) ) { //<S2SV> skip_to_eol ( s ) ; //<S2SV> goto skip_more_whitespace_and_comments ; //<S2SV> } //<S2SV> if ( eof ( s ) ) return TOK_END_OF_FILE ; //<S2SV> s -> token_line = s -> line ; //<S2SV> s -> token_column = s -> column ; //<S2SV> s -> buf_pos = 0 ; //<S2SV> if ( chr ( s , '<' ) ) { //<S2SV> while ( peek ( s ) != '>' && ! eol ( s ) ) //<S2SV> buf_append ( s , next ( s ) ) ; //<S2SV> if ( ! chr ( s , '>' ) ) { //<S2SV> scanner_err ( s , "unterminated<S2SV_blank>keysym<S2SV_blank>literal" ) ; //<S2SV> return TOK_ERROR ; //<S2SV> } //<S2SV> if ( ! buf_append ( s , '\\0' ) ) { //<S2SV> scanner_err ( s , "keysym<S2SV_blank>literal<S2SV_blank>is<S2SV_blank>too<S2SV_blank>long" ) ; //<S2SV> return TOK_ERROR ; //<S2SV> } //<S2SV> val -> string . str = s -> buf ; //<S2SV> val -> string . len = s -> buf_pos ; //<S2SV> return TOK_LHS_KEYSYM ; //<S2SV> } //<S2SV> if ( chr ( s , ':' ) ) //<S2SV> return TOK_COLON ; //<S2SV> if ( chr ( s , '!' ) ) //<S2SV> return TOK_BANG ; //<S2SV> if ( chr ( s , '~' ) ) //<S2SV> return TOK_TILDE ; //<S2SV> if ( chr ( s , \'\\"\' ) ) { //<S2SV> while ( ! eof ( s ) && ! eol ( s ) && peek ( s ) != \'\\"\' ) { //<S2SV> if ( chr ( s , '\\\\' ) ) { //<S2SV> uint8_t o ; //<S2SV> if ( chr ( s , '\\\\' ) ) { //<S2SV> buf_append ( s , '\\\\' ) ; //<S2SV> } //<S2SV> else if ( chr ( s , \'"\' ) ) { //<S2SV> buf_append ( s , \'"\' ) ; //<S2SV> } //<S2SV> else if ( chr ( s , 'x' ) || chr ( s , 'X' ) ) { //<S2SV> if ( hex ( s , & o ) ) //<S2SV> buf_append ( s , ( char ) o ) ; //<S2SV> else //<S2SV> scanner_warn ( s , "illegal<S2SV_blank>hexadecimal<S2SV_blank>escape<S2SV_blank>sequence<S2SV_blank>in<S2SV_blank>string<S2SV_blank>literal" ) ; //<S2SV> } //<S2SV> else if ( oct ( s , & o ) ) { //<S2SV> buf_append ( s , ( char ) o ) ; //<S2SV> } //<S2SV> else { //<S2SV> scanner_warn ( s , "unknown<S2SV_blank>escape<S2SV_blank>sequence<S2SV_blank>(%c)<S2SV_blank>in<S2SV_blank>string<S2SV_blank>literal" , peek ( s ) ) ; //<S2SV> } //<S2SV> } else { //<S2SV> buf_append ( s , next ( s ) ) ; //<S2SV> } //<S2SV> } //<S2SV> if ( ! chr ( s , \'\\"\' ) ) { //<S2SV> scanner_err ( s , "unterminated<S2SV_blank>string<S2SV_blank>literal" ) ; //<S2SV> return TOK_ERROR ; //<S2SV> } //<S2SV> if ( ! buf_append ( s , '\\0' ) ) { //<S2SV> scanner_err ( s , "string<S2SV_blank>literal<S2SV_blank>is<S2SV_blank>too<S2SV_blank>long" ) ; //<S2SV> return TOK_ERROR ; //<S2SV> } //<S2SV> if ( ! is_valid_utf8 ( s -> buf , s -> buf_pos - 1 ) ) { //<S2SV> scanner_err ( s , "string<S2SV_blank>literal<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>valid<S2SV_blank>UTF-8<S2SV_blank>string" ) ; //<S2SV> return TOK_ERROR ; //<S2SV> } //<S2SV> val -> string . str = s -> buf ; //<S2SV> val -> string . len = s -> buf_pos ; //<S2SV> return TOK_STRING ; //<S2SV> } //<S2SV> if ( is_alpha ( peek ( s ) ) || peek ( s ) == '_' ) { //<S2SV> s -> buf_pos = 0 ; //<S2SV> while ( is_alnum ( peek ( s ) ) || peek ( s ) == '_' ) //<S2SV> buf_append ( s , next ( s ) ) ; //<S2SV> if ( ! buf_append ( s , '\\0' ) ) { //<S2SV> scanner_err ( s , "identifier<S2SV_blank>is<S2SV_blank>too<S2SV_blank>long" ) ; //<S2SV> return TOK_ERROR ; //<S2SV> } //<S2SV> if ( streq ( s -> buf , "include" ) ) //<S2SV> return TOK_INCLUDE ; //<S2SV> val -> string . str = s -> buf ; //<S2SV> val -> string . len = s -> buf_pos ; //<S2SV> return TOK_IDENT ; //<S2SV> } //<S2SV> skip_to_eol ( s ) ; //<S2SV> scanner_err ( s , "unrecognized<S2SV_blank>token" ) ; //<S2SV> return TOK_ERROR ; //<S2SV> } //<S2SV> 