<S2SV_ModStart> ; th -> dest = ireq -> ir_rmt_port ; skb -> ip_summed = CHECKSUM_PARTIAL ; th -> seq = htonl ( tcp_rsk ( req ) -> snt_isn <S2SV_ModEnd> ) ; th -> ack_seq = htonl ( tcp_rsk
<S2SV_ModStart> ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDP0 <S2SV_ModEnd> + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift
<S2SV_ModStart> timeout ) ; if ( ! timeout ) { dev_err <S2SV_ModEnd> ( device , "firmware:<S2SV_blank>%s<S2SV_blank>loading<S2SV_blank>timed<S2SV_blank>out\\n" , name ) ; ret
<S2SV_ModStart> , id ) ; if ( rc ) { <S2SV_ModEnd> dev_dbg ( device , "loading<S2SV_blank>%s<S2SV_blank>failed<S2SV_blank>with<S2SV_blank>error<S2SV_blank>%d\\n" , path , rc <S2SV_ModStart> device , "loading<S2SV_blank>%s<S2SV_blank>failed<S2SV_blank>with<S2SV_blank>error<S2SV_blank>%d\\n" , path , rc ) ; continue ; } dev_info ( device , "firmware:<S2SV_blank>direct-loading<S2SV_blank>firmware<S2SV_blank>%s\\n" <S2SV_ModEnd> , buf -> fw_id ) ; buf -> size <S2SV_ModStart> ; break ; } __putname ( path ) ; if ( rc ) dev_err ( device , "firmware:<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>load<S2SV_blank>%s<S2SV_blank>(%d)\\n" , buf -> fw_id , rc ) ;
<S2SV_ModStart> * data , char * content ) { struct config * conf = get_config ( ) ; struct <S2SV_ModStart> * param = data ; struct uh_client * cl ; const char * remote_addr <S2SV_ModEnd> ; char mac [ 18 ] = "" ; <S2SV_ModStart> - 1 ; if ( ! param ) return ; cl = param -> cl ; remote_addr = cl -> get_peer_addr ( cl )
<S2SV_ModStart> { static unsigned char asso_values [ ] = { 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 3 , 43 , 0 , 33 , 10 , 30 , 45 , 45 , 4 , 38 , 37 , 5 , 27 , 45 , 2 , 45 , 45 , 1 , 11 , 28 , 6 , 26 , 45 , 36 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 3 , 43 , 0 , 33 , 10 , 30 , 45 , 45 , 4 , 38 , 37 , 5 , 27 , 45 , 2 , 45 , 45 <S2SV_ModEnd> , 1 , 11 , 28 , 6 , <S2SV_ModStart> , 11 , 28 , 6 , 26 , 45 , 36 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 , 45 <S2SV_ModEnd> } ; register int hval = len ; switch
<S2SV_ModStart> patchi -> filetype == patchj -> filetype ) { <S2SV_ModEnd> LOCK_COMPRESS ReadBoundary ( i , LOAD , & errorcode <S2SV_ModStart> i , LOAD , & errorcode ) ; UNLOCK_COMPRESS <S2SV_ModEnd> } } } force_redisplay = 1 ; UpdateFrameNumber (
<S2SV_ModStart> ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDP0 <S2SV_ModEnd> + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift
<S2SV_ModStart> = lhs_len ; memcpy ( dst , lhs , lens_dist_reservoir_len ( lhs_len ) <S2SV_ModEnd> * sizeof ( * lhs ) ) ; to_merge <S2SV_ModStart> = rhs_len ; memcpy ( dst , rhs , lens_dist_reservoir_len ( rhs_len ) <S2SV_ModEnd> * sizeof ( * rhs ) ) ; to_merge <S2SV_ModStart> dst_len ) ; if ( ! to_merge_len ) return lens_dist_reservoir_len ( dst_len ) <S2SV_ModEnd> ; if ( dst_len < optics_dist_samples ) { size_t <S2SV_ModStart> , to_copy * sizeof ( * lhs ) ) ; dst_len += to_copy
<S2SV_ModStart> = & dist_head -> epochs [ epoch ] ; size_t samples_len = 0 ; double samples [ optics_dist_samples ] ; { if ( slock_is_locked ( & dist -> lock ) ) return optics_busy ; samples_len = dist -> n ; if ( value -> max < dist -> max ) value -> max = dist -> max ; size_t to_copy = lens_dist_reservoir_len ( samples_len ) ; memcpy ( samples , dist -> samples , to_copy * sizeof ( samples [ 0 ] ) ) ; dist -> max = 0 ; dist -> n = 0 ; slock_unlock ( & dist -> lock ) ; } if ( ! samples_len ) return optics_ok ; double result [ optics_dist_samples ] ; size_t result_len = lens_dist_merge ( result , samples , samples_len , value -> samples , value -> n ) ; memcpy ( value -> samples , result , optics_dist_samples * sizeof ( double ) ) ; qsort ( result , result_len , sizeof ( double ) , lens_dist_value_cmp ) ; value -> n += samples_len ; value -> p50 = result [ lens_dist_p ( 50 , result_len ) ] ; value -> p90 = result [ lens_dist_p ( 90 , result_len ) ] ; value -> p99 = result [ lens_dist_p ( 99 , result_len ) ] ; return optics_ok ; <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ; if ( ! histo ) return optics_err ; if ( ! value -> buckets_len ) { <S2SV_ModStart> histo -> buckets [ 0 ] ) ) ; } else { if ( histo -> buckets_len != value -> buckets_len ) return optics_err ; for ( size_t i = 0 ; i < histo -> buckets_len ; ++ i ) if ( histo -> buckets [ i ] != value -> buckets [ i ] ) return optics_err ; } <S2SV_ModStart> -> epochs [ epoch ] ; value -> below += <S2SV_ModEnd> atomic_exchange_explicit ( & counters -> below , 0 , <S2SV_ModStart> , 0 , memory_order_relaxed ) ; value -> above += <S2SV_ModEnd> atomic_exchange_explicit ( & counters -> above , 0 ,
<S2SV_ModStart> optics_epoch_inc ( test -> optics ) ; int64_t value = 0
<S2SV_ModStart> ) , cmocka_unit_test ( lens_counter_record_read_test ) , cmocka_unit_test ( lens_counter_merge_test ) , cmocka_unit_test (
<S2SV_ModStart> idx + 1 ) ; if ( idx < EC_MAX_NODES <S2SV_ModEnd> ) mask |= 1ULL << idx ; } ec_dispatch_mask
<S2SV_ModStart> fop , idx ) ; if ( i < EC_MAX_NODES <S2SV_ModEnd> ) { idx = i ; fop -> remaining <S2SV_ModStart> fop -> lock ) ; if ( i < EC_MAX_NODES <S2SV_ModEnd> ) { fop -> wind ( ec , fop
<S2SV_ModStart> numCurrentRegDomainDfsChannels ) ; return false ; } num_channels = sap_ch_params_to_bonding_channels ( & sap_context -> ch_params , channels <S2SV_ModEnd> ) ; for ( j = 0 ; j
<S2SV_ModStart> ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDP0 <S2SV_ModEnd> + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> file , 0x100 , SEEK_SET ) ; while ( ! embFile_eof ( file ) <S2SV_ModEnd> ) { short b1 , b2 ; stitchType = <S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> file , 0x100 , SEEK_SET ) ; while ( ! embFile_eof ( file ) <S2SV_ModEnd> ) { int stitchType = NORMAL ; int b1 <S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> file , 0x200 , SEEK_SET ) ; while ( ! embFile_eof ( file ) <S2SV_ModEnd> ) { int stitchType = NORMAL ; int b1 <S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ( file ) ; if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ; } embFile_close ( file ) ; if ( pattern -> lastStitch &&
<S2SV_ModStart> return 0 ; } if ( pattern -> lastStitch && pattern -> lastStitch
<S2SV_ModStart> ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDP0 <S2SV_ModEnd> + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift
<S2SV_ModStart> ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Metadata<S2SV_blank>in<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>corrupted." , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } close ( fd ) ; break ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "size<S2SV_blank>%lu<S2SV_blank>of<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>smaller<S2SV_blank>then<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>struct<S2SV_blank>size." , ckptFS . st_size , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO <S2SV_ModEnd> ; } } } } closedir ( L1CkptDir )
<S2SV_ModStart> ) ; MPI_Group_free ( & appProcsGroup ) ; FTIFF_L2Info * appProcsMetaInfo = calloc ( appCommSize <S2SV_ModEnd> , sizeof ( FTIFF_L2Info ) ) ; FTIFF_L2Info _myMetaInfo <S2SV_ModStart> ( fd ) ; goto GATHER_INFO ; } } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Metadata<S2SV_blank>in<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>corrupted." , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } close ( fd ) ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "size<S2SV_blank>%lu<S2SV_blank>of<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>smaller<S2SV_blank>then<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>struct<S2SV_blank>size." , ckptFS . st_size , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO <S2SV_ModEnd> ; } } else { ckptID = tmpCkptID ; <S2SV_ModStart> ( fd ) ; goto GATHER_INFO ; } } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Metadata<S2SV_blank>in<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>corrupted." , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } close ( fd ) ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "size<S2SV_blank>%lu<S2SV_blank>of<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>smaller<S2SV_blank>then<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>struct<S2SV_blank>size." , ckptFS . st_size , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO <S2SV_ModEnd> ; } } else { ckptID = tmpCkptID ; <S2SV_ModStart> FTI_Exec -> ckptID , FTI_Topo -> myRank ) ; free ( appProcsMetaInfo ) ;
<S2SV_ModStart> ; goto err ; } binder_debug ( BINDER_DEBUG_READ_WRITE , "%d:%d<S2SV_blank>write<S2SV_blank>%zd<S2SV_blank>at<S2SV_blank>%016lx,<S2SV_blank>read<S2SV_blank>%zd<S2SV_blank>at<S2SV_blank>%016lx\\n" <S2SV_ModEnd> , proc -> pid , thread -> pid ,
<S2SV_ModStart> if ( ref == NULL ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>handle,<S2SV_blank>%d\\n" <S2SV_ModEnd> , proc -> pid , thread -> pid , <S2SV_ModStart> -> flags & TF_ACCEPT_FDS ) ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>reply<S2SV_blank>with<S2SV_blank>fd,<S2SV_blank>%d,<S2SV_blank>but<S2SV_blank>target<S2SV_blank>does<S2SV_blank>not<S2SV_blank>allow<S2SV_blank>fds\\n" <S2SV_ModEnd> , proc -> pid , thread -> pid , <S2SV_ModStart> ( ! target_node -> accept_fds ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>fd,<S2SV_blank>%d,<S2SV_blank>but<S2SV_blank>target<S2SV_blank>does<S2SV_blank>not<S2SV_blank>allow<S2SV_blank>fds\\n" <S2SV_ModEnd> , proc -> pid , thread -> pid , <S2SV_ModStart> if ( file == NULL ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>fd,<S2SV_blank>%d\\n" <S2SV_ModEnd> , proc -> pid , thread -> pid , <S2SV_ModStart> handle , target_fd ) ; binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>fd<S2SV_blank>%d<S2SV_blank>-><S2SV_blank>%d\\n" <S2SV_ModEnd> , fp -> handle , target_fd ) ; fp <S2SV_ModStart> target_fd ; } break ; default : binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>object<S2SV_blank>type,<S2SV_blank>%x\\n" <S2SV_ModEnd> , proc -> pid , thread -> pid ,
<S2SV_ModStart> if ( ref == NULL ) { pr_err ( "transaction<S2SV_blank>release<S2SV_blank>%d<S2SV_blank>bad<S2SV_blank>handle<S2SV_blank>%d\\n" <S2SV_ModEnd> , debug_id , fp -> handle ) ; break <S2SV_ModStart> break ; case BINDER_TYPE_FD : binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>fd<S2SV_blank>%d\\n" <S2SV_ModEnd> , fp -> handle ) ; if ( failed_at <S2SV_ModStart> handle ) ; break ; default : pr_err ( "transaction<S2SV_blank>release<S2SV_blank>%d<S2SV_blank>bad<S2SV_blank>object<S2SV_blank>type<S2SV_blank>%x\\n" <S2SV_ModEnd> , debug_id , fp -> type ) ; break
<S2SV_ModStart> ) { int r ; u64 mqd_gpu_addr ; struct cik_mqd <S2SV_ModEnd> * mqd ; struct amdgpu_ring * ring = & <S2SV_ModStart> r = amdgpu_bo_create ( adev , sizeof ( struct cik_mqd <S2SV_ModEnd> ) , PAGE_SIZE , true , AMDGPU_GEM_DOMAIN_GTT , 0
<S2SV_ModStart> int gfx_v7_0_mqd_commit ( struct amdgpu_device * adev , struct cik_mqd <S2SV_ModEnd> * mqd ) { u32 tmp ; tmp = <S2SV_ModStart> tmp ) ; WREG32 ( mmCP_MQD_BASE_ADDR , mqd -> cp_mqd_base_addr_lo ) ; WREG32 ( mmCP_MQD_BASE_ADDR_HI , mqd -> <S2SV_ModEnd> cp_mqd_base_addr_hi ) ; WREG32 ( mmCP_MQD_CONTROL , mqd -> <S2SV_ModStart> cp_mqd_base_addr_hi ) ; WREG32 ( mmCP_MQD_CONTROL , mqd -> <S2SV_ModEnd> cp_mqd_control ) ; WREG32 ( mmCP_HQD_PQ_BASE , mqd -> <S2SV_ModStart> cp_mqd_control ) ; WREG32 ( mmCP_HQD_PQ_BASE , mqd -> cp_hqd_pq_base_lo ) ; WREG32 ( mmCP_HQD_PQ_BASE_HI , mqd -> <S2SV_ModEnd> cp_hqd_pq_base_hi ) ; WREG32 ( mmCP_HQD_PQ_CONTROL , mqd -> <S2SV_ModStart> cp_hqd_pq_base_hi ) ; WREG32 ( mmCP_HQD_PQ_CONTROL , mqd -> <S2SV_ModEnd> cp_hqd_pq_control ) ; WREG32 ( mmCP_HQD_PQ_WPTR_POLL_ADDR , mqd -> <S2SV_ModStart> cp_hqd_pq_control ) ; WREG32 ( mmCP_HQD_PQ_WPTR_POLL_ADDR , mqd -> cp_hqd_pq_wptr_poll_addr_lo ) ; WREG32 ( mmCP_HQD_PQ_WPTR_POLL_ADDR_HI , mqd -> <S2SV_ModEnd> cp_hqd_pq_wptr_poll_addr_hi ) ; WREG32 ( mmCP_HQD_PQ_RPTR_REPORT_ADDR , mqd -> <S2SV_ModStart> cp_hqd_pq_wptr_poll_addr_hi ) ; WREG32 ( mmCP_HQD_PQ_RPTR_REPORT_ADDR , mqd -> cp_hqd_pq_rptr_report_addr_lo ) ; WREG32 ( mmCP_HQD_PQ_RPTR_REPORT_ADDR_HI , mqd -> <S2SV_ModEnd> cp_hqd_pq_rptr_report_addr_hi ) ; WREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL , mqd -> <S2SV_ModStart> cp_hqd_pq_rptr_report_addr_hi ) ; WREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL , mqd -> <S2SV_ModEnd> cp_hqd_pq_doorbell_control ) ; WREG32 ( mmCP_HQD_PQ_WPTR , mqd -> <S2SV_ModStart> cp_hqd_pq_doorbell_control ) ; WREG32 ( mmCP_HQD_PQ_WPTR , mqd -> <S2SV_ModEnd> cp_hqd_pq_wptr ) ; WREG32 ( mmCP_HQD_VMID , mqd -> <S2SV_ModStart> cp_hqd_pq_wptr ) ; WREG32 ( mmCP_HQD_VMID , mqd -> <S2SV_ModEnd> cp_hqd_vmid ) ; WREG32 ( mmCP_HQD_ACTIVE , mqd -> <S2SV_ModStart> cp_hqd_vmid ) ; WREG32 ( mmCP_HQD_ACTIVE , mqd -> <S2SV_ModEnd> cp_hqd_active ) ; return 0 ; } <S2SV_null> <S2SV_null>
<S2SV_ModStart> void gfx_v7_0_mqd_init ( struct amdgpu_device * adev , struct cik_mqd <S2SV_ModEnd> * mqd , uint64_t mqd_gpu_addr , struct amdgpu_ring * <S2SV_ModStart> memset ( mqd , 0 , sizeof ( struct cik_mqd <S2SV_ModEnd> ) ) ; mqd -> header = 0xC0310800 ; <S2SV_ModStart> ; mqd -> header = 0xC0310800 ; mqd -> compute_static_thread_mgmt_se0 = 0xffffffff ; mqd -> compute_static_thread_mgmt_se1 = 0xffffffff ; mqd -> compute_static_thread_mgmt_se2 = 0xffffffff ; mqd -> compute_static_thread_mgmt_se3 = 0xffffffff ; mqd -> <S2SV_ModEnd> cp_hqd_pq_doorbell_control = RREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL ) ; if ( <S2SV_ModStart> ; if ( ring -> use_doorbell ) mqd -> cp_hqd_pq_doorbell_control |= CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_EN_MASK ; else mqd -> cp_hqd_pq_doorbell_control &= ~ CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_EN_MASK ; mqd -> cp_mqd_base_addr_lo = mqd_gpu_addr & 0xfffffffc ; mqd -> <S2SV_ModEnd> cp_mqd_base_addr_hi = upper_32_bits ( mqd_gpu_addr ) ; mqd -> <S2SV_ModStart> cp_mqd_base_addr_hi = upper_32_bits ( mqd_gpu_addr ) ; mqd -> <S2SV_ModEnd> cp_mqd_control = RREG32 ( mmCP_MQD_CONTROL ) ; mqd -> <S2SV_ModStart> cp_mqd_control = RREG32 ( mmCP_MQD_CONTROL ) ; mqd -> <S2SV_ModEnd> cp_mqd_control &= ~ CP_MQD_CONTROL__VMID_MASK ; hqd_gpu_addr = ring -> <S2SV_ModStart> = ring -> gpu_addr >> 8 ; mqd -> cp_hqd_pq_base_lo = hqd_gpu_addr ; mqd -> <S2SV_ModEnd> cp_hqd_pq_base_hi = upper_32_bits ( hqd_gpu_addr ) ; mqd -> <S2SV_ModStart> cp_hqd_pq_base_hi = upper_32_bits ( hqd_gpu_addr ) ; mqd -> <S2SV_ModEnd> cp_hqd_pq_control = RREG32 ( mmCP_HQD_PQ_CONTROL ) ; mqd -> <S2SV_ModStart> cp_hqd_pq_control = RREG32 ( mmCP_HQD_PQ_CONTROL ) ; mqd -> <S2SV_ModEnd> cp_hqd_pq_control &= ~ ( CP_HQD_PQ_CONTROL__QUEUE_SIZE_MASK | CP_HQD_PQ_CONTROL__RPTR_BLOCK_SIZE_MASK ) ; <S2SV_ModStart> ~ ( CP_HQD_PQ_CONTROL__QUEUE_SIZE_MASK | CP_HQD_PQ_CONTROL__RPTR_BLOCK_SIZE_MASK ) ; mqd -> <S2SV_ModEnd> cp_hqd_pq_control |= order_base_2 ( ring -> ring_size / 8 <S2SV_ModStart> ring -> ring_size / 8 ) ; mqd -> <S2SV_ModEnd> cp_hqd_pq_control |= ( order_base_2 ( AMDGPU_GPU_PAGE_SIZE / 8 ) <S2SV_ModStart> << 8 ) ; # ifdef __BIG_ENDIAN mqd -> <S2SV_ModEnd> cp_hqd_pq_control |= 2 << CP_HQD_PQ_CONTROL__ENDIAN_SWAP__SHIFT ; # endif mqd <S2SV_ModStart> |= 2 << CP_HQD_PQ_CONTROL__ENDIAN_SWAP__SHIFT ; # endif mqd -> <S2SV_ModEnd> cp_hqd_pq_control &= ~ ( CP_HQD_PQ_CONTROL__UNORD_DISPATCH_MASK | CP_HQD_PQ_CONTROL__ROQ_PQ_IB_FLIP_MASK | CP_HQD_PQ_CONTROL__PQ_VOLATILE_MASK <S2SV_ModStart> CP_HQD_PQ_CONTROL__UNORD_DISPATCH_MASK | CP_HQD_PQ_CONTROL__ROQ_PQ_IB_FLIP_MASK | CP_HQD_PQ_CONTROL__PQ_VOLATILE_MASK ) ; mqd -> <S2SV_ModEnd> cp_hqd_pq_control |= CP_HQD_PQ_CONTROL__PRIV_STATE_MASK | CP_HQD_PQ_CONTROL__KMD_QUEUE_MASK ; wb_gpu_addr = adev <S2SV_ModStart> ring -> wptr_offs * 4 ) ; mqd -> cp_hqd_pq_wptr_poll_addr_lo = wb_gpu_addr & 0xfffffffc ; mqd -> <S2SV_ModEnd> cp_hqd_pq_wptr_poll_addr_hi = upper_32_bits ( wb_gpu_addr ) & 0xffff ; <S2SV_ModStart> ring -> rptr_offs * 4 ) ; mqd -> cp_hqd_pq_rptr_report_addr_lo = wb_gpu_addr & 0xfffffffc ; mqd -> <S2SV_ModEnd> cp_hqd_pq_rptr_report_addr_hi = upper_32_bits ( wb_gpu_addr ) & 0xffff ; <S2SV_ModStart> if ( ring -> use_doorbell ) { mqd -> <S2SV_ModEnd> cp_hqd_pq_doorbell_control = RREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL ) ; mqd -> <S2SV_ModStart> cp_hqd_pq_doorbell_control = RREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL ) ; mqd -> cp_hqd_pq_doorbell_control &= ~ CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_OFFSET_MASK ; mqd -> <S2SV_ModEnd> cp_hqd_pq_doorbell_control |= ( ring -> doorbell_index << CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_OFFSET__SHIFT ) <S2SV_ModStart> ring -> doorbell_index << CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_OFFSET__SHIFT ) ; mqd -> cp_hqd_pq_doorbell_control |= CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_EN_MASK ; mqd -> <S2SV_ModEnd> cp_hqd_pq_doorbell_control &= ~ ( CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_SOURCE_MASK | CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_HIT_MASK ) ; <S2SV_ModStart> | CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_HIT_MASK ) ; } else { mqd -> <S2SV_ModEnd> cp_hqd_pq_doorbell_control = 0 ; } ring -> wptr = <S2SV_ModStart> } ring -> wptr = 0 ; mqd -> <S2SV_ModEnd> cp_hqd_pq_wptr = lower_32_bits ( ring -> wptr ) ; <S2SV_ModStart> lower_32_bits ( ring -> wptr ) ; mqd -> <S2SV_ModEnd> cp_hqd_pq_rptr = RREG32 ( mmCP_HQD_PQ_RPTR ) ; mqd -> <S2SV_ModStart> cp_hqd_pq_rptr = RREG32 ( mmCP_HQD_PQ_RPTR ) ; mqd -> cp_hqd_vmid = 0 ; mqd -> <S2SV_ModEnd> cp_hqd_active = 1 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ) { u64 in_param = 0 ; int err ; if ( ! cnt ) return
<S2SV_ModStart> ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDP0 <S2SV_ModEnd> + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift
<S2SV_ModStart> EIP197_HIA_xDR_CFG_RD_CACHE ( RD_CACHE_3BITS ) ; val |= EIP197_HIA_xDR_WR_RES_BUF | EIP197_HIA_xDR_WR_CTRL_BUF <S2SV_ModEnd> ; writel ( val , EIP197_HIA_RDR ( priv ,
<S2SV_ModStart> ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDP0 <S2SV_ModEnd> + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift
<S2SV_ModStart> pst -> tickets [ i ] = process . ntix <S2SV_ModEnd> ; pst -> pid [ i ] = process
<S2SV_ModStart> ; db_stree_t * treelist ; snode_t * * inner ; long * debug_opt_diploid = opt_diploid ; opt_diploid = NULL <S2SV_ModStart> ; i < index ; ++ i ) { stree_t * t = parse_tree ( treelist [ i ] . newick ) <S2SV_ModEnd> ; char * delim = create_delim_string ( t ) <S2SV_ModStart> ( inner ) ; fclose ( fp_mcmc ) ; opt_diploid = debug_opt_diploid ;
<S2SV_ModStart> ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Metadata<S2SV_blank>in<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>corrupted." , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } close ( fd ) ; break ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "size<S2SV_blank>%lu<S2SV_blank>of<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>smaller<S2SV_blank>then<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>struct<S2SV_blank>size." , ckptFS . st_size , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO <S2SV_ModEnd> ; } } } } closedir ( L1CkptDir )
<S2SV_ModStart> ) ; MPI_Group_free ( & appProcsGroup ) ; FTIFF_L2Info * appProcsMetaInfo = calloc ( appCommSize <S2SV_ModEnd> , sizeof ( FTIFF_L2Info ) ) ; FTIFF_L2Info _myMetaInfo <S2SV_ModStart> ( fd ) ; goto GATHER_INFO ; } } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Metadata<S2SV_blank>in<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>corrupted." , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } close ( fd ) ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "size<S2SV_blank>%lu<S2SV_blank>of<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>smaller<S2SV_blank>then<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>struct<S2SV_blank>size." , ckptFS . st_size , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO <S2SV_ModEnd> ; } } else { ckptID = tmpCkptID ; <S2SV_ModStart> ( fd ) ; goto GATHER_INFO ; } } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Metadata<S2SV_blank>in<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>corrupted." , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } close ( fd ) ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "size<S2SV_blank>%lu<S2SV_blank>of<S2SV_blank>file<S2SV_blank>\\"%s\\"<S2SV_blank>is<S2SV_blank>smaller<S2SV_blank>then<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>struct<S2SV_blank>size." , ckptFS . st_size , entry -> d_name ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO <S2SV_ModEnd> ; } } else { ckptID = tmpCkptID ; <S2SV_ModStart> FTI_Exec -> ckptID , FTI_Topo -> myRank ) ; free ( appProcsMetaInfo ) ;
<S2SV_ModStart> scheduler ( void ) { int random , i = 0 <S2SV_ModStart> ( & ptable . lock ) ; if ( tix_count <S2SV_ModEnd> == 0 ) continue ; random = rand ( <S2SV_ModStart> ) continue ; random = rand ( ) % tix_count <S2SV_ModEnd> ; selected = tickets [ random ] ; p
<S2SV_ModStart> ( & mbox -> txq -> tasklet ) ; flush_work <S2SV_ModEnd> ( & mbox -> rxq -> work ) ;
<S2SV_ModStart> delay = usecs_to_jiffies ( info -> poll_int ) ; INIT_DEFERRABLE_WORK <S2SV_ModEnd> ( & info -> work , spu_gov_work ) ;
<S2SV_ModStart> ) ; platform_set_drvdata ( pdev , NULL ) ; flush_work <S2SV_ModEnd> ( & psw -> work ) ; del_timer_sync (
<S2SV_ModStart> ( td ) || td -> limits_changed ) { mod_delayed_work <S2SV_ModEnd> ( kthrotld_workqueue , dwork , delay ) ; throtl_log
<S2SV_ModStart> 4 ) ; if ( check_now ) queue_delayed_work ( system_freezable_wq <S2SV_ModEnd> , & ev -> dwork , 0 ) ; <S2SV_ModStart> ) ; else if ( intv ) queue_delayed_work ( system_freezable_wq <S2SV_ModEnd> , & ev -> dwork , intv ) ;
<S2SV_ModStart> ) ; disk_block_events ( disk ) ; queue_delayed_work ( system_freezable_wq <S2SV_ModEnd> , & ev -> dwork , 0 ) ;
<S2SV_ModStart> ! ev -> block && intv ) queue_delayed_work ( system_freezable_wq <S2SV_ModEnd> , & ev -> dwork , intv ) ;
<S2SV_ModStart> mask ; if ( ! ev -> block ) mod_delayed_work ( system_freezable_wq <S2SV_ModEnd> , & ev -> dwork , 0 ) ; <S2SV_ModStart> , & ev -> dwork , 0 ) ; <S2SV_ModEnd> spin_unlock_irq ( & ev -> lock ) ; }
<S2SV_ModStart> ; del_singleshot_timer_sync ( & chip -> user_read_timer ) ; flush_work <S2SV_ModEnd> ( & chip -> work ) ; ret_size =
<S2SV_ModStart> ; del_singleshot_timer_sync ( & chip -> user_read_timer ) ; flush_work <S2SV_ModEnd> ( & chip -> work ) ; file ->
<S2SV_ModStart> % delay ; dbs_info -> enable = 1 ; INIT_DEFERRABLE_WORK <S2SV_ModEnd> ( & dbs_info -> work , do_dbs_timer ) ;
<S2SV_ModStart> void devfreq_monitor_start ( struct devfreq * devfreq ) { INIT_DEFERRABLE_WORK ( & devfreq_work <S2SV_ModEnd> , devfreq_monitor ) ; if ( devfreq -> profile
<S2SV_ModStart> struct mem_ctl_info * mci ; struct list_head * item <S2SV_ModEnd> ; mutex_lock ( & mem_ctls_mutex ) ; list_for_each (
<S2SV_ModStart> ( & mci -> work , edac_mc_workq_function ) ; mod_delayed_work <S2SV_ModEnd> ( edac_workqueue , & mci -> work , msecs_to_jiffies
<S2SV_ModStart> mode_config . output_poll_work ) ; if ( drm_kms_helper_poll ) schedule_delayed_work ( <S2SV_ModEnd> & dev -> mode_config . output_poll_work , 0 )
<S2SV_ModStart> poll = true ; } if ( poll ) schedule_delayed_work ( <S2SV_ModEnd> & dev -> mode_config . output_poll_work , DRM_OUTPUT_POLL_PERIOD )
<S2SV_ModStart> ( dev ) ; } if ( repoll ) schedule_delayed_work ( <S2SV_ModEnd> delayed_work , DRM_OUTPUT_POLL_PERIOD ) ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> , tmp , & tofree , head ) { flush_work <S2SV_ModEnd> ( & isr -> work ) ; kfree (
<S2SV_ModStart> ) pci_disable_msi ( rdev -> pdev ) ; } flush_work <S2SV_ModEnd> ( & rdev -> hotplug_work ) ; } <S2SV_null>
<S2SV_ModStart> par -> dirty . lock , flags ) ; flush_delayed_work <S2SV_ModEnd> ( & info -> deferred_work ) ; par ->
<S2SV_ModStart> void wiiext_schedule ( struct wiimote_ext * ext ) { schedule_work ( <S2SV_ModEnd> & ext -> worker ) ; } <S2SV_null> <S2SV_null>
<S2SV_ModStart> ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDP0 <S2SV_ModEnd> + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift
<S2SV_ModStart> lock ) ; out_put_map : if ( use_ptemod ) { map -> vma = NULL ; unmap_grant_pages ( map , 0 , map -> count ) ; } <S2SV_ModEnd> gntdev_put_map ( priv , map ) ; return err
<S2SV_ModStart> ; stats -> rx_length_errors ++ ; continue ; } skb = netdev_alloc_skb_ip_align ( ndev , EMAC_BUFFER_SIZE ) ; if ( unlikely ( ! skb ) ) { if ( net_ratelimit ( ) ) netdev_err ( ndev , "cannot<S2SV_blank>allocate<S2SV_blank>skb\\n" ) ; rxbd -> info = cpu_to_le32 ( FOR_EMAC | EMAC_BUFFER_SIZE ) ; stats -> rx_errors ++ ; stats -> rx_dropped ++ ; continue ; } addr = dma_map_single ( & ndev -> dev , ( void * ) skb -> data , EMAC_BUFFER_SIZE , DMA_FROM_DEVICE ) ; if ( dma_mapping_error ( & ndev -> dev , addr ) ) { if ( net_ratelimit ( ) ) netdev_err ( ndev , "cannot<S2SV_blank>map<S2SV_blank>dma<S2SV_blank>buffer\\n" ) ; dev_kfree_skb ( skb ) ; rxbd -> info = cpu_to_le32 ( FOR_EMAC | EMAC_BUFFER_SIZE ) ; stats -> rx_errors ++ ; stats -> rx_dropped ++ ; continue ; } dma_unmap_single ( & ndev -> dev , dma_unmap_addr ( rx_buff , addr ) , dma_unmap_len ( rx_buff , len ) , DMA_FROM_DEVICE ) ; <S2SV_ModStart> rx_packets ++ ; stats -> rx_bytes += pktlen ; skb_put ( rx_buff -> skb , pktlen ) ; rx_buff -> skb -> dev = ndev ; rx_buff -> skb -> protocol = eth_type_trans ( rx_buff -> skb , ndev ) ; netif_receive_skb ( rx_buff -> skb ) ; rx_buff -> skb = skb ; <S2SV_ModEnd> dma_unmap_addr_set ( rx_buff , addr , addr ) ;
<S2SV_ModStart> ( p , argp -> p , avail ) ; argp -> pagelist ++ <S2SV_ModStart> ( argp -> pagelist [ 0 ] ) ; <S2SV_ModEnd> if ( argp -> pagelen < PAGE_SIZE ) {
<S2SV_ModStart> long ) dev -> cpu ) ; int error ; if ( ! cpu_dev ) return - ENODEV
<S2SV_ModStart> BGP_EVPN_VNI_NODE : case BGP_IPV6L_NODE : case RMAP_NODE : case PBRMAP_NODE : case
<S2SV_ModStart> ENODEV ; if ( ! cpuidle_get_driver ( ) || acpi_processor_using_idle_driver ( ) <S2SV_ModEnd> ) acpi_processor_power_init ( pr ) ; result = acpi_pss_perf_init
<S2SV_ModStart> ; if ( pr -> id == 0 && acpi_processor_using_idle_driver ( ) <S2SV_ModEnd> ) { get_online_cpus ( ) ; cpuidle_pause_and_lock ( )
<S2SV_ModStart> long ) dev -> cpu ) ; int error ; if ( ! cpu_dev ) return - ENODEV
<S2SV_ModStart> ) return ; aux_channel = child -> aux_channel ; <S2SV_ModEnd> is_dvi = child -> device_type & DEVICE_TYPE_TMDS_DVI_SIGNALING ; is_dp <S2SV_ModStart> port ) ) ; if ( is_dvi ) { ddc_pin = map_ddc_pin ( dev_priv , child -> ddc_pin ) ; if ( intel_gmbus_is_valid_pin ( dev_priv , ddc_pin ) ) { info -> alternate_ddc_pin = ddc_pin ; sanitize_ddc_pin ( dev_priv , port ) ; } else { DRM_DEBUG_KMS ( "Port<S2SV_blank>%c<S2SV_blank>has<S2SV_blank>invalid<S2SV_blank>DDC<S2SV_blank>pin<S2SV_blank>%d,<S2SV_blank>" "sticking<S2SV_blank>to<S2SV_blank>defaults\\n" , port_name ( port ) , ddc_pin ) ; } <S2SV_ModEnd> } if ( is_dp ) { info -> alternate_aux_channel
<S2SV_ModStart> ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) rcode =
<S2SV_ModStart> ; Hunk_SmallLog ( ) ; Com_Error ( ERR_DROP , "Hunk_Alloc<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>%i<S2SV_blank>bytes<S2SV_blank>(increase<S2SV_blank>com_hunkMegs<S2SV_blank>cvar<S2SV_blank>value,<S2SV_blank>current<S2SV_blank>value<S2SV_blank>%d):<S2SV_blank>%s,<S2SV_blank>line:<S2SV_blank>%d<S2SV_blank>(%s)" , size , Cvar_VariableIntegerValue ( "com_hunkMegs" ) <S2SV_ModEnd> , file , line , label ) ; # <S2SV_ModStart> label ) ; # else Com_Error ( ERR_DROP , "Hunk_Alloc<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>%i<S2SV_blank>bytes<S2SV_blank>(increase<S2SV_blank>com_hunkMegs<S2SV_blank>cvar<S2SV_blank>value,<S2SV_blank>current<S2SV_blank>value<S2SV_blank>%d)" , size , Cvar_VariableIntegerValue ( "com_hunkMegs" ) <S2SV_ModEnd> ) ; # endif } if ( hunk_permanent ==
<S2SV_ModStart> size > s_hunkTotal ) { Com_Error ( ERR_DROP , "Hunk_AllocateTempMemory:<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>%i<S2SV_blank>bytes<S2SV_blank>(increase<S2SV_blank>com_hunkMegs<S2SV_blank>cvar<S2SV_blank>value,<S2SV_blank>current<S2SV_blank>value<S2SV_blank>%d)" , size , Cvar_VariableIntegerValue ( "com_hunkMegs" ) <S2SV_ModEnd> ) ; } if ( hunk_temp == & hunk_low
<S2SV_ModStart> do { if ( rover == start ) { char cvarMessage [ 128 ] ; const char * cvarName ; cvarName = Z_CvarNameForZone ( zone ) ; if ( cvarName ) { Com_sprintf ( cvarMessage , sizeof ( cvarMessage ) , "<S2SV_blank>(increase<S2SV_blank>%s<S2SV_blank>cvar<S2SV_blank>value,<S2SV_blank>current<S2SV_blank>value<S2SV_blank>%s)" , cvarName , Cvar_VariableString ( cvarName ) ) ; } else { cvarMessage [ 0 ] = '\\0' ; } <S2SV_ModStart> ZONE_DEBUG Z_LogHeap ( ) ; Com_Error ( ERR_FATAL , "Z_Malloc:<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>allocation<S2SV_blank>of<S2SV_blank>%i<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>the<S2SV_blank>%s<S2SV_blank>zone%s:<S2SV_blank>%s,<S2SV_blank>line:<S2SV_blank>%d<S2SV_blank>(%s)" , size , Z_NameForZone ( zone ) , cvarMessage <S2SV_ModEnd> , file , line , label ) ; # <S2SV_ModStart> label ) ; # else Com_Error ( ERR_FATAL , "Z_Malloc:<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>allocation<S2SV_blank>of<S2SV_blank>%i<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>the<S2SV_blank>%s<S2SV_blank>zone%s" , size , Z_NameForZone ( zone ) , cvarMessage <S2SV_ModEnd> ) ; # endif return NULL ; } if
<S2SV_ModStart> i_private ; char configuration [ TESTBUS_CFG_BUFF_LINE_SIZE ] = { '\\0' <S2SV_ModEnd> } ; loff_t buff_pos = 0 ; char * <S2SV_ModStart> "%s:<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>user<S2SV_blank>data\\n" , __func__ ) ; goto out ; } configuration [ ret ] = '\\0' ;
<S2SV_ModStart> ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) rcode =
<S2SV_ModStart> NULL ) ; if ( ret == 1 ) { sock = NULL ; goto retry ; } <S2SV_ModEnd> if ( ret ) { sock = NULL ;
<S2SV_ModStart> ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) rcode =
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_ModEnd> int fname_encrypt ( struct inode * inode , const <S2SV_ModStart> * inode , const struct qstr * iname , u8 * out , unsigned int olen <S2SV_ModEnd> ) { struct ablkcipher_request * req = NULL ; <S2SV_ModStart> = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct crypto_ablkcipher * tfm = inode -> i_crypt_info <S2SV_ModEnd> -> ci_ctfm ; int res = 0 ; char <S2SV_ModStart> iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; if ( WARN_ON ( olen < iname -> len ) ) return - ENOBUFS ; memcpy ( out , iname -> name , iname -> len ) ; memset ( out + iname -> len , 0 , olen <S2SV_ModEnd> - iname -> len ) ; memset ( iv <S2SV_ModStart> & wait ) ; sg_init_one ( & sg , out , olen <S2SV_ModEnd> ) ; ablkcipher_request_set_crypt ( req , & sg , <S2SV_ModStart> ( req , & sg , & sg , olen <S2SV_ModEnd> , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt <S2SV_ModStart> __func__ , res ) ; return res ; } <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 max_encrypted_len , struct fscrypt_str * crypto_str ) { <S2SV_ModEnd> const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS <S2SV_ModStart> ( sizeof ( struct fscrypt_digested_name ) ) ) ; u32 max_presented_len ; max_presented_len = max ( max_encoded_len , max_encrypted_len ) ; crypto_str -> name = kmalloc ( max_presented_len <S2SV_ModEnd> + 1 , GFP_NOFS ) ; if ( ! <S2SV_ModStart> + 1 , GFP_NOFS ) ; if ( ! crypto_str -> name ) return - ENOMEM ; crypto_str -> len = max_presented_len ; <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> bool <S2SV_ModEnd> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 <S2SV_ModStart> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 orig_len , u32 max_len , u32 * encrypted_len_ret ) { int padding = 4 << ( inode -> i_crypt_info -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; u32 encrypted_len ; if ( orig_len > max_len ) return false ; encrypted_len = max ( orig_len , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; encrypted_len = round_up ( encrypted_len , padding ) ; * encrypted_len_ret = min ( encrypted_len , max_len ) ; return true ; <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ret ; if ( dir -> i_crypt_info ) { if ( ! fscrypt_fname_encrypted_size ( dir , iname -> len , dir -> i_sb -> s_cop -> max_namelen ( dir ) , & fname -> crypto_buf . len ) ) return - ENAMETOOLONG ; fname -> crypto_buf . name = kmalloc ( fname -> crypto_buf . len , GFP_NOFS ) ; if ( ! fname -> crypto_buf . name ) return - ENOMEM <S2SV_ModEnd> ; ret = fname_encrypt ( dir , iname , <S2SV_ModStart> ; ret = fname_encrypt ( dir , iname , fname -> crypto_buf . name , fname -> crypto_buf . len <S2SV_ModEnd> ) ; if ( ret ) goto errout ; <S2SV_ModStart> . len ; } return 0 ; errout : kfree ( fname -> crypto_buf . name <S2SV_ModEnd> ) ; return ret ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) rcode =
<S2SV_ModStart> ; mp_aframe_get_chmap ( aframe , & chmap ) ; bool format_change = afmt != p -> in_afmt || srate != p -> in_srate || ! <S2SV_ModEnd> mp_chmap_equals ( & chmap , & p -> in_chmap <S2SV_ModStart> ( & chmap , & p -> in_chmap ) || p -> force_update ; if ( ! format_change <S2SV_ModStart> -> resampling_forced || p -> sub . filter ) ) goto cont ; <S2SV_ModEnd> if ( ! mp_subfilter_drain_destroy ( & p -> sub <S2SV_ModStart> ( & p -> sub ) ) return ; if ( format_change && p -> public . on_audio_format_change ) { if ( p -> format_change_blocked ) return ; if ( ! p -> format_change_cont ) { p -> format_change_blocked = true ; p -> public . on_audio_format_change ( p -> public . on_audio_format_change_opaque ) ; return ; } p -> format_change_cont = false ; }
<S2SV_ModStart> ; mp_subfilter_reset ( & p -> sub ) ; p -> format_change_cont = false ; p -> format_change_blocked = false ;
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_ModEnd> int fname_encrypt ( struct inode * inode , const <S2SV_ModStart> * inode , const struct qstr * iname , u8 * out , unsigned int olen <S2SV_ModEnd> ) { struct ablkcipher_request * req = NULL ; <S2SV_ModStart> = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct crypto_ablkcipher * tfm = inode -> i_crypt_info <S2SV_ModEnd> -> ci_ctfm ; int res = 0 ; char <S2SV_ModStart> iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; if ( WARN_ON ( olen < iname -> len ) ) return - ENOBUFS ; memcpy ( out , iname -> name , iname -> len ) ; memset ( out + iname -> len , 0 , olen <S2SV_ModEnd> - iname -> len ) ; memset ( iv <S2SV_ModStart> & wait ) ; sg_init_one ( & sg , out , olen <S2SV_ModEnd> ) ; ablkcipher_request_set_crypt ( req , & sg , <S2SV_ModStart> ( req , & sg , & sg , olen <S2SV_ModEnd> , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt <S2SV_ModStart> __func__ , res ) ; return res ; } <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 max_encrypted_len , struct fscrypt_str * crypto_str ) { <S2SV_ModEnd> const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS <S2SV_ModStart> ( sizeof ( struct fscrypt_digested_name ) ) ) ; u32 max_presented_len ; max_presented_len = max ( max_encoded_len , max_encrypted_len ) ; crypto_str -> name = kmalloc ( max_presented_len <S2SV_ModEnd> + 1 , GFP_NOFS ) ; if ( ! <S2SV_ModStart> + 1 , GFP_NOFS ) ; if ( ! crypto_str -> name ) return - ENOMEM ; crypto_str -> len = max_presented_len ; <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> bool <S2SV_ModEnd> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 <S2SV_ModStart> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 orig_len , u32 max_len , u32 * encrypted_len_ret ) { int padding = 4 << ( inode -> i_crypt_info -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; u32 encrypted_len ; if ( orig_len > max_len ) return false ; encrypted_len = max ( orig_len , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; encrypted_len = round_up ( encrypted_len , padding ) ; * encrypted_len_ret = min ( encrypted_len , max_len ) ; return true ; <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ret ; if ( dir -> i_crypt_info ) { if ( ! fscrypt_fname_encrypted_size ( dir , iname -> len , dir -> i_sb -> s_cop -> max_namelen ( dir ) , & fname -> crypto_buf . len ) ) return - ENAMETOOLONG ; fname -> crypto_buf . name = kmalloc ( fname -> crypto_buf . len , GFP_NOFS ) ; if ( ! fname -> crypto_buf . name ) return - ENOMEM <S2SV_ModEnd> ; ret = fname_encrypt ( dir , iname , <S2SV_ModStart> ; ret = fname_encrypt ( dir , iname , fname -> crypto_buf . name , fname -> crypto_buf . len <S2SV_ModEnd> ) ; if ( ret ) goto errout ; <S2SV_ModStart> . len ; } return 0 ; errout : kfree ( fname -> crypto_buf . name <S2SV_ModEnd> ) ; return ret ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> uniforms ) { const struct glsl_type * glsl_type = ( var -> interface_type ? var -> interface_type : glsl_without_array ( var -> type ) ) <S2SV_ModEnd> ; if ( ! glsl_type_is_image ( glsl_type ) )
<S2SV_ModStart> ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) rcode =
<S2SV_ModStart> ( sizeof ( uint32_t ) * entities_len + 1 - ENTITY_ID_FIRST <S2SV_ModStart> "Error<S2SV_blank>allocating<S2SV_blank>ids[]!" ) ; } for ( uint32_t i = ENTITY_ID_FIRST <S2SV_ModEnd> ; i < entities_len ; i ++ ) { <S2SV_ModStart> entities_len ; i ++ ) { ids [ i - ENTITY_ID_FIRST ] = i ; } ids [ entities_len - ENTITY_ID_FIRST ] = ENTID_NONE ; s_send_entities_unsafe ( player , entities_len - ENTITY_ID_FIRST <S2SV_ModEnd> , players_len , ids ) ; free ( ids
<S2SV_ModStart> } size_t size = sizeof ( entities_mbuf_t ) + ecount * sizeof ( entity_t ) + pcount * sizeof ( struct player_context ) <S2SV_ModEnd> ; entities_mbuf_t * msg = ( entities_mbuf_t * ) <S2SV_ModStart> ) ; size_t i = 0 ; while ( ENTID_NONE != <S2SV_ModStart> -- ; } i ++ ; if ( ecount <= ENTITY_ID_FIRST ) { break ; } } if ( ( ecount > ENTITY_ID_FIRST ) <S2SV_ModEnd> || pcount ) { panic ( "Invalid<S2SV_blank>ecount<S2SV_blank>or<S2SV_blank>pcount<S2SV_blank>in<S2SV_blank>s_send_entities_unsafe()!" ) ;
<S2SV_ModStart> ; id < players_len ; id ++ ) { s_send_entities_full <S2SV_ModEnd> ( players [ id ] ) ; } }
<S2SV_ModStart> ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) rcode =
<S2SV_ModStart> unsigned int cmd , unsigned long arg ) { struct snd_timer_user * tu = file -> private_data ; long ret ; mutex_lock ( & tu -> ioctl_lock ) ; ret = __snd_timer_user_ioctl_compat ( file , cmd , arg ) ; mutex_unlock ( & tu -> ioctl_lock ) ; return ret <S2SV_ModEnd> ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_ModEnd> int fname_encrypt ( struct inode * inode , const <S2SV_ModStart> * inode , const struct qstr * iname , u8 * out , unsigned int olen <S2SV_ModEnd> ) { struct ablkcipher_request * req = NULL ; <S2SV_ModStart> = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct crypto_ablkcipher * tfm = inode -> i_crypt_info <S2SV_ModEnd> -> ci_ctfm ; int res = 0 ; char <S2SV_ModStart> iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; if ( WARN_ON ( olen < iname -> len ) ) return - ENOBUFS ; memcpy ( out , iname -> name , iname -> len ) ; memset ( out + iname -> len , 0 , olen <S2SV_ModEnd> - iname -> len ) ; memset ( iv <S2SV_ModStart> & wait ) ; sg_init_one ( & sg , out , olen <S2SV_ModEnd> ) ; ablkcipher_request_set_crypt ( req , & sg , <S2SV_ModStart> ( req , & sg , & sg , olen <S2SV_ModEnd> , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt <S2SV_ModStart> __func__ , res ) ; return res ; } <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 max_encrypted_len , struct fscrypt_str * crypto_str ) { <S2SV_ModEnd> const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS <S2SV_ModStart> ( sizeof ( struct fscrypt_digested_name ) ) ) ; u32 max_presented_len ; max_presented_len = max ( max_encoded_len , max_encrypted_len ) ; crypto_str -> name = kmalloc ( max_presented_len <S2SV_ModEnd> + 1 , GFP_NOFS ) ; if ( ! <S2SV_ModStart> + 1 , GFP_NOFS ) ; if ( ! crypto_str -> name ) return - ENOMEM ; crypto_str -> len = max_presented_len ; <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> bool <S2SV_ModEnd> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 <S2SV_ModStart> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 orig_len , u32 max_len , u32 * encrypted_len_ret ) { int padding = 4 << ( inode -> i_crypt_info -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; u32 encrypted_len ; if ( orig_len > max_len ) return false ; encrypted_len = max ( orig_len , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; encrypted_len = round_up ( encrypted_len , padding ) ; * encrypted_len_ret = min ( encrypted_len , max_len ) ; return true ; <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ret ; if ( dir -> i_crypt_info ) { if ( ! fscrypt_fname_encrypted_size ( dir , iname -> len , dir -> i_sb -> s_cop -> max_namelen ( dir ) , & fname -> crypto_buf . len ) ) return - ENAMETOOLONG ; fname -> crypto_buf . name = kmalloc ( fname -> crypto_buf . len , GFP_NOFS ) ; if ( ! fname -> crypto_buf . name ) return - ENOMEM <S2SV_ModEnd> ; ret = fname_encrypt ( dir , iname , <S2SV_ModStart> ; ret = fname_encrypt ( dir , iname , fname -> crypto_buf . name , fname -> crypto_buf . len <S2SV_ModEnd> ) ; if ( ret ) goto errout ; <S2SV_ModStart> . len ; } return 0 ; errout : kfree ( fname -> crypto_buf . name <S2SV_ModEnd> ) ; return ret ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ; mp_aframe_get_chmap ( aframe , & chmap ) ; bool format_change = afmt != p -> in_afmt || srate != p -> in_srate || ! <S2SV_ModEnd> mp_chmap_equals ( & chmap , & p -> in_chmap <S2SV_ModStart> ( & chmap , & p -> in_chmap ) || p -> force_update ; if ( ! format_change <S2SV_ModStart> -> resampling_forced || p -> sub . filter ) ) goto cont ; <S2SV_ModEnd> if ( ! mp_subfilter_drain_destroy ( & p -> sub <S2SV_ModStart> ( & p -> sub ) ) return ; if ( format_change && p -> public . on_audio_format_change ) { if ( p -> format_change_blocked ) return ; if ( ! p -> format_change_cont ) { p -> format_change_blocked = true ; p -> public . on_audio_format_change ( p -> public . on_audio_format_change_opaque ) ; return ; } p -> format_change_cont = false ; }
<S2SV_ModStart> ; mp_subfilter_reset ( & p -> sub ) ; p -> format_change_cont = false ; p -> format_change_blocked = false ;
<S2SV_ModStart> if ( rwa -> raw ) { if ( drro -> drr_object < rwa -> or_firstobj || drro -> drr_object >= rwa -> or_firstobj + rwa -> or_numslots || <S2SV_ModStart> ) ; } if ( rwa -> raw ) { err = dmu_convert_mdn_block_to_raw ( rwa -> os , rwa -> or_firstobj , rwa -> or_byteorder , rwa -> or_salt , rwa -> or_iv , rwa -> or_mac , tx ) ; if ( err != 0 ) { dmu_tx_commit ( tx ) ; return ( SET_ERROR ( EINVAL ) ) ; } } <S2SV_ModEnd> dmu_object_set_checksum ( rwa -> os , drro -> drr_object
<S2SV_ModStart> * rwa , struct drr_object_range * drror ) { <S2SV_ModEnd> boolean_t byteorder = ZFS_HOST_BYTEORDER ^ rwa -> byteswap ^ <S2SV_ModStart> ) return ( SET_ERROR ( EINVAL ) ) ; rwa -> or_firstobj = drror -> drr_firstobj ; rwa -> or_numslots = drror -> drr_numslots ; bcopy ( drror -> drr_salt , rwa -> or_salt , ZIO_DATA_SALT_LEN ) ; bcopy ( drror -> drr_iv , rwa -> or_iv , ZIO_DATA_IV_LEN ) ; bcopy ( drror -> drr_mac , rwa -> or_mac , ZIO_DATA_MAC_LEN ) ; rwa -> or_byteorder = byteorder <S2SV_ModEnd> ; return ( 0 ) ; } <S2SV_null> <S2SV_null>
<S2SV_ModStart> key ) i ++ ; ft_dprintf ( STDERR_FILENO , FMT_SYN <S2SV_ModEnd> , ( char * ) tok [ i ]
<S2SV_ModStart> job [ 0 ] ) ) != NULL ) { <S2SV_ModStart> + 1 , job [ 2 ] ) ; if ( * tokens != NULL && ( * tokens ) -> type == SEMICOL ) break ; }
<S2SV_ModStart> return ( 0 ) ; } else if ( tokens -> type & SEMICOL <S2SV_ModEnd> ) { if ( tokens -> next == NULL
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_ModEnd> int fname_encrypt ( struct inode * inode , const <S2SV_ModStart> * inode , const struct qstr * iname , u8 * out , unsigned int olen <S2SV_ModEnd> ) { struct ablkcipher_request * req = NULL ; <S2SV_ModStart> = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct crypto_ablkcipher * tfm = inode -> i_crypt_info <S2SV_ModEnd> -> ci_ctfm ; int res = 0 ; char <S2SV_ModStart> iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; if ( WARN_ON ( olen < iname -> len ) ) return - ENOBUFS ; memcpy ( out , iname -> name , iname -> len ) ; memset ( out + iname -> len , 0 , olen <S2SV_ModEnd> - iname -> len ) ; memset ( iv <S2SV_ModStart> & wait ) ; sg_init_one ( & sg , out , olen <S2SV_ModEnd> ) ; ablkcipher_request_set_crypt ( req , & sg , <S2SV_ModStart> ( req , & sg , & sg , olen <S2SV_ModEnd> , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt <S2SV_ModStart> __func__ , res ) ; return res ; } <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 max_encrypted_len , struct fscrypt_str * crypto_str ) { <S2SV_ModEnd> const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS <S2SV_ModStart> ( sizeof ( struct fscrypt_digested_name ) ) ) ; u32 max_presented_len ; max_presented_len = max ( max_encoded_len , max_encrypted_len ) ; crypto_str -> name = kmalloc ( max_presented_len <S2SV_ModEnd> + 1 , GFP_NOFS ) ; if ( ! <S2SV_ModStart> + 1 , GFP_NOFS ) ; if ( ! crypto_str -> name ) return - ENOMEM ; crypto_str -> len = max_presented_len ; <S2SV_ModEnd> return 0 ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> bool <S2SV_ModEnd> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 <S2SV_ModStart> fscrypt_fname_encrypted_size ( const struct inode * inode , u32 orig_len , u32 max_len , u32 * encrypted_len_ret ) { int padding = 4 << ( inode -> i_crypt_info -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; u32 encrypted_len ; if ( orig_len > max_len ) return false ; encrypted_len = max ( orig_len , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; encrypted_len = round_up ( encrypted_len , padding ) ; * encrypted_len_ret = min ( encrypted_len , max_len ) ; return true ; <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ret ; if ( dir -> i_crypt_info ) { if ( ! fscrypt_fname_encrypted_size ( dir , iname -> len , dir -> i_sb -> s_cop -> max_namelen ( dir ) , & fname -> crypto_buf . len ) ) return - ENAMETOOLONG ; fname -> crypto_buf . name = kmalloc ( fname -> crypto_buf . len , GFP_NOFS ) ; if ( ! fname -> crypto_buf . name ) return - ENOMEM <S2SV_ModEnd> ; ret = fname_encrypt ( dir , iname , <S2SV_ModStart> ; ret = fname_encrypt ( dir , iname , fname -> crypto_buf . name , fname -> crypto_buf . len <S2SV_ModEnd> ) ; if ( ret ) goto errout ; <S2SV_ModStart> . len ; } return 0 ; errout : kfree ( fname -> crypto_buf . name <S2SV_ModEnd> ) ; return ret ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ; unsigned long max_pages = ra -> ra_pages ; unsigned long add_pages ; <S2SV_ModStart> ra -> size == ra -> async_size ) { add_pages = get_next_ra_size ( ra , max_pages ) ; if ( ra -> size + add_pages <= max_pages ) { ra -> async_size = add_pages ; ra -> size += add_pages ; } else { ra -> size = max_pages ; ra -> async_size = max_pages >> 1 ; } <S2SV_ModEnd> } return ra_submit ( ra , mapping , filp
<S2SV_ModStart> ; p = * lp_gid ( i ) ? conf_strtok ( lp_gid ( i ) <S2SV_ModEnd> ) : NULL ; if ( p ) { <S2SV_ModStart> return - 1 ; while ( ( p = conf_strtok ( NULL <S2SV_ModEnd> ) ) != NULL ) { # if defined
<S2SV_ModStart> void intel_cleanup_overlay ( struct drm_i915_private * dev_priv ) { struct intel_overlay * overlay ; overlay = fetch_and_zero ( & dev_priv -> overlay ) ; if ( ! overlay ) return ; WARN_ON ( overlay -> active ) ; i915_gem_object_put ( overlay -> reg_bo ) ; kfree ( <S2SV_ModEnd> overlay ) ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> to_i915 ( dev ) ; struct intel_overlay * overlay <S2SV_ModEnd> ; int ret ; overlay = dev_priv -> overlay <S2SV_ModStart> ; overlay -> saturation = attrs -> saturation ; update_reg_attrs ( overlay , overlay -> <S2SV_ModEnd> regs ) ; if ( attrs -> flags &
<S2SV_ModStart> * new_bo , struct put_image_params * params ) { struct overlay_registers __iomem * regs = overlay -> regs <S2SV_ModEnd> ; struct drm_i915_private * dev_priv = overlay -> i915 <S2SV_ModStart> pipe pipe = overlay -> crtc -> pipe ; bool scale_changed = false ; struct i915_vma * vma ; int ret , tmp_width <S2SV_ModEnd> ; lockdep_assert_held ( & dev_priv -> drm . struct_mutex <S2SV_ModStart> ! overlay -> active ) { u32 oconfig ; <S2SV_ModEnd> oconfig = OCONF_CC_OUT_8BIT ; if ( IS_GEN4 ( dev_priv <S2SV_ModStart> ( oconfig , & regs -> OCONFIG ) ; <S2SV_ModEnd> ret = intel_overlay_on ( overlay ) ; if ( <S2SV_ModStart> overlay ) ; if ( ret != 0 ) <S2SV_ModEnd> goto out_unpin ; } iowrite32 ( ( params -> <S2SV_ModStart> params ) , & regs -> OCMD ) ; <S2SV_ModEnd> ret = intel_overlay_continue ( overlay , vma , scale_changed
<S2SV_ModStart> { struct drm_i915_private * dev_priv = overlay -> i915 <S2SV_ModEnd> ; int ret ; lockdep_assert_held ( & dev_priv -> <S2SV_ModStart> if ( ret != 0 ) return ret ; iowrite32 ( 0 , & overlay -> regs -> OCMD <S2SV_ModEnd> ) ; return intel_overlay_off ( overlay ) ; }
<S2SV_ModStart> * dev_priv ) { struct intel_overlay * overlay ; <S2SV_ModEnd> int ret ; if ( ! HAS_OVERLAY ( dev_priv <S2SV_ModStart> GFP_KERNEL ) ; if ( ! overlay ) return ; overlay -> i915 = dev_priv ; overlay -> color_key = 0x0101fe ; overlay -> color_key_enabled = true ; overlay -> brightness = - 19 ; overlay -> contrast = 75 ; overlay -> saturation = 146 ; init_request_active ( & overlay -> last_flip , NULL ) <S2SV_ModStart> ( & dev_priv -> drm . struct_mutex ) ; ret = get_registers ( overlay , OVERLAY_NEEDS_PHYSICAL ( dev_priv ) ) ; if ( ret ) goto out_free ; ret = i915_gem_object_set_to_gtt_domain ( overlay -> reg_bo , true ) ; if ( ret ) goto out_reg_bo <S2SV_ModEnd> ; mutex_unlock ( & dev_priv -> drm . struct_mutex <S2SV_ModStart> ( & dev_priv -> drm . struct_mutex ) ; memset_io ( overlay -> regs , 0 , sizeof ( struct overlay_registers ) ) ; update_polyphase_filter ( overlay -> regs ) ; update_reg_attrs ( overlay , overlay -> regs ) ; dev_priv -> overlay = overlay ; DRM_INFO ( "Initialized<S2SV_blank>overlay<S2SV_blank>support.\\n" ) ; return ; out_reg_bo : i915_gem_object_put ( overlay -> <S2SV_ModEnd> reg_bo ) ; out_free : mutex_unlock ( & dev_priv <S2SV_ModStart> . struct_mutex ) ; kfree ( overlay ) ; <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> -> prev_cpu_wall ) ; j_cdbs -> prev_cpu_wall = cur_wall_time ; if ( cur_idle_time < j_cdbs -> prev_cpu_idle ) cur_idle_time = j_cdbs -> prev_cpu_idle
<S2SV_ModStart> , kring -> nr_hwtail , kring -> nkr_hwlease , kring -> rhead , kring -> rcur , kring -> rtail , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail , hw_kring <S2SV_ModEnd> -> rtail ) ; hw_kring -> rhead = hw_kring <S2SV_ModStart> , kring -> nr_hwtail , kring -> nkr_hwlease , kring -> rhead , kring -> rcur , kring -> rtail <S2SV_ModEnd> , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail ,
<S2SV_ModStart> , intf ) ; if ( rv ) goto out_err <S2SV_ModEnd> ; rv = __bmc_get_device_id ( intf , NULL , <S2SV_ModStart> ( si_dev , "Unable<S2SV_blank>to<S2SV_blank>get<S2SV_blank>the<S2SV_blank>device<S2SV_blank>id:<S2SV_blank>%d\\n" , rv ) ; goto out_err_started <S2SV_ModEnd> ; } mutex_lock ( & intf -> bmc_reg_mutex ) <S2SV_ModStart> ; mutex_unlock ( & intf -> bmc_reg_mutex ) ; if ( rv ) goto out_err_bmc_reg ; smp_wmb ( ) ; intf -> intf_num = i ; mutex_unlock ( & ipmi_interfaces_mutex ) ; call_smi_watchers ( i , intf -> si_dev ) ; return 0 ; out_err_bmc_reg : ipmi_bmc_unregister ( intf ) ; out_err_started : if ( intf -> handlers -> shutdown ) intf -> handlers -> shutdown ( intf -> send_info ) ; out_err : <S2SV_ModEnd> list_del_rcu ( & intf -> link ) ; mutex_unlock <S2SV_ModStart> ( & intf -> refcount , intf_free ) ; <S2SV_ModEnd> return rv ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ( & intf -> users_srcu , index ) ; if ( intf -> handlers -> shutdown )
<S2SV_ModStart> ; kthread_stop ( ssif_info -> thread ) ; } <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> * ssif_info = i2c_get_clientdata ( client ) ; struct <S2SV_ModEnd> ssif_addr_info * addr_info ; if ( ! ssif_info ) <S2SV_ModStart> ; if ( ! ssif_info ) return 0 ; ipmi_unregister_smi ( ssif_info -> <S2SV_ModEnd> intf ) ; list_for_each_entry ( addr_info , & ssif_infos <S2SV_ModStart> -> client = NULL ; break ; } } kfree ( ssif_info ) ;
<S2SV_ModStart> ; if ( session_context -> query_context != NULL && ( ! SL_MODE || ( SL_MODE && ! pool_is_doing_extended_query_message ( ) ) ) <S2SV_ModEnd> ) handle_query_context ( backend ) ; if ( SL_MODE
<S2SV_ModStart> ; unsigned long max_pages = ra -> ra_pages ; unsigned long add_pages ; <S2SV_ModStart> ra -> size == ra -> async_size ) { add_pages = get_next_ra_size ( ra , max_pages ) ; if ( ra -> size + add_pages <= max_pages ) { ra -> async_size = add_pages ; ra -> size += add_pages ; } else { ra -> size = max_pages ; ra -> async_size = max_pages >> 1 ; } <S2SV_ModEnd> } return ra_submit ( ra , mapping , filp
<S2SV_ModStart> ; guint offset = 0 ; guint32 header_form ; quic_datagram * dgram_info = NULL ; <S2SV_ModStart> ; if ( PINFO_FD_VISITED ( pinfo ) ) { dgram_info = ( quic_datagram <S2SV_ModEnd> * ) p_get_proto_data ( wmem_file_scope ( ) , pinfo <S2SV_ModStart> proto_quic , 0 ) ; } if ( ! dgram_info ) { dgram_info = wmem_new0 ( wmem_file_scope ( ) , quic_datagram <S2SV_ModEnd> ) ; p_add_proto_data ( wmem_file_scope ( ) , pinfo <S2SV_ModStart> ( ) , pinfo , proto_quic , 0 , dgram_info <S2SV_ModEnd> ) ; } ti = proto_tree_add_item ( tree , <S2SV_ModStart> & scid , & dcid , from_server ) ; dgram_info -> conn = conn ; dgram_info <S2SV_ModEnd> -> from_server = from_server ; # if 0 proto_tree_add_debug_text <S2SV_ModStart> ( quic_tree , "Connection:<S2SV_blank>%d<S2SV_blank>%p<S2SV_blank>DCID=%s<S2SV_blank>SCID=%s<S2SV_blank>from_server:%d" , pinfo -> num , dgram_info <S2SV_ModEnd> -> conn , cid_to_string ( & dcid ) , <S2SV_ModStart> dcid ) , cid_to_string ( & scid ) , dgram_info <S2SV_ModEnd> -> from_server ) ; } else { proto_tree_add_debug_text ( <S2SV_ModStart> ( quic_tree , "Connection:<S2SV_blank>%d<S2SV_blank>%p<S2SV_blank>from_server:%d" , pinfo -> num , dgram_info -> conn , dgram_info <S2SV_ModEnd> -> from_server ) ; # endif } quic_add_connection_info ( <S2SV_ModStart> } quic_add_connection_info ( tvb , pinfo , quic_tree , dgram_info -> conn ) ; do { if ( ! quic_packet ) { quic_packet = & dgram_info -> first_packet ; } else if ( ! PINFO_FD_VISITED ( pinfo ) ) { quic_packet -> next = wmem_new0 ( wmem_file_scope ( ) , quic_packet_info_t ) ; quic_packet = quic_packet -> next ; } else { quic_packet = quic_packet -> next ; DISSECTOR_ASSERT ( quic_packet ) ; } <S2SV_ModEnd> tvbuff_t * next_tvb = quic_get_message_tvb ( tvb , offset <S2SV_ModStart> } dissect_quic_long_header ( next_tvb , pinfo , quic_tree , dgram_info , <S2SV_ModStart> else { dissect_quic_short_header ( next_tvb , pinfo , quic_tree , dgram_info
<S2SV_ModStart> offset , quic_info_data_t * quic_info , quic_packet_info_t * quic_packet , gboolean from_server <S2SV_ModStart> , offset ) ; } quic_cipher * cipher = <S2SV_ModEnd> from_server ? & quic_info -> server_handshake_cipher : & quic_info
<S2SV_ModStart> offset , quic_info_data_t * quic_info , quic_packet_info_t * quic_packet , gboolean from_server <S2SV_ModStart> DISSECTOR_ASSERT ( quic_info ) ; quic_cipher * cipher = <S2SV_ModEnd> from_server ? & quic_info -> server_handshake_cipher : & quic_info
<S2SV_ModStart> , packet_info * pinfo , proto_tree * quic_tree , quic_datagram * dgram_info , <S2SV_ModStart> pkn_len ; guint64 pkn ; quic_info_data_t * conn = dgram_info -> conn ; const gboolean from_server = dgram_info -> from_server <S2SV_ModEnd> ; quic_cipher * cipher = NULL ; proto_tree_add_item_ret_uint ( <S2SV_ModStart> pinfo ) && ( long_packet_type == QUIC_LPT_INITIAL && ! <S2SV_ModEnd> from_server ) && conn && ! memcmp ( & <S2SV_ModStart> } if ( conn ) { cipher = ! <S2SV_ModEnd> from_server ? & conn -> client_handshake_cipher : & conn <S2SV_ModStart> pinfo , quic_tree , offset , conn , quic_packet , from_server <S2SV_ModStart> , quic_tree , offset , conn , quic_packet , from_server , <S2SV_ModStart> , quic_tree , offset , conn , quic_packet , from_server ,
<S2SV_ModStart> , quic_info_data_t * quic_info , quic_packet_info_t * quic_packet , gboolean from_server , <S2SV_ModStart> ! PINFO_FD_VISITED ( pinfo ) ) { if ( <S2SV_ModEnd> from_server ) { pkn = quic_pkt_adjust_pkt_num ( quic_info ->
<S2SV_ModStart> , packet_info * pinfo , proto_tree * quic_tree , quic_datagram * dgram_info , <S2SV_ModStart> * cipher = NULL ; quic_info_data_t * conn = dgram_info -> conn ; const gboolean from_server = dgram_info -> from_server <S2SV_ModEnd> ; proto_tree_add_item_ret_boolean ( quic_tree , hf_quic_short_kp_flag , tvb , <S2SV_ModStart> if ( conn ) { dcid . len = <S2SV_ModEnd> from_server ? conn -> client_cids . data . len <S2SV_ModStart> ( pinfo , key_phase , pkn , conn , <S2SV_ModEnd> from_server ) ; } # endif pkn_len = dissect_quic_packet_number <S2SV_ModStart> pinfo , quic_tree , offset , conn , quic_packet , from_server
<S2SV_ModStart> , packet_info * pinfo , proto_tree * tree , quic_info_data_t * conn <S2SV_ModEnd> ) { proto_tree * ctree ; proto_item * pi <S2SV_ModStart> ) { proto_tree * ctree ; proto_item * pi <S2SV_ModEnd> ; ctree = proto_tree_add_subtree ( tree , tvb ,
<S2SV_ModStart> , kring -> nr_hwtail , kring -> nkr_hwlease , kring -> rhead , kring -> rcur , kring -> rtail , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail , hw_kring <S2SV_ModEnd> -> rtail ) ; hw_kring -> rhead = hw_kring <S2SV_ModStart> , kring -> nr_hwtail , kring -> nkr_hwlease , kring -> rhead , kring -> rcur , kring -> rtail <S2SV_ModEnd> , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail ,
<S2SV_ModStart> , intf ) ; if ( rv ) goto out_err <S2SV_ModEnd> ; rv = __bmc_get_device_id ( intf , NULL , <S2SV_ModStart> ( si_dev , "Unable<S2SV_blank>to<S2SV_blank>get<S2SV_blank>the<S2SV_blank>device<S2SV_blank>id:<S2SV_blank>%d\\n" , rv ) ; goto out_err_started <S2SV_ModEnd> ; } mutex_lock ( & intf -> bmc_reg_mutex ) <S2SV_ModStart> ; mutex_unlock ( & intf -> bmc_reg_mutex ) ; if ( rv ) goto out_err_bmc_reg ; smp_wmb ( ) ; intf -> intf_num = i ; mutex_unlock ( & ipmi_interfaces_mutex ) ; call_smi_watchers ( i , intf -> si_dev ) ; return 0 ; out_err_bmc_reg : ipmi_bmc_unregister ( intf ) ; out_err_started : if ( intf -> handlers -> shutdown ) intf -> handlers -> shutdown ( intf -> send_info ) ; out_err : <S2SV_ModEnd> list_del_rcu ( & intf -> link ) ; mutex_unlock <S2SV_ModStart> ( & intf -> refcount , intf_free ) ; <S2SV_ModEnd> return rv ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ( & intf -> users_srcu , index ) ; if ( intf -> handlers -> shutdown )
<S2SV_ModStart> ; kthread_stop ( ssif_info -> thread ) ; } <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> * ssif_info = i2c_get_clientdata ( client ) ; struct <S2SV_ModEnd> ssif_addr_info * addr_info ; if ( ! ssif_info ) <S2SV_ModStart> ; if ( ! ssif_info ) return 0 ; ipmi_unregister_smi ( ssif_info -> <S2SV_ModEnd> intf ) ; list_for_each_entry ( addr_info , & ssif_infos <S2SV_ModStart> -> client = NULL ; break ; } } kfree ( ssif_info ) ;
<S2SV_ModStart> -> input_handler ) ; if ( ret ) { spin_lock_irqsave ( & kdev -> lock , flags ) ; <S2SV_ModStart> ( keychords ) ; kdev -> keychords = 0 ; spin_unlock_irqrestore ( & kdev -> lock , flags )
<S2SV_ModStart> -> head ; f -> head = cell ; if ( ! f -> tail ) f -> tail = cell ;
<S2SV_ModStart> == NULL ) f -> head = cell ; cell -> next = NULL ;
<S2SV_ModStart> ; # ifdef BACKLIGHT_ENABLE if ( BACKLIT_DIRTY ) { # ifdef USE_I2C backlight_set ( i2c_slave_buffer [ I2C_BACKLIT_START ] ) ; # else backlight_set ( serial_master_buffer [ SERIAL_BACKLIT_START ] ) ; # endif <S2SV_ModEnd> BACKLIT_DIRTY = false ; } # endif # ifdef <S2SV_ModStart> = false ; } # endif # ifdef RGBLIGHT_ENABLE # ifdef USE_I2C <S2SV_ModStart> = false ; sei ( ) ; } # else # endif #
<S2SV_ModStart> ; unsigned long max_pages = ra -> ra_pages ; unsigned long add_pages ; <S2SV_ModStart> ra -> size == ra -> async_size ) { add_pages = get_next_ra_size ( ra , max_pages ) ; if ( ra -> size + add_pages <= max_pages ) { ra -> async_size = add_pages ; ra -> size += add_pages ; } else { ra -> size = max_pages ; ra -> async_size = max_pages >> 1 ; } <S2SV_ModEnd> } return ra_submit ( ra , mapping , filp
<S2SV_ModStart> , IntOverflowError , item . init -> start , "Value<S2SV_blank>for<S2SV_blank>enum<S2SV_blank>case<S2SV_blank>exceeds<S2SV_blank>the<S2SV_blank>max<S2SV_blank>value<S2SV_blank>for<S2SV_blank>the<S2SV_blank>enum<S2SV_blank>backing<S2SV_blank>type<S2SV_blank>(%s)" , DescribeType ( backingType ) ) ; ReportNote ( pkg , item . init -> start , "You<S2SV_blank>can<S2SV_blank>force<S2SV_blank>the<S2SV_blank>overflow<S2SV_blank>by<S2SV_blank>explicitly<S2SV_blank>casting<S2SV_blank>the<S2SV_blank>value<S2SV_blank>\'%s(%s)" , DescribeType ( backingType ) , DescribeExpr ( item . init ) <S2SV_ModEnd> ) ; continue ; } ArrayPush ( fields , <S2SV_ModStart> mode = ExprMode_Type ; return type ; unresolved : if ( fields ) ArrayFree ( fields ) ;
<S2SV_ModStart> ( ! isNumericOrPointer ( switchType ) && ! isBoolean ( switchType ) && ! isEnum
<S2SV_ModStart> |= ConversionFlag_Signed ; return result ; } if ( isEnum ( type ) && IsInteger ( target ) ) { return ConversionKind_Enum <S2SV_ModEnd> ; } if ( IsFloat ( type ) &&
<S2SV_ModStart> functions , it -> name , type ) ; break ; case TypeKind_Enum : { For ( type -> Enum . cases ) { struct EnumField field = type -> Enum . cases [ i ] ; ArrayPrintf ( ctx -> primitiveDecls , "#define<S2SV_blank>%s_%s<S2SV_blank>%lu\\n" , type -> Symbol -> name , field . name , field . val ) ; } } <S2SV_ModStart> ) ; } ArrayPrintf ( ctx -> complexDecls , "};\\n\\n" <S2SV_ModEnd> ) ; } break ; default : { String
<S2SV_ModStart> ( type -> kind ) { case TypeKind_Int : if ( type -> Width == 1 ) return cgenType ( buffer , name , I8Type ) ; <S2SV_ModStart> Width ) ; break ; case TypeKind_Pointer : { if ( type == RawptrType ) { ArrayPrintf ( * buffer , "KaiRawptr" ) ; } else { <S2SV_ModStart> pointee ) ; ArrayFree ( pointee ) ; } } break ; case TypeKind_Enum : { cgenType ( buffer , name , type -> Enum . backingType ) ; return ; }
<S2SV_ModStart> { return type -> Symbol -> name ; } switch ( type -> kind ) { case TypeKind_Pointer : { String desc = NULL ; const char * pointeeType = DescribeType ( type -> Pointer . pointeeType ) ; ArrayPrintf ( desc , "*%s" , pointeeType ) ; return ( char * ) desc ; } default : return DescribeTypeKind ( type -> kind ) ; } <S2SV_ModEnd> } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ; ret = scnprintf ( buf , PAGE_SIZE , "%d\\n" <S2SV_ModEnd> , aod_mode ) ; return ret ; } <S2SV_null>
<S2SV_ModStart> const char * buf , size_t count ) { <S2SV_ModEnd> int ret = 0 ; int aod_mode = 0 <S2SV_ModStart> "kstrtoint<S2SV_blank>failed.<S2SV_blank>ret=%d\\n" , ret ) ; return ret ; } <S2SV_ModEnd> return count ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> case SDE_MODE_DPMS_LP1 : printk ( KERN_ERR "SDE_MODE_DPMS_LP1\\n" ) ; if ( strcmp ( display -> panel -> name , "samsung<S2SV_blank>s6e3fc2x01<S2SV_blank>cmd<S2SV_blank>mode<S2SV_blank>dsi<S2SV_blank>panel" ) == 0 ) { display -> panel -> aod_mode = 2 ; } else display -> panel -> aod_mode = 0 ; if ( display -> panel -> <S2SV_ModEnd> aod_mode != 0 ) { dsi_panel_set_aod_mode ( display -> <S2SV_ModStart> 0 ) { dsi_panel_set_aod_mode ( display -> panel , display -> panel -> aod_mode ) ; display -> panel -> aod_status = 1 <S2SV_ModEnd> ; } break ; case SDE_MODE_DPMS_LP2 : printk (
<S2SV_ModStart> ( & swap_header -> info . nr_badpages ) ; if ( swap_header -> info . nr_badpages > MAX_SWAP_BADPAGES ) return 0 ;
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes ) { # ifdef
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes , int endianess )
<S2SV_ModStart> MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { if ( ! ds -> decoder_state ) { # ifdef MVM_BIGENDIAN init_utf16_decoder_state ( ds , UTF16_DECODE_BIG_ENDIAN ) ; # else init_utf16_decoder_state ( ds , UTF16_DECODE_LITTLE_ENDIAN ) ; # endif }
<S2SV_ModStart> ; MVMint32 last_accept_pos , last_was_cr ; MVMuint32 reached_stopper ; int low , high ; MVMint32 pos = cur_bytes == ds -> bytes_head ? ds -> bytes_head_pos : 0 ; MVMuint8 * bytes = ( unsigned char * ) cur_bytes -> bytes ; <S2SV_ModEnd> if ( ! ds -> bytes_head ) return 0 <S2SV_ModStart> ; last_was_cr = 0 ; reached_stopper = 0 ; if ( utf16_decoder_state ( ds ) == UTF16_DECODE_LITTLE_ENDIAN ) { low = 0 ; high = 1 ; } else if ( utf16_decoder_state ( ds ) == UTF16_DECODE_BIG_ENDIAN ) { low = 1 ; high = 0 ; } else { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Unknown<S2SV_blank>config<S2SV_blank>setting<S2SV_blank>in<S2SV_blank>utf16<S2SV_blank>decodestream.<S2SV_blank>This<S2SV_blank>should<S2SV_blank>never<S2SV_blank>happen." ) ; } <S2SV_ModStart> 0 ; high = 1 ; last_accept_pos = pos += 2 ; utf16_decoder_state ( ds ) = UTF16_DECODE_LITTLE_ENDIAN ; <S2SV_ModEnd> } else if ( is_big_endian ( bytes + pos <S2SV_ModStart> = 1 ; high = 0 ; last_accept_pos = pos += 2 ; utf16_decoder_state ( ds ) = UTF16_DECODE_BIG_ENDIAN ; } } while ( pos + 1 < cur_bytes -> length <S2SV_ModEnd> ) { MVMuint32 value = ( bytes [ pos <S2SV_ModStart> value ; last_accept_bytes = cur_bytes ; last_accept_pos = pos += 2 <S2SV_ModStart> MVM_string_decodestream_discard_to ( tc , ds , last_accept_bytes , last_accept_pos <S2SV_ModEnd> ) ; return reached_stopper ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main
<S2SV_ModStart> MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { init_utf16_decoder_state ( ds , UTF16_DECODE_BIG_ENDIAN ) ;
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main
<S2SV_ModStart> MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { init_utf16_decoder_state ( ds , UTF16_DECODE_LITTLE_ENDIAN ) ;
<S2SV_ModStart> ; unsigned long max_pages = ra -> ra_pages ; unsigned long add_pages ; <S2SV_ModStart> ra -> size == ra -> async_size ) { add_pages = get_next_ra_size ( ra , max_pages ) ; if ( ra -> size + add_pages <= max_pages ) { ra -> async_size = add_pages ; ra -> size += add_pages ; } else { ra -> size = max_pages ; ra -> async_size = max_pages >> 1 ; } <S2SV_ModEnd> } return ra_submit ( ra , mapping , filp
<S2SV_ModStart> ; # ifdef BACKLIGHT_ENABLE if ( BACKLIT_DIRTY ) { # ifdef USE_I2C backlight_set ( i2c_slave_buffer [ I2C_BACKLIT_START ] ) ; # else backlight_set ( serial_master_buffer [ SERIAL_BACKLIT_START ] ) ; # endif <S2SV_ModEnd> BACKLIT_DIRTY = false ; } # endif # ifdef <S2SV_ModStart> = false ; } # endif # ifdef RGBLIGHT_ENABLE # ifdef USE_I2C <S2SV_ModStart> = false ; sei ( ) ; } # else # endif #
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes ) { # ifdef
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes , int endianess )
<S2SV_ModStart> MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { if ( ! ds -> decoder_state ) { # ifdef MVM_BIGENDIAN init_utf16_decoder_state ( ds , UTF16_DECODE_BIG_ENDIAN ) ; # else init_utf16_decoder_state ( ds , UTF16_DECODE_LITTLE_ENDIAN ) ; # endif }
<S2SV_ModStart> ; MVMint32 last_accept_pos , last_was_cr ; MVMuint32 reached_stopper ; int low , high ; MVMint32 pos = cur_bytes == ds -> bytes_head ? ds -> bytes_head_pos : 0 ; MVMuint8 * bytes = ( unsigned char * ) cur_bytes -> bytes ; <S2SV_ModEnd> if ( ! ds -> bytes_head ) return 0 <S2SV_ModStart> ; last_was_cr = 0 ; reached_stopper = 0 ; if ( utf16_decoder_state ( ds ) == UTF16_DECODE_LITTLE_ENDIAN ) { low = 0 ; high = 1 ; } else if ( utf16_decoder_state ( ds ) == UTF16_DECODE_BIG_ENDIAN ) { low = 1 ; high = 0 ; } else { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Unknown<S2SV_blank>config<S2SV_blank>setting<S2SV_blank>in<S2SV_blank>utf16<S2SV_blank>decodestream.<S2SV_blank>This<S2SV_blank>should<S2SV_blank>never<S2SV_blank>happen." ) ; } <S2SV_ModStart> 0 ; high = 1 ; last_accept_pos = pos += 2 ; utf16_decoder_state ( ds ) = UTF16_DECODE_LITTLE_ENDIAN ; <S2SV_ModEnd> } else if ( is_big_endian ( bytes + pos <S2SV_ModStart> = 1 ; high = 0 ; last_accept_pos = pos += 2 ; utf16_decoder_state ( ds ) = UTF16_DECODE_BIG_ENDIAN ; } } while ( pos + 1 < cur_bytes -> length <S2SV_ModEnd> ) { MVMuint32 value = ( bytes [ pos <S2SV_ModStart> value ; last_accept_bytes = cur_bytes ; last_accept_pos = pos += 2 <S2SV_ModStart> MVM_string_decodestream_discard_to ( tc , ds , last_accept_bytes , last_accept_pos <S2SV_ModEnd> ) ; return reached_stopper ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main
<S2SV_ModStart> MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { init_utf16_decoder_state ( ds , UTF16_DECODE_BIG_ENDIAN ) ;
<S2SV_ModStart> MVMThreadContext * tc , const MVMObject * result_type , MVMuint8 <S2SV_ModEnd> * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main
<S2SV_ModStart> MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { init_utf16_decoder_state ( ds , UTF16_DECODE_LITTLE_ENDIAN ) ;
<S2SV_ModStart> ( cnd , KEEP ( chr_append ( subclass , KEEP ( r_string ( "condition" ) ) ) ) ) ; FREE ( 4 <S2SV_ModEnd> ) ; return cnd ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> * oc , struct task_struct * p ) { nodemask_t * nm = ( oc -> nodemask ) ? oc -> nodemask : & cpuset_current_mems_allowed ; pr_warn ( "%s<S2SV_blank>invoked<S2SV_blank>oom-killer:<S2SV_blank>gfp_mask=%#x(%pGg),<S2SV_blank>nodemask=%*pbl,<S2SV_blank>order=%d,<S2SV_blank>oom_score_adj=%hd\\n" <S2SV_ModEnd> , current -> comm , oc -> gfp_mask , <S2SV_ModStart> , oc -> gfp_mask , & oc -> gfp_mask , nodemask_pr_args ( nm )
<S2SV_ModStart> codec ; list_for_each_codec ( codec , bus ) { if ( current_work ( ) != & codec -> jackpoll_work . work )
<S2SV_ModStart> ; unsigned long max_pages = ra -> ra_pages ; unsigned long add_pages ; <S2SV_ModStart> ra -> size == ra -> async_size ) { add_pages = get_next_ra_size ( ra , max_pages ) ; if ( ra -> size + add_pages <= max_pages ) { ra -> async_size = add_pages ; ra -> size += add_pages ; } else { ra -> size = max_pages ; ra -> async_size = max_pages >> 1 ; } <S2SV_ModEnd> } return ra_submit ( ra , mapping , filp
<S2SV_ModStart> error_status1 & ( 1 << 0 ) ) { pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>camif<S2SV_blank>error<S2SV_blank>status:<S2SV_blank>0x%x\\n" , __func__ , vfe_dev -> error_info . <S2SV_ModStart> ( error_status1 & ( 1 << 1 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>stats<S2SV_blank>bhist<S2SV_blank>overwrite\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 2 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>stats<S2SV_blank>cs<S2SV_blank>overwrite\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 3 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>stats<S2SV_blank>ihist<S2SV_blank>overwrite\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 4 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>realign<S2SV_blank>buf<S2SV_blank>y<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 5 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>realign<S2SV_blank>buf<S2SV_blank>cb<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 6 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>realign<S2SV_blank>buf<S2SV_blank>cr<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> error_status1 & ( 1 << 7 ) ) { pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>violation\\n" , __func__ ) ; msm_vfe40_process_violation_status ( vfe_dev <S2SV_ModStart> ( error_status1 & ( 1 << 9 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>0<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 10 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>1<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 11 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>2<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 12 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>3<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 13 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>4<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 14 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>5<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 15 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>6<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 16 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>be<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 17 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>bg<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 18 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>bf<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 19 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>awb<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 20 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>rs<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 21 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>cs<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 22 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>ihist<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 <S2SV_ModStart> ( error_status1 & ( 1 << 23 ) ) pr_err_ratelimited <S2SV_ModEnd> ( "%s:<S2SV_blank>status<S2SV_blank>skin<S2SV_blank>bhist<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; } <S2SV_null> <S2SV_null>
<S2SV_ModStart> case Opt_default_normal : vfsopts -> default_normal = true ; break ;
<S2SV_ModStart> u32 make_rpcs ( struct drm_i915_private * dev_priv ) { bool subslice_pg = INTEL_INFO ( dev_priv ) -> sseu . has_subslice_pg ; u8 slices = <S2SV_ModEnd> hweight8 ( INTEL_INFO ( dev_priv ) -> sseu . <S2SV_ModStart> INTEL_INFO ( dev_priv ) -> sseu . slice_mask ) ; u8 subslices = <S2SV_ModEnd> hweight8 ( INTEL_INFO ( dev_priv ) -> sseu . <S2SV_ModStart> ) -> sseu . subslice_mask [ 0 ] ) ; u32 rpcs = 0 ; if ( INTEL_GEN ( dev_priv ) < 9 ) return 0 ; if ( IS_GEN11 ( dev_priv ) && slices == 1 && subslices >= 4 ) { GEM_BUG_ON ( subslices & 1 ) ; subslice_pg = false ; slices *= 2 ; } if ( INTEL_INFO ( dev_priv ) -> sseu . has_slice_pg ) { u32 mask , val = slices ; if ( INTEL_GEN ( dev_priv ) >= 11 ) { mask = GEN11_RPCS_S_CNT_MASK ; val <<= GEN11_RPCS_S_CNT_SHIFT ; } else { mask = GEN8_RPCS_S_CNT_MASK ; val <<= GEN8_RPCS_S_CNT_SHIFT ; } GEM_BUG_ON ( val & ~ mask ) ; val &= mask ; rpcs |= GEN8_RPCS_ENABLE | GEN8_RPCS_S_CNT_ENABLE | val ; } if ( subslice_pg ) { u32 val = subslices ; val <<= GEN8_RPCS_SS_CNT_SHIFT ; GEM_BUG_ON ( val & ~ GEN8_RPCS_SS_CNT_MASK ) ; val &= GEN8_RPCS_SS_CNT_MASK ; rpcs |= GEN8_RPCS_ENABLE | GEN8_RPCS_SS_CNT_ENABLE | val <S2SV_ModEnd> ; } if ( INTEL_INFO ( dev_priv ) -> <S2SV_ModStart> ( dev_priv ) -> sseu . has_eu_pg ) { u32 val ; val = <S2SV_ModEnd> INTEL_INFO ( dev_priv ) -> sseu . eu_per_subslice << <S2SV_ModStart> dev_priv ) -> sseu . eu_per_subslice << GEN8_RPCS_EU_MIN_SHIFT ; GEM_BUG_ON ( val & ~ GEN8_RPCS_EU_MIN_MASK ) ; val &= GEN8_RPCS_EU_MIN_MASK ; rpcs |= val ; val = <S2SV_ModEnd> INTEL_INFO ( dev_priv ) -> sseu . eu_per_subslice << <S2SV_ModStart> dev_priv ) -> sseu . eu_per_subslice << GEN8_RPCS_EU_MAX_SHIFT ; GEM_BUG_ON ( val & ~ GEN8_RPCS_EU_MAX_MASK ) ; val &= GEN8_RPCS_EU_MAX_MASK ; rpcs |= val ;
<S2SV_ModStart> ) ; ASSERT_SUCCESS ( err_code , "Hash<S2SV_blank>Map<S2SV_blank>put<S2SV_blank>should<S2SV_blank>have<S2SV_blank>succeeded." ) ; ASSERT_INT_EQUALS ( 2 , aws_hash_table_get_entry_count ( & hash_table ) ) ; <S2SV_ModStart> ) ; ASSERT_INT_EQUALS ( 2 , s_value_removal_counter , "Clear<S2SV_blank>should<S2SV_blank>destroy<S2SV_blank>all<S2SV_blank>values" ) ; ASSERT_INT_EQUALS ( 0 , aws_hash_table_get_entry_count ( & hash_table )
<S2SV_ModStart> codec ; list_for_each_codec ( codec , bus ) { if ( current_work ( ) != & codec -> jackpoll_work . work )
<S2SV_ModStart> ) { kthread_stop ( chip -> task ) ; put_task_struct ( chip -> task ) ;
<S2SV_ModStart> ; unsigned int sampling_us = SAMPLING_PERIOD ( chip ) ; struct task_struct * task <S2SV_ModStart> dev , "Async<S2SV_blank>readout<S2SV_blank>mode:<S2SV_blank>%d\\n" , chip -> allow_async_readout ) ; task = kthread_create <S2SV_ModEnd> ( ina2xx_capture_thread , ( void * ) indio_dev , <S2SV_ModStart> name , indio_dev -> id , sampling_us ) ; if ( IS_ERR ( task ) ) return PTR_ERR ( task ) ; get_task_struct ( task ) ; wake_up_process ( task ) ; chip -> task = task ; return 0 <S2SV_ModEnd> ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> -> argc - field_pos ) < 2 || ( ( c -> argc - field_pos ) <S2SV_ModEnd> % 2 ) == 1 ) { addReplyError (
<S2SV_ModStart> root ) ; err = - EINVAL ; goto free_stats <S2SV_ModEnd> ; } sb -> s_root = d_make_root ( root
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ;
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ;
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ;
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ; <S2SV_ModStart> ++ ) { list_rpush ( l , list_node_new ( <S2SV_ModEnd> getJSONItemValue ( cJSON_GetArrayItem ( cjson , j ) ) <S2SV_ModStart> cJSON_GetArrayItem ( cjson , j ) ) ) ) <S2SV_ModEnd> ; } return l ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> , dbuf , size ) ; if ( tmp ) { INIT_LIST_HEAD ( & tmp -> list ) ; if ( <S2SV_ModEnd> ! ( opt_flags & FW_OPT_NOCACHE ) ) list_add ( <S2SV_ModStart> -> list , & fwc -> head ) ; }
<S2SV_ModStart> ; vm -> sharedCacheAPI -> xShareClassesPresent = TRUE ; vm -> sharedCacheAPI -> sharedCacheEnabled = TRUE ; <S2SV_ModStart> ; } return J9VMDLLMAIN_FAILED ; } } else { OMRPORT_ACCESS_FROM_J9PORT ( vm -> portLibrary ) ; vm -> sharedCacheAPI -> xShareClassesPresent = FALSE ; if ( J9_SHARED_CACHE_DEFAULT_BOOT_SHARING ( vm ) && ( J9_ARE_NO_BITS_SET ( omrsysinfo_cgroup_are_subsystems_enabled ( OMR_CGROUP_SUBSYSTEM_ALL ) , OMR_CGROUP_SUBSYSTEM_ALL ) ) ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_NONFATAL ; runtimeFlags &= ~ J9SHR_RUNTIMEFLAG_ENABLE_CACHE_NON_BOOT_CLASSES ; vm -> sharedCacheAPI -> verboseFlags = 0 ; vm -> sharedCacheAPI -> sharedCacheEnabled = TRUE ; } else { vm -> sharedCacheAPI -> verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; } vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags <S2SV_ModEnd> ; } } switch ( stage ) { case <S2SV_ModStart> j9shr_destroySharedCache ; if ( ( vm -> sharedCacheAPI -> sharedCacheEnabled <S2SV_ModEnd> == TRUE ) && ( vm -> sharedCacheAPI -> <S2SV_ModStart> : { if ( ( vm -> sharedCacheAPI -> sharedCacheEnabled <S2SV_ModEnd> == TRUE ) && ( vm -> sharedCacheAPI ->
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_ModEnd> void virtDBusConnectFree ( virtDBusConnect * connect ) { if
<S2SV_ModStart> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_ModEnd> void virtDBusNetworkDHCPLeaseListFree ( virNetworkDHCPLeasePtr * leases ) { for
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ;
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ;
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ;
<S2SV_ModStart> oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } initCJSON ( ) ; <S2SV_ModStart> ++ ) { list_rpush ( l , list_node_new ( <S2SV_ModEnd> getJSONItemValue ( cJSON_GetArrayItem ( cjson , j ) ) <S2SV_ModStart> cJSON_GetArrayItem ( cjson , j ) ) ) ) <S2SV_ModEnd> ; } return l ; } <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> ; vm -> sharedCacheAPI -> xShareClassesPresent = TRUE ; vm -> sharedCacheAPI -> sharedCacheEnabled = TRUE ; <S2SV_ModStart> ; } return J9VMDLLMAIN_FAILED ; } } else { OMRPORT_ACCESS_FROM_J9PORT ( vm -> portLibrary ) ; vm -> sharedCacheAPI -> xShareClassesPresent = FALSE ; if ( J9_SHARED_CACHE_DEFAULT_BOOT_SHARING ( vm ) && ( J9_ARE_NO_BITS_SET ( omrsysinfo_cgroup_are_subsystems_enabled ( OMR_CGROUP_SUBSYSTEM_ALL ) , OMR_CGROUP_SUBSYSTEM_ALL ) ) ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_NONFATAL ; runtimeFlags &= ~ J9SHR_RUNTIMEFLAG_ENABLE_CACHE_NON_BOOT_CLASSES ; vm -> sharedCacheAPI -> verboseFlags = 0 ; vm -> sharedCacheAPI -> sharedCacheEnabled = TRUE ; } else { vm -> sharedCacheAPI -> verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; } vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags <S2SV_ModEnd> ; } } switch ( stage ) { case <S2SV_ModStart> j9shr_destroySharedCache ; if ( ( vm -> sharedCacheAPI -> sharedCacheEnabled <S2SV_ModEnd> == TRUE ) && ( vm -> sharedCacheAPI -> <S2SV_ModStart> : { if ( ( vm -> sharedCacheAPI -> sharedCacheEnabled <S2SV_ModEnd> == TRUE ) && ( vm -> sharedCacheAPI ->
<S2SV_ModStart> ) ; if ( IS_ERR ( dentry_page ) ) { err = PTR_ERR ( dentry_page ) ; if ( err == - ENOENT ) continue ; else goto out ; } <S2SV_ModEnd> dentry_blk = kmap ( dentry_page ) ; make_dentry_ptr (
<S2SV_ModStart> ( ) ; StringInfo response ; bool useInvisibilityMap = strstr ( userQuery , "#limit" ) != NULL || strstr ( userQuery , "#options" ) != NULL ||
<S2SV_ModStart> * hits ; ZDBScore max_score ; bool useInvisibilityMap = strstr ( queries [ 0 ] , "#limit" ) != NULL || strstr ( queries [ 0 ] , "#options" ) != NULL ||
<S2SV_ModStart> RFCOMM_PARSE_LEN_FIELD ( eal , len , p_data ) ; if ( eal == 0 && p_buf -> len > RFCOMM_CTRL_FRAME_LEN ) { len += ( * ( p_data ) ++ << RFCOMM_SHIFT_LENGTH2 ) ; } else if ( eal == 0 ) { RFCOMM_TRACE_ERROR1 ( "Bad<S2SV_blank>Length<S2SV_blank>when<S2SV_blank>EAL<S2SV_blank>=<S2SV_blank>0:<S2SV_blank>%d" , p_buf -> len ) ; android_errorWriteLog ( 0x534e4554 , "78288018" ) ; return RFC_EVENT_BAD_FRAME ; }
<S2SV_ModStart> ; break ; case NAV_CLUSTER : rgblight_mode ( 29 ) ; break ; case RGB : eeconfig_update_rgblight_default (
<S2SV_ModStart> ndo , "%04x:%04x<S2SV_blank>" , panid , EXTRACT_LE_16BITS ( p <S2SV_ModEnd> ) ) ) ; p += 2 ; caplen
<S2SV_ModStart> ) { kthread_stop ( chip -> task ) ; put_task_struct ( chip -> task ) ;
<S2SV_ModStart> ; unsigned int sampling_us = SAMPLING_PERIOD ( chip ) ; struct task_struct * task <S2SV_ModStart> dev , "Async<S2SV_blank>readout<S2SV_blank>mode:<S2SV_blank>%d\\n" , chip -> allow_async_readout ) ; task = kthread_create <S2SV_ModEnd> ( ina2xx_capture_thread , ( void * ) indio_dev , <S2SV_ModStart> name , indio_dev -> id , sampling_us ) ; if ( IS_ERR ( task ) ) return PTR_ERR ( task ) ; get_task_struct ( task ) ; wake_up_process ( task ) ; chip -> task = task ; return 0 <S2SV_ModEnd> ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> 0 ; goto retry ; } } if ( ( ext4_group_first_block_no ( sb , n_group ) + ext4_group_overhead_blocks ( sb , n_group ) + 2 + sbi -> s_itb_per_group + sbi -> s_cluster_ratio ) >= n_blocks_count ) { n_blocks_count = ext4_group_first_block_no ( sb , n_group ) ; n_group -- ; n_blocks_count_retry = 0 ; if ( resize_inode ) { iput ( resize_inode ) ; resize_inode = NULL ; } goto retry ; } if (
<S2SV_ModStart> ; # ifdef BACKLIGHT_ENABLE if ( BACKLIT_DIRTY ) { # ifdef USE_I2C backlight_set ( i2c_slave_buffer [ I2C_BACKLIT_START ] ) ; # else backlight_set ( serial_master_buffer [ SERIAL_BACKLIT_START ] ) ; # endif <S2SV_ModEnd> BACKLIT_DIRTY = false ; } # endif # ifdef <S2SV_ModStart> = false ; } # endif # ifdef RGBLIGHT_ENABLE # ifdef USE_I2C <S2SV_ModStart> = false ; sei ( ) ; } # else # endif #
<S2SV_ModStart> ) { kthread_stop ( chip -> task ) ; put_task_struct ( chip -> task ) ;
<S2SV_ModStart> ; unsigned int sampling_us = SAMPLING_PERIOD ( chip ) ; struct task_struct * task <S2SV_ModStart> dev , "Async<S2SV_blank>readout<S2SV_blank>mode:<S2SV_blank>%d\\n" , chip -> allow_async_readout ) ; task = kthread_create <S2SV_ModEnd> ( ina2xx_capture_thread , ( void * ) indio_dev , <S2SV_ModStart> name , indio_dev -> id , sampling_us ) ; if ( IS_ERR ( task ) ) return PTR_ERR ( task ) ; get_task_struct ( task ) ; wake_up_process ( task ) ; chip -> task = task ; return 0 <S2SV_ModEnd> ; } <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null> <S2SV_null>
<S2SV_ModStart> root ) ; err = - EINVAL ; goto free_stats <S2SV_ModEnd> ; } sb -> s_root = d_make_root ( root
<S2SV_ModStart> ; vm -> sharedCacheAPI -> xShareClassesPresent = TRUE ; vm -> sharedCacheAPI -> sharedCacheEnabled = TRUE ; <S2SV_ModStart> ; } return J9VMDLLMAIN_FAILED ; } } else { OMRPORT_ACCESS_FROM_J9PORT ( vm -> portLibrary ) ; vm -> sharedCacheAPI -> xShareClassesPresent = FALSE ; if ( J9_SHARED_CACHE_DEFAULT_BOOT_SHARING ( vm ) && ( J9_ARE_NO_BITS_SET ( omrsysinfo_cgroup_are_subsystems_enabled ( OMR_CGROUP_SUBSYSTEM_ALL ) , OMR_CGROUP_SUBSYSTEM_ALL ) ) ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_NONFATAL ; runtimeFlags &= ~ J9SHR_RUNTIMEFLAG_ENABLE_CACHE_NON_BOOT_CLASSES ; vm -> sharedCacheAPI -> verboseFlags = 0 ; vm -> sharedCacheAPI -> sharedCacheEnabled = TRUE ; } else { vm -> sharedCacheAPI -> verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; } vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags <S2SV_ModEnd> ; } } switch ( stage ) { case <S2SV_ModStart> j9shr_destroySharedCache ; if ( ( vm -> sharedCacheAPI -> sharedCacheEnabled <S2SV_ModEnd> == TRUE ) && ( vm -> sharedCacheAPI -> <S2SV_ModStart> : { if ( ( vm -> sharedCacheAPI -> sharedCacheEnabled <S2SV_ModEnd> == TRUE ) && ( vm -> sharedCacheAPI ->
