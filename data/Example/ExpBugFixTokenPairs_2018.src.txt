struct sk_buff * tcp_make_synack ( const struct sock * sk , struct dst_entry * dst , struct request_sock * req , struct tcp_fastopen_cookie * foc , bool attach_req ) { struct inet_request_sock * ireq = inet_rsk ( req ) ; const struct tcp_sock * tp = tcp_sk ( sk ) ; struct tcp_md5sig_key * md5 = NULL ; struct tcp_out_options opts ; struct sk_buff * skb ; int tcp_header_size ; struct tcphdr * th ; u16 user_mss ; int mss ; skb = alloc_skb ( MAX_TCP_HEADER , GFP_ATOMIC ) ; if ( unlikely ( ! skb ) ) { dst_release ( dst ) ; return NULL ; } skb_reserve ( skb , MAX_TCP_HEADER ) ; if ( attach_req ) { skb_set_owner_w ( skb , req_to_sk ( req ) ) ; } else { skb_set_owner_w ( skb , ( struct sock * ) sk ) ; } skb_dst_set ( skb , dst ) ; mss = dst_metric_advmss ( dst ) ; user_mss = READ_ONCE ( tp -> rx_opt . user_mss ) ; if ( user_mss && user_mss < mss ) mss = user_mss ; memset ( & opts , 0 , sizeof ( opts ) ) ; # ifdef CONFIG_SYN_COOKIES if ( unlikely ( req -> cookie_ts ) ) skb -> skb_mstamp . stamp_jiffies = cookie_init_timestamp ( req ) ; else # endif skb_mstamp_get ( & skb -> skb_mstamp ) ; # ifdef CONFIG_TCP_MD5SIG rcu_read_lock ( ) ; md5 = tcp_rsk ( req ) -> af_specific -> req_md5_lookup ( sk , req_to_sk ( req ) ) ; # endif skb_set_hash ( skb , tcp_rsk ( req ) -> txhash , PKT_HASH_TYPE_L4 ) ; tcp_header_size = tcp_synack_options ( req , mss , skb , & opts , md5 , foc ) + sizeof ( * th ) ; skb_push ( skb , tcp_header_size ) ; skb_reset_transport_header ( skb ) ; th = tcp_hdr ( skb ) ; memset ( th , 0 , sizeof ( struct tcphdr ) ) ; th -> syn = 1 ; th -> ack = 1 ; tcp_ecn_make_synack ( req , th ) ; th -> source = htons ( ireq -> ir_num ) ; th -> dest = ireq -> ir_rmt_port ; tcp_init_nondata_skb ( skb , tcp_rsk ( req ) -> snt_isn , TCPHDR_SYN | TCPHDR_ACK ) ; th -> seq = htonl ( TCP_SKB_CB ( skb ) -> seq ) ; th -> ack_seq = htonl ( tcp_rsk ( req ) -> rcv_nxt ) ; th -> window = htons ( min ( req -> rsk_rcv_wnd , 65535U ) ) ; tcp_options_write ( ( __be32 * ) ( th + 1 ) , NULL , & opts ) ; th -> doff = ( tcp_header_size >> 2 ) ; TCP_INC_STATS_BH ( sock_net ( sk ) , TCP_MIB_OUTSEGS ) ; # ifdef CONFIG_TCP_MD5SIG if ( md5 ) tcp_rsk ( req ) -> af_specific -> calc_md5_hash ( opts . hash_location , md5 , req_to_sk ( req ) , skb ) ; rcu_read_unlock ( ) ; # endif skb -> tstamp . tv64 = 0 ; return skb ; }
static inline int _is_in_region ( u32_t r_index , u32_t start , u32_t size ) { # if CONFIG_ARC_MPU_VER == 2 u32_t r_addr_start ; u32_t r_addr_end ; u32_t r_size_lshift ; r_addr_start = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift = ( r_size_lshift & 0x3 ) | ( ( r_size_lshift >> 7 ) & 0x1C ) ; r_addr_end = r_addr_start + ( 1 << ( r_size_lshift + 1 ) ) ; if ( start >= r_addr_start && ( start + size ) < r_addr_end ) { return 1 ; } # elif CONFIG_ARC_MPU_VER == 3 if ( ( r_index == _mpu_probe ( start ) ) && ( r_index == _mpu_probe ( start + size ) ) ) { return 1 ; } # endif return 0 ; }
static int _request_firmware ( const struct firmware * * firmware_p , const char * name , struct device * device , void * buf , size_t size , unsigned int opt_flags ) { struct firmware * fw = NULL ; long timeout ; int ret ; if ( ! firmware_p ) return - EINVAL ; if ( ! name || name [ 0 ] == '\\0' ) { ret = - EINVAL ; goto out ; } ret = _request_firmware_prepare ( & fw , name , device , buf , size ) ; if ( ret <= 0 ) goto out ; ret = 0 ; timeout = firmware_loading_timeout ( ) ; if ( opt_flags & FW_OPT_NOWAIT ) { timeout = usermodehelper_read_lock_wait ( timeout ) ; if ( ! timeout ) { dev_dbg ( device , "firmware:<S2SV_blank>%s<S2SV_blank>loading<S2SV_blank>timed<S2SV_blank>out\\n" , name ) ; ret = - EBUSY ; goto out ; } } else { ret = usermodehelper_read_trylock ( ) ; if ( WARN_ON ( ret ) ) { dev_err ( device , "firmware:<S2SV_blank>%s<S2SV_blank>will<S2SV_blank>not<S2SV_blank>be<S2SV_blank>loaded\\n" , name ) ; goto out ; } } ret = fw_get_filesystem_firmware ( device , fw -> priv ) ; if ( ret ) { if ( ! ( opt_flags & FW_OPT_NO_WARN ) ) dev_warn ( device , "Direct<S2SV_blank>firmware<S2SV_blank>load<S2SV_blank>for<S2SV_blank>%s<S2SV_blank>failed<S2SV_blank>with<S2SV_blank>error<S2SV_blank>%d\\n" , name , ret ) ; if ( opt_flags & FW_OPT_USERHELPER ) { dev_warn ( device , "Falling<S2SV_blank>back<S2SV_blank>to<S2SV_blank>user<S2SV_blank>helper\\n" ) ; ret = fw_load_from_user_helper ( fw , name , device , opt_flags , timeout ) ; } } if ( ! ret ) ret = assign_firmware_buf ( fw , device , opt_flags ) ; usermodehelper_read_unlock ( ) ; out : if ( ret < 0 ) { release_firmware ( fw ) ; fw = NULL ; } * firmware_p = fw ; return ret ; }
static int fw_get_filesystem_firmware ( struct device * device , struct firmware_buf * buf ) { loff_t size ; int i , len ; int rc = - ENOENT ; char * path ; enum kernel_read_file_id id = READING_FIRMWARE ; size_t msize = INT_MAX ; if ( buf -> data ) { id = READING_FIRMWARE_PREALLOC_BUFFER ; msize = buf -> allocated_size ; } path = __getname ( ) ; if ( ! path ) return - ENOMEM ; for ( i = 0 ; i < ARRAY_SIZE ( fw_path ) ; i ++ ) { if ( ! fw_path [ i ] [ 0 ] ) continue ; len = snprintf ( path , PATH_MAX , "%s/%s" , fw_path [ i ] , buf -> fw_id ) ; if ( len >= PATH_MAX ) { rc = - ENAMETOOLONG ; break ; } buf -> size = 0 ; rc = kernel_read_file_from_path ( path , & buf -> data , & size , msize , id ) ; if ( rc ) { if ( rc == - ENOENT ) dev_dbg ( device , "loading<S2SV_blank>%s<S2SV_blank>failed<S2SV_blank>with<S2SV_blank>error<S2SV_blank>%d\\n" , path , rc ) ; else dev_warn ( device , "loading<S2SV_blank>%s<S2SV_blank>failed<S2SV_blank>with<S2SV_blank>error<S2SV_blank>%d\\n" , path , rc ) ; continue ; } dev_dbg ( device , "direct-loading<S2SV_blank>%s\\n" , buf -> fw_id ) ; buf -> size = size ; fw_finish_direct_load ( device , buf ) ; break ; } __putname ( path ) ; return rc ; }
static void authserver_request_cb ( void * data , char * content ) { struct authserver_request_param * param = data ; struct uh_client * cl = param -> cl ; struct config * conf = get_config ( ) ; const char * remote_addr = cl -> get_peer_addr ( cl ) ; char mac [ 18 ] = "" ; int code = - 1 ; if ( ! param ) return ; if ( arp_get ( conf -> gw_interface , remote_addr , mac , sizeof ( mac ) ) < 0 ) { ULOG_ERR ( "arp_get<S2SV_blank>failed<S2SV_blank>for<S2SV_blank>%s\\n" , remote_addr ) ; cl -> request_done ( cl ) ; return ; } ULOG_INFO ( "auth<S2SV_blank>for<S2SV_blank>%s:<S2SV_blank>%s\\n" , mac , content ) ; if ( ! content ) goto deny ; sscanf ( content , "Auth:<S2SV_blank>%d" , & code ) ; if ( code == 1 ) { allow_termianl ( mac , param -> token , false ) ; cl -> redirect ( cl , 302 , conf -> portal_url ) ; free ( param ) ; return ; } else { cl -> redirect ( cl , 302 , conf -> msg_url ) ; free ( param ) ; return ; } deny : deny_termianl ( mac ) ; free ( param ) ; }
__inline # else # ifdef __cplusplus inline # endif # endif static unsigned int hash ( str , len ) register const char * str ; register unsigned int len ; { static unsigned char asso_values [ ] = { 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 3 , 39 , 0 , 32 , 10 , 30 , 44 , 44 , 4 , 37 , 36 , 5 , 27 , 44 , 2 , 44 , 44 , 1 , 11 , 28 , 6 , 26 , 44 , 33 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 3 , 39 , 0 , 32 , 10 , 30 , 44 , 44 , 4 , 37 , 36 , 5 , 27 , 44 , 2 , 44 , 44 , 1 , 11 , 28 , 6 , 26 , 44 , 33 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 , 44 } ; register int hval = len ; switch ( hval ) { default : hval += asso_values [ ( unsigned char ) str [ 1 ] ] ; case 1 : hval += asso_values [ ( unsigned char ) str [ 0 ] ] ; break ; } return hval ; }
void LoadBoundaryMenu ( int value ) { int errorcode ; int i , ii ; int boundarytypenew ; glutSetCursor ( GLUT_CURSOR_WAIT ) ; if ( value >= 0 ) { boundarytypenew = GetBoundaryType ( patchinfo + value ) ; if ( boundarytypenew != - 1 ) { for ( ii = 0 ; ii < npatch_loaded ; ii ++ ) { patchdata * patchi ; i = patch_loaded_list [ ii ] ; patchi = patchinfo + i ; if ( patchi -> type != boundarytypenew ) ReadBoundary ( i , UNLOAD , & errorcode ) ; } } if ( scriptoutstream != NULL ) { patchdata * patchi ; patchi = patchinfo + value ; fprintf ( scriptoutstream , "//<S2SV_blank>LOADFILE\\n" ) ; fprintf ( scriptoutstream , "//<S2SV_blank><S2SV_blank>%s\\n" , patchi -> file ) ; fprintf ( scriptoutstream , "LOADBOUNDARYM\\n" ) ; fprintf ( scriptoutstream , "<S2SV_blank>%s\\n" , patchi -> label . longlabel ) ; fprintf ( scriptoutstream , "<S2SV_blank>%i\\n" , patchi -> blocknumber + 1 ) ; } if ( scriptoutstream == NULL || defer_file_loading == 0 ) { LOCK_COMPRESS ReadBoundary ( value , LOAD , & errorcode ) ; UNLOCK_COMPRESS } } else if ( value <= - 10 ) { patchdata * patchj ; value = - ( value + 10 ) ; patchj = patchinfo + value ; if ( scriptoutstream != NULL ) { fprintf ( scriptoutstream , "LOADBOUNDARY\\n" ) ; fprintf ( scriptoutstream , "<S2SV_blank>%s\\n" , patchj -> label . longlabel ) ; } if ( scriptoutstream == NULL || defer_file_loading == 0 ) { for ( i = 0 ; i < npatchinfo ; i ++ ) { patchdata * patchi ; patchi = patchinfo + i ; if ( strcmp ( patchi -> label . longlabel , patchj -> label . longlabel ) == 0 && patchi -> filetype == patchj -> filetype ) { if ( patchi -> geom_fdsfiletype == NULL || strcmp ( patchi -> geom_fdsfiletype , "INCLUDE_GEOM" ) != 0 ) { LOCK_COMPRESS ReadBoundary ( i , LOAD , & errorcode ) ; UNLOCK_COMPRESS } } } } force_redisplay = 1 ; UpdateFrameNumber ( 0 ) ; } else { switch ( value ) { case MENU_UPDATEBOUNDS : UpdateAllBoundaryBounds ( ) ; break ; case MENU_BOUNDARY_SETTINGS : ShowBoundsDialog ( DLG_BOUNDARY ) ; break ; case MENU_KEEP_ALL : if ( boundaryslicedup_option != SLICEDUP_KEEPALL ) { boundaryslicedup_option = SLICEDUP_KEEPALL ; updatemenu = 1 ; glutPostRedisplay ( ) ; UpdateBoundarySliceDups ( ) ; UpdateSliceDupDialog ( ) ; } break ; case MENU_KEEP_COARSE : if ( boundaryslicedup_option != SLICEDUP_KEEPCOARSE ) { boundaryslicedup_option = SLICEDUP_KEEPCOARSE ; updatemenu = 1 ; glutPostRedisplay ( ) ; UpdateBoundarySliceDups ( ) ; UpdateSliceDupDialog ( ) ; } break ; case MENU_KEEP_FINE : if ( boundaryslicedup_option != SLICEDUP_KEEPFINE ) { boundaryslicedup_option = SLICEDUP_KEEPFINE ; updatemenu = 1 ; glutPostRedisplay ( ) ; UpdateBoundarySliceDups ( ) ; UpdateSliceDupDialog ( ) ; } break ; default : for ( i = 0 ; i < npatchinfo ; i ++ ) { patchdata * patchi ; patchi = patchinfo + i ; if ( patchi -> geom_fdsfiletype == NULL || strcmp ( patchi -> geom_fdsfiletype , "INCLUDE_GEOM" ) != 0 ) { ReadBoundary ( i , UNLOAD , & errorcode ) ; } } break ; } } updatemenu = 1 ; glutPostRedisplay ( ) ; glutSetCursor ( GLUT_CURSOR_LEFT_ARROW ) ; }
static inline int _is_in_region ( u32_t r_index , u32_t start , u32_t size ) { # if CONFIG_ARC_MPU_VER == 2 u32_t r_addr_start ; u32_t r_addr_end ; u32_t r_size_lshift ; r_addr_start = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift = ( r_size_lshift & 0x3 ) | ( ( r_size_lshift >> 7 ) & 0x1C ) ; r_addr_end = r_addr_start + ( 1 << ( r_size_lshift + 1 ) ) ; if ( start >= r_addr_start && ( start + size ) < r_addr_end ) { return 1 ; } # elif CONFIG_ARC_MPU_VER == 3 if ( ( r_index == _mpu_probe ( start ) ) && ( r_index == _mpu_probe ( start + size ) ) ) { return 1 ; } # endif return 0 ; }
static size_t lens_dist_merge ( double * dst , const double * lhs , size_t lhs_len , const double * rhs , size_t rhs_len ) { size_t dst_len = 0 ; const double * to_merge = NULL ; size_t to_merge_len = 0 ; if ( lhs_len >= rhs_len ) { dst_len = lhs_len ; memcpy ( dst , lhs , lhs_len * sizeof ( * lhs ) ) ; to_merge = rhs ; to_merge_len = rhs_len ; } else { dst_len = rhs_len ; memcpy ( dst , rhs , rhs_len * sizeof ( * rhs ) ) ; to_merge = lhs ; to_merge_len = lhs_len ; } assert ( to_merge_len <= dst_len ) ; if ( ! to_merge_len ) return dst_len ; if ( dst_len < optics_dist_samples ) { size_t to_copy = optics_dist_samples - dst_len ; if ( to_copy > to_merge_len ) to_copy = to_merge_len ; memcpy ( dst + dst_len , to_merge , to_copy * sizeof ( * lhs ) ) ; to_merge += to_copy ; to_merge_len -= to_copy ; if ( ! to_merge_len ) return dst_len ; } if ( to_merge_len <= optics_dist_samples ) { for ( size_t i = 0 ; i < to_merge_len ; ++ i ) { size_t index = rng_gen_range ( rng_global ( ) , 0 , dst_len ) ; if ( index < optics_dist_samples ) dst [ index ] = to_merge [ i ] ; dst_len ++ ; } } else { const double rate = ( double ) to_merge_len / ( double ) ( to_merge_len + dst_len ) ; for ( size_t i = 0 ; i < optics_dist_samples ; ++ i ) { if ( rng_gen_prob ( rng_global ( ) , rate ) ) dst [ i ] = to_merge [ i ] ; } } return optics_dist_samples ; }
static enum optics_ret lens_dist_read ( struct optics_lens * lens , optics_epoch_t epoch , struct optics_dist * value ) { struct lens_dist * dist_head = lens_sub_ptr ( lens -> lens , optics_dist ) ; if ( ! dist_head ) return optics_err ; struct lens_dist_epoch * dist = & dist_head -> epochs [ epoch ] ; memset ( value , 0 , sizeof ( * value ) ) ; size_t value_len = value -> n , dist_len = 0 ; double samples [ optics_dist_samples ] ; { if ( slock_is_locked ( & dist -> lock ) ) return optics_busy ; value -> n += dist -> n ; dist -> n = 0 ; if ( value -> max < dist -> max ) value -> max = dist -> max ; dist -> max = 0 ; dist_len = value -> n <= optics_dist_samples ? value -> n : optics_dist_samples ; memcpy ( samples , dist -> samples , dist_len * sizeof ( double ) ) ; slock_unlock ( & dist -> lock ) ; } if ( ! dist_len ) return optics_ok ; double result [ optics_dist_samples ] ; size_t result_len = lens_dist_merge ( result , samples , dist_len , value -> samples , value_len ) ; memcpy ( value -> samples , result , result_len * sizeof ( double ) ) ; qsort ( result , result_len , sizeof ( double ) , lens_dist_value_cmp ) ; value -> p50 = result [ lens_dist_p ( 50 , result_len ) ] ; value -> p90 = result [ lens_dist_p ( 90 , result_len ) ] ; value -> p99 = result [ lens_dist_p ( 99 , result_len ) ] ; return optics_ok ; }
static enum optics_ret lens_histo_read ( struct optics_lens * lens , optics_epoch_t epoch , struct optics_histo * value ) { ( void ) epoch ; struct lens_histo * histo = lens_sub_ptr ( lens -> lens , optics_histo ) ; if ( ! histo ) return optics_err ; value -> buckets_len = histo -> buckets_len ; memcpy ( value -> buckets , histo -> buckets , histo -> buckets_len * sizeof ( histo -> buckets [ 0 ] ) ) ; struct lens_histo_epoch * counters = & histo -> epochs [ epoch ] ; value -> below = atomic_exchange_explicit ( & counters -> below , 0 , memory_order_relaxed ) ; value -> above = atomic_exchange_explicit ( & counters -> above , 0 , memory_order_relaxed ) ; for ( size_t i = 0 ; i < histo -> buckets_len - 1 ; ++ i ) { value -> counts [ i ] += atomic_exchange_explicit ( & counters -> counts [ i ] , 0 , memory_order_relaxed ) ; } return optics_ok ; }
size_t epoch_test_read_lens ( struct epoch_test * test ) { optics_epoch_t epoch = optics_epoch_inc ( test -> optics ) ; int64_t value ; assert_int_equal ( optics_counter_read ( test -> lens , epoch , & value ) , optics_ok ) ; return value ; }
int main ( void ) { const struct CMUnitTest tests [ ] = { cmocka_unit_test ( lens_counter_open_close_test ) , cmocka_unit_test ( lens_counter_alloc_get_test ) , cmocka_unit_test ( lens_counter_record_read_test ) , cmocka_unit_test ( lens_counter_type_test ) , cmocka_unit_test ( lens_counter_epoch_st_test ) , cmocka_unit_test ( lens_counter_epoch_mt_test ) , } ; return cmocka_run_group_tests ( tests , NULL , NULL ) ; }
void ec_dispatch_min ( ec_fop_data_t * fop ) { ec_t * ec = fop -> xl -> private ; uintptr_t mask ; uint32_t idx ; int32_t count ; ec_dispatch_start ( fop ) ; if ( ec_child_select ( fop ) ) { fop -> expected = count = ec -> fragments ; fop -> first = ec_select_first_by_read_policy ( fop -> xl -> private , fop ) ; idx = fop -> first - 1 ; mask = 0 ; while ( count -- > 0 ) { idx = ec_child_next ( ec , fop , idx + 1 ) ; if ( idx < EC_METHOD_MAX_NODES ) mask |= 1ULL << idx ; } ec_dispatch_mask ( fop , mask ) ; } }
void ec_dispatch_next ( ec_fop_data_t * fop , uint32_t idx ) { uint32_t i = EC_INVALID_INDEX ; ec_t * ec = fop -> xl -> private ; LOCK ( & fop -> lock ) ; i = ec_child_next ( ec , fop , idx ) ; if ( i < EC_METHOD_MAX_NODES ) { idx = i ; fop -> remaining ^= 1ULL << idx ; ec_trace ( "EXECUTE" , fop , "idx=%d" , idx ) ; fop -> winds ++ ; fop -> refs ++ ; } UNLOCK ( & fop -> lock ) ; if ( i < EC_METHOD_MAX_NODES ) { fop -> wind ( ec , fop , idx ) ; } }
bool sap_dfs_is_channel_in_nol_list ( ptSapContext sap_context , uint8_t channel_number , ePhyChanBondState chan_bondState ) { int i = 0 , j ; tHalHandle h_hal = CDS_GET_HAL_CB ( sap_context -> p_cds_gctx ) ; tpAniSirGlobal mac_ctx ; uint8_t channels [ MAX_BONDED_CHANNELS ] ; uint8_t num_channels ; tSapDfsNolInfo * nol ; tSapDfsInfo * dfs_info ; bool channel_available ; if ( NULL == h_hal ) { QDF_TRACE ( QDF_MODULE_ID_SAP , QDF_TRACE_LEVEL_ERROR , FL ( "invalid<S2SV_blank>h_hal" ) ) ; return false ; } else { mac_ctx = PMAC_STRUCT ( h_hal ) ; } dfs_info = & mac_ctx -> sap . SapDfsInfo ; if ( ( dfs_info -> numCurrentRegDomainDfsChannels == 0 ) || ( dfs_info -> numCurrentRegDomainDfsChannels > NUM_5GHZ_CHANNELS ) ) { QDF_TRACE ( QDF_MODULE_ID_SAP , QDF_TRACE_LEVEL_INFO_LOW , FL ( "invalid<S2SV_blank>dfs<S2SV_blank>channel<S2SV_blank>count<S2SV_blank>%d" ) , dfs_info -> numCurrentRegDomainDfsChannels ) ; return false ; } num_channels = sap_get_bonding_channels ( sap_context , channel_number , channels , MAX_BONDED_CHANNELS , chan_bondState ) ; for ( j = 0 ; j < num_channels ; j ++ ) { for ( i = 0 ; i < dfs_info -> numCurrentRegDomainDfsChannels ; i ++ ) { nol = & dfs_info -> sapDfsChannelNolList [ i ] ; if ( nol -> dfs_channel_number != channels [ j ] ) continue ; channel_available = sap_dfs_check_if_channel_avaialable ( nol ) ; if ( channel_available == false ) break ; } if ( i < dfs_info -> numCurrentRegDomainDfsChannels ) break ; } if ( j < num_channels && i < dfs_info -> numCurrentRegDomainDfsChannels ) { if ( num_channels > MAX_BONDED_CHANNELS ) { QDF_TRACE ( QDF_MODULE_ID_SAP , QDF_TRACE_LEVEL_WARN , FL ( "num_channel>MAX_BONDED_CHANNEL,<S2SV_blank>reset" ) ) ; num_channels = MAX_BONDED_CHANNELS ; } nol = & dfs_info -> sapDfsChannelNolList [ i ] ; sap_mark_dfs_channels ( sap_context , channels , num_channels , nol -> radar_found_timestamp ) ; sap_signal_hdd_event ( sap_context , NULL , eSAP_DFS_NOL_SET , ( void * ) eSAP_STATUS_SUCCESS ) ; return true ; } return false ; }
static inline int _is_in_region ( u32_t r_index , u32_t start , u32_t size ) { # if CONFIG_ARC_MPU_VER == 2 u32_t r_addr_start ; u32_t r_addr_end ; u32_t r_size_lshift ; r_addr_start = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift = ( r_size_lshift & 0x3 ) | ( ( r_size_lshift >> 7 ) & 0x1C ) ; r_addr_end = r_addr_start + ( 1 << ( r_size_lshift + 1 ) ) ; if ( start >= r_addr_start && ( start + size ) < r_addr_end ) { return 1 ; } # elif CONFIG_ARC_MPU_VER == 3 if ( ( r_index == _mpu_probe ( start ) ) && ( r_index == _mpu_probe ( start + size ) ) ) { return 1 ; } # endif return 0 ; }
int read100 ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; int x , y ; int stitchType ; unsigned char b [ 4 ] ; if ( ! pattern ) { embLog_error ( "format-100.c<S2SV_blank>read100(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-100.c<S2SV_blank>read100(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-100.c<S2SV_blank>read100(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; while ( embFile_read ( b , 1 , 4 , file ) == 4 ) { stitchType = NORMAL ; x = ( b [ 2 ] > 0x80 ) ? - ( b [ 2 ] - 0x80 ) : b [ 2 ] ; y = ( b [ 3 ] > 0x80 ) ? - ( b [ 3 ] - 0x80 ) : b [ 3 ] ; if ( ! ( b [ 0 ] & 0x01 ) ) stitchType = STOP ; if ( b [ 0 ] == 0x1F ) stitchType = END ; embPattern_addStitchRel ( pattern , x / 10.0 , y / 10.0 , stitchType , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int read10o ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-10o.c<S2SV_blank>read10o(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-10o.c<S2SV_blank>read10o(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-10o.c<S2SV_blank>read10o(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; while ( 1 ) { int x , y ; int stitchType = NORMAL ; unsigned char ctrl = ( unsigned char ) embFile_getc ( file ) ; if ( embFile_eof ( file ) ) break ; y = embFile_getc ( file ) ; if ( embFile_eof ( file ) ) break ; x = embFile_getc ( file ) ; if ( embFile_eof ( file ) ) break ; if ( ctrl & 0x20 ) x = - x ; if ( ctrl & 0x40 ) y = - y ; if ( ctrl & 0x01 ) stitchType = TRIM ; if ( ( ctrl & 0x5 ) == 5 ) { stitchType = STOP ; } if ( ctrl == 0xF8 || ctrl == 0x91 || ctrl == 0x87 ) { embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; break ; } embPattern_addStitchRel ( pattern , x / 10.0 , y / 10.0 , stitchType , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeArt ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-art.c<S2SV_blank>writeArt(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-art.c<S2SV_blank>writeArt(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-art.c<S2SV_blank>writeArt(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readBro ( EmbPattern * pattern , const char * fileName ) { unsigned char x55 ; short unknown1 , unknown2 , unknown3 , unknown4 , moreBytesToEnd ; char name [ 8 ] ; int stitchType ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-bro.c<S2SV_blank>readBro(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-bro.c<S2SV_blank>readBro(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-bro.c<S2SV_blank>readBro(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; x55 = binaryReadByte ( file ) ; unknown1 = binaryReadInt16 ( file ) ; embFile_read ( name , 1 , 8 , file ) ; unknown2 = binaryReadInt16 ( file ) ; unknown3 = binaryReadInt16 ( file ) ; unknown4 = binaryReadInt16 ( file ) ; moreBytesToEnd = binaryReadInt16 ( file ) ; embFile_seek ( file , 0x100 , SEEK_SET ) ; while ( 1 ) { short b1 , b2 ; stitchType = NORMAL ; b1 = binaryReadByte ( file ) ; b2 = binaryReadByte ( file ) ; if ( b1 == - 128 ) { unsigned char bCode = binaryReadByte ( file ) ; b1 = binaryReadInt16 ( file ) ; b2 = binaryReadInt16 ( file ) ; if ( bCode == 2 ) { stitchType = STOP ; } else if ( bCode == 3 ) { stitchType = TRIM ; } else if ( bCode == 0x7E ) { embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; break ; } } embPattern_addStitchRel ( pattern , b1 / 10.0 , b2 / 10.0 , stitchType , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeCnd ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-cnd.c<S2SV_blank>writeCnd(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-cnd.c<S2SV_blank>writeCnd(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-cnd.c<S2SV_blank>writeCnd(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readDat ( EmbPattern * pattern , const char * fileName ) { int fileLength , stitchesRemaining ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-dat.c<S2SV_blank>readDat(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-dat.c<S2SV_blank>readDat(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-dat.c<S2SV_blank>readDat(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; embFile_seek ( file , 0x00 , SEEK_END ) ; fileLength = embFile_tell ( file ) ; embFile_seek ( file , 0x02 , SEEK_SET ) ; stitchesRemaining = binaryReadUInt16 ( file ) ; embFile_seek ( file , 0x100 , SEEK_SET ) ; while ( embFile_tell ( file ) < fileLength ) { int b1 = ( int ) binaryReadUInt8 ( file ) ; int b2 = ( int ) binaryReadUInt8 ( file ) ; unsigned char b0 = binaryReadByte ( file ) ; int stitchType = NORMAL ; stitchesRemaining -- ; if ( ( b0 & 0x02 ) == 0 ) stitchType = TRIM ; if ( b0 == 0x87 ) { stitchType = STOP ; } if ( b0 == 0xF8 ) { break ; } if ( b1 >= 0x80 ) { b1 = - ( b1 & 0x7F ) ; } if ( b2 >= 0x80 ) { b2 = - ( b2 & 0x7F ) ; } embPattern_addStitchRel ( pattern , b1 / 10.0 , b2 / 10.0 , stitchType , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeDat ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-dat.c<S2SV_blank>writeDat(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-dat.c<S2SV_blank>writeDat(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-dat.c<S2SV_blank>writeDat(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int writeDem ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-dem.c<S2SV_blank>writeDem(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-dem.c<S2SV_blank>writeDem(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-dem.c<S2SV_blank>writeDem(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readDsz ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-dsz.c<S2SV_blank>readDsz(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-dsz.c<S2SV_blank>readDsz(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-dsz.c<S2SV_blank>readDsz(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; embFile_seek ( file , 0x200 , SEEK_SET ) ; while ( 1 ) { int x , y ; unsigned char ctrl ; int stitchType = NORMAL ; y = embFile_getc ( file ) ; if ( embFile_eof ( file ) ) break ; x = embFile_getc ( file ) ; if ( embFile_eof ( file ) ) break ; ctrl = ( unsigned char ) embFile_getc ( file ) ; if ( embFile_eof ( file ) ) break ; if ( ctrl & 0x01 ) stitchType = TRIM ; if ( ctrl & 0x20 ) y = - y ; if ( ctrl & 0x40 ) x = - x ; if ( ctrl & 0x0E ) { int headNumber = ( ctrl & 0x0E ) >> 1 ; stitchType = STOP ; } if ( ctrl & 0x10 ) { embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; break ; } embPattern_addStitchRel ( pattern , x / 10.0 , y / 10.0 , stitchType , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeDsz ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-dsz.c<S2SV_blank>writeDsz(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-dsz.c<S2SV_blank>writeDsz(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-dsz.c<S2SV_blank>writeDsz(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readEmd ( EmbPattern * pattern , const char * fileName ) { unsigned char b0 = 0 , b1 = 0 ; char dx = 0 , dy = 0 ; int flags = NORMAL ; char endOfStream = 0 ; unsigned char jemd0 [ 6 ] ; int width , height , colors ; int i ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-emd.c<S2SV_blank>readEmd(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-emd.c<S2SV_blank>readEmd(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-emd.c<S2SV_blank>readEmd(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; binaryReadBytes ( file , jemd0 , 6 ) ; width = binaryReadInt16 ( file ) ; height = binaryReadInt16 ( file ) ; colors = binaryReadInt16 ( file ) ; embFile_seek ( file , 0x30 , SEEK_SET ) ; for ( i = 0 ; ! endOfStream ; i ++ ) { flags = NORMAL ; b0 = binaryReadUInt8 ( file ) ; b1 = binaryReadUInt8 ( file ) ; if ( b0 == 0x80 ) { if ( b1 == 0x2A ) { embPattern_addStitchRel ( pattern , 0 , 0 , STOP , 1 ) ; continue ; } else if ( b1 == 0x80 ) { b0 = binaryReadUInt8 ( file ) ; b1 = binaryReadUInt8 ( file ) ; flags = TRIM ; } else if ( b1 == 0xFD ) { embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; break ; } else { continue ; } } dx = emdDecode ( b0 ) ; dy = emdDecode ( b1 ) ; embPattern_addStitchRel ( pattern , dx / 10.0 , dy / 10.0 , flags , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeEmd ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-emd.c<S2SV_blank>writeEmd(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-emd.c<S2SV_blank>writeEmd(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-emd.c<S2SV_blank>writeEmd(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readExy ( EmbPattern * pattern , const char * fileName ) { unsigned char b [ 3 ] ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-exy.c<S2SV_blank>readExy(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-exy.c<S2SV_blank>readExy(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-exy.c<S2SV_blank>readExy(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; embFile_seek ( file , 0x100 , SEEK_SET ) ; while ( embFile_read ( b , 1 , 3 , file ) == 3 ) { int flags ; int x = 0 ; int y = 0 ; if ( b [ 0 ] & 0x01 ) x += 1 ; if ( b [ 0 ] & 0x02 ) x -= 1 ; if ( b [ 0 ] & 0x04 ) x += 9 ; if ( b [ 0 ] & 0x08 ) x -= 9 ; if ( b [ 0 ] & 0x80 ) y += 1 ; if ( b [ 0 ] & 0x40 ) y -= 1 ; if ( b [ 0 ] & 0x20 ) y += 9 ; if ( b [ 0 ] & 0x10 ) y -= 9 ; if ( b [ 1 ] & 0x01 ) x += 3 ; if ( b [ 1 ] & 0x02 ) x -= 3 ; if ( b [ 1 ] & 0x04 ) x += 27 ; if ( b [ 1 ] & 0x08 ) x -= 27 ; if ( b [ 1 ] & 0x80 ) y += 3 ; if ( b [ 1 ] & 0x40 ) y -= 3 ; if ( b [ 1 ] & 0x20 ) y += 27 ; if ( b [ 1 ] & 0x10 ) y -= 27 ; if ( b [ 2 ] & 0x04 ) x += 81 ; if ( b [ 2 ] & 0x08 ) x -= 81 ; if ( b [ 2 ] & 0x20 ) y += 81 ; if ( b [ 2 ] & 0x10 ) y -= 81 ; flags = exyDecodeFlags ( b [ 2 ] ) ; if ( ( flags & END ) == END ) { embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; break ; } embPattern_addStitchRel ( pattern , x / 10.0 , y / 10.0 , flags , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeExy ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-exy.c<S2SV_blank>writeExy(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-exy.c<S2SV_blank>writeExy(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-exy.c<S2SV_blank>writeExy(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int writeEys ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-eys.c<S2SV_blank>writeEys(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-eys.c<S2SV_blank>writeEys(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-eys.c<S2SV_blank>writeEys(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readFxy ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-fxy.c<S2SV_blank>readFxy(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-fxy.c<S2SV_blank>readFxy(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-fxy.c<S2SV_blank>readFxy(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; embFile_seek ( file , 0x100 , SEEK_SET ) ; while ( 1 ) { int stitchType = NORMAL ; int b1 = ( int ) binaryReadByte ( file ) ; int b2 = ( int ) binaryReadByte ( file ) ; unsigned char commandByte = binaryReadByte ( file ) ; if ( commandByte == 0x91 ) { embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; break ; } if ( ( commandByte & 0x01 ) == 0x01 ) stitchType = TRIM ; if ( ( commandByte & 0x02 ) == 0x02 ) stitchType = STOP ; if ( ( commandByte & 0x20 ) == 0x20 ) b1 = - b1 ; if ( ( commandByte & 0x40 ) == 0x40 ) b2 = - b2 ; embPattern_addStitchRel ( pattern , b2 / 10.0 , b1 / 10.0 , stitchType , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeFxy ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-fxy.c<S2SV_blank>writeFxy(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-fxy.c<S2SV_blank>writeFxy(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-fxy.c<S2SV_blank>writeFxy(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int writeGc ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-gc.c<S2SV_blank>writeGc(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-gc.c<S2SV_blank>writeGc(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-gc.c<S2SV_blank>writeGc(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int writeGnc ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-gnc.c<S2SV_blank>writeGnc(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-gnc.c<S2SV_blank>writeGnc(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-gnc.c<S2SV_blank>writeGnc(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readGt ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-gt.c<S2SV_blank>readGt(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-gt.c<S2SV_blank>readGt(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-gt.c<S2SV_blank>readGt(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; embFile_seek ( file , 0x200 , SEEK_SET ) ; while ( 1 ) { int stitchType = NORMAL ; int b1 = ( int ) binaryReadByte ( file ) ; int b2 = ( int ) binaryReadByte ( file ) ; unsigned char commandByte = binaryReadByte ( file ) ; if ( commandByte == 0x91 ) { embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; break ; } if ( ( commandByte & 0x01 ) == 0x01 ) stitchType = TRIM ; if ( ( commandByte & 0x02 ) == 0x02 ) stitchType = STOP ; if ( ( commandByte & 0x20 ) == 0x20 ) b1 = - b1 ; if ( ( commandByte & 0x40 ) == 0x40 ) b2 = - b2 ; embPattern_addStitchRel ( pattern , b2 / 10.0 , b1 / 10.0 , stitchType , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeGt ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-gt.c<S2SV_blank>writeGt(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-gt.c<S2SV_blank>writeGt(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-gt.c<S2SV_blank>writeGt(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readInb ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; unsigned char fileDescription [ 8 ] ; unsigned char nullVal ; int stitchCount ; short width ; short height ; short colorCount ; short unknown3 ; short unknown2 ; short imageWidth ; short imageHeight ; unsigned char bytesUnknown [ 300 ] ; short nullbyte ; short left ; short right ; short top ; short bottom ; int x = 0 ; int y = 0 ; int i ; int fileLength ; if ( ! pattern ) { embLog_error ( "format-inb.c<S2SV_blank>readInb(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-inb.c<S2SV_blank>readInb(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-inb.c<S2SV_blank>readInb(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; embFile_seek ( file , 0 , SEEK_END ) ; fileLength = embFile_tell ( file ) ; binaryReadBytes ( file , fileDescription , 8 ) ; nullVal = binaryReadByte ( file ) ; binaryReadInt16 ( file ) ; stitchCount = binaryReadInt32 ( file ) ; width = binaryReadInt16 ( file ) ; height = binaryReadInt16 ( file ) ; colorCount = binaryReadInt16 ( file ) ; unknown3 = binaryReadInt16 ( file ) ; unknown2 = binaryReadInt16 ( file ) ; imageWidth = binaryReadInt16 ( file ) ; imageHeight = binaryReadInt16 ( file ) ; binaryReadBytes ( file , bytesUnknown , 300 ) ; nullbyte = binaryReadInt16 ( file ) ; left = binaryReadInt16 ( file ) ; right = binaryReadInt16 ( file ) ; top = binaryReadInt16 ( file ) ; bottom = binaryReadInt16 ( file ) ; embFile_seek ( file , 0x2000 , SEEK_SET ) ; stitchCount = ( int ) ( ( fileLength - 0x2000 ) / 3 ) ; for ( i = 0 ; i < stitchCount ; i ++ ) { unsigned char type ; int stitch = NORMAL ; x = binaryReadByte ( file ) ; y = binaryReadByte ( file ) ; type = binaryReadByte ( file ) ; if ( ( type & 0x40 ) > 0 ) x = - x ; if ( ( type & 0x10 ) > 0 ) y = - y ; if ( ( type & 1 ) > 0 ) stitch = STOP ; if ( ( type & 2 ) > 0 ) stitch = TRIM ; embPattern_addStitchRel ( pattern , x / 10.0 , y / 10.0 , stitch , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; embPattern_flipVertical ( pattern ) ; return 1 ; }
int writeInb ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-inb.c<S2SV_blank>writeInb(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-inb.c<S2SV_blank>writeInb(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-inb.c<S2SV_blank>writeInb(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
int readKsm ( EmbPattern * pattern , const char * fileName ) { int prevStitchType = NORMAL ; char b [ 3 ] ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-ksm.c<S2SV_blank>readKsm(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-ksm.c<S2SV_blank>readKsm(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-ksm.c<S2SV_blank>readKsm(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embFile_seek ( file , 0x200 , SEEK_SET ) ; while ( embFile_read ( b , 1 , 3 , file ) == 3 ) { int flags = NORMAL ; if ( ( ( prevStitchType & 0x08 ) == 0x08 ) && ( b [ 2 ] & 0x08 ) == 0x08 ) { flags = STOP ; } else if ( ( b [ 2 ] & 0x1F ) != 0 ) { flags = TRIM ; } prevStitchType = b [ 2 ] ; if ( b [ 2 ] & 0x40 ) b [ 1 ] = - b [ 1 ] ; if ( b [ 2 ] & 0x20 ) b [ 0 ] = - b [ 0 ] ; embPattern_addStitchRel ( pattern , b [ 1 ] / 10.0 , b [ 0 ] / 10.0 , flags , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeKsm ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; EmbStitchList * pointer = 0 ; double xx = 0 , yy = 0 , dx = 0 , dy = 0 ; int flags = 0 ; int i = 0 ; unsigned char b [ 4 ] ; if ( ! pattern ) { embLog_error ( "format-ksm.c<S2SV_blank>writeKsm(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-ksm.c<S2SV_blank>writeKsm(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-ksm.c<S2SV_blank>writeKsm(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; file = embFile_open ( fileName , "wb" ) ; if ( ! file ) { embLog_error ( "format-ksm.c<S2SV_blank>writeKsm(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>writing\\n" , fileName ) ; return 0 ; } for ( i = 0 ; i < 0x80 ; i ++ ) { binaryWriteInt ( file , 0 ) ; } xx = yy = 0 ; pointer = pattern -> stitchList ; while ( pointer ) { dx = pointer -> stitch . xx - xx ; dy = pointer -> stitch . yy - yy ; xx = pointer -> stitch . xx ; yy = pointer -> stitch . yy ; flags = pointer -> stitch . flags ; ksmEncode ( b , ( char ) ( dx * 10.0 ) , ( char ) ( dy * 10.0 ) , flags ) ; embFile_printf ( file , "%c%c" , b [ 0 ] , b [ 1 ] ) ; pointer = pointer -> next ; } embFile_printf ( file , "\\x1a" ) ; embFile_close ( file ) ; return 1 ; }
int readMax ( EmbPattern * pattern , const char * fileName ) { int i = 0 ; unsigned char b [ 8 ] ; double dx = 0 , dy = 0 ; int flags = 0 ; int stitchCount ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-max.c<S2SV_blank>readMax(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-max.c<S2SV_blank>readMax(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-max.c<S2SV_blank>readMax(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embFile_seek ( file , 0xD5 , SEEK_SET ) ; stitchCount = binaryReadUInt32 ( file ) ; for ( i = 0 ; i < stitchCount ; i ++ ) { flags = NORMAL ; if ( embFile_read ( b , 1 , 8 , file ) != 8 ) break ; dx = maxDecode ( b [ 0 ] , b [ 1 ] , b [ 2 ] ) ; dy = maxDecode ( b [ 4 ] , b [ 5 ] , b [ 6 ] ) ; embPattern_addStitchAbs ( pattern , dx / 10.0 , dy / 10.0 , flags , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; embPattern_flipVertical ( pattern ) ; return 1 ; }
int writeMax ( EmbPattern * pattern , const char * fileName ) { EmbFile * file = 0 ; EmbStitchList * pointer = 0 ; char header [ ] = { 0x56 , 0x43 , 0x53 , 0x4D , 0xFC , 0x03 , 0x00 , 0x00 , 0x01 , 0x00 , 0x00 , 0x00 , 0x01 , 0x00 , 0x00 , 0x00 , 0xF6 , 0x25 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x08 , 0x00 , 0x00 , 0x00 , 0x05 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x01 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x31 , 0x33 , 0x37 , 0x38 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x4D , 0x61 , 0x64 , 0x65 , 0x69 , 0x72 , 0x61 , 0x20 , 0x52 , 0x61 , 0x79 , 0x6F , 0x6E , 0x20 , 0x34 , 0x30 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x01 , 0x38 , 0x09 , 0x31 , 0x33 , 0x30 , 0x2F , 0x37 , 0x30 , 0x35 , 0x20 , 0x48 , 0xFA , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 } ; if ( ! pattern ) { embLog_error ( "format-max.c<S2SV_blank>writeMax(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-max.c<S2SV_blank>writeMax(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-max.c<S2SV_blank>writeMax(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; file = embFile_open ( fileName , "wb" ) ; if ( ! file ) { embLog_error ( "format-max.c<S2SV_blank>writeMax(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>writing\\n" , fileName ) ; return 0 ; } binaryWriteBytes ( file , header , 0xD5 ) ; pointer = pattern -> stitchList ; while ( pointer ) { maxEncode ( file , roundDouble ( pointer -> stitch . xx * 10.0 ) , roundDouble ( pointer -> stitch . yy * 10.0 ) ) ; pointer = pointer -> next ; } embFile_close ( file ) ; return 1 ; }
int readMit ( EmbPattern * pattern , const char * fileName ) { unsigned char data [ 2 ] ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-mit.c<S2SV_blank>readMit(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-mit.c<S2SV_blank>readMit(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-mit.c<S2SV_blank>readMit(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } while ( binaryReadBytes ( file , data , 2 ) == 2 ) { embPattern_addStitchRel ( pattern , mitDecodeStitch ( data [ 0 ] ) / 10.0 , mitDecodeStitch ( data [ 1 ] ) / 10.0 , NORMAL , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int readNew ( EmbPattern * pattern , const char * fileName ) { unsigned int stitchCount ; unsigned char data [ 3 ] ; EmbFile * file = 0 ; if ( ! pattern ) { embLog_error ( "format-new.c<S2SV_blank>readNew(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-new.c<S2SV_blank>readNew(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } file = embFile_open ( fileName , "rb" ) ; if ( ! file ) { embLog_error ( "format-new.c<S2SV_blank>readNew(),<S2SV_blank>cannot<S2SV_blank>open<S2SV_blank>%s<S2SV_blank>for<S2SV_blank>reading\\n" , fileName ) ; return 0 ; } embPattern_loadExternalColorFile ( pattern , fileName ) ; stitchCount = binaryReadUInt16 ( file ) ; while ( binaryReadBytes ( file , data , 3 ) == 3 ) { int x = decodeNewStitch ( data [ 0 ] ) ; int y = decodeNewStitch ( data [ 1 ] ) ; int flag = NORMAL ; char val = data [ 2 ] ; if ( data [ 2 ] & 0x40 ) { x = - x ; } if ( data [ 2 ] & 0x20 ) { y = - y ; } if ( data [ 2 ] & 0x10 ) { flag = TRIM ; } if ( data [ 2 ] & 0x01 ) { flag = JUMP ; } if ( ( val & 0x1E ) == 0x02 ) { flag = STOP ; } embPattern_addStitchRel ( pattern , x / 10.0 , y / 10.0 , flag , 1 ) ; } embFile_close ( file ) ; if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 1 ; }
int writeNew ( EmbPattern * pattern , const char * fileName ) { if ( ! pattern ) { embLog_error ( "format-new.c<S2SV_blank>writeNew(),<S2SV_blank>pattern<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! fileName ) { embLog_error ( "format-new.c<S2SV_blank>writeNew(),<S2SV_blank>fileName<S2SV_blank>argument<S2SV_blank>is<S2SV_blank>null\\n" ) ; return 0 ; } if ( ! embStitchList_count ( pattern -> stitchList ) ) { embLog_error ( "format-new.c<S2SV_blank>writeNew(),<S2SV_blank>pattern<S2SV_blank>contains<S2SV_blank>no<S2SV_blank>stitches\\n" ) ; return 0 ; } if ( pattern -> lastStitch -> stitch . flags != END ) embPattern_addStitchRel ( pattern , 0 , 0 , END , 1 ) ; return 0 ; }
static inline int _is_in_region ( u32_t r_index , u32_t start , u32_t size ) { # if CONFIG_ARC_MPU_VER == 2 u32_t r_addr_start ; u32_t r_addr_end ; u32_t r_size_lshift ; r_addr_start = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift = ( r_size_lshift & 0x3 ) | ( ( r_size_lshift >> 7 ) & 0x1C ) ; r_addr_end = r_addr_start + ( 1 << ( r_size_lshift + 1 ) ) ; if ( start >= r_addr_start && ( start + size ) < r_addr_end ) { return 1 ; } # elif CONFIG_ARC_MPU_VER == 3 if ( ( r_index == _mpu_probe ( start ) ) && ( r_index == _mpu_probe ( start + size ) ) ) { return 1 ; } # endif return 0 ; }
int FTIFF_CheckL1RecoverInit ( FTIT_execution * FTI_Exec , FTIT_topology * FTI_Topo , FTIT_checkpoint * FTI_Ckpt ) { char str [ FTI_BUFS ] , tmpfn [ FTI_BUFS ] , strerr [ FTI_BUFS ] ; int fexist = 0 , fileTarget , ckptID , fcount ; struct dirent * entry ; struct stat ckptFS ; struct stat ckptDIR ; FTIFF_metaInfo * FTIFFMeta = calloc ( 1 , sizeof ( FTIFF_metaInfo ) ) ; if ( FTIFFMeta == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoverInit<S2SV_blank>-<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>allocate<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>for<S2SV_blank>\'FTIFFMeta\'" , sizeof ( FTIFF_metaInfo ) ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; goto SEND_NOFILE_INFO ; } MD5_CTX mdContext ; bool L1CkptDirExists = false ; if ( stat ( FTI_Ckpt [ 1 ] . dir , & ckptDIR ) == 0 ) { if ( S_ISDIR ( ckptDIR . st_mode ) != 0 ) { L1CkptDirExists = true ; } else { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoverInit<S2SV_blank>-<S2SV_blank>(%s)<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>directory." , FTI_Ckpt [ 1 ] . dir ) ; FTI_Print ( strerr , FTI_WARN ) ; free ( FTIFFMeta ) ; goto SEND_NOFILE_INFO ; } } if ( L1CkptDirExists ) { DIR * L1CkptDir = opendir ( FTI_Ckpt [ 1 ] . dir ) ; if ( L1CkptDir == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>checkpoint<S2SV_blank>directory<S2SV_blank>(%s)<S2SV_blank>could<S2SV_blank>not<S2SV_blank>be<S2SV_blank>accessed." , FTI_Ckpt [ 1 ] . dir ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; goto SEND_NOFILE_INFO ; } while ( ( entry = readdir ( L1CkptDir ) ) != NULL ) { if ( strcmp ( entry -> d_name , "." ) && strcmp ( entry -> d_name , ".." ) ) { snprintf ( str , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>found<S2SV_blank>file<S2SV_blank>with<S2SV_blank>name:<S2SV_blank>%s" , entry -> d_name ) ; FTI_Print ( str , FTI_DBUG ) ; sscanf ( entry -> d_name , "Ckpt%d-Rank%d.fti" , & ckptID , & fileTarget ) ; if ( fileTarget == FTI_Topo -> myRank ) { snprintf ( tmpfn , FTI_BUFS , "%s/%s" , FTI_Ckpt [ 1 ] . dir , entry -> d_name ) ; if ( stat ( tmpfn , & ckptFS ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>Problem<S2SV_blank>with<S2SV_blank>stats<S2SV_blank>on<S2SV_blank>file<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } if ( S_ISREG ( ckptFS . st_mode ) == 0 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>%s<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>regular<S2SV_blank>file" , tmpfn ) ; FTI_Print ( strerr , FTI_WARN ) ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } if ( ckptFS . st_size > sizeof ( FTIFF_metaInfo ) ) { int fd = open ( tmpfn , O_RDONLY ) ; if ( fd == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>open<S2SV_blank>\'%s\'<S2SV_blank>for<S2SV_blank>reading." , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } if ( lseek ( fd , 0 , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } if ( read ( fd , FTIFFMeta , sizeof ( FTIFF_metaInfo ) ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>request<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>from:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; FTIFF_GetHashMetaInfo ( hash , FTIFFMeta ) ; if ( memcmp ( FTIFFMeta -> myHash , hash , MD5_DIGEST_LENGTH ) == 0 ) { long rcount = sizeof ( FTIFF_metaInfo ) , toRead , diff ; int rbuffer ; char * buffer = malloc ( CHUNK_SIZE ) ; if ( buffer == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoverInit<S2SV_blank>-<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>allocate<S2SV_blank>%d<S2SV_blank>bytes<S2SV_blank>for<S2SV_blank>\'buffer\'" , CHUNK_SIZE ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } MD5_Init ( & mdContext ) ; while ( rcount < FTIFFMeta -> fs ) { if ( lseek ( fd , rcount , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; close ( fd ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } diff = FTIFFMeta -> fs - rcount ; toRead = ( diff < CHUNK_SIZE ) ? diff : CHUNK_SIZE ; rbuffer = read ( fd , buffer , toRead ) ; if ( rbuffer == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>file:<S2SV_blank>%s" , toRead , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } rcount += rbuffer ; MD5_Update ( & mdContext , buffer , rbuffer ) ; } free ( buffer ) ; unsigned char hash [ MD5_DIGEST_LENGTH ] ; MD5_Final ( hash , & mdContext ) ; int i ; char checksum [ MD5_DIGEST_STRING_LENGTH ] ; int ii = 0 ; for ( i = 0 ; i < MD5_DIGEST_LENGTH ; i ++ ) { sprintf ( & checksum [ ii ] , "%02x" , hash [ i ] ) ; ii += 2 ; } if ( strcmp ( checksum , FTIFFMeta -> checksum ) == 0 ) { FTI_Exec -> meta [ 1 ] . fs [ 0 ] = ckptFS . st_size ; FTI_Exec -> ckptID = ckptID ; strncpy ( FTI_Exec -> meta [ 1 ] . ckptFile , entry -> d_name , NAME_MAX ) ; fexist = 1 ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Checksum<S2SV_blank>do<S2SV_blank>not<S2SV_blank>match.<S2SV_blank>\\"%s\\"<S2SV_blank>file<S2SV_blank>is<S2SV_blank>corrupted.<S2SV_blank>%s<S2SV_blank>!=<S2SV_blank>%s" , entry -> d_name , checksum , FTIFFMeta -> checksum ) ; FTI_Print ( str , FTI_WARN ) ; close ( fd ) ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } } close ( fd ) ; break ; } } } } closedir ( L1CkptDir ) ; } MPI_Allreduce ( & fexist , & fcount , 1 , MPI_INT , MPI_SUM , FTI_COMM_WORLD ) ; int fneeded = FTI_Topo -> nbNodes * FTI_Topo -> nbApprocs ; int res = ( fcount == fneeded ) ? FTI_SCES : FTI_NSCS ; free ( FTIFFMeta ) ; return res ; SEND_NOFILE_INFO : fexist = 0 ; MPI_Allreduce ( & fexist , & fcount , 1 , MPI_INT , MPI_SUM , FTI_COMM_WORLD ) ; return FTI_NSCS ; }
int FTIFF_CheckL2RecoverInit ( FTIT_execution * FTI_Exec , FTIT_topology * FTI_Topo , FTIT_checkpoint * FTI_Ckpt , int * exists ) { char dbgstr [ FTI_BUFS ] , strerr [ FTI_BUFS ] ; enum { LEFT_FILE , MY_FILE , MY_COPY , LEFT_COPY } ; MPI_Group nodesGroup ; MPI_Comm_group ( FTI_Exec -> groupComm , & nodesGroup ) ; MPI_Group appProcsGroup ; MPI_Comm_group ( FTI_COMM_WORLD , & appProcsGroup ) ; int baseRanks [ ] = { FTI_Topo -> left , FTI_Topo -> right } ; int projRanks [ 2 ] ; MPI_Group_translate_ranks ( nodesGroup , 2 , baseRanks , appProcsGroup , projRanks ) ; int leftIdx = projRanks [ 0 ] , rightIdx = projRanks [ 1 ] ; int appCommSize = FTI_Topo -> nbNodes * FTI_Topo -> nbApprocs ; int fneeded = appCommSize ; MPI_Group_free ( & nodesGroup ) ; MPI_Group_free ( & appProcsGroup ) ; FTIFF_L2Info _appProcsMetaInfo ; FTIFF_L2Info * appProcsMetaInfo = memset ( & _appProcsMetaInfo , 0x0 , sizeof ( FTIFF_L2Info ) ) ; FTIFF_L2Info _myMetaInfo ; FTIFF_L2Info * myMetaInfo = memset ( & _myMetaInfo , 0x0 , sizeof ( FTIFF_L2Info ) ) ; myMetaInfo -> rightIdx = rightIdx ; MD5_CTX mdContext ; char str [ FTI_BUFS ] , tmpfn [ FTI_BUFS ] ; int fileTarget , ckptID = - 1 , fcount = 0 , match ; struct dirent * entry ; struct stat ckptFS , ckptDIR ; FTIFF_metaInfo _FTIFFMeta ; FTIFF_metaInfo * FTIFFMeta = memset ( & _FTIFFMeta , 0x0 , sizeof ( FTIFF_metaInfo ) ) ; bool L2CkptDirExists = false ; if ( stat ( FTI_Ckpt [ 2 ] . dir , & ckptDIR ) == 0 ) { if ( S_ISDIR ( ckptDIR . st_mode ) != 0 ) { L2CkptDirExists = true ; } else { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoverInit<S2SV_blank>-<S2SV_blank>(%s)<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>directory." , FTI_Ckpt [ 2 ] . dir ) ; FTI_Print ( strerr , FTI_WARN ) ; goto GATHER_INFO ; } } if ( L2CkptDirExists ) { int tmpCkptID ; DIR * L2CkptDir = opendir ( FTI_Ckpt [ 2 ] . dir ) ; if ( L2CkptDir == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>checkpoint<S2SV_blank>directory<S2SV_blank>(%s)<S2SV_blank>could<S2SV_blank>not<S2SV_blank>be<S2SV_blank>accessed." , FTI_Ckpt [ 2 ] . dir ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; goto GATHER_INFO ; } while ( ( entry = readdir ( L2CkptDir ) ) != NULL ) { if ( strcmp ( entry -> d_name , "." ) && strcmp ( entry -> d_name , ".." ) ) { snprintf ( str , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>found<S2SV_blank>file<S2SV_blank>with<S2SV_blank>name:<S2SV_blank>%s" , entry -> d_name ) ; FTI_Print ( str , FTI_DBUG ) ; tmpCkptID = ckptID ; match = sscanf ( entry -> d_name , "Ckpt%d-Rank%d.fti" , & ckptID , & fileTarget ) ; if ( match == 2 && fileTarget == FTI_Topo -> myRank ) { snprintf ( tmpfn , FTI_BUFS , "%s/%s" , FTI_Ckpt [ 2 ] . dir , entry -> d_name ) ; if ( stat ( tmpfn , & ckptFS ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Problem<S2SV_blank>with<S2SV_blank>stats<S2SV_blank>on<S2SV_blank>file<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( S_ISREG ( ckptFS . st_mode ) == 0 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>%s<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>regular<S2SV_blank>file" , tmpfn ) ; FTI_Print ( strerr , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( ckptFS . st_size > sizeof ( FTIFF_metaInfo ) ) { int fd = open ( tmpfn , O_RDONLY ) ; if ( fd == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>open<S2SV_blank>\'%s\'<S2SV_blank>for<S2SV_blank>reading." , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( lseek ( fd , 0 , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; close ( fd ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } if ( read ( fd , FTIFFMeta , sizeof ( FTIFF_metaInfo ) ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>request<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>from:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; FTIFF_GetHashMetaInfo ( hash , FTIFFMeta ) ; if ( memcmp ( FTIFFMeta -> myHash , hash , MD5_DIGEST_LENGTH ) == 0 ) { long rcount = sizeof ( FTIFF_metaInfo ) , toRead , diff ; int rbuffer ; char buffer [ CHUNK_SIZE ] ; MD5_Init ( & mdContext ) ; while ( rcount < FTIFFMeta -> fs ) { if ( lseek ( fd , rcount , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } diff = FTIFFMeta -> fs - rcount ; toRead = ( diff < CHUNK_SIZE ) ? diff : CHUNK_SIZE ; rbuffer = read ( fd , buffer , toRead ) ; if ( rbuffer == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>file:<S2SV_blank>%s" , toRead , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } rcount += rbuffer ; MD5_Update ( & mdContext , buffer , rbuffer ) ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; MD5_Final ( hash , & mdContext ) ; int i ; char checksum [ MD5_DIGEST_STRING_LENGTH ] ; int ii = 0 ; for ( i = 0 ; i < MD5_DIGEST_LENGTH ; i ++ ) { sprintf ( & checksum [ ii ] , "%02x" , hash [ i ] ) ; ii += 2 ; } if ( strcmp ( checksum , FTIFFMeta -> checksum ) == 0 ) { myMetaInfo -> fs = FTIFFMeta -> fs ; myMetaInfo -> ckptID = ckptID ; myMetaInfo -> FileExists = 1 ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Checksum<S2SV_blank>do<S2SV_blank>not<S2SV_blank>match.<S2SV_blank>\\"%s\\"<S2SV_blank>file<S2SV_blank>is<S2SV_blank>corrupted.<S2SV_blank>%s<S2SV_blank>!=<S2SV_blank>%s" , entry -> d_name , checksum , FTIFFMeta -> checksum ) ; FTI_Print ( str , FTI_WARN ) ; close ( fd ) ; goto GATHER_INFO ; } } close ( fd ) ; } } else { ckptID = tmpCkptID ; } tmpCkptID = ckptID ; match = sscanf ( entry -> d_name , "Ckpt%d-Pcof%d.fti" , & ckptID , & fileTarget ) ; if ( match == 2 && fileTarget == FTI_Topo -> myRank ) { snprintf ( tmpfn , FTI_BUFS , "%s/%s" , FTI_Ckpt [ 2 ] . dir , entry -> d_name ) ; if ( stat ( tmpfn , & ckptFS ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Problem<S2SV_blank>with<S2SV_blank>stats<S2SV_blank>on<S2SV_blank>file<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( S_ISREG ( ckptFS . st_mode ) == 0 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>%s<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>regular<S2SV_blank>file" , tmpfn ) ; FTI_Print ( strerr , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( ckptFS . st_size > sizeof ( FTIFF_metaInfo ) ) { int fd = open ( tmpfn , O_RDONLY ) ; if ( fd == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>open<S2SV_blank>\'%s\'<S2SV_blank>for<S2SV_blank>reading." , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( lseek ( fd , 0 , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; close ( fd ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } if ( read ( fd , FTIFFMeta , sizeof ( FTIFF_metaInfo ) ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>request<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>from:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; FTIFF_GetHashMetaInfo ( hash , FTIFFMeta ) ; if ( memcmp ( FTIFFMeta -> myHash , hash , MD5_DIGEST_LENGTH ) == 0 ) { long rcount = sizeof ( FTIFF_metaInfo ) , toRead , diff ; int rbuffer ; char buffer [ CHUNK_SIZE ] ; MD5_Init ( & mdContext ) ; while ( rcount < FTIFFMeta -> fs ) { if ( lseek ( fd , rcount , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } diff = FTIFFMeta -> fs - rcount ; toRead = ( diff < CHUNK_SIZE ) ? diff : CHUNK_SIZE ; rbuffer = read ( fd , buffer , toRead ) ; if ( rbuffer == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>file:<S2SV_blank>%s" , toRead , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } rcount += rbuffer ; MD5_Update ( & mdContext , buffer , rbuffer ) ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; MD5_Final ( hash , & mdContext ) ; int i ; char checksum [ MD5_DIGEST_STRING_LENGTH ] ; int ii = 0 ; for ( i = 0 ; i < MD5_DIGEST_LENGTH ; i ++ ) { sprintf ( & checksum [ ii ] , "%02x" , hash [ i ] ) ; ii += 2 ; } if ( strcmp ( checksum , FTIFFMeta -> checksum ) == 0 ) { myMetaInfo -> pfs = FTIFFMeta -> fs ; myMetaInfo -> ckptID = ckptID ; myMetaInfo -> CopyExists = 1 ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Checksum<S2SV_blank>do<S2SV_blank>not<S2SV_blank>match.<S2SV_blank>\\"%s\\"<S2SV_blank>file<S2SV_blank>is<S2SV_blank>corrupted.<S2SV_blank>%s<S2SV_blank>!=<S2SV_blank>%s" , entry -> d_name , checksum , FTIFFMeta -> checksum ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } } close ( fd ) ; } } else { ckptID = tmpCkptID ; } } if ( myMetaInfo -> FileExists && myMetaInfo -> CopyExists ) { break ; } } closedir ( L2CkptDir ) ; } GATHER_INFO : if ( ! ( myMetaInfo -> FileExists ) && ! ( myMetaInfo -> CopyExists ) ) { myMetaInfo -> ckptID = - 1 ; } MPI_Allgather ( myMetaInfo , 1 , FTIFF_MpiTypes [ FTIFF_L2_INFO ] , appProcsMetaInfo , 1 , FTIFF_MpiTypes [ FTIFF_L2_INFO ] , FTI_COMM_WORLD ) ; exists [ LEFT_FILE ] = appProcsMetaInfo [ leftIdx ] . FileExists ; exists [ MY_FILE ] = appProcsMetaInfo [ FTI_Topo -> splitRank ] . FileExists ; exists [ MY_COPY ] = appProcsMetaInfo [ rightIdx ] . CopyExists ; exists [ LEFT_COPY ] = appProcsMetaInfo [ FTI_Topo -> splitRank ] . CopyExists ; snprintf ( dbgstr , FTI_BUFS , "FTI-FF<S2SV_blank>-<S2SV_blank>L2Recovery::FileCheck<S2SV_blank>-<S2SV_blank>CkptFile:<S2SV_blank>%i,<S2SV_blank>CkptCopy:<S2SV_blank>%i" , myMetaInfo -> FileExists , myMetaInfo -> CopyExists ) ; FTI_Print ( dbgstr , FTI_DBUG ) ; int i , saneCkptID = 0 ; ckptID = 0 ; for ( i = 0 ; i < appCommSize ; i ++ ) { fcount += ( appProcsMetaInfo [ i ] . FileExists || appProcsMetaInfo [ appProcsMetaInfo [ i ] . rightIdx ] . CopyExists ) ? 1 : 0 ; if ( appProcsMetaInfo [ i ] . ckptID > 0 ) { saneCkptID ++ ; ckptID += appProcsMetaInfo [ i ] . ckptID ; } } int res = ( fcount == fneeded ) ? FTI_SCES : FTI_NSCS ; if ( res == FTI_SCES ) { FTI_Exec -> ckptID = ckptID / saneCkptID ; if ( myMetaInfo -> FileExists ) { FTI_Exec -> meta [ 2 ] . fs [ 0 ] = myMetaInfo -> fs ; } else { FTI_Exec -> meta [ 2 ] . fs [ 0 ] = appProcsMetaInfo [ rightIdx ] . pfs ; } if ( myMetaInfo -> CopyExists ) { FTI_Exec -> meta [ 2 ] . pfs [ 0 ] = myMetaInfo -> pfs ; } else { FTI_Exec -> meta [ 2 ] . pfs [ 0 ] = appProcsMetaInfo [ leftIdx ] . fs ; } } snprintf ( dbgstr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2-Recovery<S2SV_blank>-<S2SV_blank>rank:<S2SV_blank>%i,<S2SV_blank>left:<S2SV_blank>%i,<S2SV_blank>right:<S2SV_blank>%i,<S2SV_blank>fs:<S2SV_blank>%ld,<S2SV_blank>pfs:<S2SV_blank>%ld,<S2SV_blank>ckptID:<S2SV_blank>%i" , FTI_Topo -> myRank , leftIdx , rightIdx , FTI_Exec -> meta [ 2 ] . fs [ 0 ] , FTI_Exec -> meta [ 2 ] . pfs [ 0 ] , FTI_Exec -> ckptID ) ; FTI_Print ( dbgstr , FTI_DBUG ) ; snprintf ( FTI_Exec -> meta [ 2 ] . ckptFile , FTI_BUFS , "Ckpt%d-Rank%d.fti" , FTI_Exec -> ckptID , FTI_Topo -> myRank ) ; return res ; }
static long binder_ioctl ( struct file * filp , unsigned int cmd , unsigned long arg ) { int ret ; struct binder_proc * proc = filp -> private_data ; struct binder_thread * thread ; unsigned int size = _IOC_SIZE ( cmd ) ; void __user * ubuf = ( void __user * ) arg ; trace_binder_ioctl ( cmd , arg ) ; ret = wait_event_interruptible ( binder_user_error_wait , binder_stop_on_user_error < 2 ) ; if ( ret ) goto err_unlocked ; binder_lock ( __func__ ) ; thread = binder_get_thread ( proc ) ; if ( thread == NULL ) { ret = - ENOMEM ; goto err ; } switch ( cmd ) { case BINDER_WRITE_READ : { struct binder_write_read bwr ; if ( size != sizeof ( struct binder_write_read ) ) { ret = - EINVAL ; goto err ; } if ( copy_from_user ( & bwr , ubuf , sizeof ( bwr ) ) ) { ret = - EFAULT ; goto err ; } binder_debug ( BINDER_DEBUG_READ_WRITE , "%d:%d<S2SV_blank>write<S2SV_blank>%zd<S2SV_blank>at<S2SV_blank>%08lx,<S2SV_blank>read<S2SV_blank>%zd<S2SV_blank>at<S2SV_blank>%08lx\\n" , proc -> pid , thread -> pid , bwr . write_size , bwr . write_buffer , bwr . read_size , bwr . read_buffer ) ; if ( bwr . write_size > 0 ) { ret = binder_thread_write ( proc , thread , ( void __user * ) bwr . write_buffer , bwr . write_size , & bwr . write_consumed ) ; trace_binder_write_done ( ret ) ; if ( ret < 0 ) { bwr . read_consumed = 0 ; if ( copy_to_user ( ubuf , & bwr , sizeof ( bwr ) ) ) ret = - EFAULT ; goto err ; } } if ( bwr . read_size > 0 ) { ret = binder_thread_read ( proc , thread , ( void __user * ) bwr . read_buffer , bwr . read_size , & bwr . read_consumed , filp -> f_flags & O_NONBLOCK ) ; trace_binder_read_done ( ret ) ; if ( ! list_empty ( & proc -> todo ) ) wake_up_interruptible ( & proc -> wait ) ; if ( ret < 0 ) { if ( copy_to_user ( ubuf , & bwr , sizeof ( bwr ) ) ) ret = - EFAULT ; goto err ; } } binder_debug ( BINDER_DEBUG_READ_WRITE , "%d:%d<S2SV_blank>wrote<S2SV_blank>%zd<S2SV_blank>of<S2SV_blank>%zd,<S2SV_blank>read<S2SV_blank>return<S2SV_blank>%zd<S2SV_blank>of<S2SV_blank>%zd\\n" , proc -> pid , thread -> pid , bwr . write_consumed , bwr . write_size , bwr . read_consumed , bwr . read_size ) ; if ( copy_to_user ( ubuf , & bwr , sizeof ( bwr ) ) ) { ret = - EFAULT ; goto err ; } break ; } case BINDER_SET_MAX_THREADS : if ( copy_from_user ( & proc -> max_threads , ubuf , sizeof ( proc -> max_threads ) ) ) { ret = - EINVAL ; goto err ; } break ; case BINDER_SET_CONTEXT_MGR : if ( binder_context_mgr_node != NULL ) { pr_err ( "BINDER_SET_CONTEXT_MGR<S2SV_blank>already<S2SV_blank>set\\n" ) ; ret = - EBUSY ; goto err ; } ret = security_binder_set_context_mgr ( proc -> tsk ) ; if ( ret < 0 ) goto err ; if ( binder_context_mgr_uid != - 1 ) { if ( binder_context_mgr_uid != current -> cred -> euid ) { pr_err ( "binder:<S2SV_blank>BINDER_SET_CONTEXT_MGR<S2SV_blank>bad<S2SV_blank>uid<S2SV_blank>%d<S2SV_blank>!=<S2SV_blank>%d\\n" , current -> cred -> euid , binder_context_mgr_uid ) ; ret = - EPERM ; goto err ; } } else binder_context_mgr_uid = current -> cred -> euid ; binder_context_mgr_node = binder_new_node ( proc , NULL , NULL ) ; if ( binder_context_mgr_node == NULL ) { ret = - ENOMEM ; goto err ; } binder_context_mgr_node -> local_weak_refs ++ ; binder_context_mgr_node -> local_strong_refs ++ ; binder_context_mgr_node -> has_strong_ref = 1 ; binder_context_mgr_node -> has_weak_ref = 1 ; break ; case BINDER_THREAD_EXIT : binder_debug ( BINDER_DEBUG_THREADS , "%d:%d<S2SV_blank>exit\\n" , proc -> pid , thread -> pid ) ; binder_free_thread ( proc , thread ) ; thread = NULL ; break ; case BINDER_VERSION : if ( size != sizeof ( struct binder_version ) ) { ret = - EINVAL ; goto err ; } if ( put_user ( BINDER_CURRENT_PROTOCOL_VERSION , & ( ( struct binder_version * ) ubuf ) -> protocol_version ) ) { ret = - EINVAL ; goto err ; } break ; default : ret = - EINVAL ; goto err ; } ret = 0 ; err : if ( thread ) thread -> looper &= ~ BINDER_LOOPER_STATE_NEED_RETURN ; binder_unlock ( __func__ ) ; wait_event_interruptible ( binder_user_error_wait , binder_stop_on_user_error < 2 ) ; if ( ret && ret != - ERESTARTSYS ) pr_info ( "%d:%d<S2SV_blank>ioctl<S2SV_blank>%x<S2SV_blank>%lx<S2SV_blank>returned<S2SV_blank>%d\\n" , proc -> pid , current -> pid , cmd , arg , ret ) ; err_unlocked : trace_binder_ioctl_done ( ret ) ; return ret ; }
static void binder_transaction ( struct binder_proc * proc , struct binder_thread * thread , struct binder_transaction_data * tr , int reply ) { struct binder_transaction * t ; struct binder_work * tcomplete ; size_t * offp , * off_end ; struct binder_proc * target_proc ; struct binder_thread * target_thread = NULL ; struct binder_node * target_node = NULL ; struct list_head * target_list ; wait_queue_head_t * target_wait ; struct binder_transaction * in_reply_to = NULL ; struct binder_transaction_log_entry * e ; uint32_t return_error ; e = binder_transaction_log_add ( & binder_transaction_log ) ; e -> call_type = reply ? 2 : ! ! ( tr -> flags & TF_ONE_WAY ) ; e -> from_proc = proc -> pid ; e -> from_thread = thread -> pid ; e -> target_handle = tr -> target . handle ; e -> data_size = tr -> data_size ; e -> offsets_size = tr -> offsets_size ; if ( reply ) { in_reply_to = thread -> transaction_stack ; if ( in_reply_to == NULL ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>reply<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>no<S2SV_blank>transaction<S2SV_blank>stack\\n" , proc -> pid , thread -> pid ) ; return_error = BR_FAILED_REPLY ; goto err_empty_call_stack ; } binder_set_nice ( in_reply_to -> saved_priority ) ; if ( in_reply_to -> to_thread != thread ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>reply<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>bad<S2SV_blank>transaction<S2SV_blank>stack,<S2SV_blank>transaction<S2SV_blank>%d<S2SV_blank>has<S2SV_blank>target<S2SV_blank>%d:%d\\n" , proc -> pid , thread -> pid , in_reply_to -> debug_id , in_reply_to -> to_proc ? in_reply_to -> to_proc -> pid : 0 , in_reply_to -> to_thread ? in_reply_to -> to_thread -> pid : 0 ) ; return_error = BR_FAILED_REPLY ; in_reply_to = NULL ; goto err_bad_call_stack ; } thread -> transaction_stack = in_reply_to -> to_parent ; target_thread = in_reply_to -> from ; if ( target_thread == NULL ) { return_error = BR_DEAD_REPLY ; goto err_dead_binder ; } if ( target_thread -> transaction_stack != in_reply_to ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>reply<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>bad<S2SV_blank>target<S2SV_blank>transaction<S2SV_blank>stack<S2SV_blank>%d,<S2SV_blank>expected<S2SV_blank>%d\\n" , proc -> pid , thread -> pid , target_thread -> transaction_stack ? target_thread -> transaction_stack -> debug_id : 0 , in_reply_to -> debug_id ) ; return_error = BR_FAILED_REPLY ; in_reply_to = NULL ; target_thread = NULL ; goto err_dead_binder ; } target_proc = target_thread -> proc ; } else { if ( tr -> target . handle ) { struct binder_ref * ref ; ref = binder_get_ref ( proc , tr -> target . handle , true ) ; if ( ref == NULL ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>to<S2SV_blank>invalid<S2SV_blank>handle\\n" , proc -> pid , thread -> pid ) ; return_error = BR_FAILED_REPLY ; goto err_invalid_target_handle ; } target_node = ref -> node ; } else { target_node = binder_context_mgr_node ; if ( target_node == NULL ) { return_error = BR_DEAD_REPLY ; goto err_no_context_mgr_node ; } } e -> to_node = target_node -> debug_id ; target_proc = target_node -> proc ; if ( target_proc == NULL ) { return_error = BR_DEAD_REPLY ; goto err_dead_binder ; } if ( security_binder_transaction ( proc -> tsk , target_proc -> tsk ) < 0 ) { return_error = BR_FAILED_REPLY ; goto err_invalid_target_handle ; } if ( ! ( tr -> flags & TF_ONE_WAY ) && thread -> transaction_stack ) { struct binder_transaction * tmp ; tmp = thread -> transaction_stack ; if ( tmp -> to_thread != thread ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>new<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>bad<S2SV_blank>transaction<S2SV_blank>stack,<S2SV_blank>transaction<S2SV_blank>%d<S2SV_blank>has<S2SV_blank>target<S2SV_blank>%d:%d\\n" , proc -> pid , thread -> pid , tmp -> debug_id , tmp -> to_proc ? tmp -> to_proc -> pid : 0 , tmp -> to_thread ? tmp -> to_thread -> pid : 0 ) ; return_error = BR_FAILED_REPLY ; goto err_bad_call_stack ; } while ( tmp ) { if ( tmp -> from && tmp -> from -> proc == target_proc ) target_thread = tmp -> from ; tmp = tmp -> from_parent ; } } } if ( target_thread ) { e -> to_thread = target_thread -> pid ; target_list = & target_thread -> todo ; target_wait = & target_thread -> wait ; } else { target_list = & target_proc -> todo ; target_wait = & target_proc -> wait ; } e -> to_proc = target_proc -> pid ; t = kzalloc ( sizeof ( * t ) , GFP_KERNEL ) ; if ( t == NULL ) { return_error = BR_FAILED_REPLY ; goto err_alloc_t_failed ; } binder_stats_created ( BINDER_STAT_TRANSACTION ) ; tcomplete = kzalloc ( sizeof ( * tcomplete ) , GFP_KERNEL ) ; if ( tcomplete == NULL ) { return_error = BR_FAILED_REPLY ; goto err_alloc_tcomplete_failed ; } binder_stats_created ( BINDER_STAT_TRANSACTION_COMPLETE ) ; t -> debug_id = ++ binder_last_id ; e -> debug_id = t -> debug_id ; if ( reply ) binder_debug ( BINDER_DEBUG_TRANSACTION , "%d:%d<S2SV_blank>BC_REPLY<S2SV_blank>%d<S2SV_blank>-><S2SV_blank>%d:%d,<S2SV_blank>data<S2SV_blank>%p-%p<S2SV_blank>size<S2SV_blank>%zd-%zd\\n" , proc -> pid , thread -> pid , t -> debug_id , target_proc -> pid , target_thread -> pid , tr -> data . ptr . buffer , tr -> data . ptr . offsets , tr -> data_size , tr -> offsets_size ) ; else binder_debug ( BINDER_DEBUG_TRANSACTION , "%d:%d<S2SV_blank>BC_TRANSACTION<S2SV_blank>%d<S2SV_blank>-><S2SV_blank>%d<S2SV_blank>-<S2SV_blank>node<S2SV_blank>%d,<S2SV_blank>data<S2SV_blank>%p-%p<S2SV_blank>size<S2SV_blank>%zd-%zd\\n" , proc -> pid , thread -> pid , t -> debug_id , target_proc -> pid , target_node -> debug_id , tr -> data . ptr . buffer , tr -> data . ptr . offsets , tr -> data_size , tr -> offsets_size ) ; if ( ! reply && ! ( tr -> flags & TF_ONE_WAY ) ) t -> from = thread ; else t -> from = NULL ; t -> sender_euid = proc -> tsk -> cred -> euid ; t -> to_proc = target_proc ; t -> to_thread = target_thread ; t -> code = tr -> code ; t -> flags = tr -> flags ; t -> priority = task_nice ( current ) ; trace_binder_transaction ( reply , t , target_node ) ; t -> buffer = binder_alloc_buf ( target_proc , tr -> data_size , tr -> offsets_size , ! reply && ( t -> flags & TF_ONE_WAY ) ) ; if ( t -> buffer == NULL ) { return_error = BR_FAILED_REPLY ; goto err_binder_alloc_buf_failed ; } t -> buffer -> allow_user_free = 0 ; t -> buffer -> debug_id = t -> debug_id ; t -> buffer -> transaction = t ; t -> buffer -> target_node = target_node ; trace_binder_transaction_alloc_buf ( t -> buffer ) ; if ( target_node ) binder_inc_node ( target_node , 1 , 0 , NULL ) ; offp = ( size_t * ) ( t -> buffer -> data + ALIGN ( tr -> data_size , sizeof ( void * ) ) ) ; if ( copy_from_user ( t -> buffer -> data , tr -> data . ptr . buffer , tr -> data_size ) ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>data<S2SV_blank>ptr\\n" , proc -> pid , thread -> pid ) ; return_error = BR_FAILED_REPLY ; goto err_copy_data_failed ; } if ( copy_from_user ( offp , tr -> data . ptr . offsets , tr -> offsets_size ) ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>offsets<S2SV_blank>ptr\\n" , proc -> pid , thread -> pid ) ; return_error = BR_FAILED_REPLY ; goto err_copy_data_failed ; } if ( ! IS_ALIGNED ( tr -> offsets_size , sizeof ( size_t ) ) ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>offsets<S2SV_blank>size,<S2SV_blank>%zd\\n" , proc -> pid , thread -> pid , tr -> offsets_size ) ; return_error = BR_FAILED_REPLY ; goto err_bad_offset ; } off_end = ( void * ) offp + tr -> offsets_size ; for ( ; offp < off_end ; offp ++ ) { struct flat_binder_object * fp ; if ( * offp > t -> buffer -> data_size - sizeof ( * fp ) || t -> buffer -> data_size < sizeof ( * fp ) || ! IS_ALIGNED ( * offp , sizeof ( u32 ) ) ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>offset,<S2SV_blank>%zd\\n" , proc -> pid , thread -> pid , * offp ) ; return_error = BR_FAILED_REPLY ; goto err_bad_offset ; } fp = ( struct flat_binder_object * ) ( t -> buffer -> data + * offp ) ; switch ( fp -> type ) { case BINDER_TYPE_BINDER : case BINDER_TYPE_WEAK_BINDER : { struct binder_ref * ref ; struct binder_node * node = binder_get_node ( proc , fp -> binder ) ; if ( node == NULL ) { node = binder_new_node ( proc , fp -> binder , fp -> cookie ) ; if ( node == NULL ) { return_error = BR_FAILED_REPLY ; goto err_binder_new_node_failed ; } node -> min_priority = fp -> flags & FLAT_BINDER_FLAG_PRIORITY_MASK ; node -> accept_fds = ! ! ( fp -> flags & FLAT_BINDER_FLAG_ACCEPTS_FDS ) ; } if ( fp -> cookie != node -> cookie ) { binder_user_error ( "%d:%d<S2SV_blank>sending<S2SV_blank>u%p<S2SV_blank>node<S2SV_blank>%d,<S2SV_blank>cookie<S2SV_blank>mismatch<S2SV_blank>%p<S2SV_blank>!=<S2SV_blank>%p\\n" , proc -> pid , thread -> pid , fp -> binder , node -> debug_id , fp -> cookie , node -> cookie ) ; goto err_binder_get_ref_for_node_failed ; } if ( security_binder_transfer_binder ( proc -> tsk , target_proc -> tsk ) ) { return_error = BR_FAILED_REPLY ; goto err_binder_get_ref_for_node_failed ; } ref = binder_get_ref_for_node ( target_proc , node ) ; if ( ref == NULL ) { return_error = BR_FAILED_REPLY ; goto err_binder_get_ref_for_node_failed ; } if ( fp -> type == BINDER_TYPE_BINDER ) fp -> type = BINDER_TYPE_HANDLE ; else fp -> type = BINDER_TYPE_WEAK_HANDLE ; fp -> handle = ref -> desc ; binder_inc_ref ( ref , fp -> type == BINDER_TYPE_HANDLE , & thread -> todo ) ; trace_binder_transaction_node_to_ref ( t , node , ref ) ; binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>node<S2SV_blank>%d<S2SV_blank>u%p<S2SV_blank>-><S2SV_blank>ref<S2SV_blank>%d<S2SV_blank>desc<S2SV_blank>%d\\n" , node -> debug_id , node -> ptr , ref -> debug_id , ref -> desc ) ; } break ; case BINDER_TYPE_HANDLE : case BINDER_TYPE_WEAK_HANDLE : { struct binder_ref * ref = binder_get_ref ( proc , fp -> handle , fp -> type == BINDER_TYPE_HANDLE ) ; if ( ref == NULL ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>handle,<S2SV_blank>%ld\\n" , proc -> pid , thread -> pid , fp -> handle ) ; return_error = BR_FAILED_REPLY ; goto err_binder_get_ref_failed ; } if ( security_binder_transfer_binder ( proc -> tsk , target_proc -> tsk ) ) { return_error = BR_FAILED_REPLY ; goto err_binder_get_ref_failed ; } if ( ref -> node -> proc == target_proc ) { if ( fp -> type == BINDER_TYPE_HANDLE ) fp -> type = BINDER_TYPE_BINDER ; else fp -> type = BINDER_TYPE_WEAK_BINDER ; fp -> binder = ref -> node -> ptr ; fp -> cookie = ref -> node -> cookie ; binder_inc_node ( ref -> node , fp -> type == BINDER_TYPE_BINDER , 0 , NULL ) ; trace_binder_transaction_ref_to_node ( t , ref ) ; binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>ref<S2SV_blank>%d<S2SV_blank>desc<S2SV_blank>%d<S2SV_blank>-><S2SV_blank>node<S2SV_blank>%d<S2SV_blank>u%p\\n" , ref -> debug_id , ref -> desc , ref -> node -> debug_id , ref -> node -> ptr ) ; } else { struct binder_ref * new_ref ; new_ref = binder_get_ref_for_node ( target_proc , ref -> node ) ; if ( new_ref == NULL ) { return_error = BR_FAILED_REPLY ; goto err_binder_get_ref_for_node_failed ; } fp -> handle = new_ref -> desc ; binder_inc_ref ( new_ref , fp -> type == BINDER_TYPE_HANDLE , NULL ) ; trace_binder_transaction_ref_to_ref ( t , ref , new_ref ) ; binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>ref<S2SV_blank>%d<S2SV_blank>desc<S2SV_blank>%d<S2SV_blank>-><S2SV_blank>ref<S2SV_blank>%d<S2SV_blank>desc<S2SV_blank>%d<S2SV_blank>(node<S2SV_blank>%d)\\n" , ref -> debug_id , ref -> desc , new_ref -> debug_id , new_ref -> desc , ref -> node -> debug_id ) ; } } break ; case BINDER_TYPE_FD : { int target_fd ; struct file * file ; if ( reply ) { if ( ! ( in_reply_to -> flags & TF_ACCEPT_FDS ) ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>reply<S2SV_blank>with<S2SV_blank>fd,<S2SV_blank>%ld,<S2SV_blank>but<S2SV_blank>target<S2SV_blank>does<S2SV_blank>not<S2SV_blank>allow<S2SV_blank>fds\\n" , proc -> pid , thread -> pid , fp -> handle ) ; return_error = BR_FAILED_REPLY ; goto err_fd_not_allowed ; } } else if ( ! target_node -> accept_fds ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>fd,<S2SV_blank>%ld,<S2SV_blank>but<S2SV_blank>target<S2SV_blank>does<S2SV_blank>not<S2SV_blank>allow<S2SV_blank>fds\\n" , proc -> pid , thread -> pid , fp -> handle ) ; return_error = BR_FAILED_REPLY ; goto err_fd_not_allowed ; } file = fget ( fp -> handle ) ; if ( file == NULL ) { binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>fd,<S2SV_blank>%ld\\n" , proc -> pid , thread -> pid , fp -> handle ) ; return_error = BR_FAILED_REPLY ; goto err_fget_failed ; } if ( security_binder_transfer_file ( proc -> tsk , target_proc -> tsk , file ) < 0 ) { fput ( file ) ; return_error = BR_FAILED_REPLY ; goto err_get_unused_fd_failed ; } target_fd = task_get_unused_fd_flags ( target_proc , O_CLOEXEC ) ; if ( target_fd < 0 ) { fput ( file ) ; return_error = BR_FAILED_REPLY ; goto err_get_unused_fd_failed ; } task_fd_install ( target_proc , target_fd , file ) ; trace_binder_transaction_fd ( t , fp -> handle , target_fd ) ; binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>fd<S2SV_blank>%ld<S2SV_blank>-><S2SV_blank>%d\\n" , fp -> handle , target_fd ) ; fp -> handle = target_fd ; } break ; default : binder_user_error ( "%d:%d<S2SV_blank>got<S2SV_blank>transaction<S2SV_blank>with<S2SV_blank>invalid<S2SV_blank>object<S2SV_blank>type,<S2SV_blank>%lx\\n" , proc -> pid , thread -> pid , fp -> type ) ; return_error = BR_FAILED_REPLY ; goto err_bad_object_type ; } } if ( reply ) { BUG_ON ( t -> buffer -> async_transaction != 0 ) ; binder_pop_transaction ( target_thread , in_reply_to ) ; } else if ( ! ( t -> flags & TF_ONE_WAY ) ) { BUG_ON ( t -> buffer -> async_transaction != 0 ) ; t -> need_reply = 1 ; t -> from_parent = thread -> transaction_stack ; thread -> transaction_stack = t ; } else { BUG_ON ( target_node == NULL ) ; BUG_ON ( t -> buffer -> async_transaction != 1 ) ; if ( target_node -> has_async_transaction ) { target_list = & target_node -> async_todo ; target_wait = NULL ; } else target_node -> has_async_transaction = 1 ; } t -> work . type = BINDER_WORK_TRANSACTION ; list_add_tail ( & t -> work . entry , target_list ) ; tcomplete -> type = BINDER_WORK_TRANSACTION_COMPLETE ; list_add_tail ( & tcomplete -> entry , & thread -> todo ) ; if ( target_wait ) wake_up_interruptible ( target_wait ) ; return ; err_get_unused_fd_failed : err_fget_failed : err_fd_not_allowed : err_binder_get_ref_for_node_failed : err_binder_get_ref_failed : err_binder_new_node_failed : err_bad_object_type : err_bad_offset : err_copy_data_failed : trace_binder_transaction_failed_buffer_release ( t -> buffer ) ; binder_transaction_buffer_release ( target_proc , t -> buffer , offp ) ; t -> buffer -> transaction = NULL ; binder_free_buf ( target_proc , t -> buffer ) ; err_binder_alloc_buf_failed : kfree ( tcomplete ) ; binder_stats_deleted ( BINDER_STAT_TRANSACTION_COMPLETE ) ; err_alloc_tcomplete_failed : kfree ( t ) ; binder_stats_deleted ( BINDER_STAT_TRANSACTION ) ; err_alloc_t_failed : err_bad_call_stack : err_empty_call_stack : err_dead_binder : err_invalid_target_handle : err_no_context_mgr_node : binder_debug ( BINDER_DEBUG_FAILED_TRANSACTION , "%d:%d<S2SV_blank>transaction<S2SV_blank>failed<S2SV_blank>%d,<S2SV_blank>size<S2SV_blank>%zd-%zd\\n" , proc -> pid , thread -> pid , return_error , tr -> data_size , tr -> offsets_size ) ; { struct binder_transaction_log_entry * fe ; fe = binder_transaction_log_add ( & binder_transaction_log_failed ) ; * fe = * e ; } BUG_ON ( thread -> return_error != BR_OK ) ; if ( in_reply_to ) { thread -> return_error = BR_TRANSACTION_COMPLETE ; binder_send_failed_reply ( in_reply_to , return_error ) ; } else thread -> return_error = return_error ; }
static void binder_transaction_buffer_release ( struct binder_proc * proc , struct binder_buffer * buffer , size_t * failed_at ) { size_t * offp , * off_end ; int debug_id = buffer -> debug_id ; binder_debug ( BINDER_DEBUG_TRANSACTION , "%d<S2SV_blank>buffer<S2SV_blank>release<S2SV_blank>%d,<S2SV_blank>size<S2SV_blank>%zd-%zd,<S2SV_blank>failed<S2SV_blank>at<S2SV_blank>%p\\n" , proc -> pid , buffer -> debug_id , buffer -> data_size , buffer -> offsets_size , failed_at ) ; if ( buffer -> target_node ) binder_dec_node ( buffer -> target_node , 1 , 0 ) ; offp = ( size_t * ) ( buffer -> data + ALIGN ( buffer -> data_size , sizeof ( void * ) ) ) ; if ( failed_at ) off_end = failed_at ; else off_end = ( void * ) offp + buffer -> offsets_size ; for ( ; offp < off_end ; offp ++ ) { struct flat_binder_object * fp ; if ( * offp > buffer -> data_size - sizeof ( * fp ) || buffer -> data_size < sizeof ( * fp ) || ! IS_ALIGNED ( * offp , sizeof ( u32 ) ) ) { pr_err ( "transaction<S2SV_blank>release<S2SV_blank>%d<S2SV_blank>bad<S2SV_blank>offset<S2SV_blank>%zd,<S2SV_blank>size<S2SV_blank>%zd\\n" , debug_id , * offp , buffer -> data_size ) ; continue ; } fp = ( struct flat_binder_object * ) ( buffer -> data + * offp ) ; switch ( fp -> type ) { case BINDER_TYPE_BINDER : case BINDER_TYPE_WEAK_BINDER : { struct binder_node * node = binder_get_node ( proc , fp -> binder ) ; if ( node == NULL ) { pr_err ( "transaction<S2SV_blank>release<S2SV_blank>%d<S2SV_blank>bad<S2SV_blank>node<S2SV_blank>%p\\n" , debug_id , fp -> binder ) ; break ; } binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>node<S2SV_blank>%d<S2SV_blank>u%p\\n" , node -> debug_id , node -> ptr ) ; binder_dec_node ( node , fp -> type == BINDER_TYPE_BINDER , 0 ) ; } break ; case BINDER_TYPE_HANDLE : case BINDER_TYPE_WEAK_HANDLE : { struct binder_ref * ref = binder_get_ref ( proc , fp -> handle , fp -> type == BINDER_TYPE_HANDLE ) ; if ( ref == NULL ) { pr_err ( "transaction<S2SV_blank>release<S2SV_blank>%d<S2SV_blank>bad<S2SV_blank>handle<S2SV_blank>%ld\\n" , debug_id , fp -> handle ) ; break ; } binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>ref<S2SV_blank>%d<S2SV_blank>desc<S2SV_blank>%d<S2SV_blank>(node<S2SV_blank>%d)\\n" , ref -> debug_id , ref -> desc , ref -> node -> debug_id ) ; binder_dec_ref ( ref , fp -> type == BINDER_TYPE_HANDLE ) ; } break ; case BINDER_TYPE_FD : binder_debug ( BINDER_DEBUG_TRANSACTION , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>fd<S2SV_blank>%ld\\n" , fp -> handle ) ; if ( failed_at ) task_close_fd ( proc , fp -> handle ) ; break ; default : pr_err ( "transaction<S2SV_blank>release<S2SV_blank>%d<S2SV_blank>bad<S2SV_blank>object<S2SV_blank>type<S2SV_blank>%lx\\n" , debug_id , fp -> type ) ; break ; } } }
static int gfx_v7_0_compute_queue_init ( struct amdgpu_device * adev , int ring_id ) { int r ; u64 mqd_gpu_addr ; struct bonaire_mqd * mqd ; struct amdgpu_ring * ring = & adev -> gfx . compute_ring [ ring_id ] ; if ( ring -> mqd_obj == NULL ) { r = amdgpu_bo_create ( adev , sizeof ( struct bonaire_mqd ) , PAGE_SIZE , true , AMDGPU_GEM_DOMAIN_GTT , 0 , NULL , NULL , & ring -> mqd_obj ) ; if ( r ) { dev_warn ( adev -> dev , "(%d)<S2SV_blank>create<S2SV_blank>MQD<S2SV_blank>bo<S2SV_blank>failed\\n" , r ) ; return r ; } } r = amdgpu_bo_reserve ( ring -> mqd_obj , false ) ; if ( unlikely ( r != 0 ) ) goto out ; r = amdgpu_bo_pin ( ring -> mqd_obj , AMDGPU_GEM_DOMAIN_GTT , & mqd_gpu_addr ) ; if ( r ) { dev_warn ( adev -> dev , "(%d)<S2SV_blank>pin<S2SV_blank>MQD<S2SV_blank>bo<S2SV_blank>failed\\n" , r ) ; goto out_unreserve ; } r = amdgpu_bo_kmap ( ring -> mqd_obj , ( void * * ) & mqd ) ; if ( r ) { dev_warn ( adev -> dev , "(%d)<S2SV_blank>map<S2SV_blank>MQD<S2SV_blank>bo<S2SV_blank>failed\\n" , r ) ; goto out_unreserve ; } mutex_lock ( & adev -> srbm_mutex ) ; cik_srbm_select ( adev , ring -> me , ring -> pipe , ring -> queue , 0 ) ; gfx_v7_0_mqd_init ( adev , mqd , mqd_gpu_addr , ring ) ; gfx_v7_0_mqd_deactivate ( adev ) ; gfx_v7_0_mqd_commit ( adev , mqd ) ; cik_srbm_select ( adev , 0 , 0 , 0 , 0 ) ; mutex_unlock ( & adev -> srbm_mutex ) ; amdgpu_bo_kunmap ( ring -> mqd_obj ) ; out_unreserve : amdgpu_bo_unreserve ( ring -> mqd_obj ) ; out : return 0 ; }
static int gfx_v7_0_mqd_commit ( struct amdgpu_device * adev , struct bonaire_mqd * mqd ) { u32 tmp ; tmp = RREG32 ( mmCP_PQ_WPTR_POLL_CNTL ) ; tmp = REG_SET_FIELD ( tmp , CP_PQ_WPTR_POLL_CNTL , EN , 0 ) ; WREG32 ( mmCP_PQ_WPTR_POLL_CNTL , tmp ) ; WREG32 ( mmCP_MQD_BASE_ADDR , mqd -> queue_state . cp_mqd_base_addr ) ; WREG32 ( mmCP_MQD_BASE_ADDR_HI , mqd -> queue_state . cp_mqd_base_addr_hi ) ; WREG32 ( mmCP_MQD_CONTROL , mqd -> queue_state . cp_mqd_control ) ; WREG32 ( mmCP_HQD_PQ_BASE , mqd -> queue_state . cp_hqd_pq_base ) ; WREG32 ( mmCP_HQD_PQ_BASE_HI , mqd -> queue_state . cp_hqd_pq_base_hi ) ; WREG32 ( mmCP_HQD_PQ_CONTROL , mqd -> queue_state . cp_hqd_pq_control ) ; WREG32 ( mmCP_HQD_PQ_WPTR_POLL_ADDR , mqd -> queue_state . cp_hqd_pq_wptr_poll_addr ) ; WREG32 ( mmCP_HQD_PQ_WPTR_POLL_ADDR_HI , mqd -> queue_state . cp_hqd_pq_wptr_poll_addr_hi ) ; WREG32 ( mmCP_HQD_PQ_RPTR_REPORT_ADDR , mqd -> queue_state . cp_hqd_pq_rptr_report_addr ) ; WREG32 ( mmCP_HQD_PQ_RPTR_REPORT_ADDR_HI , mqd -> queue_state . cp_hqd_pq_rptr_report_addr_hi ) ; WREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL , mqd -> queue_state . cp_hqd_pq_doorbell_control ) ; WREG32 ( mmCP_HQD_PQ_WPTR , mqd -> queue_state . cp_hqd_pq_wptr ) ; WREG32 ( mmCP_HQD_VMID , mqd -> queue_state . cp_hqd_vmid ) ; WREG32 ( mmCP_HQD_ACTIVE , mqd -> queue_state . cp_hqd_active ) ; return 0 ; }
static void gfx_v7_0_mqd_init ( struct amdgpu_device * adev , struct bonaire_mqd * mqd , uint64_t mqd_gpu_addr , struct amdgpu_ring * ring ) { u64 hqd_gpu_addr ; u64 wb_gpu_addr ; memset ( mqd , 0 , sizeof ( struct bonaire_mqd ) ) ; mqd -> header = 0xC0310800 ; mqd -> static_thread_mgmt01 [ 0 ] = 0xffffffff ; mqd -> static_thread_mgmt01 [ 1 ] = 0xffffffff ; mqd -> static_thread_mgmt23 [ 0 ] = 0xffffffff ; mqd -> static_thread_mgmt23 [ 1 ] = 0xffffffff ; mqd -> queue_state . cp_hqd_pq_doorbell_control = RREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL ) ; if ( ring -> use_doorbell ) mqd -> queue_state . cp_hqd_pq_doorbell_control |= CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_EN_MASK ; else mqd -> queue_state . cp_hqd_pq_doorbell_control &= ~ CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_EN_MASK ; mqd -> queue_state . cp_mqd_base_addr = mqd_gpu_addr & 0xfffffffc ; mqd -> queue_state . cp_mqd_base_addr_hi = upper_32_bits ( mqd_gpu_addr ) ; mqd -> queue_state . cp_mqd_control = RREG32 ( mmCP_MQD_CONTROL ) ; mqd -> queue_state . cp_mqd_control &= ~ CP_MQD_CONTROL__VMID_MASK ; hqd_gpu_addr = ring -> gpu_addr >> 8 ; mqd -> queue_state . cp_hqd_pq_base = hqd_gpu_addr ; mqd -> queue_state . cp_hqd_pq_base_hi = upper_32_bits ( hqd_gpu_addr ) ; mqd -> queue_state . cp_hqd_pq_control = RREG32 ( mmCP_HQD_PQ_CONTROL ) ; mqd -> queue_state . cp_hqd_pq_control &= ~ ( CP_HQD_PQ_CONTROL__QUEUE_SIZE_MASK | CP_HQD_PQ_CONTROL__RPTR_BLOCK_SIZE_MASK ) ; mqd -> queue_state . cp_hqd_pq_control |= order_base_2 ( ring -> ring_size / 8 ) ; mqd -> queue_state . cp_hqd_pq_control |= ( order_base_2 ( AMDGPU_GPU_PAGE_SIZE / 8 ) << 8 ) ; # ifdef __BIG_ENDIAN mqd -> queue_state . cp_hqd_pq_control |= 2 << CP_HQD_PQ_CONTROL__ENDIAN_SWAP__SHIFT ; # endif mqd -> queue_state . cp_hqd_pq_control &= ~ ( CP_HQD_PQ_CONTROL__UNORD_DISPATCH_MASK | CP_HQD_PQ_CONTROL__ROQ_PQ_IB_FLIP_MASK | CP_HQD_PQ_CONTROL__PQ_VOLATILE_MASK ) ; mqd -> queue_state . cp_hqd_pq_control |= CP_HQD_PQ_CONTROL__PRIV_STATE_MASK | CP_HQD_PQ_CONTROL__KMD_QUEUE_MASK ; wb_gpu_addr = adev -> wb . gpu_addr + ( ring -> wptr_offs * 4 ) ; mqd -> queue_state . cp_hqd_pq_wptr_poll_addr = wb_gpu_addr & 0xfffffffc ; mqd -> queue_state . cp_hqd_pq_wptr_poll_addr_hi = upper_32_bits ( wb_gpu_addr ) & 0xffff ; wb_gpu_addr = adev -> wb . gpu_addr + ( ring -> rptr_offs * 4 ) ; mqd -> queue_state . cp_hqd_pq_rptr_report_addr = wb_gpu_addr & 0xfffffffc ; mqd -> queue_state . cp_hqd_pq_rptr_report_addr_hi = upper_32_bits ( wb_gpu_addr ) & 0xffff ; if ( ring -> use_doorbell ) { mqd -> queue_state . cp_hqd_pq_doorbell_control = RREG32 ( mmCP_HQD_PQ_DOORBELL_CONTROL ) ; mqd -> queue_state . cp_hqd_pq_doorbell_control &= ~ CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_OFFSET_MASK ; mqd -> queue_state . cp_hqd_pq_doorbell_control |= ( ring -> doorbell_index << CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_OFFSET__SHIFT ) ; mqd -> queue_state . cp_hqd_pq_doorbell_control |= CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_EN_MASK ; mqd -> queue_state . cp_hqd_pq_doorbell_control &= ~ ( CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_SOURCE_MASK | CP_HQD_PQ_DOORBELL_CONTROL__DOORBELL_HIT_MASK ) ; } else { mqd -> queue_state . cp_hqd_pq_doorbell_control = 0 ; } ring -> wptr = 0 ; mqd -> queue_state . cp_hqd_pq_wptr = lower_32_bits ( ring -> wptr ) ; mqd -> queue_state . cp_hqd_pq_rptr = RREG32 ( mmCP_HQD_PQ_RPTR ) ; mqd -> queue_state . cp_hqd_vmid = 0 ; mqd -> queue_state . cp_hqd_active = 1 ; }
void mlx4_qp_release_range ( struct mlx4_dev * dev , int base_qpn , int cnt ) { u64 in_param = 0 ; int err ; if ( mlx4_is_mfunc ( dev ) ) { set_param_l ( & in_param , base_qpn ) ; set_param_h ( & in_param , cnt ) ; err = mlx4_cmd ( dev , in_param , RES_QP , RES_OP_RESERVE , MLX4_CMD_FREE_RES , MLX4_CMD_TIME_CLASS_A , MLX4_CMD_WRAPPED ) ; if ( err ) { mlx4_warn ( dev , "Failed<S2SV_blank>to<S2SV_blank>release<S2SV_blank>qp<S2SV_blank>range<S2SV_blank>base:%d<S2SV_blank>cnt:%d\\n" , base_qpn , cnt ) ; } } else __mlx4_qp_release_range ( dev , base_qpn , cnt ) ; }
static inline int _is_in_region ( u32_t r_index , u32_t start , u32_t size ) { # if CONFIG_ARC_MPU_VER == 2 u32_t r_addr_start ; u32_t r_addr_end ; u32_t r_size_lshift ; r_addr_start = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift = ( r_size_lshift & 0x3 ) | ( ( r_size_lshift >> 7 ) & 0x1C ) ; r_addr_end = r_addr_start + ( 1 << ( r_size_lshift + 1 ) ) ; if ( start >= r_addr_start && ( start + size ) < r_addr_end ) { return 1 ; } # elif CONFIG_ARC_MPU_VER == 3 if ( ( r_index == _mpu_probe ( start ) ) && ( r_index == _mpu_probe ( start + size ) ) ) { return 1 ; } # endif return 0 ; }
static int safexcel_hw_setup_rdesc_rings ( struct safexcel_crypto_priv * priv ) { u32 hdw , rd_size_rnd , val ; int i ; hdw = readl ( EIP197_HIA_AIC_G ( priv ) + EIP197_HIA_OPTIONS ) ; hdw &= GENMASK ( 27 , 25 ) ; hdw >>= 25 ; rd_size_rnd = ( priv -> config . rd_size + ( BIT ( hdw ) - 1 ) ) >> hdw ; for ( i = 0 ; i < priv -> config . rings ; i ++ ) { writel ( lower_32_bits ( priv -> ring [ i ] . rdr . base_dma ) , EIP197_HIA_RDR ( priv , i ) + EIP197_HIA_xDR_RING_BASE_ADDR_LO ) ; writel ( upper_32_bits ( priv -> ring [ i ] . rdr . base_dma ) , EIP197_HIA_RDR ( priv , i ) + EIP197_HIA_xDR_RING_BASE_ADDR_HI ) ; writel ( EIP197_xDR_DESC_MODE_64BIT | ( priv -> config . rd_offset << 16 ) | priv -> config . rd_size , EIP197_HIA_RDR ( priv , i ) + EIP197_HIA_xDR_DESC_SIZE ) ; writel ( ( ( EIP197_FETCH_COUNT * ( rd_size_rnd << hdw ) ) << 16 ) | ( EIP197_FETCH_COUNT * priv -> config . rd_offset ) , EIP197_HIA_RDR ( priv , i ) + EIP197_HIA_xDR_CFG ) ; val = EIP197_HIA_xDR_CFG_WR_CACHE ( WR_CACHE_3BITS ) ; val |= EIP197_HIA_xDR_CFG_RD_CACHE ( RD_CACHE_3BITS ) ; val |= EIP197_HIA_xDR_WR_RES_BUF | EIP197_HIA_xDR_WR_CTRL_BUG ; writel ( val , EIP197_HIA_RDR ( priv , i ) + EIP197_HIA_xDR_DMA_CFG ) ; writel ( GENMASK ( 7 , 0 ) , EIP197_HIA_RDR ( priv , i ) + EIP197_HIA_xDR_STAT ) ; val = readl ( EIP197_HIA_AIC_R ( priv ) + EIP197_HIA_AIC_R_ENABLE_CTRL ( i ) ) ; val |= EIP197_RDR_IRQ ( i ) ; writel ( val , EIP197_HIA_AIC_R ( priv ) + EIP197_HIA_AIC_R_ENABLE_CTRL ( i ) ) ; } return 0 ; }
static inline int _is_in_region ( u32_t r_index , u32_t start , u32_t size ) { # if CONFIG_ARC_MPU_VER == 2 u32_t r_addr_start ; u32_t r_addr_end ; u32_t r_size_lshift ; r_addr_start = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift = ( r_size_lshift & 0x3 ) | ( ( r_size_lshift >> 7 ) & 0x1C ) ; r_addr_end = r_addr_start + ( 1 << ( r_size_lshift + 1 ) ) ; if ( start >= r_addr_start && ( start + size ) < r_addr_end ) { return 1 ; } # elif CONFIG_ARC_MPU_VER == 3 if ( ( r_index == _mpu_probe ( start ) ) && ( r_index == _mpu_probe ( start + size ) ) ) { return 1 ; } # endif return 0 ; }
int getpinfo ( struct pstat * pst ) { acquire ( & ptable . lock ) ; for ( int i = 0 ; i < NPROC ; ++ i ) { struct proc process = ptable . proc [ i ] ; pst -> inuse [ i ] = 1 ; pst -> tickets [ i ] = process . tickets ; pst -> pid [ i ] = process . pid ; pst -> ticks [ i ] = 0 ; } release ( & ptable . lock ) ; return 0 ; }
void mixed_summary ( FILE * fp_out ) { int64_t line_count = 0 ; int64_t i , j ; FILE * fp_mcmc ; db_stree_t * treelist ; snode_t * * inner ; fp_mcmc = xopen ( opt_mcmcfile , "r" ) ; inner = ( snode_t * * ) xmalloc ( ( size_t ) opt_max_species_count * sizeof ( snode_t * ) ) ; treelist = ( db_stree_t * ) xmalloc ( ( size_t ) ( opt_samples + 1 ) * sizeof ( db_stree_t ) ) ; while ( getnextline ( fp_mcmc ) ) { char * tmp = strchr ( line , ';' ) ; tmp ++ ; * tmp = 0 ; tmp ++ ; if ( opt_est_theta ) strip_theta_attributes ( line ) ; stree_t * t = stree_parse_newick_string ( line ) ; stree_sort ( t ) ; char * dnewick = get_delimit_string ( t ) ; int64_t species_count ; if ( ! get_int64 ( tmp , & species_count ) ) fatal ( "Cannot<S2SV_blank>read<S2SV_blank>number<S2SV_blank>of<S2SV_blank>species;<S2SV_blank>line<S2SV_blank>%ld<S2SV_blank>of<S2SV_blank>%s" , line_count + 1 , opt_mcmcfile ) ; treelist [ line_count ] . newick = dnewick ; treelist [ line_count ] . species = species_count ; treelist [ line_count ] . count = 1 ; line_count ++ ; stree_destroy ( t , NULL ) ; } qsort ( treelist , ( size_t ) line_count , sizeof ( db_stree_t ) , cb_stree_species ) ; int64_t start = 0 ; int64_t freq = 1 ; for ( i = 1 ; i < line_count ; ++ i ) { if ( treelist [ i ] . species == treelist [ i - 1 ] . species ) ++ freq ; else { qsort ( treelist + start , ( size_t ) freq , sizeof ( db_stree_t ) , cb_stree_strcmp ) ; start = i ; freq = 1 ; } } if ( freq > 1 ) qsort ( treelist + start , ( size_t ) freq , sizeof ( db_stree_t ) , cb_stree_strcmp ) ; int64_t index = 0 ; start = 0 ; freq = 1 ; for ( i = 1 ; i < line_count ; ++ i ) { if ( ! strcmp ( treelist [ i ] . newick , treelist [ i - 1 ] . newick ) ) { ++ freq ; } else { replace ( treelist , index , start , freq ) ; ++ index ; start = i ; freq = 1 ; } } replace ( treelist , index , start , freq ) ; ++ index ; hashtable_t * ht_species = hashtable_create ( 100 * treelist [ 0 ] . species ) ; hashtable_t * ht_delims = hashtable_create ( 100 * treelist [ 0 ] . species ) ; qsort ( treelist , ( size_t ) index , sizeof ( db_stree_t ) , cb_stree_count ) ; int maxlen = logint64_len ( treelist [ 0 ] . count ) ; double prob ; double cum = 0 ; start = 0 ; freq = 1 ; fprintf ( stdout , "\\n(A)<S2SV_blank>List<S2SV_blank>of<S2SV_blank>best<S2SV_blank>models<S2SV_blank>(count<S2SV_blank>postP<S2SV_blank>#species<S2SV_blank>SpeciesTree)\\n" ) ; fprintf ( fp_out , "\\n(A)<S2SV_blank>List<S2SV_blank>of<S2SV_blank>best<S2SV_blank>models<S2SV_blank>(count<S2SV_blank>postP<S2SV_blank>#species<S2SV_blank>SpeciesTree)\\n" ) ; for ( i = 0 ; i < index ; ++ i ) { char * dbgtmp = opt_reorder ; opt_reorder = NULL ; stree_t * t = stree_parse_newick_string ( treelist [ i ] . newick ) ; opt_reorder = dbgtmp ; char * delim = create_delim_string ( t ) ; cum += treelist [ i ] . count / ( double ) opt_samples ; prob = treelist [ i ] . count / ( double ) opt_samples ; fprintf ( stdout , "%*ld<S2SV_blank>%f<S2SV_blank>%f<S2SV_blank>%ld<S2SV_blank>" , maxlen , treelist [ i ] . count , prob , cum , treelist [ i ] . species ) ; fprintf ( fp_out , "%*ld<S2SV_blank>%f<S2SV_blank>%f<S2SV_blank>%ld<S2SV_blank>" , maxlen , treelist [ i ] . count , prob , cum , treelist [ i ] . species ) ; fprintf ( stdout , "<S2SV_blank>(%s)<S2SV_blank>" , delim ) ; fprintf ( fp_out , "<S2SV_blank>(%s)<S2SV_blank>" , delim ) ; fprintf ( stdout , "<S2SV_blank>%s\\n" , treelist [ i ] . newick ) ; fprintf ( fp_out , "<S2SV_blank>%s\\n" , treelist [ i ] . newick ) ; stringfreq_t * query = hashtable_find ( ht_delims , ( void * ) delim , hash_fnv ( delim ) , cb_cmp_label ) ; if ( query ) { query -> count += treelist [ i ] . count ; free ( delim ) ; } else { query = ( stringfreq_t * ) xmalloc ( sizeof ( stringfreq_t ) ) ; query -> count = treelist [ i ] . count ; query -> label = delim ; query -> word_count = t -> tip_count ; hashtable_insert_force ( ht_delims , ( void * ) query , hash_fnv ( query -> label ) ) ; } for ( j = 0 ; j < t -> tip_count ; ++ j ) { stringfreq_t * sf = hashtable_find ( ht_species , ( void * ) ( t -> nodes [ j ] -> label ) , hash_fnv ( t -> nodes [ j ] -> label ) , cb_cmp_label ) ; if ( sf ) { sf -> count += treelist [ i ] . count ; } else { sf = ( stringfreq_t * ) xmalloc ( sizeof ( stringfreq_t ) ) ; sf -> count = treelist [ i ] . count ; sf -> label = xstrdup ( t -> nodes [ j ] -> label ) ; hashtable_insert_force ( ht_species , ( void * ) sf , hash_fnv ( sf -> label ) ) ; } } stree_destroy ( t , NULL ) ; } for ( i = 0 ; i < line_count ; ++ i ) { if ( treelist [ i ] . newick ) free ( treelist [ i ] . newick ) ; } free ( treelist ) ; stringfreq_t * * dfreqs = hashtable_serialize ( ht_delims ) ; qsort ( dfreqs , ht_delims -> entries_count , sizeof ( stringfreq_t * ) , cb_countcmp ) ; fprintf ( stdout , "\\n(B)<S2SV_blank>%ld<S2SV_blank>species<S2SV_blank>delimitations<S2SV_blank>&<S2SV_blank>their<S2SV_blank>posterior<S2SV_blank>probabilities\\n" , ht_delims -> entries_count ) ; fprintf ( fp_out , "\\n(B)<S2SV_blank>%ld<S2SV_blank>species<S2SV_blank>delimitations<S2SV_blank>&<S2SV_blank>their<S2SV_blank>posterior<S2SV_blank>probabilities\\n" , ht_delims -> entries_count ) ; maxlen = logint64_len ( dfreqs [ 0 ] -> count ) ; for ( i = 0 ; i < ht_delims -> entries_count ; ++ i ) { fprintf ( stdout , "%*ld<S2SV_blank>%f<S2SV_blank>%3ld<S2SV_blank>(%s)\\n" , maxlen , dfreqs [ i ] -> count , dfreqs [ i ] -> count / ( double ) opt_samples , dfreqs [ i ] -> word_count , dfreqs [ i ] -> label ) ; fprintf ( fp_out , "%*ld<S2SV_blank>%f<S2SV_blank>%3ld<S2SV_blank>(%s)\\n" , maxlen , dfreqs [ i ] -> count , dfreqs [ i ] -> count / ( double ) opt_samples , dfreqs [ i ] -> word_count , dfreqs [ i ] -> label ) ; } double * posterior = ( double * ) xcalloc ( ( size_t ) ( opt_max_species_count + 1 ) , sizeof ( double ) ) ; for ( i = 0 ; i < ht_delims -> entries_count ; ++ i ) posterior [ dfreqs [ i ] -> word_count ] += dfreqs [ i ] -> count ; for ( i = 1 ; i <= opt_max_species_count ; ++ i ) posterior [ i ] /= opt_samples ; free ( dfreqs ) ; dfreqs = hashtable_serialize ( ht_species ) ; qsort ( dfreqs , ht_species -> entries_count , sizeof ( stringfreq_t * ) , cb_countcmp ) ; fprintf ( stdout , "\\n(C)<S2SV_blank>%ld<S2SV_blank>delimited<S2SV_blank>species<S2SV_blank>&<S2SV_blank>their<S2SV_blank>posterior<S2SV_blank>probabilities\\n" , ht_species -> entries_count ) ; fprintf ( fp_out , "\\n(C)<S2SV_blank>%ld<S2SV_blank>delimited<S2SV_blank>species<S2SV_blank>&<S2SV_blank>their<S2SV_blank>posterior<S2SV_blank>probabilities\\n" , ht_species -> entries_count ) ; maxlen = logint64_len ( dfreqs [ 0 ] -> count ) ; for ( i = 0 ; i < ht_species -> entries_count ; ++ i ) { fprintf ( stdout , "%*ld<S2SV_blank>%f<S2SV_blank>%s\\n" , maxlen , dfreqs [ i ] -> count , dfreqs [ i ] -> count / ( double ) opt_samples , dfreqs [ i ] -> label ) ; fprintf ( fp_out , "%*ld<S2SV_blank>%f<S2SV_blank>%s\\n" , maxlen , dfreqs [ i ] -> count , dfreqs [ i ] -> count / ( double ) opt_samples , dfreqs [ i ] -> label ) ; } free ( dfreqs ) ; fprintf ( stdout , "\\n(D)<S2SV_blank>Posterior<S2SV_blank>probability<S2SV_blank>for<S2SV_blank>#<S2SV_blank>of<S2SV_blank>species\\n" ) ; fprintf ( fp_out , "\\n(D)<S2SV_blank>Posterior<S2SV_blank>probability<S2SV_blank>for<S2SV_blank>#<S2SV_blank>of<S2SV_blank>species\\n" ) ; maxlen = logint64_len ( opt_max_species_count ) ; double * prior_A11 = getpriorA11 ( ) ; if ( opt_delimit_prior == BPP_SPECIES_PRIOR_SLH || opt_delimit_prior == BPP_SPECIES_PRIOR_SUNIFORM ) for ( i = 0 ; i < opt_max_species_count ; ++ i ) prior_A11 [ i ] = 1.0 / opt_max_species_count ; for ( i = 1 ; i <= opt_max_species_count ; ++ i ) { fprintf ( stdout , "P[%*ld]<S2SV_blank>=<S2SV_blank>%f<S2SV_blank><S2SV_blank>prior[%*ld]<S2SV_blank>=<S2SV_blank>%f\\n" , maxlen , i , posterior [ i ] , maxlen , i , prior_A11 [ i - 1 ] ) ; fprintf ( fp_out , "P[%*ld]<S2SV_blank>=<S2SV_blank>%f<S2SV_blank><S2SV_blank>prior[%*ld]<S2SV_blank>=<S2SV_blank>%f\\n" , maxlen , i , posterior [ i ] , maxlen , i , prior_A11 [ i - 1 ] ) ; } free ( posterior ) ; hashtable_destroy ( ht_species , cb_stringfreq_dealloc ) ; hashtable_destroy ( ht_delims , cb_stringfreq_dealloc ) ; free ( inner ) ; fclose ( fp_mcmc ) ; }
int FTIFF_CheckL1RecoverInit ( FTIT_execution * FTI_Exec , FTIT_topology * FTI_Topo , FTIT_checkpoint * FTI_Ckpt ) { char str [ FTI_BUFS ] , tmpfn [ FTI_BUFS ] , strerr [ FTI_BUFS ] ; int fexist = 0 , fileTarget , ckptID , fcount ; struct dirent * entry ; struct stat ckptFS ; struct stat ckptDIR ; FTIFF_metaInfo * FTIFFMeta = calloc ( 1 , sizeof ( FTIFF_metaInfo ) ) ; if ( FTIFFMeta == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoverInit<S2SV_blank>-<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>allocate<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>for<S2SV_blank>\'FTIFFMeta\'" , sizeof ( FTIFF_metaInfo ) ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; goto SEND_NOFILE_INFO ; } MD5_CTX mdContext ; bool L1CkptDirExists = false ; if ( stat ( FTI_Ckpt [ 1 ] . dir , & ckptDIR ) == 0 ) { if ( S_ISDIR ( ckptDIR . st_mode ) != 0 ) { L1CkptDirExists = true ; } else { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoverInit<S2SV_blank>-<S2SV_blank>(%s)<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>directory." , FTI_Ckpt [ 1 ] . dir ) ; FTI_Print ( strerr , FTI_WARN ) ; free ( FTIFFMeta ) ; goto SEND_NOFILE_INFO ; } } if ( L1CkptDirExists ) { DIR * L1CkptDir = opendir ( FTI_Ckpt [ 1 ] . dir ) ; if ( L1CkptDir == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>checkpoint<S2SV_blank>directory<S2SV_blank>(%s)<S2SV_blank>could<S2SV_blank>not<S2SV_blank>be<S2SV_blank>accessed." , FTI_Ckpt [ 1 ] . dir ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; goto SEND_NOFILE_INFO ; } while ( ( entry = readdir ( L1CkptDir ) ) != NULL ) { if ( strcmp ( entry -> d_name , "." ) && strcmp ( entry -> d_name , ".." ) ) { snprintf ( str , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>found<S2SV_blank>file<S2SV_blank>with<S2SV_blank>name:<S2SV_blank>%s" , entry -> d_name ) ; FTI_Print ( str , FTI_DBUG ) ; sscanf ( entry -> d_name , "Ckpt%d-Rank%d.fti" , & ckptID , & fileTarget ) ; if ( fileTarget == FTI_Topo -> myRank ) { snprintf ( tmpfn , FTI_BUFS , "%s/%s" , FTI_Ckpt [ 1 ] . dir , entry -> d_name ) ; if ( stat ( tmpfn , & ckptFS ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>Problem<S2SV_blank>with<S2SV_blank>stats<S2SV_blank>on<S2SV_blank>file<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } if ( S_ISREG ( ckptFS . st_mode ) == 0 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>%s<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>regular<S2SV_blank>file" , tmpfn ) ; FTI_Print ( strerr , FTI_WARN ) ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } if ( ckptFS . st_size > sizeof ( FTIFF_metaInfo ) ) { int fd = open ( tmpfn , O_RDONLY ) ; if ( fd == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>open<S2SV_blank>\'%s\'<S2SV_blank>for<S2SV_blank>reading." , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } if ( lseek ( fd , 0 , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } if ( read ( fd , FTIFFMeta , sizeof ( FTIFF_metaInfo ) ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>request<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>from:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; FTIFF_GetHashMetaInfo ( hash , FTIFFMeta ) ; if ( memcmp ( FTIFFMeta -> myHash , hash , MD5_DIGEST_LENGTH ) == 0 ) { long rcount = sizeof ( FTIFF_metaInfo ) , toRead , diff ; int rbuffer ; char * buffer = malloc ( CHUNK_SIZE ) ; if ( buffer == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoverInit<S2SV_blank>-<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>allocate<S2SV_blank>%d<S2SV_blank>bytes<S2SV_blank>for<S2SV_blank>\'buffer\'" , CHUNK_SIZE ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } MD5_Init ( & mdContext ) ; while ( rcount < FTIFFMeta -> fs ) { if ( lseek ( fd , rcount , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; close ( fd ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } diff = FTIFFMeta -> fs - rcount ; toRead = ( diff < CHUNK_SIZE ) ? diff : CHUNK_SIZE ; rbuffer = read ( fd , buffer , toRead ) ; if ( rbuffer == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L1RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>file:<S2SV_blank>%s" , toRead , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; close ( fd ) ; goto SEND_NOFILE_INFO ; } rcount += rbuffer ; MD5_Update ( & mdContext , buffer , rbuffer ) ; } free ( buffer ) ; unsigned char hash [ MD5_DIGEST_LENGTH ] ; MD5_Final ( hash , & mdContext ) ; int i ; char checksum [ MD5_DIGEST_STRING_LENGTH ] ; int ii = 0 ; for ( i = 0 ; i < MD5_DIGEST_LENGTH ; i ++ ) { sprintf ( & checksum [ ii ] , "%02x" , hash [ i ] ) ; ii += 2 ; } if ( strcmp ( checksum , FTIFFMeta -> checksum ) == 0 ) { FTI_Exec -> meta [ 1 ] . fs [ 0 ] = ckptFS . st_size ; FTI_Exec -> ckptID = ckptID ; strncpy ( FTI_Exec -> meta [ 1 ] . ckptFile , entry -> d_name , NAME_MAX ) ; fexist = 1 ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Checksum<S2SV_blank>do<S2SV_blank>not<S2SV_blank>match.<S2SV_blank>\\"%s\\"<S2SV_blank>file<S2SV_blank>is<S2SV_blank>corrupted.<S2SV_blank>%s<S2SV_blank>!=<S2SV_blank>%s" , entry -> d_name , checksum , FTIFFMeta -> checksum ) ; FTI_Print ( str , FTI_WARN ) ; close ( fd ) ; free ( FTIFFMeta ) ; closedir ( L1CkptDir ) ; goto SEND_NOFILE_INFO ; } } close ( fd ) ; break ; } } } } closedir ( L1CkptDir ) ; } MPI_Allreduce ( & fexist , & fcount , 1 , MPI_INT , MPI_SUM , FTI_COMM_WORLD ) ; int fneeded = FTI_Topo -> nbNodes * FTI_Topo -> nbApprocs ; int res = ( fcount == fneeded ) ? FTI_SCES : FTI_NSCS ; free ( FTIFFMeta ) ; return res ; SEND_NOFILE_INFO : fexist = 0 ; MPI_Allreduce ( & fexist , & fcount , 1 , MPI_INT , MPI_SUM , FTI_COMM_WORLD ) ; return FTI_NSCS ; }
int FTIFF_CheckL2RecoverInit ( FTIT_execution * FTI_Exec , FTIT_topology * FTI_Topo , FTIT_checkpoint * FTI_Ckpt , int * exists ) { char dbgstr [ FTI_BUFS ] , strerr [ FTI_BUFS ] ; enum { LEFT_FILE , MY_FILE , MY_COPY , LEFT_COPY } ; MPI_Group nodesGroup ; MPI_Comm_group ( FTI_Exec -> groupComm , & nodesGroup ) ; MPI_Group appProcsGroup ; MPI_Comm_group ( FTI_COMM_WORLD , & appProcsGroup ) ; int baseRanks [ ] = { FTI_Topo -> left , FTI_Topo -> right } ; int projRanks [ 2 ] ; MPI_Group_translate_ranks ( nodesGroup , 2 , baseRanks , appProcsGroup , projRanks ) ; int leftIdx = projRanks [ 0 ] , rightIdx = projRanks [ 1 ] ; int appCommSize = FTI_Topo -> nbNodes * FTI_Topo -> nbApprocs ; int fneeded = appCommSize ; MPI_Group_free ( & nodesGroup ) ; MPI_Group_free ( & appProcsGroup ) ; FTIFF_L2Info _appProcsMetaInfo ; FTIFF_L2Info * appProcsMetaInfo = memset ( & _appProcsMetaInfo , 0x0 , sizeof ( FTIFF_L2Info ) ) ; FTIFF_L2Info _myMetaInfo ; FTIFF_L2Info * myMetaInfo = memset ( & _myMetaInfo , 0x0 , sizeof ( FTIFF_L2Info ) ) ; myMetaInfo -> rightIdx = rightIdx ; MD5_CTX mdContext ; char str [ FTI_BUFS ] , tmpfn [ FTI_BUFS ] ; int fileTarget , ckptID = - 1 , fcount = 0 , match ; struct dirent * entry ; struct stat ckptFS , ckptDIR ; FTIFF_metaInfo _FTIFFMeta ; FTIFF_metaInfo * FTIFFMeta = memset ( & _FTIFFMeta , 0x0 , sizeof ( FTIFF_metaInfo ) ) ; bool L2CkptDirExists = false ; if ( stat ( FTI_Ckpt [ 2 ] . dir , & ckptDIR ) == 0 ) { if ( S_ISDIR ( ckptDIR . st_mode ) != 0 ) { L2CkptDirExists = true ; } else { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoverInit<S2SV_blank>-<S2SV_blank>(%s)<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>directory." , FTI_Ckpt [ 2 ] . dir ) ; FTI_Print ( strerr , FTI_WARN ) ; goto GATHER_INFO ; } } if ( L2CkptDirExists ) { int tmpCkptID ; DIR * L2CkptDir = opendir ( FTI_Ckpt [ 2 ] . dir ) ; if ( L2CkptDir == NULL ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>checkpoint<S2SV_blank>directory<S2SV_blank>(%s)<S2SV_blank>could<S2SV_blank>not<S2SV_blank>be<S2SV_blank>accessed." , FTI_Ckpt [ 2 ] . dir ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; goto GATHER_INFO ; } while ( ( entry = readdir ( L2CkptDir ) ) != NULL ) { if ( strcmp ( entry -> d_name , "." ) && strcmp ( entry -> d_name , ".." ) ) { snprintf ( str , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>found<S2SV_blank>file<S2SV_blank>with<S2SV_blank>name:<S2SV_blank>%s" , entry -> d_name ) ; FTI_Print ( str , FTI_DBUG ) ; tmpCkptID = ckptID ; match = sscanf ( entry -> d_name , "Ckpt%d-Rank%d.fti" , & ckptID , & fileTarget ) ; if ( match == 2 && fileTarget == FTI_Topo -> myRank ) { snprintf ( tmpfn , FTI_BUFS , "%s/%s" , FTI_Ckpt [ 2 ] . dir , entry -> d_name ) ; if ( stat ( tmpfn , & ckptFS ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Problem<S2SV_blank>with<S2SV_blank>stats<S2SV_blank>on<S2SV_blank>file<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( S_ISREG ( ckptFS . st_mode ) == 0 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>%s<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>regular<S2SV_blank>file" , tmpfn ) ; FTI_Print ( strerr , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( ckptFS . st_size > sizeof ( FTIFF_metaInfo ) ) { int fd = open ( tmpfn , O_RDONLY ) ; if ( fd == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>open<S2SV_blank>\'%s\'<S2SV_blank>for<S2SV_blank>reading." , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( lseek ( fd , 0 , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; close ( fd ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } if ( read ( fd , FTIFFMeta , sizeof ( FTIFF_metaInfo ) ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>request<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>from:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; FTIFF_GetHashMetaInfo ( hash , FTIFFMeta ) ; if ( memcmp ( FTIFFMeta -> myHash , hash , MD5_DIGEST_LENGTH ) == 0 ) { long rcount = sizeof ( FTIFF_metaInfo ) , toRead , diff ; int rbuffer ; char buffer [ CHUNK_SIZE ] ; MD5_Init ( & mdContext ) ; while ( rcount < FTIFFMeta -> fs ) { if ( lseek ( fd , rcount , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } diff = FTIFFMeta -> fs - rcount ; toRead = ( diff < CHUNK_SIZE ) ? diff : CHUNK_SIZE ; rbuffer = read ( fd , buffer , toRead ) ; if ( rbuffer == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>file:<S2SV_blank>%s" , toRead , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } rcount += rbuffer ; MD5_Update ( & mdContext , buffer , rbuffer ) ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; MD5_Final ( hash , & mdContext ) ; int i ; char checksum [ MD5_DIGEST_STRING_LENGTH ] ; int ii = 0 ; for ( i = 0 ; i < MD5_DIGEST_LENGTH ; i ++ ) { sprintf ( & checksum [ ii ] , "%02x" , hash [ i ] ) ; ii += 2 ; } if ( strcmp ( checksum , FTIFFMeta -> checksum ) == 0 ) { myMetaInfo -> fs = FTIFFMeta -> fs ; myMetaInfo -> ckptID = ckptID ; myMetaInfo -> FileExists = 1 ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Checksum<S2SV_blank>do<S2SV_blank>not<S2SV_blank>match.<S2SV_blank>\\"%s\\"<S2SV_blank>file<S2SV_blank>is<S2SV_blank>corrupted.<S2SV_blank>%s<S2SV_blank>!=<S2SV_blank>%s" , entry -> d_name , checksum , FTIFFMeta -> checksum ) ; FTI_Print ( str , FTI_WARN ) ; close ( fd ) ; goto GATHER_INFO ; } } close ( fd ) ; } } else { ckptID = tmpCkptID ; } tmpCkptID = ckptID ; match = sscanf ( entry -> d_name , "Ckpt%d-Pcof%d.fti" , & ckptID , & fileTarget ) ; if ( match == 2 && fileTarget == FTI_Topo -> myRank ) { snprintf ( tmpfn , FTI_BUFS , "%s/%s" , FTI_Ckpt [ 2 ] . dir , entry -> d_name ) ; if ( stat ( tmpfn , & ckptFS ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Problem<S2SV_blank>with<S2SV_blank>stats<S2SV_blank>on<S2SV_blank>file<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( S_ISREG ( ckptFS . st_mode ) == 0 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>%s<S2SV_blank>is<S2SV_blank>not<S2SV_blank>a<S2SV_blank>regular<S2SV_blank>file" , tmpfn ) ; FTI_Print ( strerr , FTI_WARN ) ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( ckptFS . st_size > sizeof ( FTIFF_metaInfo ) ) { int fd = open ( tmpfn , O_RDONLY ) ; if ( fd == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>open<S2SV_blank>\'%s\'<S2SV_blank>for<S2SV_blank>reading." , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; goto GATHER_INFO ; } if ( lseek ( fd , 0 , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; close ( fd ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } if ( read ( fd , FTIFFMeta , sizeof ( FTIFF_metaInfo ) ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>request<S2SV_blank>file<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>from:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; FTIFF_GetHashMetaInfo ( hash , FTIFFMeta ) ; if ( memcmp ( FTIFFMeta -> myHash , hash , MD5_DIGEST_LENGTH ) == 0 ) { long rcount = sizeof ( FTIFF_metaInfo ) , toRead , diff ; int rbuffer ; char buffer [ CHUNK_SIZE ] ; MD5_Init ( & mdContext ) ; while ( rcount < FTIFFMeta -> fs ) { if ( lseek ( fd , rcount , SEEK_SET ) == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>could<S2SV_blank>not<S2SV_blank>seek<S2SV_blank>in<S2SV_blank>file:<S2SV_blank>%s" , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } diff = FTIFFMeta -> fs - rcount ; toRead = ( diff < CHUNK_SIZE ) ? diff : CHUNK_SIZE ; rbuffer = read ( fd , buffer , toRead ) ; if ( rbuffer == - 1 ) { snprintf ( strerr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2RecoveryInit<S2SV_blank>-<S2SV_blank>Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>%ld<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>file:<S2SV_blank>%s" , toRead , tmpfn ) ; FTI_Print ( strerr , FTI_EROR ) ; errno = 0 ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } rcount += rbuffer ; MD5_Update ( & mdContext , buffer , rbuffer ) ; } unsigned char hash [ MD5_DIGEST_LENGTH ] ; MD5_Final ( hash , & mdContext ) ; int i ; char checksum [ MD5_DIGEST_STRING_LENGTH ] ; int ii = 0 ; for ( i = 0 ; i < MD5_DIGEST_LENGTH ; i ++ ) { sprintf ( & checksum [ ii ] , "%02x" , hash [ i ] ) ; ii += 2 ; } if ( strcmp ( checksum , FTIFFMeta -> checksum ) == 0 ) { myMetaInfo -> pfs = FTIFFMeta -> fs ; myMetaInfo -> ckptID = ckptID ; myMetaInfo -> CopyExists = 1 ; } else { char str [ FTI_BUFS ] ; snprintf ( str , FTI_BUFS , "Checksum<S2SV_blank>do<S2SV_blank>not<S2SV_blank>match.<S2SV_blank>\\"%s\\"<S2SV_blank>file<S2SV_blank>is<S2SV_blank>corrupted.<S2SV_blank>%s<S2SV_blank>!=<S2SV_blank>%s" , entry -> d_name , checksum , FTIFFMeta -> checksum ) ; FTI_Print ( str , FTI_WARN ) ; closedir ( L2CkptDir ) ; close ( fd ) ; goto GATHER_INFO ; } } close ( fd ) ; } } else { ckptID = tmpCkptID ; } } if ( myMetaInfo -> FileExists && myMetaInfo -> CopyExists ) { break ; } } closedir ( L2CkptDir ) ; } GATHER_INFO : if ( ! ( myMetaInfo -> FileExists ) && ! ( myMetaInfo -> CopyExists ) ) { myMetaInfo -> ckptID = - 1 ; } MPI_Allgather ( myMetaInfo , 1 , FTIFF_MpiTypes [ FTIFF_L2_INFO ] , appProcsMetaInfo , 1 , FTIFF_MpiTypes [ FTIFF_L2_INFO ] , FTI_COMM_WORLD ) ; exists [ LEFT_FILE ] = appProcsMetaInfo [ leftIdx ] . FileExists ; exists [ MY_FILE ] = appProcsMetaInfo [ FTI_Topo -> splitRank ] . FileExists ; exists [ MY_COPY ] = appProcsMetaInfo [ rightIdx ] . CopyExists ; exists [ LEFT_COPY ] = appProcsMetaInfo [ FTI_Topo -> splitRank ] . CopyExists ; snprintf ( dbgstr , FTI_BUFS , "FTI-FF<S2SV_blank>-<S2SV_blank>L2Recovery::FileCheck<S2SV_blank>-<S2SV_blank>CkptFile:<S2SV_blank>%i,<S2SV_blank>CkptCopy:<S2SV_blank>%i" , myMetaInfo -> FileExists , myMetaInfo -> CopyExists ) ; FTI_Print ( dbgstr , FTI_DBUG ) ; int i , saneCkptID = 0 ; ckptID = 0 ; for ( i = 0 ; i < appCommSize ; i ++ ) { fcount += ( appProcsMetaInfo [ i ] . FileExists || appProcsMetaInfo [ appProcsMetaInfo [ i ] . rightIdx ] . CopyExists ) ? 1 : 0 ; if ( appProcsMetaInfo [ i ] . ckptID > 0 ) { saneCkptID ++ ; ckptID += appProcsMetaInfo [ i ] . ckptID ; } } int res = ( fcount == fneeded ) ? FTI_SCES : FTI_NSCS ; if ( res == FTI_SCES ) { FTI_Exec -> ckptID = ckptID / saneCkptID ; if ( myMetaInfo -> FileExists ) { FTI_Exec -> meta [ 2 ] . fs [ 0 ] = myMetaInfo -> fs ; } else { FTI_Exec -> meta [ 2 ] . fs [ 0 ] = appProcsMetaInfo [ rightIdx ] . pfs ; } if ( myMetaInfo -> CopyExists ) { FTI_Exec -> meta [ 2 ] . pfs [ 0 ] = myMetaInfo -> pfs ; } else { FTI_Exec -> meta [ 2 ] . pfs [ 0 ] = appProcsMetaInfo [ leftIdx ] . fs ; } } snprintf ( dbgstr , FTI_BUFS , "FTI-FF:<S2SV_blank>L2-Recovery<S2SV_blank>-<S2SV_blank>rank:<S2SV_blank>%i,<S2SV_blank>left:<S2SV_blank>%i,<S2SV_blank>right:<S2SV_blank>%i,<S2SV_blank>fs:<S2SV_blank>%ld,<S2SV_blank>pfs:<S2SV_blank>%ld,<S2SV_blank>ckptID:<S2SV_blank>%i" , FTI_Topo -> myRank , leftIdx , rightIdx , FTI_Exec -> meta [ 2 ] . fs [ 0 ] , FTI_Exec -> meta [ 2 ] . pfs [ 0 ] , FTI_Exec -> ckptID ) ; FTI_Print ( dbgstr , FTI_DBUG ) ; snprintf ( FTI_Exec -> meta [ 2 ] . ckptFile , FTI_BUFS , "Ckpt%d-Rank%d.fti" , FTI_Exec -> ckptID , FTI_Topo -> myRank ) ; return res ; }
void scheduler ( void ) { int random , i ; struct proc * p , * selected ; struct cpu * c = mycpu ( ) ; c -> proc = 0 ; for ( ; ; ) { sti ( ) ; acquire ( & ptable . lock ) ; if ( count == 0 ) continue ; random = rand ( ) % count ; selected = tickets [ random ] ; p = selected ; if ( p -> state != RUNNABLE ) continue ; c -> proc = p ; switchuvm ( p ) ; p -> ticks ++ ; p -> state = RUNNING ; swtch ( & ( c -> scheduler ) , p -> context ) ; switchkvm ( ) ; c -> proc = 0 ; release ( & ptable . lock ) ; } int getpinfo ( struct pstat * pst ) { int i ; acquire ( & ptable . lock ) ; for ( i = 0 ; i < NPROC ; i ++ ) { struct proc process = ptable . proc [ i ] ; pst -> inuse [ i ] = process . state != UNUSED ; pst -> tickets [ i ] = process . ntix ; pst -> pid [ i ] = process . pid ; pst -> ticks [ i ] = process . ticks ; } release ( & ptable . lock ) ; return 0 ; } void sched ( void ) { int intena ; struct proc * p = myproc ( ) ; if ( ! holding ( & ptable . lock ) ) panic ( "sched<S2SV_blank>ptable.lock" ) ; if ( mycpu ( ) -> ncli != 1 ) panic ( "sched<S2SV_blank>locks" ) ; if ( p -> state == RUNNING ) panic ( "sched<S2SV_blank>running" ) ; if ( readeflags ( ) & FL_IF ) panic ( "sched<S2SV_blank>interruptible" ) ; intena = mycpu ( ) -> intena ; swtch ( & p -> context , mycpu ( ) -> scheduler ) ; mycpu ( ) -> intena = intena ; } void yield ( void ) { acquire ( & ptable . lock ) ; myproc ( ) -> state = RUNNABLE ; sched ( ) ; release ( & ptable . lock ) ; } void forkret ( void ) { static int first = 1 ; release ( & ptable . lock ) ; if ( first ) { first = 0 ; iinit ( ROOTDEV ) ; initlog ( ROOTDEV ) ; } } void sleep ( void * chan , struct spinlock * lk ) { struct proc * p = myproc ( ) ; if ( p == 0 ) panic ( "sleep" ) ; if ( lk == 0 ) panic ( "sleep<S2SV_blank>without<S2SV_blank>lk" ) ; if ( lk != & ptable . lock ) { acquire ( & ptable . lock ) ; release ( lk ) ; } p -> chan = chan ; p -> state = SLEEPING ; sched ( ) ; p -> chan = 0 ; if ( lk != & ptable . lock ) { release ( & ptable . lock ) ; acquire ( lk ) ; } } static void wakeup1 ( void * chan ) { struct proc * p ; for ( p = ptable . proc ; p < & ptable . proc [ NPROC ] ; p ++ ) if ( p -> state == SLEEPING && p -> chan == chan ) p -> state = RUNNABLE ; } void wakeup ( void * chan ) { acquire ( & ptable . lock ) ; wakeup1 ( chan ) ; release ( & ptable . lock ) ; } int kill ( int pid ) { struct proc * p ; acquire ( & ptable . lock ) ; for ( p = ptable . proc ; p < & ptable . proc [ NPROC ] ; p ++ ) { if ( p -> pid == pid ) { p -> killed = 1 ; if ( p -> state == SLEEPING ) p -> state = RUNNABLE ; release ( & ptable . lock ) ; return 0 ; } } release ( & ptable . lock ) ; return - 1 ; } void procdump ( void ) { static char * states [ ] = { [ UNUSED ] "unused" , [ EMBRYO ] "embryo" , [ SLEEPING ] "sleep<S2SV_blank>" , [ RUNNABLE ] "runble" , [ RUNNING ] "run<S2SV_blank><S2SV_blank><S2SV_blank>" , [ ZOMBIE ] "zombie" } ; int i ; struct proc * p ; char * state ; uint pc [ 10 ] ; for ( p = ptable . proc ; p < & ptable . proc [ NPROC ] ; p ++ ) { if ( p -> state == UNUSED ) continue ; if ( p -> state >= 0 && p -> state < NELEM ( states ) && states [ p -> state ] ) state = states [ p -> state ] ; else state = "???" ; cprintf ( "%d<S2SV_blank>%s<S2SV_blank>%s<S2SV_blank>%d<S2SV_blank>tickets" , p -> pid , state , p -> name , p -> ntix ) ; if ( p -> state == SLEEPING ) { getcallerpcs ( ( uint * ) p -> context -> ebp + 2 , pc ) ; for ( i = 0 ; i < 10 && pc [ i ] != 0 ; i ++ ) cprintf ( "<S2SV_blank>%p" , pc [ i ] ) ; } cprintf ( "\\n" ) ; cprintf ( "Number<S2SV_blank>of<S2SV_blank>tickets<S2SV_blank>issued:<S2SV_blank>%d\\n" , tix_count ) ; for ( int i = 0 ; i < tix_count ; ++ i ) { cprintf ( "ticketno:<S2SV_blank>%d\\tpid:<S2SV_blank>%d\\n" , i , tickets [ i ] -> pid ) ; } } }
static void omap_mbox_fini ( struct omap_mbox * mbox ) { mutex_lock ( & mbox_configured_lock ) ; if ( ! -- mbox -> use_count ) { free_irq ( mbox -> irq , mbox ) ; tasklet_kill ( & mbox -> txq -> tasklet ) ; flush_work_sync ( & mbox -> rxq -> work ) ; mbox_queue_free ( mbox -> txq ) ; mbox_queue_free ( mbox -> rxq ) ; } if ( likely ( mbox -> ops -> shutdown ) ) { if ( ! -- mbox_configured ) mbox -> ops -> shutdown ( mbox ) ; } mutex_unlock ( & mbox_configured_lock ) ; }
static void spu_gov_init_work ( struct spu_gov_info_struct * info ) { int delay = usecs_to_jiffies ( info -> poll_int ) ; INIT_DELAYED_WORK_DEFERRABLE ( & info -> work , spu_gov_work ) ; schedule_delayed_work_on ( info -> policy -> cpu , & info -> work , delay ) ; }
static int switch_drv_remove ( struct platform_device * pdev ) { struct push_switch * psw = platform_get_drvdata ( pdev ) ; struct push_switch_platform_info * psw_info = pdev -> dev . platform_data ; int irq = platform_get_irq ( pdev , 0 ) ; if ( psw_info -> name ) device_remove_file ( & pdev -> dev , & dev_attr_switch ) ; platform_set_drvdata ( pdev , NULL ) ; flush_work_sync ( & psw -> work ) ; del_timer_sync ( & psw -> debounce ) ; free_irq ( irq , pdev ) ; kfree ( psw ) ; return 0 ; }
static void throtl_schedule_delayed_work ( struct throtl_data * td , unsigned long delay ) { struct delayed_work * dwork = & td -> throtl_work ; if ( total_nr_queued ( td ) || td -> limits_changed ) { __cancel_delayed_work ( dwork ) ; queue_delayed_work ( kthrotld_workqueue , dwork , delay ) ; throtl_log ( td , "schedule<S2SV_blank>work.<S2SV_blank>delay=%lu<S2SV_blank>jiffies=%lu" , delay , jiffies ) ; } }
static void __disk_unblock_events ( struct gendisk * disk , bool check_now ) { struct disk_events * ev = disk -> ev ; unsigned long intv ; unsigned long flags ; spin_lock_irqsave ( & ev -> lock , flags ) ; if ( WARN_ON_ONCE ( ev -> block <= 0 ) ) goto out_unlock ; if ( -- ev -> block ) goto out_unlock ; intv = disk_events_poll_jiffies ( disk ) ; set_timer_slack ( & ev -> dwork . timer , intv / 4 ) ; if ( check_now ) queue_delayed_work ( system_nrt_freezable_wq , & ev -> dwork , 0 ) ; else if ( intv ) queue_delayed_work ( system_nrt_freezable_wq , & ev -> dwork , intv ) ; out_unlock : spin_unlock_irqrestore ( & ev -> lock , flags ) ; }
unsigned int disk_clear_events ( struct gendisk * disk , unsigned int mask ) { const struct block_device_operations * bdops = disk -> fops ; struct disk_events * ev = disk -> ev ; unsigned int pending ; if ( ! ev ) { if ( ( mask & DISK_EVENT_MEDIA_CHANGE ) && bdops -> media_changed && bdops -> media_changed ( disk ) ) return DISK_EVENT_MEDIA_CHANGE ; return 0 ; } spin_lock_irq ( & ev -> lock ) ; ev -> clearing |= mask ; spin_unlock_irq ( & ev -> lock ) ; disk_block_events ( disk ) ; queue_delayed_work ( system_nrt_freezable_wq , & ev -> dwork , 0 ) ; flush_delayed_work ( & ev -> dwork ) ; __disk_unblock_events ( disk , false ) ; spin_lock_irq ( & ev -> lock ) ; WARN_ON_ONCE ( ev -> clearing & mask ) ; pending = ev -> pending & mask ; ev -> pending &= ~ mask ; spin_unlock_irq ( & ev -> lock ) ; return pending ; }
static void disk_events_workfn ( struct work_struct * work ) { struct delayed_work * dwork = to_delayed_work ( work ) ; struct disk_events * ev = container_of ( dwork , struct disk_events , dwork ) ; struct gendisk * disk = ev -> disk ; char * envp [ ARRAY_SIZE ( disk_uevents ) + 1 ] = { } ; unsigned int clearing = ev -> clearing ; unsigned int events ; unsigned long intv ; int nr_events = 0 , i ; events = disk -> fops -> check_events ( disk , clearing ) ; spin_lock_irq ( & ev -> lock ) ; events &= ~ ev -> pending ; ev -> pending |= events ; ev -> clearing &= ~ clearing ; intv = disk_events_poll_jiffies ( disk ) ; if ( ! ev -> block && intv ) queue_delayed_work ( system_nrt_freezable_wq , & ev -> dwork , intv ) ; spin_unlock_irq ( & ev -> lock ) ; for ( i = 0 ; i < ARRAY_SIZE ( disk_uevents ) ; i ++ ) if ( events & disk -> events & ( 1 << i ) ) envp [ nr_events ++ ] = disk_uevents [ i ] ; if ( nr_events ) kobject_uevent_env ( & disk_to_dev ( disk ) -> kobj , KOBJ_CHANGE , envp ) ; }
void disk_flush_events ( struct gendisk * disk , unsigned int mask ) { struct disk_events * ev = disk -> ev ; if ( ! ev ) return ; spin_lock_irq ( & ev -> lock ) ; ev -> clearing |= mask ; if ( ! ev -> block ) { cancel_delayed_work ( & ev -> dwork ) ; queue_delayed_work ( system_nrt_freezable_wq , & ev -> dwork , 0 ) ; } spin_unlock_irq ( & ev -> lock ) ; }
ssize_t tpm_read ( struct file * file , char __user * buf , size_t size , loff_t * off ) { struct tpm_chip * chip = file -> private_data ; ssize_t ret_size ; int rc ; del_singleshot_timer_sync ( & chip -> user_read_timer ) ; flush_work_sync ( & chip -> work ) ; ret_size = atomic_read ( & chip -> data_pending ) ; atomic_set ( & chip -> data_pending , 0 ) ; if ( ret_size > 0 ) { ssize_t orig_ret_size = ret_size ; if ( size < ret_size ) ret_size = size ; mutex_lock ( & chip -> buffer_mutex ) ; rc = copy_to_user ( buf , chip -> data_buffer , ret_size ) ; memset ( chip -> data_buffer , 0 , orig_ret_size ) ; if ( rc ) ret_size = - EFAULT ; mutex_unlock ( & chip -> buffer_mutex ) ; } return ret_size ; }
int tpm_release ( struct inode * inode , struct file * file ) { struct tpm_chip * chip = file -> private_data ; del_singleshot_timer_sync ( & chip -> user_read_timer ) ; flush_work_sync ( & chip -> work ) ; file -> private_data = NULL ; atomic_set ( & chip -> data_pending , 0 ) ; kfree ( chip -> data_buffer ) ; clear_bit ( 0 , & chip -> is_open ) ; put_device ( chip -> dev ) ; return 0 ; }
static inline void dbs_timer_init ( struct cpu_dbs_info_s * dbs_info ) { int delay = usecs_to_jiffies ( dbs_tuners_ins . sampling_rate ) ; delay -= jiffies % delay ; dbs_info -> enable = 1 ; INIT_DELAYED_WORK_DEFERRABLE ( & dbs_info -> work , do_dbs_timer ) ; queue_delayed_work_on ( dbs_info -> cpu , dbs_wq , & dbs_info -> work , delay ) ; }
void devfreq_monitor_start ( struct devfreq * devfreq ) { INIT_DELAYED_WORK_DEFERRABLE ( & devfreq -> work , devfreq_monitor ) ; if ( devfreq -> profile -> polling_ms ) queue_delayed_work ( devfreq_wq , & devfreq -> work , msecs_to_jiffies ( devfreq -> profile -> polling_ms ) ) ; }
void edac_mc_reset_delay_period ( int value ) { struct mem_ctl_info * mci ; struct list_head * item ; mutex_lock ( & mem_ctls_mutex ) ; list_for_each ( item , & mc_devices ) { mci = list_entry ( item , struct mem_ctl_info , link ) ; if ( mci -> op_state == OP_RUNNING_POLL ) cancel_delayed_work ( & mci -> work ) ; } mutex_unlock ( & mem_ctls_mutex ) ; mutex_lock ( & mem_ctls_mutex ) ; list_for_each ( item , & mc_devices ) { mci = list_entry ( item , struct mem_ctl_info , link ) ; edac_mc_workq_setup ( mci , ( unsigned long ) value ) ; } mutex_unlock ( & mem_ctls_mutex ) ; }
static void edac_mc_workq_setup ( struct mem_ctl_info * mci , unsigned msec ) { debugf0 ( "%s()\\n" , __func__ ) ; if ( mci -> op_state != OP_RUNNING_POLL ) return ; INIT_DELAYED_WORK ( & mci -> work , edac_mc_workq_function ) ; queue_delayed_work ( edac_workqueue , & mci -> work , msecs_to_jiffies ( msec ) ) ; }
void drm_helper_hpd_irq_event ( struct drm_device * dev ) { if ( ! dev -> mode_config . poll_enabled ) return ; cancel_delayed_work ( & dev -> mode_config . output_poll_work ) ; if ( drm_kms_helper_poll ) queue_delayed_work ( system_nrt_wq , & dev -> mode_config . output_poll_work , 0 ) ; }
void drm_kms_helper_poll_enable ( struct drm_device * dev ) { bool poll = false ; struct drm_connector * connector ; if ( ! dev -> mode_config . poll_enabled || ! drm_kms_helper_poll ) return ; list_for_each_entry ( connector , & dev -> mode_config . connector_list , head ) { if ( connector -> polled ) poll = true ; } if ( poll ) queue_delayed_work ( system_nrt_wq , & dev -> mode_config . output_poll_work , DRM_OUTPUT_POLL_PERIOD ) ; }
static void output_poll_execute ( struct work_struct * work ) { struct delayed_work * delayed_work = to_delayed_work ( work ) ; struct drm_device * dev = container_of ( delayed_work , struct drm_device , mode_config . output_poll_work ) ; struct drm_connector * connector ; enum drm_connector_status old_status ; bool repoll = false , changed = false ; if ( ! drm_kms_helper_poll ) return ; mutex_lock ( & dev -> mode_config . mutex ) ; list_for_each_entry ( connector , & dev -> mode_config . connector_list , head ) { if ( ! connector -> polled ) continue ; else if ( connector -> polled & ( DRM_CONNECTOR_POLL_CONNECT | DRM_CONNECTOR_POLL_DISCONNECT ) ) repoll = true ; old_status = connector -> status ; if ( old_status == connector_status_connected && ! ( connector -> polled & DRM_CONNECTOR_POLL_DISCONNECT ) && ! ( connector -> polled & DRM_CONNECTOR_POLL_HPD ) ) continue ; connector -> status = connector -> funcs -> detect ( connector , false ) ; DRM_DEBUG_KMS ( "[CONNECTOR:%d:%s]<S2SV_blank>status<S2SV_blank>updated<S2SV_blank>from<S2SV_blank>%d<S2SV_blank>to<S2SV_blank>%d\\n" , connector -> base . id , drm_get_connector_name ( connector ) , old_status , connector -> status ) ; if ( old_status != connector -> status ) changed = true ; } mutex_unlock ( & dev -> mode_config . mutex ) ; if ( changed ) { drm_sysfs_hotplug_event ( dev ) ; if ( dev -> mode_config . funcs -> output_poll_changed ) dev -> mode_config . funcs -> output_poll_changed ( dev ) ; } if ( repoll ) queue_delayed_work ( system_nrt_wq , delayed_work , DRM_OUTPUT_POLL_PERIOD ) ; }
void nouveau_gpio_isr_del ( struct drm_device * dev , int idx , u8 tag , u8 line , void ( * handler ) ( void * , int ) , void * data ) { struct drm_nouveau_private * dev_priv = dev -> dev_private ; struct nouveau_gpio_engine * pgpio = & dev_priv -> engine . gpio ; struct gpio_isr * isr , * tmp ; struct gpio_func func ; unsigned long flags ; LIST_HEAD ( tofree ) ; int ret ; ret = nouveau_gpio_find ( dev , idx , tag , line , & func ) ; if ( ret == 0 ) { spin_lock_irqsave ( & pgpio -> lock , flags ) ; list_for_each_entry_safe ( isr , tmp , & pgpio -> isr , head ) { if ( memcmp ( & isr -> func , & func , sizeof ( func ) ) || isr -> idx != idx || isr -> handler != handler || isr -> data != data ) continue ; list_move ( & isr -> head , & tofree ) ; } spin_unlock_irqrestore ( & pgpio -> lock , flags ) ; list_for_each_entry_safe ( isr , tmp , & tofree , head ) { flush_work_sync ( & isr -> work ) ; kfree ( isr ) ; } } }
void radeon_irq_kms_fini ( struct radeon_device * rdev ) { drm_vblank_cleanup ( rdev -> ddev ) ; if ( rdev -> irq . installed ) { drm_irq_uninstall ( rdev -> ddev ) ; rdev -> irq . installed = false ; if ( rdev -> msi_enabled ) pci_disable_msi ( rdev -> pdev ) ; } flush_work_sync ( & rdev -> hotplug_work ) ; }
int vmw_fb_off ( struct vmw_private * vmw_priv ) { struct fb_info * info ; struct vmw_fb_par * par ; unsigned long flags ; if ( ! vmw_priv -> fb_info ) return - EINVAL ; info = vmw_priv -> fb_info ; par = info -> par ; spin_lock_irqsave ( & par -> dirty . lock , flags ) ; par -> dirty . active = false ; spin_unlock_irqrestore ( & par -> dirty . lock , flags ) ; flush_delayed_work_sync ( & info -> deferred_work ) ; par -> bo_ptr = NULL ; ttm_bo_kunmap ( & par -> map ) ; vmw_dmabuf_unpin ( vmw_priv , par -> vmw_bo , false ) ; return 0 ; }
static void wiiext_schedule ( struct wiimote_ext * ext ) { queue_work ( system_nrt_wq , & ext -> worker ) ; }
static inline int _is_in_region ( u32_t r_index , u32_t start , u32_t size ) { # if CONFIG_ARC_MPU_VER == 2 u32_t r_addr_start ; u32_t r_addr_end ; u32_t r_size_lshift ; r_addr_start = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & ( ~ AUX_MPU_RDB_VALID_MASK ) ; r_size_lshift = _arc_v2_aux_reg_read ( _ARC_V2_MPU_RDB0 + 2 * r_index ) & AUX_MPU_RDP_ATTR_MASK ; r_size_lshift = ( r_size_lshift & 0x3 ) | ( ( r_size_lshift >> 7 ) & 0x1C ) ; r_addr_end = r_addr_start + ( 1 << ( r_size_lshift + 1 ) ) ; if ( start >= r_addr_start && ( start + size ) < r_addr_end ) { return 1 ; } # elif CONFIG_ARC_MPU_VER == 3 if ( ( r_index == _mpu_probe ( start ) ) && ( r_index == _mpu_probe ( start + size ) ) ) { return 1 ; } # endif return 0 ; }
static int gntdev_mmap ( struct file * flip , struct vm_area_struct * vma ) { struct gntdev_priv * priv = flip -> private_data ; int index = vma -> vm_pgoff ; int count = ( vma -> vm_end - vma -> vm_start ) >> PAGE_SHIFT ; struct grant_map * map ; int i , err = - EINVAL ; if ( ( vma -> vm_flags & VM_WRITE ) && ! ( vma -> vm_flags & VM_SHARED ) ) return - EINVAL ; pr_debug ( "map<S2SV_blank>%d+%d<S2SV_blank>at<S2SV_blank>%lx<S2SV_blank>(pgoff<S2SV_blank>%lx)\\n" , index , count , vma -> vm_start , vma -> vm_pgoff ) ; mutex_lock ( & priv -> lock ) ; map = gntdev_find_map_index ( priv , index , count ) ; if ( ! map ) goto unlock_out ; if ( use_ptemod && map -> vma ) goto unlock_out ; if ( use_ptemod && priv -> mm != vma -> vm_mm ) { pr_warn ( "Huh?<S2SV_blank>Other<S2SV_blank>mm?\\n" ) ; goto unlock_out ; } atomic_inc ( & map -> users ) ; vma -> vm_ops = & gntdev_vmops ; vma -> vm_flags |= VM_DONTEXPAND | VM_DONTDUMP | VM_MIXEDMAP ; if ( use_ptemod ) vma -> vm_flags |= VM_DONTCOPY ; vma -> vm_private_data = map ; if ( use_ptemod ) map -> vma = vma ; if ( map -> flags ) { if ( ( vma -> vm_flags & VM_WRITE ) && ( map -> flags & GNTMAP_readonly ) ) goto out_unlock_put ; } else { map -> flags = GNTMAP_host_map ; if ( ! ( vma -> vm_flags & VM_WRITE ) ) map -> flags |= GNTMAP_readonly ; } mutex_unlock ( & priv -> lock ) ; if ( use_ptemod ) { map -> pages_vm_start = vma -> vm_start ; err = apply_to_page_range ( vma -> vm_mm , vma -> vm_start , vma -> vm_end - vma -> vm_start , find_grant_ptes , map ) ; if ( err ) { pr_warn ( "find_grant_ptes()<S2SV_blank>failure.\\n" ) ; goto out_put_map ; } } err = map_grant_pages ( map ) ; if ( err ) goto out_put_map ; if ( ! use_ptemod ) { for ( i = 0 ; i < count ; i ++ ) { err = vm_insert_page ( vma , vma -> vm_start + i * PAGE_SIZE , map -> pages [ i ] ) ; if ( err ) goto out_put_map ; } } else { # ifdef CONFIG_X86 if ( ! xen_feature ( XENFEAT_gnttab_map_avail_bits ) ) { apply_to_page_range ( vma -> vm_mm , vma -> vm_start , vma -> vm_end - vma -> vm_start , set_grant_ptes_as_special , NULL ) ; } # endif } return 0 ; unlock_out : mutex_unlock ( & priv -> lock ) ; return err ; out_unlock_put : mutex_unlock ( & priv -> lock ) ; out_put_map : if ( use_ptemod ) map -> vma = NULL ; gntdev_put_map ( priv , map ) ; return err ; }
static int arc_emac_rx ( struct net_device * ndev , int budget ) { struct arc_emac_priv * priv = netdev_priv ( ndev ) ; unsigned int work_done ; for ( work_done = 0 ; work_done < budget ; work_done ++ ) { unsigned int * last_rx_bd = & priv -> last_rx_bd ; struct net_device_stats * stats = & ndev -> stats ; struct buffer_state * rx_buff = & priv -> rx_buff [ * last_rx_bd ] ; struct arc_emac_bd * rxbd = & priv -> rxbd [ * last_rx_bd ] ; unsigned int pktlen , info = le32_to_cpu ( rxbd -> info ) ; struct sk_buff * skb ; dma_addr_t addr ; if ( unlikely ( ( info & OWN_MASK ) == FOR_EMAC ) ) break ; * last_rx_bd = ( * last_rx_bd + 1 ) % RX_BD_NUM ; if ( unlikely ( ( info & FIRST_OR_LAST_MASK ) != FIRST_OR_LAST_MASK ) ) { if ( net_ratelimit ( ) ) netdev_err ( ndev , "incomplete<S2SV_blank>packet<S2SV_blank>received\\n" ) ; rxbd -> info = cpu_to_le32 ( FOR_EMAC | EMAC_BUFFER_SIZE ) ; stats -> rx_errors ++ ; stats -> rx_length_errors ++ ; continue ; } pktlen = info & LEN_MASK ; stats -> rx_packets ++ ; stats -> rx_bytes += pktlen ; skb = rx_buff -> skb ; skb_put ( skb , pktlen ) ; skb -> dev = ndev ; skb -> protocol = eth_type_trans ( skb , ndev ) ; dma_unmap_single ( & ndev -> dev , dma_unmap_addr ( rx_buff , addr ) , dma_unmap_len ( rx_buff , len ) , DMA_FROM_DEVICE ) ; rx_buff -> skb = netdev_alloc_skb_ip_align ( ndev , EMAC_BUFFER_SIZE ) ; if ( unlikely ( ! rx_buff -> skb ) ) { stats -> rx_errors ++ ; stats -> rx_dropped ++ ; continue ; } netif_receive_skb ( skb ) ; addr = dma_map_single ( & ndev -> dev , ( void * ) rx_buff -> skb -> data , EMAC_BUFFER_SIZE , DMA_FROM_DEVICE ) ; if ( dma_mapping_error ( & ndev -> dev , addr ) ) { if ( net_ratelimit ( ) ) netdev_err ( ndev , "cannot<S2SV_blank>dma<S2SV_blank>map\\n" ) ; dev_kfree_skb ( rx_buff -> skb ) ; stats -> rx_errors ++ ; continue ; } dma_unmap_addr_set ( rx_buff , addr , addr ) ; dma_unmap_len_set ( rx_buff , len , EMAC_BUFFER_SIZE ) ; rxbd -> data = cpu_to_le32 ( addr ) ; wmb ( ) ; rxbd -> info = cpu_to_le32 ( FOR_EMAC | EMAC_BUFFER_SIZE ) ; } return work_done ; }
static __be32 * read_buf ( struct nfsd4_compoundargs * argp , u32 nbytes ) { unsigned int avail = ( char * ) argp -> end - ( char * ) argp -> p ; __be32 * p ; if ( avail + argp -> pagelen < nbytes ) return NULL ; if ( avail + PAGE_SIZE < nbytes ) return NULL ; if ( nbytes <= sizeof ( argp -> tmp ) ) p = argp -> tmp ; else { kfree ( argp -> tmpp ) ; p = argp -> tmpp = kmalloc ( nbytes , GFP_KERNEL ) ; if ( ! p ) return NULL ; } memcpy ( p , argp -> p , avail ) ; argp -> p = page_address ( argp -> pagelist [ 0 ] ) ; argp -> pagelist ++ ; if ( argp -> pagelen < PAGE_SIZE ) { argp -> end = argp -> p + ( argp -> pagelen >> 2 ) ; argp -> pagelen = 0 ; } else { argp -> end = argp -> p + ( PAGE_SIZE >> 2 ) ; argp -> pagelen -= PAGE_SIZE ; } memcpy ( ( ( char * ) p ) + avail , argp -> p , ( nbytes - avail ) ) ; argp -> p += XDR_QUADLEN ( nbytes - avail ) ; return p ; }
int cpuidle_add_sysfs ( struct cpuidle_device * dev ) { struct cpuidle_device_kobj * kdev ; struct device * cpu_dev = get_cpu_device ( ( unsigned long ) dev -> cpu ) ; int error ; kdev = kzalloc ( sizeof ( * kdev ) , GFP_KERNEL ) ; if ( ! kdev ) return - ENOMEM ; kdev -> dev = dev ; dev -> kobj_dev = kdev ; init_completion ( & kdev -> kobj_unregister ) ; error = kobject_init_and_add ( & kdev -> kobj , & ktype_cpuidle , & cpu_dev -> kobj , "cpuidle" ) ; if ( error ) { kfree ( kdev ) ; return error ; } kobject_uevent ( & kdev -> kobj , KOBJ_ADD ) ; return 0 ; }
DEFUN ( config_end , config_end_cmd , "end" , "End<S2SV_blank>current<S2SV_blank>mode<S2SV_blank>and<S2SV_blank>change<S2SV_blank>to<S2SV_blank>enable<S2SV_blank>mode.\\n" ) { switch ( vty -> node ) { case VIEW_NODE : case ENABLE_NODE : break ; case CONFIG_NODE : case INTERFACE_NODE : case PW_NODE : case LOGICALROUTER_NODE : case VRF_NODE : case NH_GROUP_NODE : case ZEBRA_NODE : case RIP_NODE : case RIPNG_NODE : case EIGRP_NODE : case BABEL_NODE : case BGP_NODE : case BGP_VRF_POLICY_NODE : case BGP_VNC_DEFAULTS_NODE : case BGP_VNC_NVE_GROUP_NODE : case BGP_VNC_L2_GROUP_NODE : case BGP_VPNV4_NODE : case BGP_VPNV6_NODE : case BGP_FLOWSPECV4_NODE : case BGP_FLOWSPECV6_NODE : case BGP_IPV4_NODE : case BGP_IPV4M_NODE : case BGP_IPV4L_NODE : case BGP_IPV6_NODE : case BGP_IPV6M_NODE : case BGP_EVPN_NODE : case BGP_EVPN_VNI_NODE : case BGP_IPV6L_NODE : case RMAP_NODE : case OSPF_NODE : case OSPF6_NODE : case LDP_NODE : case LDP_IPV4_NODE : case LDP_IPV6_NODE : case LDP_IPV4_IFACE_NODE : case LDP_IPV6_IFACE_NODE : case LDP_L2VPN_NODE : case LDP_PSEUDOWIRE_NODE : case ISIS_NODE : case KEYCHAIN_NODE : case KEYCHAIN_KEY_NODE : case VTY_NODE : case LINK_PARAMS_NODE : vty_config_unlock ( vty ) ; vty -> node = ENABLE_NODE ; break ; default : break ; } return CMD_SUCCESS ; }
static int __acpi_processor_start ( struct acpi_device * device ) { struct acpi_processor * pr = acpi_driver_data ( device ) ; acpi_status status ; int result = 0 ; if ( ! pr ) return - ENODEV ; if ( pr -> flags . need_hotplug_init ) return 0 ; result = acpi_cppc_processor_probe ( pr ) ; if ( result ) return - ENODEV ; if ( ! cpuidle_get_driver ( ) || cpuidle_get_driver ( ) == & acpi_idle_driver ) acpi_processor_power_init ( pr ) ; result = acpi_pss_perf_init ( pr , device ) ; if ( result ) goto err_power_exit ; status = acpi_install_notify_handler ( device -> handle , ACPI_DEVICE_NOTIFY , acpi_processor_notify , device ) ; if ( ACPI_SUCCESS ( status ) ) return 0 ; result = - ENODEV ; acpi_pss_perf_exit ( pr , device ) ; err_power_exit : acpi_processor_power_exit ( pr ) ; return result ; }
int acpi_processor_cst_has_changed ( struct acpi_processor * pr ) { int cpu ; struct acpi_processor * _pr ; struct cpuidle_device * dev ; if ( disabled_by_idle_boot_param ( ) ) return 0 ; if ( nocst ) return - ENODEV ; if ( ! pr -> flags . power_setup_done ) return - ENODEV ; if ( pr -> id == 0 && cpuidle_get_driver ( ) == & acpi_idle_driver ) { get_online_cpus ( ) ; cpuidle_pause_and_lock ( ) ; for_each_online_cpu ( cpu ) { _pr = per_cpu ( processors , cpu ) ; if ( ! _pr || ! _pr -> flags . power_setup_done ) continue ; dev = per_cpu ( acpi_cpuidle_device , cpu ) ; cpuidle_disable_device ( dev ) ; } acpi_processor_get_power_info ( pr ) ; acpi_processor_setup_cpuidle_states ( pr ) ; for_each_online_cpu ( cpu ) { _pr = per_cpu ( processors , cpu ) ; if ( ! _pr || ! _pr -> flags . power_setup_done ) continue ; acpi_processor_get_power_info ( _pr ) ; if ( _pr -> flags . power ) { dev = per_cpu ( acpi_cpuidle_device , cpu ) ; acpi_processor_setup_cpuidle_cx ( _pr , dev ) ; cpuidle_enable_device ( dev ) ; } } cpuidle_resume_and_unlock ( ) ; put_online_cpus ( ) ; } return 0 ; }
int cpuidle_add_sysfs ( struct cpuidle_device * dev ) { struct cpuidle_device_kobj * kdev ; struct device * cpu_dev = get_cpu_device ( ( unsigned long ) dev -> cpu ) ; int error ; kdev = kzalloc ( sizeof ( * kdev ) , GFP_KERNEL ) ; if ( ! kdev ) return - ENOMEM ; kdev -> dev = dev ; dev -> kobj_dev = kdev ; init_completion ( & kdev -> kobj_unregister ) ; error = kobject_init_and_add ( & kdev -> kobj , & ktype_cpuidle , & cpu_dev -> kobj , "cpuidle" ) ; if ( error ) { kfree ( kdev ) ; return error ; } kobject_uevent ( & kdev -> kobj , KOBJ_ADD ) ; return 0 ; }
static void parse_ddi_port ( struct drm_i915_private * dev_priv , enum port port , u8 bdb_version ) { struct child_device_config * it , * child = NULL ; struct ddi_vbt_port_info * info = & dev_priv -> vbt . ddi_port_info [ port ] ; uint8_t hdmi_level_shift ; int i , j ; bool is_dvi , is_hdmi , is_dp , is_edp , is_crt ; uint8_t aux_channel , ddc_pin ; int dvo_ports [ ] [ 3 ] = { { DVO_PORT_HDMIA , DVO_PORT_DPA , - 1 } , { DVO_PORT_HDMIB , DVO_PORT_DPB , - 1 } , { DVO_PORT_HDMIC , DVO_PORT_DPC , - 1 } , { DVO_PORT_HDMID , DVO_PORT_DPD , - 1 } , { DVO_PORT_CRT , DVO_PORT_HDMIE , DVO_PORT_DPE } , { DVO_PORT_HDMIF , DVO_PORT_DPF , - 1 } , } ; for ( i = 0 ; i < dev_priv -> vbt . child_dev_num ; i ++ ) { it = dev_priv -> vbt . child_dev + i ; for ( j = 0 ; j < 3 ; j ++ ) { if ( dvo_ports [ port ] [ j ] == - 1 ) break ; if ( it -> dvo_port == dvo_ports [ port ] [ j ] ) { if ( child ) { DRM_DEBUG_KMS ( "More<S2SV_blank>than<S2SV_blank>one<S2SV_blank>child<S2SV_blank>device<S2SV_blank>for<S2SV_blank>port<S2SV_blank>%c<S2SV_blank>in<S2SV_blank>VBT,<S2SV_blank>using<S2SV_blank>the<S2SV_blank>first.\\n" , port_name ( port ) ) ; } else { child = it ; } } } } if ( ! child ) return ; aux_channel = child -> aux_channel ; ddc_pin = child -> ddc_pin ; is_dvi = child -> device_type & DEVICE_TYPE_TMDS_DVI_SIGNALING ; is_dp = child -> device_type & DEVICE_TYPE_DISPLAYPORT_OUTPUT ; is_crt = child -> device_type & DEVICE_TYPE_ANALOG_OUTPUT ; is_hdmi = is_dvi && ( child -> device_type & DEVICE_TYPE_NOT_HDMI_OUTPUT ) == 0 ; is_edp = is_dp && ( child -> device_type & DEVICE_TYPE_INTERNAL_CONNECTOR ) ; if ( port == PORT_A && is_dvi ) { DRM_DEBUG_KMS ( "VBT<S2SV_blank>claims<S2SV_blank>port<S2SV_blank>A<S2SV_blank>supports<S2SV_blank>DVI%s,<S2SV_blank>ignoring\\n" , is_hdmi ? "/HDMI" : "" ) ; is_dvi = false ; is_hdmi = false ; } info -> supports_dvi = is_dvi ; info -> supports_hdmi = is_hdmi ; info -> supports_dp = is_dp ; info -> supports_edp = is_edp ; DRM_DEBUG_KMS ( "Port<S2SV_blank>%c<S2SV_blank>VBT<S2SV_blank>info:<S2SV_blank>DP:%d<S2SV_blank>HDMI:%d<S2SV_blank>DVI:%d<S2SV_blank>EDP:%d<S2SV_blank>CRT:%d\\n" , port_name ( port ) , is_dp , is_hdmi , is_dvi , is_edp , is_crt ) ; if ( is_edp && is_dvi ) DRM_DEBUG_KMS ( "Internal<S2SV_blank>DP<S2SV_blank>port<S2SV_blank>%c<S2SV_blank>is<S2SV_blank>TMDS<S2SV_blank>compatible\\n" , port_name ( port ) ) ; if ( is_crt && port != PORT_E ) DRM_DEBUG_KMS ( "Port<S2SV_blank>%c<S2SV_blank>is<S2SV_blank>analog\\n" , port_name ( port ) ) ; if ( is_crt && ( is_dvi || is_dp ) ) DRM_DEBUG_KMS ( "Analog<S2SV_blank>port<S2SV_blank>%c<S2SV_blank>is<S2SV_blank>also<S2SV_blank>DP<S2SV_blank>or<S2SV_blank>TMDS<S2SV_blank>compatible\\n" , port_name ( port ) ) ; if ( is_dvi && ( port == PORT_A || port == PORT_E ) ) DRM_DEBUG_KMS ( "Port<S2SV_blank>%c<S2SV_blank>is<S2SV_blank>TMDS<S2SV_blank>compatible\\n" , port_name ( port ) ) ; if ( ! is_dvi && ! is_dp && ! is_crt ) DRM_DEBUG_KMS ( "Port<S2SV_blank>%c<S2SV_blank>is<S2SV_blank>not<S2SV_blank>DP/TMDS/CRT<S2SV_blank>compatible\\n" , port_name ( port ) ) ; if ( is_edp && ( port == PORT_B || port == PORT_C || port == PORT_E ) ) DRM_DEBUG_KMS ( "Port<S2SV_blank>%c<S2SV_blank>is<S2SV_blank>internal<S2SV_blank>DP\\n" , port_name ( port ) ) ; if ( is_dvi ) { info -> alternate_ddc_pin = map_ddc_pin ( dev_priv , ddc_pin ) ; sanitize_ddc_pin ( dev_priv , port ) ; } if ( is_dp ) { info -> alternate_aux_channel = aux_channel ; sanitize_aux_ch ( dev_priv , port ) ; } if ( bdb_version >= 158 ) { hdmi_level_shift = child -> hdmi_level_shifter_value ; DRM_DEBUG_KMS ( "VBT<S2SV_blank>HDMI<S2SV_blank>level<S2SV_blank>shift<S2SV_blank>for<S2SV_blank>port<S2SV_blank>%c:<S2SV_blank>%d\\n" , port_name ( port ) , hdmi_level_shift ) ; info -> hdmi_level_shift = hdmi_level_shift ; } if ( bdb_version >= 204 ) { int max_tmds_clock ; switch ( child -> hdmi_max_data_rate ) { default : MISSING_CASE ( child -> hdmi_max_data_rate ) ; case HDMI_MAX_DATA_RATE_PLATFORM : max_tmds_clock = 0 ; break ; case HDMI_MAX_DATA_RATE_297 : max_tmds_clock = 297000 ; break ; case HDMI_MAX_DATA_RATE_165 : max_tmds_clock = 165000 ; break ; } if ( max_tmds_clock ) DRM_DEBUG_KMS ( "VBT<S2SV_blank>HDMI<S2SV_blank>max<S2SV_blank>TMDS<S2SV_blank>clock<S2SV_blank>for<S2SV_blank>port<S2SV_blank>%c:<S2SV_blank>%d<S2SV_blank>kHz\\n" , port_name ( port ) , max_tmds_clock ) ; info -> max_tmds_clock = max_tmds_clock ; } if ( bdb_version >= 196 && child -> iboost ) { info -> dp_boost_level = translate_iboost ( child -> dp_iboost_level ) ; DRM_DEBUG_KMS ( "VBT<S2SV_blank>(e)DP<S2SV_blank>boost<S2SV_blank>level<S2SV_blank>for<S2SV_blank>port<S2SV_blank>%c:<S2SV_blank>%d\\n" , port_name ( port ) , info -> dp_boost_level ) ; info -> hdmi_boost_level = translate_iboost ( child -> hdmi_iboost_level ) ; DRM_DEBUG_KMS ( "VBT<S2SV_blank>HDMI<S2SV_blank>boost<S2SV_blank>level<S2SV_blank>for<S2SV_blank>port<S2SV_blank>%c:<S2SV_blank>%d\\n" , port_name ( port ) , info -> hdmi_boost_level ) ; } if ( bdb_version >= 216 ) { switch ( child -> dp_max_link_rate ) { default : case VBT_DP_MAX_LINK_RATE_HBR3 : info -> dp_max_link_rate = 810000 ; break ; case VBT_DP_MAX_LINK_RATE_HBR2 : info -> dp_max_link_rate = 540000 ; break ; case VBT_DP_MAX_LINK_RATE_HBR : info -> dp_max_link_rate = 270000 ; break ; case VBT_DP_MAX_LINK_RATE_LBR : info -> dp_max_link_rate = 162000 ; break ; } DRM_DEBUG_KMS ( "VBT<S2SV_blank>DP<S2SV_blank>max<S2SV_blank>link<S2SV_blank>rate<S2SV_blank>for<S2SV_blank>port<S2SV_blank>%c:<S2SV_blank>%d\\n" , port_name ( port ) , info -> dp_max_link_rate ) ; } }
int nx_fw_cmd_set_mtu ( struct netxen_adapter * adapter , int mtu ) { u32 rcode = NX_RCODE_SUCCESS ; struct netxen_recv_context * recv_ctx = & adapter -> recv_ctx ; struct netxen_cmd_args cmd ; memset ( & cmd , 0 , sizeof ( cmd ) ) ; cmd . req . cmd = NX_CDRP_CMD_SET_MTU ; cmd . req . arg1 = recv_ctx -> context_id ; cmd . req . arg2 = mtu ; cmd . req . arg3 = 0 ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) netxen_issue_cmd ( adapter , & cmd ) ; if ( rcode != NX_RCODE_SUCCESS ) return - EIO ; return 0 ; }
void * Hunk_Alloc ( int size , ha_pref preference ) { # endif void * buf ; if ( s_hunkData == NULL ) { Com_Error ( ERR_FATAL , "Hunk_Alloc:<S2SV_blank>Hunk<S2SV_blank>memory<S2SV_blank>system<S2SV_blank>not<S2SV_blank>initialized" ) ; } if ( preference == h_dontcare || hunk_temp -> temp != hunk_temp -> permanent ) { Hunk_SwapBanks ( ) ; } else { if ( preference == h_low && hunk_permanent != & hunk_low ) { Hunk_SwapBanks ( ) ; } else if ( preference == h_high && hunk_permanent != & hunk_high ) { Hunk_SwapBanks ( ) ; } } # ifdef HUNK_DEBUG size += sizeof ( hunkblock_t ) ; # endif size = ( size + 31 ) & ~ 31 ; if ( hunk_low . temp + hunk_high . temp + size > s_hunkTotal ) { # ifdef HUNK_DEBUG Hunk_Log ( ) ; Hunk_SmallLog ( ) ; Com_Error ( ERR_DROP , "Hunk_Alloc<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>%i:<S2SV_blank>%s,<S2SV_blank>line:<S2SV_blank>%d<S2SV_blank>(%s)" , size , file , line , label ) ; # else Com_Error ( ERR_DROP , "Hunk_Alloc<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>%i" , size ) ; # endif } if ( hunk_permanent == & hunk_low ) { buf = ( void * ) ( s_hunkData + hunk_permanent -> permanent ) ; hunk_permanent -> permanent += size ; } else { hunk_permanent -> permanent += size ; buf = ( void * ) ( s_hunkData + s_hunkTotal - hunk_permanent -> permanent ) ; } hunk_permanent -> temp = hunk_permanent -> permanent ; Com_Memset ( buf , 0 , size ) ; # ifdef HUNK_DEBUG { hunkblock_t * block ; block = ( hunkblock_t * ) buf ; block -> size = size - sizeof ( hunkblock_t ) ; block -> file = file ; block -> label = label ; block -> line = line ; block -> next = hunkblocks ; hunkblocks = block ; buf = ( ( byte * ) buf ) + sizeof ( hunkblock_t ) ; } # endif return buf ; }
void * Hunk_AllocateTempMemory ( int size ) { void * buf ; hunkHeader_t * hdr ; if ( s_hunkData == NULL ) { return Z_Malloc ( size ) ; } Hunk_SwapBanks ( ) ; size = PAD ( size , sizeof ( intptr_t ) ) + sizeof ( hunkHeader_t ) ; if ( hunk_temp -> temp + hunk_permanent -> permanent + size > s_hunkTotal ) { Com_Error ( ERR_DROP , "Hunk_AllocateTempMemory:<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>%i" , size ) ; } if ( hunk_temp == & hunk_low ) { buf = ( void * ) ( s_hunkData + hunk_temp -> temp ) ; hunk_temp -> temp += size ; } else { hunk_temp -> temp += size ; buf = ( void * ) ( s_hunkData + s_hunkTotal - hunk_temp -> temp ) ; } if ( hunk_temp -> temp > hunk_temp -> tempHighwater ) { hunk_temp -> tempHighwater = hunk_temp -> temp ; } hdr = ( hunkHeader_t * ) buf ; buf = ( void * ) ( hdr + 1 ) ; hdr -> magic = HUNK_MAGIC ; hdr -> size = size ; return buf ; }
void * Z_TagMalloc ( int size , int tag ) { # endif int extra ; memblock_t * start , * rover , * new , * base ; memzone_t * zone ; if ( ! tag ) { Com_Error ( ERR_FATAL , "Z_TagMalloc:<S2SV_blank>tried<S2SV_blank>to<S2SV_blank>use<S2SV_blank>a<S2SV_blank>0<S2SV_blank>tag" ) ; } zone = Z_ZoneForTag ( tag ) ; # ifdef ZONE_DEBUG allocSize = size ; # endif size += sizeof ( memblock_t ) ; size += 4 ; size = PAD ( size , sizeof ( intptr_t ) ) ; base = rover = zone -> rover ; start = base -> prev ; do { if ( rover == start ) { # ifdef ZONE_DEBUG Z_LogHeap ( ) ; Com_Error ( ERR_FATAL , "Z_Malloc:<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>allocation<S2SV_blank>of<S2SV_blank>%i<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>the<S2SV_blank>%s<S2SV_blank>zone:<S2SV_blank>%s,<S2SV_blank>line:<S2SV_blank>%d<S2SV_blank>(%s)" , size , Z_NameForZone ( zone ) , file , line , label ) ; # else Com_Error ( ERR_FATAL , "Z_Malloc:<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>allocation<S2SV_blank>of<S2SV_blank>%i<S2SV_blank>bytes<S2SV_blank>from<S2SV_blank>the<S2SV_blank>%s<S2SV_blank>zone" , size , Z_NameForZone ( zone ) ) ; # endif return NULL ; } if ( rover -> tag ) { base = rover = rover -> next ; } else { rover = rover -> next ; } } while ( base -> tag || base -> size < size ) ; extra = base -> size - size ; if ( extra > MINFRAGMENT ) { new = ( memblock_t * ) ( ( byte * ) base + size ) ; new -> size = extra ; new -> tag = 0 ; new -> prev = base ; new -> id = ZONEID ; new -> next = base -> next ; new -> next -> prev = new ; base -> next = new ; base -> size = size ; } base -> tag = tag ; zone -> rover = base -> next ; zone -> used += base -> size ; base -> id = ZONEID ; # ifdef ZONE_DEBUG base -> d . label = label ; base -> d . file = file ; base -> d . line = line ; base -> d . allocSize = allocSize ; # endif * ( int * ) ( ( byte * ) base + base -> size - 4 ) = ZONEID ; return ( void * ) ( ( byte * ) base + sizeof ( memblock_t ) ) ; }
static ssize_t ufs_qcom_dbg_testbus_cfg_write ( struct file * file , const char __user * ubuf , size_t cnt , loff_t * ppos ) { struct ufs_qcom_host * host = file -> f_mapping -> host -> i_private ; char configuration [ TESTBUS_CFG_BUFF_LINE_SIZE ] = { 0 } ; loff_t buff_pos = 0 ; char * comma ; int ret = 0 ; int major ; int minor ; ret = simple_write_to_buffer ( configuration , TESTBUS_CFG_BUFF_LINE_SIZE , & buff_pos , ubuf , cnt ) ; if ( ret < 0 ) { dev_err ( host -> hba -> dev , "%s:<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>user<S2SV_blank>data\\n" , __func__ ) ; goto out ; } comma = strnchr ( configuration , TESTBUS_CFG_BUFF_LINE_SIZE , ',' ) ; if ( ! comma || comma == configuration ) { dev_err ( host -> hba -> dev , "%s:<S2SV_blank>error<S2SV_blank>in<S2SV_blank>configuration<S2SV_blank>of<S2SV_blank>testbus\\n" , __func__ ) ; ret = - EINVAL ; goto out ; } if ( sscanf ( configuration , "%i,%i" , & major , & minor ) != 2 ) { dev_err ( host -> hba -> dev , "%s:<S2SV_blank>couldn\'t<S2SV_blank>parse<S2SV_blank>input<S2SV_blank>to<S2SV_blank>2<S2SV_blank>numeric<S2SV_blank>values\\n" , __func__ ) ; ret = - EINVAL ; goto out ; } host -> testbus . select_major = ( u8 ) major ; host -> testbus . select_minor = ( u8 ) minor ; ret = ufs_qcom_testbus_config ( host ) ; if ( ! ret ) dev_dbg ( host -> hba -> dev , "%s:<S2SV_blank>New<S2SV_blank>configuration:<S2SV_blank>major=%d,<S2SV_blank>minor=%d\\n" , __func__ , host -> testbus . select_major , host -> testbus . select_minor ) ; out : return ret ? ret : cnt ; }
int nx_fw_cmd_set_mtu ( struct netxen_adapter * adapter , int mtu ) { u32 rcode = NX_RCODE_SUCCESS ; struct netxen_recv_context * recv_ctx = & adapter -> recv_ctx ; struct netxen_cmd_args cmd ; memset ( & cmd , 0 , sizeof ( cmd ) ) ; cmd . req . cmd = NX_CDRP_CMD_SET_MTU ; cmd . req . arg1 = recv_ctx -> context_id ; cmd . req . arg2 = mtu ; cmd . req . arg3 = 0 ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) netxen_issue_cmd ( adapter , & cmd ) ; if ( rcode != NX_RCODE_SUCCESS ) return - EIO ; return 0 ; }
SYSCALL_DEFINE2 ( mq_notify , mqd_t , mqdes , const struct sigevent __user * , u_notification ) { int ret ; struct fd f ; struct sock * sock ; struct inode * inode ; struct sigevent notification ; struct mqueue_inode_info * info ; struct sk_buff * nc ; if ( u_notification ) { if ( copy_from_user ( & notification , u_notification , sizeof ( struct sigevent ) ) ) return - EFAULT ; } audit_mq_notify ( mqdes , u_notification ? & notification : NULL ) ; nc = NULL ; sock = NULL ; if ( u_notification != NULL ) { if ( unlikely ( notification . sigev_notify != SIGEV_NONE && notification . sigev_notify != SIGEV_SIGNAL && notification . sigev_notify != SIGEV_THREAD ) ) return - EINVAL ; if ( notification . sigev_notify == SIGEV_SIGNAL && ! valid_signal ( notification . sigev_signo ) ) { return - EINVAL ; } if ( notification . sigev_notify == SIGEV_THREAD ) { long timeo ; nc = alloc_skb ( NOTIFY_COOKIE_LEN , GFP_KERNEL ) ; if ( ! nc ) { ret = - ENOMEM ; goto out ; } if ( copy_from_user ( nc -> data , notification . sigev_value . sival_ptr , NOTIFY_COOKIE_LEN ) ) { ret = - EFAULT ; goto out ; } skb_put ( nc , NOTIFY_COOKIE_LEN ) ; retry : f = fdget ( notification . sigev_signo ) ; if ( ! f . file ) { ret = - EBADF ; goto out ; } sock = netlink_getsockbyfilp ( f . file ) ; fdput ( f ) ; if ( IS_ERR ( sock ) ) { ret = PTR_ERR ( sock ) ; sock = NULL ; goto out ; } timeo = MAX_SCHEDULE_TIMEOUT ; ret = netlink_attachskb ( sock , nc , & timeo , NULL ) ; if ( ret == 1 ) goto retry ; if ( ret ) { sock = NULL ; nc = NULL ; goto out ; } } } f = fdget ( mqdes ) ; if ( ! f . file ) { ret = - EBADF ; goto out ; } inode = file_inode ( f . file ) ; if ( unlikely ( f . file -> f_op != & mqueue_file_operations ) ) { ret = - EBADF ; goto out_fput ; } info = MQUEUE_I ( inode ) ; ret = 0 ; spin_lock ( & info -> lock ) ; if ( u_notification == NULL ) { if ( info -> notify_owner == task_tgid ( current ) ) { remove_notification ( info ) ; inode -> i_atime = inode -> i_ctime = CURRENT_TIME ; } } else if ( info -> notify_owner != NULL ) { ret = - EBUSY ; } else { switch ( notification . sigev_notify ) { case SIGEV_NONE : info -> notify . sigev_notify = SIGEV_NONE ; break ; case SIGEV_THREAD : info -> notify_sock = sock ; info -> notify_cookie = nc ; sock = NULL ; nc = NULL ; info -> notify . sigev_notify = SIGEV_THREAD ; break ; case SIGEV_SIGNAL : info -> notify . sigev_signo = notification . sigev_signo ; info -> notify . sigev_value = notification . sigev_value ; info -> notify . sigev_notify = SIGEV_SIGNAL ; break ; } info -> notify_owner = get_pid ( task_tgid ( current ) ) ; info -> notify_user_ns = get_user_ns ( current_user_ns ( ) ) ; inode -> i_atime = inode -> i_ctime = CURRENT_TIME ; } spin_unlock ( & info -> lock ) ; out_fput : fdput ( f ) ; out : if ( sock ) netlink_detachskb ( sock , nc ) ; else if ( nc ) dev_kfree_skb ( nc ) ; return ret ; }
int nx_fw_cmd_set_mtu ( struct netxen_adapter * adapter , int mtu ) { u32 rcode = NX_RCODE_SUCCESS ; struct netxen_recv_context * recv_ctx = & adapter -> recv_ctx ; struct netxen_cmd_args cmd ; memset ( & cmd , 0 , sizeof ( cmd ) ) ; cmd . req . cmd = NX_CDRP_CMD_SET_MTU ; cmd . req . arg1 = recv_ctx -> context_id ; cmd . req . arg2 = mtu ; cmd . req . arg3 = 0 ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) netxen_issue_cmd ( adapter , & cmd ) ; if ( rcode != NX_RCODE_SUCCESS ) return - EIO ; return 0 ; }
static int fname_encrypt ( struct inode * inode , const struct qstr * iname , struct fscrypt_str * oname ) { struct ablkcipher_request * req = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct fscrypt_info * ci = inode -> i_crypt_info ; struct crypto_ablkcipher * tfm = ci -> ci_ctfm ; int res = 0 ; char iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; int padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; unsigned int lim ; unsigned int cryptlen ; lim = inode -> i_sb -> s_cop -> max_namelen ( inode ) ; if ( iname -> len <= 0 || iname -> len > lim ) return - EIO ; cryptlen = max_t ( unsigned int , iname -> len , FS_CRYPTO_BLOCK_SIZE ) ; cryptlen = round_up ( cryptlen , padding ) ; cryptlen = min ( cryptlen , lim ) ; memcpy ( oname -> name , iname -> name , iname -> len ) ; memset ( oname -> name + iname -> len , 0 , cryptlen - iname -> len ) ; memset ( iv , 0 , FS_CRYPTO_BLOCK_SIZE ) ; req = ablkcipher_request_alloc ( tfm , GFP_NOFS ) ; if ( ! req ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>ablkcipher_request_alloc()<S2SV_blank>failed\\n" , __func__ ) ; return - ENOMEM ; } ablkcipher_request_set_callback ( req , CRYPTO_TFM_REQ_MAY_BACKLOG | CRYPTO_TFM_REQ_MAY_SLEEP , crypto_req_done , & wait ) ; sg_init_one ( & sg , oname -> name , cryptlen ) ; ablkcipher_request_set_crypt ( req , & sg , & sg , cryptlen , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt ( req ) , & wait ) ; ablkcipher_request_free ( req ) ; if ( res < 0 ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>Error<S2SV_blank>(error<S2SV_blank>code<S2SV_blank>%d)\\n" , __func__ , res ) ; return res ; } oname -> len = cryptlen ; return 0 ; }
int fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 ilen , struct fscrypt_str * crypto_str ) { u32 olen = fscrypt_fname_encrypted_size ( inode , ilen ) ; const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) , 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) ; crypto_str -> len = olen ; olen = max ( olen , max_encoded_len ) ; crypto_str -> name = kmalloc ( olen + 1 , GFP_NOFS ) ; if ( ! ( crypto_str -> name ) ) return - ENOMEM ; return 0 ; }
u32 fscrypt_fname_encrypted_size ( const struct inode * inode , u32 ilen ) { int padding = 32 ; struct fscrypt_info * ci = inode -> i_crypt_info ; if ( ci ) padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; ilen = max ( ilen , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; return round_up ( ilen , padding ) ; }
int fscrypt_setup_filename ( struct inode * dir , const struct qstr * iname , int lookup , struct fscrypt_name * fname ) { int ret ; int digested ; memset ( fname , 0 , sizeof ( struct fscrypt_name ) ) ; fname -> usr_fname = iname ; if ( ! IS_ENCRYPTED ( dir ) || fscrypt_is_dot_dotdot ( iname ) ) { fname -> disk_name . name = ( unsigned char * ) iname -> name ; fname -> disk_name . len = iname -> len ; return 0 ; } ret = fscrypt_get_encryption_info ( dir ) ; if ( ret && ret != - EOPNOTSUPP ) return ret ; if ( dir -> i_crypt_info ) { ret = fscrypt_fname_alloc_buffer ( dir , iname -> len , & fname -> crypto_buf ) ; if ( ret ) return ret ; ret = fname_encrypt ( dir , iname , & fname -> crypto_buf ) ; if ( ret ) goto errout ; fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; return 0 ; } if ( ! lookup ) return - ENOKEY ; if ( iname -> name [ 0 ] == '_' ) { if ( iname -> len != 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) return - ENOENT ; digested = 1 ; } else { if ( iname -> len > BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) ) return - ENOENT ; digested = 0 ; } fname -> crypto_buf . name = kmalloc ( max_t ( size_t , FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE , sizeof ( struct fscrypt_digested_name ) ) , GFP_KERNEL ) ; if ( fname -> crypto_buf . name == NULL ) return - ENOMEM ; ret = digest_decode ( iname -> name + digested , iname -> len - digested , fname -> crypto_buf . name ) ; if ( ret < 0 ) { ret = - ENOENT ; goto errout ; } fname -> crypto_buf . len = ret ; if ( digested ) { const struct fscrypt_digested_name * n = ( const void * ) fname -> crypto_buf . name ; fname -> hash = n -> hash ; fname -> minor_hash = n -> minor_hash ; } else { fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; } return 0 ; errout : fscrypt_fname_free_buffer ( & fname -> crypto_buf ) ; return ret ; }
int nx_fw_cmd_set_mtu ( struct netxen_adapter * adapter , int mtu ) { u32 rcode = NX_RCODE_SUCCESS ; struct netxen_recv_context * recv_ctx = & adapter -> recv_ctx ; struct netxen_cmd_args cmd ; memset ( & cmd , 0 , sizeof ( cmd ) ) ; cmd . req . cmd = NX_CDRP_CMD_SET_MTU ; cmd . req . arg1 = recv_ctx -> context_id ; cmd . req . arg2 = mtu ; cmd . req . arg3 = 0 ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) netxen_issue_cmd ( adapter , & cmd ) ; if ( rcode != NX_RCODE_SUCCESS ) return - EIO ; return 0 ; }
static void handle_audio_frame ( struct mp_filter * f ) { struct priv * p = f -> priv ; struct mp_aframe * aframe = p -> sub . frame . data ; int afmt = mp_aframe_get_format ( aframe ) ; int srate = mp_aframe_get_rate ( aframe ) ; struct mp_chmap chmap = { 0 } ; mp_aframe_get_chmap ( aframe , & chmap ) ; if ( afmt == p -> in_afmt && srate == p -> in_srate && mp_chmap_equals ( & chmap , & p -> in_chmap ) && ( ! p -> resampling_forced || p -> sub . filter ) && ! p -> force_update ) { goto cont ; } if ( ! mp_subfilter_drain_destroy ( & p -> sub ) ) return ; p -> in_afmt = afmt ; p -> in_srate = srate ; p -> in_chmap = chmap ; p -> force_update = false ; int out_afmt = 0 ; int best_score = 0 ; for ( int n = 0 ; n < p -> num_afmts ; n ++ ) { int score = af_format_conversion_score ( p -> afmts [ n ] , afmt ) ; if ( ! out_afmt || score > best_score ) { best_score = score ; out_afmt = p -> afmts [ n ] ; } } if ( ! out_afmt ) out_afmt = afmt ; int out_srate = af_select_best_samplerate ( srate , p -> srates ) ; if ( out_srate <= 0 ) out_srate = p -> num_srates ? p -> srates [ 0 ] : srate ; struct mp_chmap out_chmap = chmap ; if ( p -> chmaps . num_chmaps ) { if ( ! mp_chmap_sel_adjust ( & p -> chmaps , & out_chmap ) ) out_chmap = p -> chmaps . chmaps [ 0 ] ; } if ( out_afmt == p -> in_afmt && out_srate == p -> in_srate && mp_chmap_equals ( & out_chmap , & p -> in_chmap ) && ! p -> resampling_forced ) { goto cont ; } MP_VERBOSE ( p , "inserting<S2SV_blank>resampler\\n" ) ; struct mp_swresample * s = mp_swresample_create ( f , NULL ) ; if ( ! s ) abort ( ) ; s -> out_format = out_afmt ; s -> out_rate = out_srate ; s -> out_channels = out_chmap ; p -> sub . filter = s -> f ; cont : if ( p -> sub . filter ) { struct mp_filter_command cmd = { . type = MP_FILTER_COMMAND_SET_SPEED_RESAMPLE , . speed = p -> audio_speed , } ; mp_filter_command ( p -> sub . filter , & cmd ) ; } mp_subfilter_continue ( & p -> sub ) ; }
static void reset ( struct mp_filter * f ) { struct priv * p = f -> priv ; mp_subfilter_reset ( & p -> sub ) ; }
static int fname_encrypt ( struct inode * inode , const struct qstr * iname , struct fscrypt_str * oname ) { struct ablkcipher_request * req = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct fscrypt_info * ci = inode -> i_crypt_info ; struct crypto_ablkcipher * tfm = ci -> ci_ctfm ; int res = 0 ; char iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; int padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; unsigned int lim ; unsigned int cryptlen ; lim = inode -> i_sb -> s_cop -> max_namelen ( inode ) ; if ( iname -> len <= 0 || iname -> len > lim ) return - EIO ; cryptlen = max_t ( unsigned int , iname -> len , FS_CRYPTO_BLOCK_SIZE ) ; cryptlen = round_up ( cryptlen , padding ) ; cryptlen = min ( cryptlen , lim ) ; memcpy ( oname -> name , iname -> name , iname -> len ) ; memset ( oname -> name + iname -> len , 0 , cryptlen - iname -> len ) ; memset ( iv , 0 , FS_CRYPTO_BLOCK_SIZE ) ; req = ablkcipher_request_alloc ( tfm , GFP_NOFS ) ; if ( ! req ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>ablkcipher_request_alloc()<S2SV_blank>failed\\n" , __func__ ) ; return - ENOMEM ; } ablkcipher_request_set_callback ( req , CRYPTO_TFM_REQ_MAY_BACKLOG | CRYPTO_TFM_REQ_MAY_SLEEP , crypto_req_done , & wait ) ; sg_init_one ( & sg , oname -> name , cryptlen ) ; ablkcipher_request_set_crypt ( req , & sg , & sg , cryptlen , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt ( req ) , & wait ) ; ablkcipher_request_free ( req ) ; if ( res < 0 ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>Error<S2SV_blank>(error<S2SV_blank>code<S2SV_blank>%d)\\n" , __func__ , res ) ; return res ; } oname -> len = cryptlen ; return 0 ; }
int fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 ilen , struct fscrypt_str * crypto_str ) { u32 olen = fscrypt_fname_encrypted_size ( inode , ilen ) ; const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) , 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) ; crypto_str -> len = olen ; olen = max ( olen , max_encoded_len ) ; crypto_str -> name = kmalloc ( olen + 1 , GFP_NOFS ) ; if ( ! ( crypto_str -> name ) ) return - ENOMEM ; return 0 ; }
u32 fscrypt_fname_encrypted_size ( const struct inode * inode , u32 ilen ) { int padding = 32 ; struct fscrypt_info * ci = inode -> i_crypt_info ; if ( ci ) padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; ilen = max ( ilen , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; return round_up ( ilen , padding ) ; }
int fscrypt_setup_filename ( struct inode * dir , const struct qstr * iname , int lookup , struct fscrypt_name * fname ) { int ret ; int digested ; memset ( fname , 0 , sizeof ( struct fscrypt_name ) ) ; fname -> usr_fname = iname ; if ( ! IS_ENCRYPTED ( dir ) || fscrypt_is_dot_dotdot ( iname ) ) { fname -> disk_name . name = ( unsigned char * ) iname -> name ; fname -> disk_name . len = iname -> len ; return 0 ; } ret = fscrypt_get_encryption_info ( dir ) ; if ( ret && ret != - EOPNOTSUPP ) return ret ; if ( dir -> i_crypt_info ) { ret = fscrypt_fname_alloc_buffer ( dir , iname -> len , & fname -> crypto_buf ) ; if ( ret ) return ret ; ret = fname_encrypt ( dir , iname , & fname -> crypto_buf ) ; if ( ret ) goto errout ; fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; return 0 ; } if ( ! lookup ) return - ENOKEY ; if ( iname -> name [ 0 ] == '_' ) { if ( iname -> len != 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) return - ENOENT ; digested = 1 ; } else { if ( iname -> len > BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) ) return - ENOENT ; digested = 0 ; } fname -> crypto_buf . name = kmalloc ( max_t ( size_t , FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE , sizeof ( struct fscrypt_digested_name ) ) , GFP_KERNEL ) ; if ( fname -> crypto_buf . name == NULL ) return - ENOMEM ; ret = digest_decode ( iname -> name + digested , iname -> len - digested , fname -> crypto_buf . name ) ; if ( ret < 0 ) { ret = - ENOENT ; goto errout ; } fname -> crypto_buf . len = ret ; if ( digested ) { const struct fscrypt_digested_name * n = ( const void * ) fname -> crypto_buf . name ; fname -> hash = n -> hash ; fname -> minor_hash = n -> minor_hash ; } else { fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; } return 0 ; errout : fscrypt_fname_free_buffer ( & fname -> crypto_buf ) ; return ret ; }
void anv_nir_apply_pipeline_layout ( struct anv_pipeline * pipeline , struct anv_pipeline_layout * layout , nir_shader * shader , struct brw_stage_prog_data * prog_data , struct anv_pipeline_bind_map * map ) { gl_shader_stage stage = shader -> info . stage ; struct apply_pipeline_layout_state state = { . shader = shader , . layout = layout , . add_bounds_checks = pipeline -> device -> robust_buffer_access , } ; void * mem_ctx = ralloc_context ( NULL ) ; for ( unsigned s = 0 ; s < layout -> num_sets ; s ++ ) { const unsigned count = layout -> set [ s ] . layout -> binding_count ; const unsigned words = BITSET_WORDS ( count ) ; state . set [ s ] . used = rzalloc_array ( mem_ctx , BITSET_WORD , words ) ; state . set [ s ] . surface_offsets = rzalloc_array ( mem_ctx , uint8_t , count ) ; state . set [ s ] . sampler_offsets = rzalloc_array ( mem_ctx , uint8_t , count ) ; state . set [ s ] . image_offsets = rzalloc_array ( mem_ctx , uint8_t , count ) ; } nir_foreach_function ( function , shader ) { if ( ! function -> impl ) continue ; nir_foreach_block ( block , function -> impl ) get_used_bindings_block ( block , & state ) ; } for ( uint32_t set = 0 ; set < layout -> num_sets ; set ++ ) { struct anv_descriptor_set_layout * set_layout = layout -> set [ set ] . layout ; BITSET_WORD b , _tmp ; BITSET_FOREACH_SET ( b , _tmp , state . set [ set ] . used , set_layout -> binding_count ) { if ( set_layout -> binding [ b ] . stage [ stage ] . surface_index >= 0 ) { map -> surface_count += anv_descriptor_set_binding_layout_get_hw_size ( & set_layout -> binding [ b ] ) ; } if ( set_layout -> binding [ b ] . stage [ stage ] . sampler_index >= 0 ) { map -> sampler_count += anv_descriptor_set_binding_layout_get_hw_size ( & set_layout -> binding [ b ] ) ; } if ( set_layout -> binding [ b ] . stage [ stage ] . image_index >= 0 ) map -> image_count += set_layout -> binding [ b ] . array_size ; } } unsigned surface = 0 ; unsigned sampler = 0 ; unsigned image = 0 ; for ( uint32_t set = 0 ; set < layout -> num_sets ; set ++ ) { struct anv_descriptor_set_layout * set_layout = layout -> set [ set ] . layout ; BITSET_WORD b , _tmp ; BITSET_FOREACH_SET ( b , _tmp , state . set [ set ] . used , set_layout -> binding_count ) { struct anv_descriptor_set_binding_layout * binding = & set_layout -> binding [ b ] ; if ( binding -> stage [ stage ] . surface_index >= 0 ) { state . set [ set ] . surface_offsets [ b ] = surface ; struct anv_sampler * * samplers = binding -> immutable_samplers ; for ( unsigned i = 0 ; i < binding -> array_size ; i ++ ) { uint8_t planes = samplers ? samplers [ i ] -> n_planes : 1 ; for ( uint8_t p = 0 ; p < planes ; p ++ ) { map -> surface_to_descriptor [ surface ] . set = set ; map -> surface_to_descriptor [ surface ] . binding = b ; map -> surface_to_descriptor [ surface ] . index = i ; map -> surface_to_descriptor [ surface ] . plane = p ; surface ++ ; } } } if ( binding -> stage [ stage ] . sampler_index >= 0 ) { state . set [ set ] . sampler_offsets [ b ] = sampler ; struct anv_sampler * * samplers = binding -> immutable_samplers ; for ( unsigned i = 0 ; i < binding -> array_size ; i ++ ) { uint8_t planes = samplers ? samplers [ i ] -> n_planes : 1 ; for ( uint8_t p = 0 ; p < planes ; p ++ ) { map -> sampler_to_descriptor [ sampler ] . set = set ; map -> sampler_to_descriptor [ sampler ] . binding = b ; map -> sampler_to_descriptor [ sampler ] . index = i ; map -> sampler_to_descriptor [ sampler ] . plane = p ; sampler ++ ; } } } if ( binding -> stage [ stage ] . image_index >= 0 ) { state . set [ set ] . image_offsets [ b ] = image ; image += binding -> array_size ; } } } nir_foreach_variable ( var , & shader -> uniforms ) { const struct glsl_type * glsl_type = var -> interface_type ? var -> interface_type : var -> type ; if ( ! glsl_type_is_image ( glsl_type ) ) continue ; enum glsl_sampler_dim dim = glsl_get_sampler_dim ( glsl_type ) ; const uint32_t set = var -> data . descriptor_set ; const uint32_t binding = var -> data . binding ; const uint32_t array_size = layout -> set [ set ] . layout -> binding [ binding ] . array_size ; if ( ! BITSET_TEST ( state . set [ set ] . used , binding ) ) continue ; struct anv_pipeline_binding * pipe_binding = & map -> surface_to_descriptor [ state . set [ set ] . surface_offsets [ binding ] ] ; for ( unsigned i = 0 ; i < array_size ; i ++ ) { assert ( pipe_binding [ i ] . set == set ) ; assert ( pipe_binding [ i ] . binding == binding ) ; assert ( pipe_binding [ i ] . index == i ) ; if ( dim == GLSL_SAMPLER_DIM_SUBPASS || dim == GLSL_SAMPLER_DIM_SUBPASS_MS ) pipe_binding [ i ] . input_attachment_index = var -> data . index + i ; pipe_binding [ i ] . write_only = var -> data . image . write_only ; } } nir_foreach_function ( function , shader ) { if ( ! function -> impl ) continue ; nir_builder_init ( & state . builder , function -> impl ) ; nir_foreach_block ( block , function -> impl ) apply_pipeline_layout_block ( block , & state ) ; nir_metadata_preserve ( function -> impl , nir_metadata_block_index | nir_metadata_dominance ) ; } if ( map -> image_count > 0 ) { assert ( map -> image_count <= MAX_IMAGES ) ; nir_foreach_variable ( var , & shader -> uniforms ) { if ( glsl_type_is_image ( var -> type ) || ( glsl_type_is_array ( var -> type ) && glsl_type_is_image ( glsl_get_array_element ( var -> type ) ) ) ) { unsigned set = var -> data . descriptor_set ; unsigned binding = var -> data . binding ; unsigned image_index = state . set [ set ] . image_offsets [ binding ] ; var -> data . driver_location = shader -> num_uniforms + image_index * BRW_IMAGE_PARAM_SIZE * 4 ; } } uint32_t * param = brw_stage_prog_data_add_params ( prog_data , map -> image_count * BRW_IMAGE_PARAM_SIZE ) ; struct anv_push_constants * null_data = NULL ; const struct brw_image_param * image_param = null_data -> images ; for ( uint32_t i = 0 ; i < map -> image_count ; i ++ ) { setup_vec4_uniform_value ( param + BRW_IMAGE_PARAM_SURFACE_IDX_OFFSET , ( uintptr_t ) & image_param -> surface_idx , 1 ) ; setup_vec4_uniform_value ( param + BRW_IMAGE_PARAM_OFFSET_OFFSET , ( uintptr_t ) image_param -> offset , 2 ) ; setup_vec4_uniform_value ( param + BRW_IMAGE_PARAM_SIZE_OFFSET , ( uintptr_t ) image_param -> size , 3 ) ; setup_vec4_uniform_value ( param + BRW_IMAGE_PARAM_STRIDE_OFFSET , ( uintptr_t ) image_param -> stride , 4 ) ; setup_vec4_uniform_value ( param + BRW_IMAGE_PARAM_TILING_OFFSET , ( uintptr_t ) image_param -> tiling , 3 ) ; setup_vec4_uniform_value ( param + BRW_IMAGE_PARAM_SWIZZLING_OFFSET , ( uintptr_t ) image_param -> swizzling , 2 ) ; param += BRW_IMAGE_PARAM_SIZE ; image_param ++ ; } assert ( param == prog_data -> param + prog_data -> nr_params ) ; shader -> num_uniforms += map -> image_count * BRW_IMAGE_PARAM_SIZE * 4 ; } ralloc_free ( mem_ctx ) ; }
int nx_fw_cmd_set_mtu ( struct netxen_adapter * adapter , int mtu ) { u32 rcode = NX_RCODE_SUCCESS ; struct netxen_recv_context * recv_ctx = & adapter -> recv_ctx ; struct netxen_cmd_args cmd ; memset ( & cmd , 0 , sizeof ( cmd ) ) ; cmd . req . cmd = NX_CDRP_CMD_SET_MTU ; cmd . req . arg1 = recv_ctx -> context_id ; cmd . req . arg2 = mtu ; cmd . req . arg3 = 0 ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) netxen_issue_cmd ( adapter , & cmd ) ; if ( rcode != NX_RCODE_SUCCESS ) return - EIO ; return 0 ; }
void s_send_entities_full ( entity_t * player ) { uint32_t * ids = ( uint32_t * ) malloc ( sizeof ( uint32_t ) * entities_len + 1 ) ; if ( ids == NULL ) { panic ( "Error<S2SV_blank>allocating<S2SV_blank>ids[]!" ) ; } for ( uint32_t i = 0 ; i < entities_len ; i ++ ) { ids [ i ] = i ; } ids [ entities_len ] = 0 ; s_send_entities_unsafe ( player , entities_len , players_len , ids ) ; free ( ids ) ; }
void s_send_entities_unsafe ( entity_t * player , size_t ecount , size_t pcount , uint32_t * ids ) { if ( ! player || ! ids ) { panic ( "Invalid<S2SV_blank>s_send_entities_unsafe()<S2SV_blank>pointers!" ) ; } if ( ! player -> player_context -> connected ) { return ; } size_t size = sizeof ( entities_mbuf_t ) + sizeof ( entity_t ) * ecount + sizeof ( struct player_context ) * pcount ; entities_mbuf_t * msg = ( entities_mbuf_t * ) malloc ( size ) ; if ( msg == NULL ) { panic ( "Error<S2SV_blank>allocating<S2SV_blank>buffer<S2SV_blank>in<S2SV_blank>s_send_entities_unsafe()!" ) ; } msg -> ecount = ecount ; msg -> pcount = pcount ; msg -> self = - 1 ; char * buffer = ( char * ) ( msg -> entities ) ; size_t i = 0 ; while ( * ( ids + i ) ) { if ( * ids >= entities_len ) { panic ( "Invalid<S2SV_blank>id<S2SV_blank>specified<S2SV_blank>for<S2SV_blank>s_send_entities_unsafe()!" ) ; } memcpy ( buffer , entities [ * ( ids + i ) ] , sizeof ( entity_t ) ) ; ( ( entity_t * ) buffer ) -> context = ( void * ) i ; buffer += sizeof ( entity_t ) ; ecount -- ; if ( entities [ * ( ids + i ) ] -> type == PLAYER ) { if ( entities [ * ( ids + i ) ] -> player_context -> connection == player -> player_context -> connection ) { msg -> self = i ; } memcpy ( buffer , entities [ * ( ids + i ) ] -> player_context , sizeof ( struct player_context ) ) ; buffer += sizeof ( struct player_context ) ; pcount -- ; } i ++ ; if ( ecount == 0 ) { break ; } } if ( ecount || pcount ) { panic ( "Invalid<S2SV_blank>ecount<S2SV_blank>or<S2SV_blank>pcount<S2SV_blank>in<S2SV_blank>s_send_entities_unsafe()!" ) ; } mbuf_t s2c_mbuf ; s2c_mbuf . payload = ( void * ) msg ; s2c_mbuf . msg . type = MSG_PUT_ENTITIES ; s2c_mbuf . msg . size = size ; logger ( "[S]<S2SV_blank>Sending<S2SV_blank>entities..." ) ; mqueue_put ( player -> player_context -> connection -> mqueueptr , s2c_mbuf ) ; }
static inline void event_loop ( ) { if ( ! start && usleep ( 100000 ) == 0 ) { return ; } for ( ; ev_count_players ( ) == 0 ; usleep ( 10000 ) ) ; for ( uint32_t uticks = 0 ; ! ev_players_ready ( ) && uticks < EV_TURN ; uticks += EV_STEP ) { usleep ( EV_STEP ) ; } if ( ! ev_count_players ( ) ) { return ; } for ( size_t player_id = 0 ; player_id < players_len ; player_id ++ ) { P_EV_LOCK ; switch ( P_EV_QUEUE . event ) { case EV_NONE : break ; case EV_MOVE : player_move ( ( player_move_t * ) P_EV_QUEUE . event_args ) ; break ; default : panic ( "[S]<S2SV_blank>Illegal<S2SV_blank>player<S2SV_blank>event!" ) ; } P_EV_QUEUE . event = EV_NONE ; if ( P_EV_QUEUE . event_args ) { free ( P_EV_QUEUE . event_args ) ; P_EV_QUEUE . event_args = NULL ; } P_EV_UNLOCK ; } for ( size_t id = 0 ; id < players_len ; id ++ ) { s_send_players_full ( players [ id ] ) ; } }
int nx_fw_cmd_set_mtu ( struct netxen_adapter * adapter , int mtu ) { u32 rcode = NX_RCODE_SUCCESS ; struct netxen_recv_context * recv_ctx = & adapter -> recv_ctx ; struct netxen_cmd_args cmd ; memset ( & cmd , 0 , sizeof ( cmd ) ) ; cmd . req . cmd = NX_CDRP_CMD_SET_MTU ; cmd . req . arg1 = recv_ctx -> context_id ; cmd . req . arg2 = mtu ; cmd . req . arg3 = 0 ; if ( recv_ctx -> state == NX_HOST_CTX_STATE_ACTIVE ) netxen_issue_cmd ( adapter , & cmd ) ; if ( rcode != NX_RCODE_SUCCESS ) return - EIO ; return 0 ; }
static long snd_timer_user_ioctl_compat ( struct file * file , unsigned int cmd , unsigned long arg ) { void __user * argp = compat_ptr ( arg ) ; switch ( cmd ) { case SNDRV_TIMER_IOCTL_PVERSION : case SNDRV_TIMER_IOCTL_TREAD : case SNDRV_TIMER_IOCTL_GINFO : case SNDRV_TIMER_IOCTL_GSTATUS : case SNDRV_TIMER_IOCTL_SELECT : case SNDRV_TIMER_IOCTL_PARAMS : case SNDRV_TIMER_IOCTL_START : case SNDRV_TIMER_IOCTL_START_OLD : case SNDRV_TIMER_IOCTL_STOP : case SNDRV_TIMER_IOCTL_STOP_OLD : case SNDRV_TIMER_IOCTL_CONTINUE : case SNDRV_TIMER_IOCTL_CONTINUE_OLD : case SNDRV_TIMER_IOCTL_PAUSE : case SNDRV_TIMER_IOCTL_PAUSE_OLD : case SNDRV_TIMER_IOCTL_NEXT_DEVICE : return snd_timer_user_ioctl ( file , cmd , ( unsigned long ) argp ) ; case SNDRV_TIMER_IOCTL_GPARAMS32 : return snd_timer_user_gparams_compat ( file , argp ) ; case SNDRV_TIMER_IOCTL_INFO32 : return snd_timer_user_info_compat ( file , argp ) ; case SNDRV_TIMER_IOCTL_STATUS32 : return snd_timer_user_status_compat ( file , argp ) ; # ifdef CONFIG_X86_X32 case SNDRV_TIMER_IOCTL_STATUS_X32 : return snd_timer_user_status_x32 ( file , argp ) ; # endif } return - ENOIOCTLCMD ; }
static int fname_encrypt ( struct inode * inode , const struct qstr * iname , struct fscrypt_str * oname ) { struct ablkcipher_request * req = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct fscrypt_info * ci = inode -> i_crypt_info ; struct crypto_ablkcipher * tfm = ci -> ci_ctfm ; int res = 0 ; char iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; int padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; unsigned int lim ; unsigned int cryptlen ; lim = inode -> i_sb -> s_cop -> max_namelen ( inode ) ; if ( iname -> len <= 0 || iname -> len > lim ) return - EIO ; cryptlen = max_t ( unsigned int , iname -> len , FS_CRYPTO_BLOCK_SIZE ) ; cryptlen = round_up ( cryptlen , padding ) ; cryptlen = min ( cryptlen , lim ) ; memcpy ( oname -> name , iname -> name , iname -> len ) ; memset ( oname -> name + iname -> len , 0 , cryptlen - iname -> len ) ; memset ( iv , 0 , FS_CRYPTO_BLOCK_SIZE ) ; req = ablkcipher_request_alloc ( tfm , GFP_NOFS ) ; if ( ! req ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>ablkcipher_request_alloc()<S2SV_blank>failed\\n" , __func__ ) ; return - ENOMEM ; } ablkcipher_request_set_callback ( req , CRYPTO_TFM_REQ_MAY_BACKLOG | CRYPTO_TFM_REQ_MAY_SLEEP , crypto_req_done , & wait ) ; sg_init_one ( & sg , oname -> name , cryptlen ) ; ablkcipher_request_set_crypt ( req , & sg , & sg , cryptlen , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt ( req ) , & wait ) ; ablkcipher_request_free ( req ) ; if ( res < 0 ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>Error<S2SV_blank>(error<S2SV_blank>code<S2SV_blank>%d)\\n" , __func__ , res ) ; return res ; } oname -> len = cryptlen ; return 0 ; }
int fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 ilen , struct fscrypt_str * crypto_str ) { u32 olen = fscrypt_fname_encrypted_size ( inode , ilen ) ; const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) , 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) ; crypto_str -> len = olen ; olen = max ( olen , max_encoded_len ) ; crypto_str -> name = kmalloc ( olen + 1 , GFP_NOFS ) ; if ( ! ( crypto_str -> name ) ) return - ENOMEM ; return 0 ; }
u32 fscrypt_fname_encrypted_size ( const struct inode * inode , u32 ilen ) { int padding = 32 ; struct fscrypt_info * ci = inode -> i_crypt_info ; if ( ci ) padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; ilen = max ( ilen , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; return round_up ( ilen , padding ) ; }
int fscrypt_setup_filename ( struct inode * dir , const struct qstr * iname , int lookup , struct fscrypt_name * fname ) { int ret ; int digested ; memset ( fname , 0 , sizeof ( struct fscrypt_name ) ) ; fname -> usr_fname = iname ; if ( ! IS_ENCRYPTED ( dir ) || fscrypt_is_dot_dotdot ( iname ) ) { fname -> disk_name . name = ( unsigned char * ) iname -> name ; fname -> disk_name . len = iname -> len ; return 0 ; } ret = fscrypt_get_encryption_info ( dir ) ; if ( ret && ret != - EOPNOTSUPP ) return ret ; if ( dir -> i_crypt_info ) { ret = fscrypt_fname_alloc_buffer ( dir , iname -> len , & fname -> crypto_buf ) ; if ( ret ) return ret ; ret = fname_encrypt ( dir , iname , & fname -> crypto_buf ) ; if ( ret ) goto errout ; fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; return 0 ; } if ( ! lookup ) return - ENOKEY ; if ( iname -> name [ 0 ] == '_' ) { if ( iname -> len != 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) return - ENOENT ; digested = 1 ; } else { if ( iname -> len > BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) ) return - ENOENT ; digested = 0 ; } fname -> crypto_buf . name = kmalloc ( max_t ( size_t , FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE , sizeof ( struct fscrypt_digested_name ) ) , GFP_KERNEL ) ; if ( fname -> crypto_buf . name == NULL ) return - ENOMEM ; ret = digest_decode ( iname -> name + digested , iname -> len - digested , fname -> crypto_buf . name ) ; if ( ret < 0 ) { ret = - ENOENT ; goto errout ; } fname -> crypto_buf . len = ret ; if ( digested ) { const struct fscrypt_digested_name * n = ( const void * ) fname -> crypto_buf . name ; fname -> hash = n -> hash ; fname -> minor_hash = n -> minor_hash ; } else { fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; } return 0 ; errout : fscrypt_fname_free_buffer ( & fname -> crypto_buf ) ; return ret ; }
static void handle_audio_frame ( struct mp_filter * f ) { struct priv * p = f -> priv ; struct mp_aframe * aframe = p -> sub . frame . data ; int afmt = mp_aframe_get_format ( aframe ) ; int srate = mp_aframe_get_rate ( aframe ) ; struct mp_chmap chmap = { 0 } ; mp_aframe_get_chmap ( aframe , & chmap ) ; if ( afmt == p -> in_afmt && srate == p -> in_srate && mp_chmap_equals ( & chmap , & p -> in_chmap ) && ( ! p -> resampling_forced || p -> sub . filter ) && ! p -> force_update ) { goto cont ; } if ( ! mp_subfilter_drain_destroy ( & p -> sub ) ) return ; p -> in_afmt = afmt ; p -> in_srate = srate ; p -> in_chmap = chmap ; p -> force_update = false ; int out_afmt = 0 ; int best_score = 0 ; for ( int n = 0 ; n < p -> num_afmts ; n ++ ) { int score = af_format_conversion_score ( p -> afmts [ n ] , afmt ) ; if ( ! out_afmt || score > best_score ) { best_score = score ; out_afmt = p -> afmts [ n ] ; } } if ( ! out_afmt ) out_afmt = afmt ; int out_srate = af_select_best_samplerate ( srate , p -> srates ) ; if ( out_srate <= 0 ) out_srate = p -> num_srates ? p -> srates [ 0 ] : srate ; struct mp_chmap out_chmap = chmap ; if ( p -> chmaps . num_chmaps ) { if ( ! mp_chmap_sel_adjust ( & p -> chmaps , & out_chmap ) ) out_chmap = p -> chmaps . chmaps [ 0 ] ; } if ( out_afmt == p -> in_afmt && out_srate == p -> in_srate && mp_chmap_equals ( & out_chmap , & p -> in_chmap ) && ! p -> resampling_forced ) { goto cont ; } MP_VERBOSE ( p , "inserting<S2SV_blank>resampler\\n" ) ; struct mp_swresample * s = mp_swresample_create ( f , NULL ) ; if ( ! s ) abort ( ) ; s -> out_format = out_afmt ; s -> out_rate = out_srate ; s -> out_channels = out_chmap ; p -> sub . filter = s -> f ; cont : if ( p -> sub . filter ) { struct mp_filter_command cmd = { . type = MP_FILTER_COMMAND_SET_SPEED_RESAMPLE , . speed = p -> audio_speed , } ; mp_filter_command ( p -> sub . filter , & cmd ) ; } mp_subfilter_continue ( & p -> sub ) ; }
static void reset ( struct mp_filter * f ) { struct priv * p = f -> priv ; mp_subfilter_reset ( & p -> sub ) ; }
static int receive_object ( struct receive_writer_arg * rwa , struct drr_object * drro , void * data ) { dmu_object_info_t doi ; dmu_tx_t * tx ; uint64_t object ; int err ; if ( drro -> drr_type == DMU_OT_NONE || ! DMU_OT_IS_VALID ( drro -> drr_type ) || ! DMU_OT_IS_VALID ( drro -> drr_bonustype ) || drro -> drr_checksumtype >= ZIO_CHECKSUM_FUNCTIONS || drro -> drr_compress >= ZIO_COMPRESS_FUNCTIONS || P2PHASE ( drro -> drr_blksz , SPA_MINBLOCKSIZE ) || drro -> drr_blksz < SPA_MINBLOCKSIZE || drro -> drr_blksz > spa_maxblocksize ( dmu_objset_spa ( rwa -> os ) ) || drro -> drr_bonuslen > DN_MAX_BONUSLEN ) { return ( SET_ERROR ( EINVAL ) ) ; } if ( rwa -> raw ) { if ( drro -> drr_raw_bonuslen < drro -> drr_bonuslen || drro -> drr_indblkshift > SPA_MAXBLOCKSHIFT || drro -> drr_nlevels > DN_MAX_LEVELS || drro -> drr_nblkptr > DN_MAX_NBLKPTR || DN_SLOTS_TO_BONUSLEN ( drro -> drr_dn_slots ) < drro -> drr_raw_bonuslen ) return ( SET_ERROR ( EINVAL ) ) ; } else { if ( drro -> drr_flags != 0 || drro -> drr_raw_bonuslen != 0 || drro -> drr_indblkshift != 0 || drro -> drr_nlevels != 0 || drro -> drr_nblkptr != 0 ) return ( SET_ERROR ( EINVAL ) ) ; } err = dmu_object_info ( rwa -> os , drro -> drr_object , & doi ) ; if ( err != 0 && err != ENOENT ) return ( SET_ERROR ( EINVAL ) ) ; if ( err == 0 ) { uint32_t indblksz = drro -> drr_indblkshift ? 1ULL << drro -> drr_indblkshift : 0 ; int nblkptr = deduce_nblkptr ( drro -> drr_bonustype , drro -> drr_bonuslen ) ; object = drro -> drr_object ; if ( rwa -> raw && nblkptr != drro -> drr_nblkptr ) return ( SET_ERROR ( EINVAL ) ) ; if ( rwa -> raw && ( drro -> drr_blksz != doi . doi_data_block_size || nblkptr < doi . doi_nblkptr || indblksz != doi . doi_metadata_block_size || drro -> drr_nlevels < doi . doi_indirection ) ) { err = dmu_free_long_range_raw ( rwa -> os , drro -> drr_object , 0 , DMU_OBJECT_END ) ; if ( err != 0 ) return ( SET_ERROR ( EINVAL ) ) ; } else if ( drro -> drr_blksz != doi . doi_data_block_size || nblkptr < doi . doi_nblkptr ) { err = dmu_free_long_range ( rwa -> os , drro -> drr_object , 0 , DMU_OBJECT_END ) ; if ( err != 0 ) return ( SET_ERROR ( EINVAL ) ) ; } if ( ( rwa -> raw && drro -> drr_nlevels < doi . doi_indirection ) ) { if ( rwa -> raw ) { err = dmu_free_long_object_raw ( rwa -> os , drro -> drr_object ) ; } else { err = dmu_free_long_object ( rwa -> os , drro -> drr_object ) ; } if ( err != 0 ) return ( SET_ERROR ( EINVAL ) ) ; txg_wait_synced ( dmu_objset_pool ( rwa -> os ) , 0 ) ; object = DMU_NEW_OBJECT ; } } else { object = DMU_NEW_OBJECT ; } tx = dmu_tx_create ( rwa -> os ) ; dmu_tx_hold_bonus ( tx , object ) ; dmu_tx_hold_write ( tx , object , 0 , 0 ) ; err = dmu_tx_assign ( tx , TXG_WAIT ) ; if ( err != 0 ) { dmu_tx_abort ( tx ) ; return ( err ) ; } if ( object == DMU_NEW_OBJECT ) { err = dmu_object_claim ( rwa -> os , drro -> drr_object , drro -> drr_type , drro -> drr_blksz , drro -> drr_bonustype , drro -> drr_bonuslen , tx ) ; } else if ( drro -> drr_type != doi . doi_type || drro -> drr_blksz != doi . doi_data_block_size || drro -> drr_bonustype != doi . doi_bonus_type || drro -> drr_bonuslen != doi . doi_bonus_size ) { err = dmu_object_reclaim ( rwa -> os , drro -> drr_object , drro -> drr_type , drro -> drr_blksz , drro -> drr_bonustype , drro -> drr_bonuslen , tx ) ; } if ( err != 0 ) { dmu_tx_commit ( tx ) ; return ( SET_ERROR ( EINVAL ) ) ; } if ( rwa -> raw ) VERIFY0 ( dmu_object_dirty_raw ( rwa -> os , drro -> drr_object , tx ) ) ; dmu_object_set_checksum ( rwa -> os , drro -> drr_object , drro -> drr_checksumtype , tx ) ; dmu_object_set_compress ( rwa -> os , drro -> drr_object , drro -> drr_compress , tx ) ; if ( rwa -> raw ) { VERIFY0 ( dmu_object_set_blocksize ( rwa -> os , drro -> drr_object , drro -> drr_blksz , drro -> drr_indblkshift , tx ) ) ; VERIFY0 ( dmu_object_set_nlevels ( rwa -> os , drro -> drr_object , drro -> drr_nlevels , tx ) ) ; VERIFY0 ( dmu_object_set_maxblkid ( rwa -> os , drro -> drr_object , drro -> drr_maxblkid , tx ) ) ; } if ( data != NULL ) { dmu_buf_t * db ; uint32_t flags = DMU_READ_NO_PREFETCH ; if ( rwa -> raw ) flags |= DMU_READ_NO_DECRYPT ; VERIFY0 ( dmu_bonus_hold_impl ( rwa -> os , drro -> drr_object , FTAG , flags , & db ) ) ; dmu_buf_will_dirty ( db , tx ) ; ASSERT3U ( db -> db_size , >= , drro -> drr_bonuslen ) ; bcopy ( data , db -> db_data , DRR_OBJECT_PAYLOAD_SIZE ( drro ) ) ; if ( rwa -> byteswap && ! rwa -> raw ) { dmu_object_byteswap_t byteswap = DMU_OT_BYTESWAP ( drro -> drr_bonustype ) ; dmu_ot_byteswap [ byteswap ] . ob_func ( db -> db_data , DRR_OBJECT_PAYLOAD_SIZE ( drro ) ) ; } dmu_buf_rele ( db , FTAG ) ; } dmu_tx_commit ( tx ) ; return ( 0 ) ; }
static int receive_object_range ( struct receive_writer_arg * rwa , struct drr_object_range * drror ) { int ret ; dmu_tx_t * tx ; dnode_t * mdn = NULL ; dmu_buf_t * db = NULL ; uint64_t offset ; boolean_t byteorder = ZFS_HOST_BYTEORDER ^ rwa -> byteswap ^ ! ! DRR_IS_RAW_BYTESWAPPED ( drror -> drr_flags ) ; if ( drror -> drr_numslots != DNODES_PER_BLOCK || P2PHASE ( drror -> drr_firstobj , DNODES_PER_BLOCK ) != 0 || ! rwa -> raw ) return ( SET_ERROR ( EINVAL ) ) ; offset = drror -> drr_firstobj * sizeof ( dnode_phys_t ) ; mdn = DMU_META_DNODE ( rwa -> os ) ; tx = dmu_tx_create ( rwa -> os ) ; ret = dmu_tx_assign ( tx , TXG_WAIT ) ; if ( ret != 0 ) { dmu_tx_abort ( tx ) ; return ( ret ) ; } ret = dmu_buf_hold_by_dnode ( mdn , offset , FTAG , & db , DMU_READ_PREFETCH | DMU_READ_NO_DECRYPT ) ; if ( ret != 0 ) { dmu_tx_commit ( tx ) ; return ( ret ) ; } dmu_convert_to_raw ( db , byteorder , drror -> drr_salt , drror -> drr_iv , drror -> drr_mac , tx ) ; dmu_buf_rele ( db , FTAG ) ; dmu_tx_commit ( tx ) ; return ( 0 ) ; }
void err_tok ( t_token * * toklist , t_token * bad_tok ) { t_kvp tok [ 20 ] ; int i ; i = 0 ; init_token_table ( tok ) ; while ( ( unsigned long ) tok [ i ] . key != bad_tok -> type && tok [ i ] . key ) i ++ ; ft_dprintf ( STDERR_FILENO , "42sh:<S2SV_blank>syntax<S2SV_blank>error<S2SV_blank>near<S2SV_blank>unexpected<S2SV_blank>token<S2SV_blank>`%s\'\\n" , ( char * ) tok [ i ] . val ) ; clear_following_redirs ( bad_tok ) ; delete_toklist ( toklist ) ; }
struct s_job * get_nextcommand ( t_token * * tokens ) { t_job * job [ 3 ] ; job [ 0 ] = NULL ; while ( ( job [ 2 ] = job_getnext ( tokens , job [ 0 ] ) ) != NULL ) job_insert ( job , job + 1 , job [ 2 ] ) ; return ( job [ 0 ] ) ; }
static int validate ( struct s_token * tokens ) { if ( tokens -> type == NEWLINE ) { if ( tokens -> next != NULL ) fatal_err ( CTX_ERR , get_ctxaddr ( ) ) ; return ( 0 ) ; } else if ( ( tokens -> type & ( SEMICOL ) ) != 0 ) { if ( tokens -> next == NULL || tokens -> next -> type == NEWLINE ) return ( 0 ) ; return ( 1 ) ; } return ( - 1 ) ; }
static int fname_encrypt ( struct inode * inode , const struct qstr * iname , struct fscrypt_str * oname ) { struct ablkcipher_request * req = NULL ; DECLARE_CRYPTO_WAIT ( wait ) ; struct fscrypt_info * ci = inode -> i_crypt_info ; struct crypto_ablkcipher * tfm = ci -> ci_ctfm ; int res = 0 ; char iv [ FS_CRYPTO_BLOCK_SIZE ] ; struct scatterlist sg ; int padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; unsigned int lim ; unsigned int cryptlen ; lim = inode -> i_sb -> s_cop -> max_namelen ( inode ) ; if ( iname -> len <= 0 || iname -> len > lim ) return - EIO ; cryptlen = max_t ( unsigned int , iname -> len , FS_CRYPTO_BLOCK_SIZE ) ; cryptlen = round_up ( cryptlen , padding ) ; cryptlen = min ( cryptlen , lim ) ; memcpy ( oname -> name , iname -> name , iname -> len ) ; memset ( oname -> name + iname -> len , 0 , cryptlen - iname -> len ) ; memset ( iv , 0 , FS_CRYPTO_BLOCK_SIZE ) ; req = ablkcipher_request_alloc ( tfm , GFP_NOFS ) ; if ( ! req ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>ablkcipher_request_alloc()<S2SV_blank>failed\\n" , __func__ ) ; return - ENOMEM ; } ablkcipher_request_set_callback ( req , CRYPTO_TFM_REQ_MAY_BACKLOG | CRYPTO_TFM_REQ_MAY_SLEEP , crypto_req_done , & wait ) ; sg_init_one ( & sg , oname -> name , cryptlen ) ; ablkcipher_request_set_crypt ( req , & sg , & sg , cryptlen , iv ) ; res = crypto_wait_req ( crypto_ablkcipher_encrypt ( req ) , & wait ) ; ablkcipher_request_free ( req ) ; if ( res < 0 ) { printk_ratelimited ( KERN_ERR "%s:<S2SV_blank>Error<S2SV_blank>(error<S2SV_blank>code<S2SV_blank>%d)\\n" , __func__ , res ) ; return res ; } oname -> len = cryptlen ; return 0 ; }
int fscrypt_fname_alloc_buffer ( const struct inode * inode , u32 ilen , struct fscrypt_str * crypto_str ) { u32 olen = fscrypt_fname_encrypted_size ( inode , ilen ) ; const u32 max_encoded_len = max_t ( u32 , BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) , 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) ; crypto_str -> len = olen ; olen = max ( olen , max_encoded_len ) ; crypto_str -> name = kmalloc ( olen + 1 , GFP_NOFS ) ; if ( ! ( crypto_str -> name ) ) return - ENOMEM ; return 0 ; }
u32 fscrypt_fname_encrypted_size ( const struct inode * inode , u32 ilen ) { int padding = 32 ; struct fscrypt_info * ci = inode -> i_crypt_info ; if ( ci ) padding = 4 << ( ci -> ci_flags & FS_POLICY_FLAGS_PAD_MASK ) ; ilen = max ( ilen , ( u32 ) FS_CRYPTO_BLOCK_SIZE ) ; return round_up ( ilen , padding ) ; }
int fscrypt_setup_filename ( struct inode * dir , const struct qstr * iname , int lookup , struct fscrypt_name * fname ) { int ret ; int digested ; memset ( fname , 0 , sizeof ( struct fscrypt_name ) ) ; fname -> usr_fname = iname ; if ( ! IS_ENCRYPTED ( dir ) || fscrypt_is_dot_dotdot ( iname ) ) { fname -> disk_name . name = ( unsigned char * ) iname -> name ; fname -> disk_name . len = iname -> len ; return 0 ; } ret = fscrypt_get_encryption_info ( dir ) ; if ( ret && ret != - EOPNOTSUPP ) return ret ; if ( dir -> i_crypt_info ) { ret = fscrypt_fname_alloc_buffer ( dir , iname -> len , & fname -> crypto_buf ) ; if ( ret ) return ret ; ret = fname_encrypt ( dir , iname , & fname -> crypto_buf ) ; if ( ret ) goto errout ; fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; return 0 ; } if ( ! lookup ) return - ENOKEY ; if ( iname -> name [ 0 ] == '_' ) { if ( iname -> len != 1 + BASE64_CHARS ( sizeof ( struct fscrypt_digested_name ) ) ) return - ENOENT ; digested = 1 ; } else { if ( iname -> len > BASE64_CHARS ( FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE ) ) return - ENOENT ; digested = 0 ; } fname -> crypto_buf . name = kmalloc ( max_t ( size_t , FSCRYPT_FNAME_MAX_UNDIGESTED_SIZE , sizeof ( struct fscrypt_digested_name ) ) , GFP_KERNEL ) ; if ( fname -> crypto_buf . name == NULL ) return - ENOMEM ; ret = digest_decode ( iname -> name + digested , iname -> len - digested , fname -> crypto_buf . name ) ; if ( ret < 0 ) { ret = - ENOENT ; goto errout ; } fname -> crypto_buf . len = ret ; if ( digested ) { const struct fscrypt_digested_name * n = ( const void * ) fname -> crypto_buf . name ; fname -> hash = n -> hash ; fname -> minor_hash = n -> minor_hash ; } else { fname -> disk_name . name = fname -> crypto_buf . name ; fname -> disk_name . len = fname -> crypto_buf . len ; } return 0 ; errout : fscrypt_fname_free_buffer ( & fname -> crypto_buf ) ; return ret ; }
static unsigned long ondemand_readahead ( struct address_space * mapping , struct file_ra_state * ra , struct file * filp , bool hit_readahead_marker , pgoff_t offset , unsigned long req_size ) { struct backing_dev_info * bdi = inode_to_bdi ( mapping -> host ) ; unsigned long max_pages = ra -> ra_pages ; pgoff_t prev_offset ; if ( req_size > max_pages && bdi -> io_pages > max_pages ) max_pages = min ( req_size , bdi -> io_pages ) ; if ( ! offset ) goto initial_readahead ; if ( ( offset == ( ra -> start + ra -> size - ra -> async_size ) || offset == ( ra -> start + ra -> size ) ) ) { ra -> start += ra -> size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( hit_readahead_marker ) { pgoff_t start ; rcu_read_lock ( ) ; start = page_cache_next_hole ( mapping , offset + 1 , max_pages ) ; rcu_read_unlock ( ) ; if ( ! start || start - offset > max_pages ) return 0 ; ra -> start = start ; ra -> size = start - offset ; ra -> size += req_size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( req_size > max_pages ) goto initial_readahead ; prev_offset = ( unsigned long long ) ra -> prev_pos >> PAGE_SHIFT ; if ( offset - prev_offset <= 1UL ) goto initial_readahead ; if ( try_context_readahead ( mapping , ra , offset , req_size , max_pages ) ) goto readit ; return __do_page_cache_readahead ( mapping , filp , offset , req_size , 0 ) ; initial_readahead : ra -> start = offset ; ra -> size = get_init_ra_size ( req_size , max_pages ) ; ra -> async_size = ra -> size > req_size ? ra -> size - req_size : ra -> size ; readit : if ( offset == ra -> start && ra -> size == ra -> async_size ) { ra -> async_size = get_next_ra_size ( ra , max_pages ) ; ra -> size += ra -> async_size ; } return ra_submit ( ra , mapping , filp ) ; }
static int rsync_module ( int f_in , int f_out , int i , const char * addr , const char * host ) { int argc ; char * * argv , * * orig_argv , * * orig_early_argv , * module_chdir ; char line [ BIGPATHBUFLEN ] ; # if defined HAVE_INITGROUPS && ! defined HAVE_GETGROUPLIST struct passwd * pw = NULL ; # endif uid_t uid ; int set_uid ; char * p , * err_msg = NULL ; char * name = lp_name ( i ) ; int use_chroot = lp_use_chroot ( i ) ; int ret , pre_exec_arg_fd = - 1 , pre_exec_error_fd = - 1 ; int save_munge_symlinks ; pid_t pre_exec_pid = 0 ; char * request = NULL ; set_env_str ( "RSYNC_MODULE_NAME" , name ) ; # ifdef ICONV_OPTION iconv_opt = lp_charset ( i ) ; if ( * iconv_opt ) setup_iconv ( ) ; iconv_opt = NULL ; # endif if ( host == undetermined_hostname && lp_reverse_lookup ( i ) ) host = client_name ( f_in ) ; set_env_str ( "RSYNC_HOST_NAME" , host ) ; set_env_str ( "RSYNC_HOST_ADDR" , addr ) ; if ( ! allow_access ( addr , & host , i ) ) { rprintf ( FLOG , "rsync<S2SV_blank>denied<S2SV_blank>on<S2SV_blank>module<S2SV_blank>%s<S2SV_blank>from<S2SV_blank>%s<S2SV_blank>(%s)\\n" , name , host , addr ) ; if ( ! lp_list ( i ) ) io_printf ( f_out , "@ERROR:<S2SV_blank>Unknown<S2SV_blank>module<S2SV_blank>\'%s\'\\n" , name ) ; else { io_printf ( f_out , "@ERROR:<S2SV_blank>access<S2SV_blank>denied<S2SV_blank>to<S2SV_blank>%s<S2SV_blank>from<S2SV_blank>%s<S2SV_blank>(%s)\\n" , name , host , addr ) ; } return - 1 ; } if ( am_daemon && am_server ) { rprintf ( FLOG , "rsync<S2SV_blank>allowed<S2SV_blank>access<S2SV_blank>on<S2SV_blank>module<S2SV_blank>%s<S2SV_blank>from<S2SV_blank>%s<S2SV_blank>(%s)\\n" , name , host , addr ) ; } if ( ! claim_connection ( lp_lock_file ( i ) , lp_max_connections ( i ) ) ) { if ( errno ) { rsyserr ( FLOG , errno , "failed<S2SV_blank>to<S2SV_blank>open<S2SV_blank>lock<S2SV_blank>file<S2SV_blank>%s" , lp_lock_file ( i ) ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>open<S2SV_blank>lock<S2SV_blank>file\\n" ) ; } else { rprintf ( FLOG , "max<S2SV_blank>connections<S2SV_blank>(%d)<S2SV_blank>reached\\n" , lp_max_connections ( i ) ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>max<S2SV_blank>connections<S2SV_blank>(%d)<S2SV_blank>reached<S2SV_blank>--<S2SV_blank>try<S2SV_blank>again<S2SV_blank>later\\n" , lp_max_connections ( i ) ) ; } return - 1 ; } read_only = lp_read_only ( i ) ; auth_user = auth_server ( f_in , f_out , i , host , addr , "@RSYNCD:<S2SV_blank>AUTHREQD<S2SV_blank>" ) ; if ( ! auth_user ) { io_printf ( f_out , "@ERROR:<S2SV_blank>auth<S2SV_blank>failed<S2SV_blank>on<S2SV_blank>module<S2SV_blank>%s\\n" , name ) ; return - 1 ; } set_env_str ( "RSYNC_USER_NAME" , auth_user ) ; module_id = i ; if ( lp_transfer_logging ( i ) && ! logfile_format ) logfile_format = lp_log_format ( i ) ; if ( log_format_has ( logfile_format , 'i' ) ) logfile_format_has_i = 1 ; if ( logfile_format_has_i || log_format_has ( logfile_format , 'o' ) ) logfile_format_has_o_or_i = 1 ; uid = MY_UID ( ) ; am_root = ( uid == 0 ) ; p = * lp_uid ( i ) ? lp_uid ( i ) : am_root ? NOBODY_USER : NULL ; if ( p ) { if ( ! user_to_uid ( p , & uid , True ) ) { rprintf ( FLOG , "Invalid<S2SV_blank>uid<S2SV_blank>%s\\n" , p ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>invalid<S2SV_blank>uid<S2SV_blank>%s\\n" , p ) ; return - 1 ; } set_uid = 1 ; } else set_uid = 0 ; p = * lp_gid ( i ) ? strtok ( lp_gid ( i ) , ",<S2SV_blank>" ) : NULL ; if ( p ) { if ( strcmp ( p , "*" ) == 0 ) { # ifdef HAVE_GETGROUPLIST if ( want_all_groups ( f_out , uid ) < 0 ) return - 1 ; # elif defined HAVE_INITGROUPS if ( ( pw = want_all_groups ( f_out , uid ) ) == NULL ) return - 1 ; # else rprintf ( FLOG , "This<S2SV_blank>rsync<S2SV_blank>does<S2SV_blank>not<S2SV_blank>support<S2SV_blank>a<S2SV_blank>gid<S2SV_blank>of<S2SV_blank>\\"*\\"\\n" ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>invalid<S2SV_blank>gid<S2SV_blank>setting.\\n" ) ; return - 1 ; # endif } else if ( add_a_group ( f_out , p ) < 0 ) return - 1 ; while ( ( p = strtok ( NULL , ",<S2SV_blank>" ) ) != NULL ) { # if defined HAVE_INITGROUPS && ! defined HAVE_GETGROUPLIST if ( pw ) { rprintf ( FLOG , "This<S2SV_blank>rsync<S2SV_blank>cannot<S2SV_blank>add<S2SV_blank>groups<S2SV_blank>after<S2SV_blank>\\"*\\".\\n" ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>invalid<S2SV_blank>gid<S2SV_blank>setting.\\n" ) ; return - 1 ; } # endif if ( add_a_group ( f_out , p ) < 0 ) return - 1 ; } } else if ( am_root ) { if ( add_a_group ( f_out , NOBODY_GROUP ) < 0 ) return - 1 ; } module_dir = lp_path ( i ) ; if ( * module_dir == '\\0' ) { rprintf ( FLOG , "No<S2SV_blank>path<S2SV_blank>specified<S2SV_blank>for<S2SV_blank>module<S2SV_blank>%s\\n" , name ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>no<S2SV_blank>path<S2SV_blank>setting.\\n" ) ; return - 1 ; } if ( use_chroot ) { if ( ( p = strstr ( module_dir , "/./" ) ) != NULL ) { * p = '\\0' ; if ( ! ( module_chdir = normalize_path ( module_dir , True , NULL ) ) ) return path_failure ( f_out , module_dir , False ) ; * p = '/' ; if ( ! ( p = normalize_path ( p + 2 , True , & module_dirlen ) ) ) return path_failure ( f_out , strstr ( module_dir , "/./" ) , False ) ; if ( ! ( full_module_path = normalize_path ( module_dir , False , NULL ) ) ) full_module_path = module_dir ; module_dir = p ; } else { if ( ! ( module_chdir = normalize_path ( module_dir , False , NULL ) ) ) return path_failure ( f_out , module_dir , False ) ; full_module_path = module_chdir ; module_dir = "/" ; module_dirlen = 1 ; } } else { if ( ! ( module_chdir = normalize_path ( module_dir , False , & module_dirlen ) ) ) return path_failure ( f_out , module_dir , False ) ; full_module_path = module_dir = module_chdir ; } set_env_str ( "RSYNC_MODULE_PATH" , full_module_path ) ; if ( module_dirlen == 1 ) { module_dirlen = 0 ; set_filter_dir ( "/" , 1 ) ; } else set_filter_dir ( module_dir , module_dirlen ) ; p = lp_filter ( i ) ; parse_filter_str ( & daemon_filter_list , p , rule_template ( FILTRULE_WORD_SPLIT ) , XFLG_ABS_IF_SLASH | XFLG_DIR2WILD3 ) ; p = lp_include_from ( i ) ; parse_filter_file ( & daemon_filter_list , p , rule_template ( FILTRULE_INCLUDE ) , XFLG_ABS_IF_SLASH | XFLG_DIR2WILD3 | XFLG_OLD_PREFIXES | XFLG_FATAL_ERRORS ) ; p = lp_include ( i ) ; parse_filter_str ( & daemon_filter_list , p , rule_template ( FILTRULE_INCLUDE | FILTRULE_WORD_SPLIT ) , XFLG_ABS_IF_SLASH | XFLG_DIR2WILD3 | XFLG_OLD_PREFIXES ) ; p = lp_exclude_from ( i ) ; parse_filter_file ( & daemon_filter_list , p , rule_template ( 0 ) , XFLG_ABS_IF_SLASH | XFLG_DIR2WILD3 | XFLG_OLD_PREFIXES | XFLG_FATAL_ERRORS ) ; p = lp_exclude ( i ) ; parse_filter_str ( & daemon_filter_list , p , rule_template ( FILTRULE_WORD_SPLIT ) , XFLG_ABS_IF_SLASH | XFLG_DIR2WILD3 | XFLG_OLD_PREFIXES ) ; log_init ( 1 ) ; # ifdef HAVE_PUTENV if ( * lp_prexfer_exec ( i ) || * lp_postxfer_exec ( i ) ) { int status ; if ( * lp_postxfer_exec ( i ) ) { pid_t pid = fork ( ) ; if ( pid < 0 ) { rsyserr ( FLOG , errno , "fork<S2SV_blank>failed" ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>fork<S2SV_blank>failed\\n" ) ; return - 1 ; } if ( pid ) { close ( f_in ) ; if ( f_out != f_in ) close ( f_out ) ; set_env_num ( "RSYNC_PID" , ( long ) pid ) ; if ( wait_process ( pid , & status , 0 ) < 0 ) status = - 1 ; set_env_num ( "RSYNC_RAW_STATUS" , status ) ; if ( WIFEXITED ( status ) ) status = WEXITSTATUS ( status ) ; else status = - 1 ; set_env_num ( "RSYNC_EXIT_STATUS" , status ) ; if ( system ( lp_postxfer_exec ( i ) ) < 0 ) status = - 1 ; _exit ( status ) ; } } if ( * lp_prexfer_exec ( i ) ) { int arg_fds [ 2 ] , error_fds [ 2 ] ; set_env_num ( "RSYNC_PID" , ( long ) getpid ( ) ) ; if ( pipe ( arg_fds ) < 0 || pipe ( error_fds ) < 0 || ( pre_exec_pid = fork ( ) ) < 0 ) { rsyserr ( FLOG , errno , "pre-xfer<S2SV_blank>exec<S2SV_blank>preparation<S2SV_blank>failed" ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>pre-xfer<S2SV_blank>exec<S2SV_blank>preparation<S2SV_blank>failed\\n" ) ; return - 1 ; } if ( pre_exec_pid == 0 ) { char buf [ BIGPATHBUFLEN ] ; int j , len ; close ( arg_fds [ 1 ] ) ; close ( error_fds [ 0 ] ) ; pre_exec_arg_fd = arg_fds [ 0 ] ; pre_exec_error_fd = error_fds [ 1 ] ; set_blocking ( pre_exec_arg_fd ) ; set_blocking ( pre_exec_error_fd ) ; len = read_arg_from_pipe ( pre_exec_arg_fd , buf , BIGPATHBUFLEN ) ; if ( len <= 0 ) _exit ( 1 ) ; set_env_str ( "RSYNC_REQUEST" , buf ) ; for ( j = 0 ; ; j ++ ) { len = read_arg_from_pipe ( pre_exec_arg_fd , buf , BIGPATHBUFLEN ) ; if ( len <= 0 ) { if ( ! len ) break ; _exit ( 1 ) ; } if ( asprintf ( & p , "RSYNC_ARG%d=%s" , j , buf ) >= 0 ) putenv ( p ) ; } close ( pre_exec_arg_fd ) ; close ( STDIN_FILENO ) ; dup2 ( pre_exec_error_fd , STDOUT_FILENO ) ; close ( pre_exec_error_fd ) ; status = system ( lp_prexfer_exec ( i ) ) ; if ( ! WIFEXITED ( status ) ) _exit ( 1 ) ; _exit ( WEXITSTATUS ( status ) ) ; } close ( arg_fds [ 0 ] ) ; close ( error_fds [ 1 ] ) ; pre_exec_arg_fd = arg_fds [ 1 ] ; pre_exec_error_fd = error_fds [ 0 ] ; set_blocking ( pre_exec_arg_fd ) ; set_blocking ( pre_exec_error_fd ) ; } } # endif if ( use_chroot ) { if ( chroot ( module_chdir ) ) { rsyserr ( FLOG , errno , "chroot<S2SV_blank>%s<S2SV_blank>failed" , module_chdir ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>chroot<S2SV_blank>failed\\n" ) ; return - 1 ; } module_chdir = module_dir ; } if ( ! change_dir ( module_chdir , CD_NORMAL ) ) return path_failure ( f_out , module_chdir , True ) ; if ( module_dirlen || ! use_chroot ) sanitize_paths = 1 ; if ( ( munge_symlinks = lp_munge_symlinks ( i ) ) < 0 ) munge_symlinks = ! use_chroot || module_dirlen ; if ( munge_symlinks ) { STRUCT_STAT st ; char prefix [ SYMLINK_PREFIX_LEN ] ; strlcpy ( prefix , SYMLINK_PREFIX , sizeof prefix ) ; if ( do_stat ( prefix , & st ) == 0 && S_ISDIR ( st . st_mode ) ) { rprintf ( FLOG , "Symlink<S2SV_blank>munging<S2SV_blank>is<S2SV_blank>unsafe<S2SV_blank>when<S2SV_blank>a<S2SV_blank>%s<S2SV_blank>directory<S2SV_blank>exists.\\n" , prefix ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>daemon<S2SV_blank>security<S2SV_blank>issue<S2SV_blank>--<S2SV_blank>contact<S2SV_blank>admin\\n" , name ) ; exit_cleanup ( RERR_UNSUPPORTED ) ; } } if ( gid_list . count ) { gid_t * gid_array = gid_list . items ; if ( setgid ( gid_array [ 0 ] ) ) { rsyserr ( FLOG , errno , "setgid<S2SV_blank>%ld<S2SV_blank>failed" , ( long ) gid_array [ 0 ] ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>setgid<S2SV_blank>failed\\n" ) ; return - 1 ; } # ifdef HAVE_SETGROUPS if ( setgroups ( gid_list . count , gid_array ) ) { rsyserr ( FLOG , errno , "setgroups<S2SV_blank>failed" ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>setgroups<S2SV_blank>failed\\n" ) ; return - 1 ; } # endif # if defined HAVE_INITGROUPS && ! defined HAVE_GETGROUPLIST if ( pw && initgroups ( pw -> pw_name , pw -> pw_gid ) < 0 ) { rsyserr ( FLOG , errno , "initgroups<S2SV_blank>failed" ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>initgroups<S2SV_blank>failed\\n" ) ; return - 1 ; } # endif } if ( set_uid ) { if ( setuid ( uid ) < 0 # ifdef HAVE_SETEUID || seteuid ( uid ) < 0 # endif ) { rsyserr ( FLOG , errno , "setuid<S2SV_blank>%ld<S2SV_blank>failed" , ( long ) uid ) ; io_printf ( f_out , "@ERROR:<S2SV_blank>setuid<S2SV_blank>failed\\n" ) ; return - 1 ; } am_root = ( MY_UID ( ) == 0 ) ; } if ( lp_temp_dir ( i ) && * lp_temp_dir ( i ) ) { tmpdir = lp_temp_dir ( i ) ; if ( strlen ( tmpdir ) >= MAXPATHLEN - 10 ) { rprintf ( FLOG , "the<S2SV_blank>\'temp<S2SV_blank>dir\'<S2SV_blank>value<S2SV_blank>for<S2SV_blank>%s<S2SV_blank>is<S2SV_blank>WAY<S2SV_blank>too<S2SV_blank>long<S2SV_blank>--<S2SV_blank>ignoring.\\n" , name ) ; tmpdir = NULL ; } } io_printf ( f_out , "@RSYNCD:<S2SV_blank>OK\\n" ) ; read_args ( f_in , name , line , sizeof line , rl_nulls , & argv , & argc , & request ) ; orig_argv = argv ; save_munge_symlinks = munge_symlinks ; reset_output_levels ( ) ; ret = parse_arguments ( & argc , ( const char * * * ) & argv ) ; if ( protect_args && ret ) { orig_early_argv = orig_argv ; protect_args = 2 ; read_args ( f_in , name , line , sizeof line , 1 , & argv , & argc , & request ) ; orig_argv = argv ; ret = parse_arguments ( & argc , ( const char * * * ) & argv ) ; } else orig_early_argv = NULL ; munge_symlinks = save_munge_symlinks ; if ( pre_exec_pid ) { err_msg = finish_pre_exec ( pre_exec_pid , pre_exec_arg_fd , pre_exec_error_fd , request , orig_early_argv , orig_argv ) ; } if ( orig_early_argv ) free ( orig_early_argv ) ; am_server = 1 ; quiet = 0 ; if ( lp_ignore_errors ( module_id ) ) ignore_errors = 1 ; if ( write_batch < 0 ) dry_run = 1 ; if ( lp_fake_super ( i ) ) { if ( preserve_xattrs > 1 ) preserve_xattrs = 1 ; am_root = - 1 ; } else if ( am_root < 0 ) am_root = 2 ; if ( filesfrom_fd == 0 ) filesfrom_fd = f_in ; if ( request ) { if ( * auth_user ) { rprintf ( FLOG , "rsync<S2SV_blank>%s<S2SV_blank>%s<S2SV_blank>from<S2SV_blank>%s@%s<S2SV_blank>(%s)\\n" , am_sender ? "on" : "to" , request , auth_user , host , addr ) ; } else { rprintf ( FLOG , "rsync<S2SV_blank>%s<S2SV_blank>%s<S2SV_blank>from<S2SV_blank>%s<S2SV_blank>(%s)\\n" , am_sender ? "on" : "to" , request , host , addr ) ; } free ( request ) ; } # ifndef DEBUG limit_output_verbosity ( lp_max_verbosity ( i ) ) ; # endif if ( protocol_version < 23 && ( protocol_version == 22 || am_sender ) ) io_start_multiplex_out ( f_out ) ; else if ( ! ret || err_msg ) { setup_protocol ( f_out , f_in ) ; if ( ! am_sender ) { if ( ! files_from ) { int i ; for ( i = 0 ; i < argc ; i ++ ) { if ( strncmp ( argv [ i ] , "--files-from" , 12 ) == 0 ) { files_from = "" ; break ; } } } if ( files_from ) write_byte ( f_out , 0 ) ; } io_start_multiplex_out ( f_out ) ; } if ( ! ret || err_msg ) { if ( err_msg ) { while ( ( p = strchr ( err_msg , '\\n' ) ) != NULL ) { int len = p - err_msg + 1 ; rwrite ( FERROR , err_msg , len , 0 ) ; err_msg += len ; } if ( * err_msg ) rprintf ( FERROR , "%s\\n" , err_msg ) ; } else option_error ( ) ; msleep ( 400 ) ; exit_cleanup ( RERR_UNSUPPORTED ) ; } # ifdef ICONV_OPTION if ( ! iconv_opt ) { if ( ic_send != ( iconv_t ) - 1 ) { iconv_close ( ic_send ) ; ic_send = ( iconv_t ) - 1 ; } if ( ic_recv != ( iconv_t ) - 1 ) { iconv_close ( ic_recv ) ; ic_recv = ( iconv_t ) - 1 ; } } # endif if ( ! numeric_ids && ( use_chroot ? lp_numeric_ids ( i ) != False : lp_numeric_ids ( i ) == True ) ) numeric_ids = - 1 ; if ( lp_timeout ( i ) && ( ! io_timeout || lp_timeout ( i ) < io_timeout ) ) set_io_timeout ( lp_timeout ( i ) ) ; if ( am_sender ) p = lp_outgoing_chmod ( i ) ; else p = lp_incoming_chmod ( i ) ; if ( * p && ! ( daemon_chmod_modes = parse_chmod ( p , & chmod_modes ) ) ) { rprintf ( FLOG , "Invalid<S2SV_blank>\\"%sing<S2SV_blank>chmod\\"<S2SV_blank>directive:<S2SV_blank>%s\\n" , am_sender ? "outgo" : "incom" , p ) ; } start_server ( f_in , f_out , argc , argv ) ; return 0 ; }
void intel_cleanup_overlay ( struct drm_i915_private * dev_priv ) { if ( ! dev_priv -> overlay ) return ; WARN_ON ( dev_priv -> overlay -> active ) ; i915_gem_object_put ( dev_priv -> overlay -> reg_bo ) ; kfree ( dev_priv -> overlay ) ; }
int intel_overlay_attrs_ioctl ( struct drm_device * dev , void * data , struct drm_file * file_priv ) { struct drm_intel_overlay_attrs * attrs = data ; struct drm_i915_private * dev_priv = to_i915 ( dev ) ; struct intel_overlay * overlay ; struct overlay_registers __iomem * regs ; int ret ; overlay = dev_priv -> overlay ; if ( ! overlay ) { DRM_DEBUG ( "userspace<S2SV_blank>bug:<S2SV_blank>no<S2SV_blank>overlay\\n" ) ; return - ENODEV ; } drm_modeset_lock_all ( dev ) ; mutex_lock ( & dev -> struct_mutex ) ; ret = - EINVAL ; if ( ! ( attrs -> flags & I915_OVERLAY_UPDATE_ATTRS ) ) { attrs -> color_key = overlay -> color_key ; attrs -> brightness = overlay -> brightness ; attrs -> contrast = overlay -> contrast ; attrs -> saturation = overlay -> saturation ; if ( ! IS_GEN2 ( dev_priv ) ) { attrs -> gamma0 = I915_READ ( OGAMC0 ) ; attrs -> gamma1 = I915_READ ( OGAMC1 ) ; attrs -> gamma2 = I915_READ ( OGAMC2 ) ; attrs -> gamma3 = I915_READ ( OGAMC3 ) ; attrs -> gamma4 = I915_READ ( OGAMC4 ) ; attrs -> gamma5 = I915_READ ( OGAMC5 ) ; } } else { if ( attrs -> brightness < - 128 || attrs -> brightness > 127 ) goto out_unlock ; if ( attrs -> contrast > 255 ) goto out_unlock ; if ( attrs -> saturation > 1023 ) goto out_unlock ; overlay -> color_key = attrs -> color_key ; overlay -> brightness = attrs -> brightness ; overlay -> contrast = attrs -> contrast ; overlay -> saturation = attrs -> saturation ; regs = intel_overlay_map_regs ( overlay ) ; if ( ! regs ) { ret = - ENOMEM ; goto out_unlock ; } update_reg_attrs ( overlay , regs ) ; intel_overlay_unmap_regs ( overlay , regs ) ; if ( attrs -> flags & I915_OVERLAY_UPDATE_GAMMA ) { if ( IS_GEN2 ( dev_priv ) ) goto out_unlock ; if ( overlay -> active ) { ret = - EBUSY ; goto out_unlock ; } ret = check_gamma ( attrs ) ; if ( ret ) goto out_unlock ; I915_WRITE ( OGAMC0 , attrs -> gamma0 ) ; I915_WRITE ( OGAMC1 , attrs -> gamma1 ) ; I915_WRITE ( OGAMC2 , attrs -> gamma2 ) ; I915_WRITE ( OGAMC3 , attrs -> gamma3 ) ; I915_WRITE ( OGAMC4 , attrs -> gamma4 ) ; I915_WRITE ( OGAMC5 , attrs -> gamma5 ) ; } } overlay -> color_key_enabled = ( attrs -> flags & I915_OVERLAY_DISABLE_DEST_COLORKEY ) == 0 ; ret = 0 ; out_unlock : mutex_unlock ( & dev -> struct_mutex ) ; drm_modeset_unlock_all ( dev ) ; return ret ; }
static int intel_overlay_do_put_image ( struct intel_overlay * overlay , struct drm_i915_gem_object * new_bo , struct put_image_params * params ) { int ret , tmp_width ; struct overlay_registers __iomem * regs ; bool scale_changed = false ; struct drm_i915_private * dev_priv = overlay -> i915 ; u32 swidth , swidthsw , sheight , ostride ; enum pipe pipe = overlay -> crtc -> pipe ; struct i915_vma * vma ; lockdep_assert_held ( & dev_priv -> drm . struct_mutex ) ; WARN_ON ( ! drm_modeset_is_locked ( & dev_priv -> drm . mode_config . connection_mutex ) ) ; ret = intel_overlay_release_old_vid ( overlay ) ; if ( ret != 0 ) return ret ; atomic_inc ( & dev_priv -> gpu_error . pending_fb_pin ) ; vma = i915_gem_object_pin_to_display_plane ( new_bo , 0 , NULL , PIN_MAPPABLE ) ; if ( IS_ERR ( vma ) ) { ret = PTR_ERR ( vma ) ; goto out_pin_section ; } intel_fb_obj_flush ( new_bo , ORIGIN_DIRTYFB ) ; ret = i915_vma_put_fence ( vma ) ; if ( ret ) goto out_unpin ; if ( ! overlay -> active ) { u32 oconfig ; regs = intel_overlay_map_regs ( overlay ) ; if ( ! regs ) { ret = - ENOMEM ; goto out_unpin ; } oconfig = OCONF_CC_OUT_8BIT ; if ( IS_GEN4 ( dev_priv ) ) oconfig |= OCONF_CSC_MODE_BT709 ; oconfig |= pipe == 0 ? OCONF_PIPE_A : OCONF_PIPE_B ; iowrite32 ( oconfig , & regs -> OCONFIG ) ; intel_overlay_unmap_regs ( overlay , regs ) ; ret = intel_overlay_on ( overlay ) ; if ( ret != 0 ) goto out_unpin ; } regs = intel_overlay_map_regs ( overlay ) ; if ( ! regs ) { ret = - ENOMEM ; goto out_unpin ; } iowrite32 ( ( params -> dst_y << 16 ) | params -> dst_x , & regs -> DWINPOS ) ; iowrite32 ( ( params -> dst_h << 16 ) | params -> dst_w , & regs -> DWINSZ ) ; if ( params -> format & I915_OVERLAY_YUV_PACKED ) tmp_width = packed_width_bytes ( params -> format , params -> src_w ) ; else tmp_width = params -> src_w ; swidth = params -> src_w ; swidthsw = calc_swidthsw ( dev_priv , params -> offset_Y , tmp_width ) ; sheight = params -> src_h ; iowrite32 ( i915_ggtt_offset ( vma ) + params -> offset_Y , & regs -> OBUF_0Y ) ; ostride = params -> stride_Y ; if ( params -> format & I915_OVERLAY_YUV_PLANAR ) { int uv_hscale = uv_hsubsampling ( params -> format ) ; int uv_vscale = uv_vsubsampling ( params -> format ) ; u32 tmp_U , tmp_V ; swidth |= ( params -> src_w / uv_hscale ) << 16 ; tmp_U = calc_swidthsw ( dev_priv , params -> offset_U , params -> src_w / uv_hscale ) ; tmp_V = calc_swidthsw ( dev_priv , params -> offset_V , params -> src_w / uv_hscale ) ; swidthsw |= max_t ( u32 , tmp_U , tmp_V ) << 16 ; sheight |= ( params -> src_h / uv_vscale ) << 16 ; iowrite32 ( i915_ggtt_offset ( vma ) + params -> offset_U , & regs -> OBUF_0U ) ; iowrite32 ( i915_ggtt_offset ( vma ) + params -> offset_V , & regs -> OBUF_0V ) ; ostride |= params -> stride_UV << 16 ; } iowrite32 ( swidth , & regs -> SWIDTH ) ; iowrite32 ( swidthsw , & regs -> SWIDTHSW ) ; iowrite32 ( sheight , & regs -> SHEIGHT ) ; iowrite32 ( ostride , & regs -> OSTRIDE ) ; scale_changed = update_scaling_factors ( overlay , regs , params ) ; update_colorkey ( overlay , regs ) ; iowrite32 ( overlay_cmd_reg ( params ) , & regs -> OCMD ) ; intel_overlay_unmap_regs ( overlay , regs ) ; ret = intel_overlay_continue ( overlay , vma , scale_changed ) ; if ( ret ) goto out_unpin ; return 0 ; out_unpin : i915_gem_object_unpin_from_display_plane ( vma ) ; out_pin_section : atomic_dec ( & dev_priv -> gpu_error . pending_fb_pin ) ; return ret ; }
int intel_overlay_switch_off ( struct intel_overlay * overlay ) { struct drm_i915_private * dev_priv = overlay -> i915 ; struct overlay_registers __iomem * regs ; int ret ; lockdep_assert_held ( & dev_priv -> drm . struct_mutex ) ; WARN_ON ( ! drm_modeset_is_locked ( & dev_priv -> drm . mode_config . connection_mutex ) ) ; ret = intel_overlay_recover_from_interrupt ( overlay ) ; if ( ret != 0 ) return ret ; if ( ! overlay -> active ) return 0 ; ret = intel_overlay_release_old_vid ( overlay ) ; if ( ret != 0 ) return ret ; regs = intel_overlay_map_regs ( overlay ) ; iowrite32 ( 0 , & regs -> OCMD ) ; intel_overlay_unmap_regs ( overlay , regs ) ; return intel_overlay_off ( overlay ) ; }
void intel_setup_overlay ( struct drm_i915_private * dev_priv ) { struct intel_overlay * overlay ; struct drm_i915_gem_object * reg_bo ; struct overlay_registers __iomem * regs ; struct i915_vma * vma = NULL ; int ret ; if ( ! HAS_OVERLAY ( dev_priv ) ) return ; overlay = kzalloc ( sizeof ( * overlay ) , GFP_KERNEL ) ; if ( ! overlay ) return ; mutex_lock ( & dev_priv -> drm . struct_mutex ) ; if ( WARN_ON ( dev_priv -> overlay ) ) goto out_free ; overlay -> i915 = dev_priv ; reg_bo = NULL ; if ( ! OVERLAY_NEEDS_PHYSICAL ( dev_priv ) ) reg_bo = i915_gem_object_create_stolen ( dev_priv , PAGE_SIZE ) ; if ( reg_bo == NULL ) reg_bo = i915_gem_object_create ( dev_priv , PAGE_SIZE ) ; if ( IS_ERR ( reg_bo ) ) goto out_free ; overlay -> reg_bo = reg_bo ; if ( OVERLAY_NEEDS_PHYSICAL ( dev_priv ) ) { ret = i915_gem_object_attach_phys ( reg_bo , PAGE_SIZE ) ; if ( ret ) { DRM_ERROR ( "failed<S2SV_blank>to<S2SV_blank>attach<S2SV_blank>phys<S2SV_blank>overlay<S2SV_blank>regs\\n" ) ; goto out_free_bo ; } overlay -> flip_addr = reg_bo -> phys_handle -> busaddr ; } else { vma = i915_gem_object_ggtt_pin ( reg_bo , NULL , 0 , PAGE_SIZE , PIN_MAPPABLE ) ; if ( IS_ERR ( vma ) ) { DRM_ERROR ( "failed<S2SV_blank>to<S2SV_blank>pin<S2SV_blank>overlay<S2SV_blank>register<S2SV_blank>bo\\n" ) ; ret = PTR_ERR ( vma ) ; goto out_free_bo ; } overlay -> flip_addr = i915_ggtt_offset ( vma ) ; ret = i915_gem_object_set_to_gtt_domain ( reg_bo , true ) ; if ( ret ) { DRM_ERROR ( "failed<S2SV_blank>to<S2SV_blank>move<S2SV_blank>overlay<S2SV_blank>register<S2SV_blank>bo<S2SV_blank>into<S2SV_blank>the<S2SV_blank>GTT\\n" ) ; goto out_unpin_bo ; } } overlay -> color_key = 0x0101fe ; overlay -> color_key_enabled = true ; overlay -> brightness = - 19 ; overlay -> contrast = 75 ; overlay -> saturation = 146 ; init_request_active ( & overlay -> last_flip , NULL ) ; regs = intel_overlay_map_regs ( overlay ) ; if ( ! regs ) goto out_unpin_bo ; memset_io ( regs , 0 , sizeof ( struct overlay_registers ) ) ; update_polyphase_filter ( regs ) ; update_reg_attrs ( overlay , regs ) ; intel_overlay_unmap_regs ( overlay , regs ) ; dev_priv -> overlay = overlay ; mutex_unlock ( & dev_priv -> drm . struct_mutex ) ; DRM_INFO ( "initialized<S2SV_blank>overlay<S2SV_blank>support\\n" ) ; return ; out_unpin_bo : if ( vma ) i915_vma_unpin ( vma ) ; out_free_bo : i915_gem_object_put ( reg_bo ) ; out_free : mutex_unlock ( & dev_priv -> drm . struct_mutex ) ; kfree ( overlay ) ; return ; }
void dbs_check_cpu ( struct dbs_data * dbs_data , int cpu ) { struct cpu_dbs_common_info * cdbs = dbs_data -> cdata -> get_cpu_cdbs ( cpu ) ; struct od_dbs_tuners * od_tuners = dbs_data -> tuners ; struct cs_dbs_tuners * cs_tuners = dbs_data -> tuners ; struct ex_dbs_tuners * ex_tuners = dbs_data -> tuners ; struct zz_dbs_tuners * zz_tuners = dbs_data -> tuners ; struct cpufreq_policy * policy ; unsigned int sampling_rate ; unsigned int max_load = 0 ; unsigned int ignore_nice ; unsigned int j ; if ( dbs_data -> cdata -> governor == GOV_ONDEMAND ) { struct od_cpu_dbs_info_s * od_dbs_info = dbs_data -> cdata -> get_cpu_dbs_info_s ( cpu ) ; sampling_rate = od_tuners -> sampling_rate ; sampling_rate *= od_dbs_info -> rate_mult ; ignore_nice = od_tuners -> ignore_nice_load ; } else if ( dbs_data -> cdata -> governor == GOV_ELEMENTALX ) { sampling_rate = ex_tuners -> sampling_rate ; ignore_nice = ex_tuners -> ignore_nice_load ; } else if ( dbs_data -> cdata -> governor == GOV_ZZMOOVE ) { sampling_rate = zz_tuners -> sampling_rate ; ignore_nice = zz_tuners -> ignore_nice_load ; } else { sampling_rate = cs_tuners -> sampling_rate ; ignore_nice = cs_tuners -> ignore_nice_load ; } policy = cdbs -> cur_policy ; for_each_cpu ( j , policy -> cpus ) { struct cpu_dbs_common_info * j_cdbs ; u64 cur_wall_time , cur_idle_time ; unsigned int idle_time , wall_time ; unsigned int load ; int io_busy = 0 ; j_cdbs = dbs_data -> cdata -> get_cpu_cdbs ( j ) ; if ( dbs_data -> cdata -> governor == GOV_ONDEMAND ) io_busy = od_tuners -> io_is_busy ; cur_idle_time = get_cpu_idle_time ( j , & cur_wall_time , io_busy ) ; wall_time = ( unsigned int ) ( cur_wall_time - j_cdbs -> prev_cpu_wall ) ; j_cdbs -> prev_cpu_wall = cur_wall_time ; idle_time = ( unsigned int ) ( cur_idle_time - j_cdbs -> prev_cpu_idle ) ; j_cdbs -> prev_cpu_idle = cur_idle_time ; if ( ignore_nice ) { u64 cur_nice ; unsigned long cur_nice_jiffies ; cur_nice = kcpustat_cpu ( j ) . cpustat [ CPUTIME_NICE ] - cdbs -> prev_cpu_nice ; cur_nice_jiffies = ( unsigned long ) cputime64_to_jiffies64 ( cur_nice ) ; cdbs -> prev_cpu_nice = kcpustat_cpu ( j ) . cpustat [ CPUTIME_NICE ] ; idle_time += jiffies_to_usecs ( cur_nice_jiffies ) ; } if ( unlikely ( ! wall_time || wall_time < idle_time ) ) continue ; if ( unlikely ( wall_time > ( 2 * sampling_rate ) && j_cdbs -> prev_load ) ) { load = j_cdbs -> prev_load ; j_cdbs -> prev_load = 0 ; } else { load = 100 * ( wall_time - idle_time ) / wall_time ; j_cdbs -> prev_load = load ; } if ( load > max_load ) max_load = load ; } dbs_data -> cdata -> gov_check_cpu ( cpu , max_load ) ; }
int netmap_bwrap_notify ( struct netmap_kring * kring , int flags ) { struct netmap_adapter * na = kring -> na ; struct netmap_bwrap_adapter * bna = na -> na_private ; struct netmap_adapter * hwna = bna -> hwna ; u_int ring_n = kring -> ring_id ; u_int lim = kring -> nkr_num_slots - 1 ; struct netmap_kring * hw_kring ; int error ; ND ( "%s:<S2SV_blank>na<S2SV_blank>%s<S2SV_blank>hwna<S2SV_blank>%s" , ( kring ? kring -> name : "NULL!" ) , ( na ? na -> name : "NULL!" ) , ( hwna ? hwna -> name : "NULL!" ) ) ; hw_kring = hwna -> tx_rings [ ring_n ] ; if ( nm_kr_tryget ( hw_kring , 0 , NULL ) ) { return ENXIO ; } netmap_vp_rxsync ( kring , flags ) ; ND ( "%s[%d]<S2SV_blank>PRE<S2SV_blank>rx(c%3d<S2SV_blank>t%3d<S2SV_blank>l%3d)<S2SV_blank>ring(h%3d<S2SV_blank>c%3d<S2SV_blank>t%3d)<S2SV_blank>tx(c%3d<S2SV_blank>ht%3d<S2SV_blank>t%3d)" , na -> name , ring_n , kring -> nr_hwcur , kring -> nr_hwtail , kring -> nkr_hwlease , ring -> head , ring -> cur , ring -> tail , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail , hw_ring -> rtail ) ; hw_kring -> rhead = hw_kring -> rcur = kring -> nr_hwtail ; error = hw_kring -> nm_sync ( hw_kring , flags ) ; if ( error ) goto put_out ; kring -> rhead = kring -> rcur = nm_next ( hw_kring -> nr_hwtail , lim ) ; netmap_vp_rxsync ( kring , flags ) ; ND ( "%s[%d]<S2SV_blank>PST<S2SV_blank>rx(c%3d<S2SV_blank>t%3d<S2SV_blank>l%3d)<S2SV_blank>ring(h%3d<S2SV_blank>c%3d<S2SV_blank>t%3d)<S2SV_blank>tx(c%3d<S2SV_blank>ht%3d<S2SV_blank>t%3d)" , na -> name , ring_n , kring -> nr_hwcur , kring -> nr_hwtail , kring -> nkr_hwlease , ring -> head , ring -> cur , ring -> tail , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail , hw_kring -> rtail ) ; put_out : nm_kr_put ( hw_kring ) ; return error ? error : NM_IRQ_COMPLETED ; }
int ipmi_register_smi ( const struct ipmi_smi_handlers * handlers , void * send_info , struct device * si_dev , unsigned char slave_addr ) { int i , j ; int rv ; struct ipmi_smi * intf , * tintf ; struct list_head * link ; struct ipmi_device_id id ; if ( ! initialized ) { rv = ipmi_init_msghandler ( ) ; if ( rv ) return rv ; if ( ! initialized ) return - ENODEV ; } intf = kzalloc ( sizeof ( * intf ) , GFP_KERNEL ) ; if ( ! intf ) return - ENOMEM ; rv = init_srcu_struct ( & intf -> users_srcu ) ; if ( rv ) { kfree ( intf ) ; return rv ; } intf -> bmc = & intf -> tmp_bmc ; INIT_LIST_HEAD ( & intf -> bmc -> intfs ) ; mutex_init ( & intf -> bmc -> dyn_mutex ) ; INIT_LIST_HEAD ( & intf -> bmc_link ) ; mutex_init ( & intf -> bmc_reg_mutex ) ; intf -> intf_num = - 1 ; kref_init ( & intf -> refcount ) ; INIT_WORK ( & intf -> bmc_reg_work , redo_bmc_reg ) ; intf -> si_dev = si_dev ; for ( j = 0 ; j < IPMI_MAX_CHANNELS ; j ++ ) { intf -> addrinfo [ j ] . address = IPMI_BMC_SLAVE_ADDR ; intf -> addrinfo [ j ] . lun = 2 ; } if ( slave_addr != 0 ) intf -> addrinfo [ 0 ] . address = slave_addr ; INIT_LIST_HEAD ( & intf -> users ) ; intf -> handlers = handlers ; intf -> send_info = send_info ; spin_lock_init ( & intf -> seq_lock ) ; for ( j = 0 ; j < IPMI_IPMB_NUM_SEQ ; j ++ ) { intf -> seq_table [ j ] . inuse = 0 ; intf -> seq_table [ j ] . seqid = 0 ; } intf -> curr_seq = 0 ; spin_lock_init ( & intf -> waiting_rcv_msgs_lock ) ; INIT_LIST_HEAD ( & intf -> waiting_rcv_msgs ) ; tasklet_init ( & intf -> recv_tasklet , smi_recv_tasklet , ( unsigned long ) intf ) ; atomic_set ( & intf -> watchdog_pretimeouts_to_deliver , 0 ) ; spin_lock_init ( & intf -> xmit_msgs_lock ) ; INIT_LIST_HEAD ( & intf -> xmit_msgs ) ; INIT_LIST_HEAD ( & intf -> hp_xmit_msgs ) ; spin_lock_init ( & intf -> events_lock ) ; atomic_set ( & intf -> event_waiters , 0 ) ; intf -> ticks_to_req_ev = IPMI_REQUEST_EV_TIME ; INIT_LIST_HEAD ( & intf -> waiting_events ) ; intf -> waiting_events_count = 0 ; mutex_init ( & intf -> cmd_rcvrs_mutex ) ; spin_lock_init ( & intf -> maintenance_mode_lock ) ; INIT_LIST_HEAD ( & intf -> cmd_rcvrs ) ; init_waitqueue_head ( & intf -> waitq ) ; for ( i = 0 ; i < IPMI_NUM_STATS ; i ++ ) atomic_set ( & intf -> stats [ i ] , 0 ) ; mutex_lock ( & ipmi_interfaces_mutex ) ; i = 0 ; link = & ipmi_interfaces ; list_for_each_entry_rcu ( tintf , & ipmi_interfaces , link ) { if ( tintf -> intf_num != i ) { link = & tintf -> link ; break ; } i ++ ; } if ( i == 0 ) list_add_rcu ( & intf -> link , & ipmi_interfaces ) ; else list_add_tail_rcu ( & intf -> link , link ) ; rv = handlers -> start_processing ( send_info , intf ) ; if ( rv ) goto out ; rv = __bmc_get_device_id ( intf , NULL , & id , NULL , NULL , i ) ; if ( rv ) { dev_err ( si_dev , "Unable<S2SV_blank>to<S2SV_blank>get<S2SV_blank>the<S2SV_blank>device<S2SV_blank>id:<S2SV_blank>%d\\n" , rv ) ; goto out ; } mutex_lock ( & intf -> bmc_reg_mutex ) ; rv = __scan_channels ( intf , & id ) ; mutex_unlock ( & intf -> bmc_reg_mutex ) ; out : if ( rv ) { ipmi_bmc_unregister ( intf ) ; list_del_rcu ( & intf -> link ) ; mutex_unlock ( & ipmi_interfaces_mutex ) ; synchronize_srcu ( & ipmi_interfaces_srcu ) ; cleanup_srcu_struct ( & intf -> users_srcu ) ; kref_put ( & intf -> refcount , intf_free ) ; } else { smp_wmb ( ) ; intf -> intf_num = i ; mutex_unlock ( & ipmi_interfaces_mutex ) ; call_smi_watchers ( i , intf -> si_dev ) ; } return rv ; }
void ipmi_unregister_smi ( struct ipmi_smi * intf ) { struct ipmi_smi_watcher * w ; int intf_num = intf -> intf_num , index ; mutex_lock ( & ipmi_interfaces_mutex ) ; intf -> intf_num = - 1 ; intf -> in_shutdown = true ; list_del_rcu ( & intf -> link ) ; mutex_unlock ( & ipmi_interfaces_mutex ) ; synchronize_srcu ( & ipmi_interfaces_srcu ) ; mutex_lock ( & smi_watchers_mutex ) ; list_for_each_entry ( w , & smi_watchers , link ) w -> smi_gone ( intf_num ) ; mutex_unlock ( & smi_watchers_mutex ) ; index = srcu_read_lock ( & intf -> users_srcu ) ; while ( ! list_empty ( & intf -> users ) ) { struct ipmi_user * user = container_of ( list_next_rcu ( & intf -> users ) , struct ipmi_user , link ) ; _ipmi_destroy_user ( user ) ; } srcu_read_unlock ( & intf -> users_srcu , index ) ; intf -> handlers -> shutdown ( intf -> send_info ) ; cleanup_smi_msgs ( intf ) ; ipmi_bmc_unregister ( intf ) ; cleanup_srcu_struct ( & intf -> users_srcu ) ; kref_put ( & intf -> refcount , intf_free ) ; }
static void shutdown_ssif ( void * send_info ) { struct ssif_info * ssif_info = send_info ; device_remove_group ( & ssif_info -> client -> dev , & ipmi_ssif_dev_attr_group ) ; dev_set_drvdata ( & ssif_info -> client -> dev , NULL ) ; while ( ssif_info -> ssif_state != SSIF_NORMAL ) schedule_timeout ( 1 ) ; ssif_info -> stopping = true ; del_timer_sync ( & ssif_info -> retry_timer ) ; if ( ssif_info -> thread ) { complete ( & ssif_info -> wake_thread ) ; kthread_stop ( ssif_info -> thread ) ; } kfree ( ssif_info ) ; }
static int ssif_remove ( struct i2c_client * client ) { struct ssif_info * ssif_info = i2c_get_clientdata ( client ) ; struct ipmi_smi * intf ; struct ssif_addr_info * addr_info ; if ( ! ssif_info ) return 0 ; intf = ssif_info -> intf ; ssif_info -> intf = NULL ; ipmi_unregister_smi ( intf ) ; list_for_each_entry ( addr_info , & ssif_infos , link ) { if ( addr_info -> client == client ) { addr_info -> client = NULL ; break ; } } return 0 ; }
POOL_STATUS CommandComplete ( POOL_CONNECTION * frontend , POOL_CONNECTION_POOL * backend , bool command_complete ) { int len , len1 ; char * p , * p1 ; int i ; POOL_SESSION_CONTEXT * session_context ; POOL_CONNECTION * con ; p1 = NULL ; len1 = 0 ; session_context = pool_get_session_context ( false ) ; if ( session_context -> query_context != NULL && ! SL_MODE ) handle_query_context ( backend ) ; if ( SL_MODE && pool_is_doing_extended_query_message ( ) ) { for ( i = 0 ; i < NUM_BACKENDS ; i ++ ) { if ( VALID_BACKEND ( i ) ) { con = CONNECTION ( backend , i ) ; if ( pool_read ( con , & len , sizeof ( len ) ) < 0 ) return POOL_END ; len = ntohl ( len ) ; len -= 4 ; len1 = len ; p = pool_read2 ( con , len ) ; if ( p == NULL ) return POOL_END ; p1 = palloc ( len ) ; memcpy ( p1 , p , len ) ; if ( session_context -> query_context && session_context -> query_context -> parse_tree && is_start_transaction_query ( session_context -> query_context -> parse_tree ) ) TSTATE ( backend , i ) = 'T' ; { ereport ( DEBUG1 , ( errmsg ( "processing<S2SV_blank>command<S2SV_blank>complete" ) , errdetail ( "set<S2SV_blank>transaction<S2SV_blank>state<S2SV_blank>to<S2SV_blank>T" ) ) ) ; } } } } else { con = MASTER ( backend ) ; if ( pool_read ( con , & len , sizeof ( len ) ) < 0 ) return POOL_END ; len = ntohl ( len ) ; len -= 4 ; len1 = len ; p = pool_read2 ( con , len ) ; if ( p == NULL ) return POOL_END ; p1 = palloc ( len ) ; memcpy ( p1 , p , len ) ; } if ( SL_MODE && pool_is_doing_extended_query_message ( ) ) { int status ; if ( p1 == NULL ) { elog ( WARNING , "CommandComplete:<S2SV_blank>expected<S2SV_blank>p1<S2SV_blank>is<S2SV_blank>not<S2SV_blank>NULL" ) ; return POOL_END ; } if ( command_complete ) status = foward_command_complete ( frontend , p1 , len1 ) ; else status = foward_empty_query ( frontend , p1 , len1 ) ; if ( status < 0 ) return POOL_END ; } else { if ( handle_mismatch_tuples ( frontend , backend , p1 , len1 , command_complete ) != POOL_CONTINUE ) return POOL_END ; } if ( pool_config -> memory_cache_enabled ) { if ( pool_is_cache_safe ( ) && ! pool_is_cache_exceeded ( ) ) { memqcache_register ( 'C' , frontend , p1 , len1 ) ; } if ( SL_MODE && pool_is_doing_extended_query_message ( ) ) { char * query ; Node * node ; char state ; if ( session_context -> query_context == NULL ) { elog ( WARNING , "expected<S2SV_blank>query_contex<S2SV_blank>is<S2SV_blank>not<S2SV_blank>NULL" ) ; return POOL_END ; } query = session_context -> query_context -> query_w_hex ; node = pool_get_parse_tree ( ) ; state = TSTATE ( backend , MASTER_NODE_ID ) ; pool_handle_query_cache ( backend , query , node , state ) ; } } pfree ( p1 ) ; if ( pool_is_doing_extended_query_message ( ) && pool_is_query_in_progress ( ) ) { pool_set_query_state ( session_context -> query_context , POOL_EXECUTE_COMPLETE ) ; } if ( SL_MODE && pool_is_doing_extended_query_message ( ) ) { pool_at_command_success ( frontend , backend ) ; pool_unset_query_in_progress ( ) ; pool_pending_message_reset_previous_message ( ) ; } return POOL_CONTINUE ; }
static unsigned long ondemand_readahead ( struct address_space * mapping , struct file_ra_state * ra , struct file * filp , bool hit_readahead_marker , pgoff_t offset , unsigned long req_size ) { struct backing_dev_info * bdi = inode_to_bdi ( mapping -> host ) ; unsigned long max_pages = ra -> ra_pages ; pgoff_t prev_offset ; if ( req_size > max_pages && bdi -> io_pages > max_pages ) max_pages = min ( req_size , bdi -> io_pages ) ; if ( ! offset ) goto initial_readahead ; if ( ( offset == ( ra -> start + ra -> size - ra -> async_size ) || offset == ( ra -> start + ra -> size ) ) ) { ra -> start += ra -> size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( hit_readahead_marker ) { pgoff_t start ; rcu_read_lock ( ) ; start = page_cache_next_hole ( mapping , offset + 1 , max_pages ) ; rcu_read_unlock ( ) ; if ( ! start || start - offset > max_pages ) return 0 ; ra -> start = start ; ra -> size = start - offset ; ra -> size += req_size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( req_size > max_pages ) goto initial_readahead ; prev_offset = ( unsigned long long ) ra -> prev_pos >> PAGE_SHIFT ; if ( offset - prev_offset <= 1UL ) goto initial_readahead ; if ( try_context_readahead ( mapping , ra , offset , req_size , max_pages ) ) goto readit ; return __do_page_cache_readahead ( mapping , filp , offset , req_size , 0 ) ; initial_readahead : ra -> start = offset ; ra -> size = get_init_ra_size ( req_size , max_pages ) ; ra -> async_size = ra -> size > req_size ? ra -> size - req_size : ra -> size ; readit : if ( offset == ra -> start && ra -> size == ra -> async_size ) { ra -> async_size = get_next_ra_size ( ra , max_pages ) ; ra -> size += ra -> async_size ; } return ra_submit ( ra , mapping , filp ) ; }
static int dissect_quic ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ ) { proto_item * ti ; proto_tree * quic_tree ; guint offset = 0 ; guint32 header_form ; quic_packet_info_t * quic_packet = NULL ; col_set_str ( pinfo -> cinfo , COL_PROTOCOL , "QUIC" ) ; if ( PINFO_FD_VISITED ( pinfo ) ) { quic_packet = ( quic_packet_info_t * ) p_get_proto_data ( wmem_file_scope ( ) , pinfo , proto_quic , 0 ) ; } if ( ! quic_packet ) { quic_packet = wmem_new0 ( wmem_file_scope ( ) , quic_packet_info_t ) ; p_add_proto_data ( wmem_file_scope ( ) , pinfo , proto_quic , 0 , quic_packet ) ; } ti = proto_tree_add_item ( tree , proto_quic , tvb , 0 , - 1 , ENC_NA ) ; quic_tree = proto_item_add_subtree ( ti , ett_quic ) ; if ( ! PINFO_FD_VISITED ( pinfo ) ) { guint8 long_packet_type ; guint32 version ; quic_cid_t dcid = { . len = 0 } , scid = { . len = 0 } ; gboolean from_server = FALSE ; quic_info_data_t * conn ; quic_extract_header ( tvb , & long_packet_type , & version , & dcid , & scid ) ; conn = quic_connection_find ( pinfo , long_packet_type , & dcid , & from_server ) ; quic_connection_create_or_update ( & conn , pinfo , long_packet_type , version , & scid , & dcid , from_server ) ; quic_packet -> conn = conn ; quic_packet -> from_server = from_server ; # if 0 proto_tree_add_debug_text ( quic_tree , "Connection:<S2SV_blank>%d<S2SV_blank>%p<S2SV_blank>DCID=%s<S2SV_blank>SCID=%s<S2SV_blank>from_server:%d" , pinfo -> num , quic_packet -> conn , cid_to_string ( & dcid ) , cid_to_string ( & scid ) , quic_packet -> from_server ) ; } else { proto_tree_add_debug_text ( quic_tree , "Connection:<S2SV_blank>%d<S2SV_blank>%p<S2SV_blank>from_server:%d" , pinfo -> num , quic_packet -> conn , quic_packet -> from_server ) ; # endif } quic_add_connection_info ( tvb , pinfo , quic_tree , quic_packet ) ; do { tvbuff_t * next_tvb = quic_get_message_tvb ( tvb , offset ) ; proto_tree_add_item_ret_uint ( quic_tree , hf_quic_header_form , next_tvb , 0 , 1 , ENC_NA , & header_form ) ; if ( header_form ) { gboolean is_vn = tvb_get_ntohl ( next_tvb , 1 ) == 0 ; if ( is_vn ) { dissect_quic_version_negotiation ( next_tvb , pinfo , quic_tree , quic_packet ) ; break ; } dissect_quic_long_header ( next_tvb , pinfo , quic_tree , quic_packet ) ; } else { dissect_quic_short_header ( next_tvb , pinfo , quic_tree , quic_packet ) ; } offset += tvb_reported_length ( next_tvb ) ; } while ( tvb_reported_length_remaining ( tvb , offset ) ) ; return offset ; }
static int dissect_quic_handshake ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * quic_tree , guint offset , quic_info_data_t * quic_info , quic_packet_info_t * quic_packet , guint pkn_len ) { proto_item * ti ; ti = proto_tree_add_item ( quic_tree , hf_quic_handshake_payload , tvb , offset , - 1 , ENC_NA ) ; if ( ! quic_info ) { return tvb_reported_length_remaining ( tvb , offset ) ; } quic_cipher * cipher = quic_packet -> from_server ? & quic_info -> server_handshake_cipher : & quic_info -> client_handshake_cipher ; quic_process_payload ( tvb , pinfo , quic_tree , ti , offset , quic_info , quic_packet , cipher , pkn_len ) ; offset += tvb_reported_length_remaining ( tvb , offset ) ; return offset ; }
static int dissect_quic_initial ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * quic_tree , guint offset , quic_info_data_t * quic_info , quic_packet_info_t * quic_packet , guint pkn_len ) { proto_item * ti ; ti = proto_tree_add_item ( quic_tree , hf_quic_initial_payload , tvb , offset , - 1 , ENC_NA ) ; DISSECTOR_ASSERT ( quic_info ) ; quic_cipher * cipher = quic_packet -> from_server ? & quic_info -> server_handshake_cipher : & quic_info -> client_handshake_cipher ; quic_process_payload ( tvb , pinfo , quic_tree , ti , offset , quic_info , quic_packet , cipher , pkn_len ) ; offset += tvb_reported_length_remaining ( tvb , offset ) ; return offset ; }
static int dissect_quic_long_header ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * quic_tree , quic_packet_info_t * quic_packet ) { guint offset = 0 ; guint32 long_packet_type ; guint32 version ; quic_cid_t dcid = { . len = 0 } , scid = { . len = 0 } ; guint32 len_token_length ; guint64 token_length ; guint32 len_payload_length ; guint64 payload_length ; guint32 pkn_len ; guint64 pkn ; quic_info_data_t * conn = quic_packet -> conn ; quic_cipher * cipher = NULL ; proto_tree_add_item_ret_uint ( quic_tree , hf_quic_long_packet_type , tvb , offset , 1 , ENC_NA , & long_packet_type ) ; offset += 1 ; col_set_str ( pinfo -> cinfo , COL_INFO , val_to_str ( long_packet_type , quic_long_packet_type_vals , "Long<S2SV_blank>Header" ) ) ; offset = dissect_quic_long_header_common ( tvb , pinfo , quic_tree , offset , quic_packet , & version , & dcid , & scid ) ; if ( ! is_quic_draft_max ( version , 12 ) && long_packet_type == QUIC_LPT_INITIAL ) { proto_tree_add_item_ret_varint ( quic_tree , hf_quic_token_length , tvb , offset , - 1 , ENC_VARINT_QUIC , & token_length , & len_token_length ) ; offset += len_token_length ; if ( token_length ) { proto_tree_add_item ( quic_tree , hf_quic_token , tvb , offset , ( guint32 ) token_length , ENC_NA ) ; offset += ( guint ) token_length ; } } proto_tree_add_item_ret_varint ( quic_tree , hf_quic_length , tvb , offset , - 1 , ENC_VARINT_QUIC , & payload_length , & len_payload_length ) ; offset += len_payload_length ; # ifdef HAVE_LIBGCRYPT_AEAD if ( ! PINFO_FD_VISITED ( pinfo ) && ( long_packet_type == QUIC_LPT_INITIAL && ! quic_packet -> from_server ) && conn && ! memcmp ( & dcid , & conn -> client_dcid_initial , sizeof ( quic_cid_t ) ) ) { const gchar * error = NULL ; if ( ! quic_create_handshake_decoders ( & dcid , & error , conn ) ) { expert_add_info_format ( pinfo , quic_tree , & ei_quic_decryption_failed , "Failed<S2SV_blank>to<S2SV_blank>create<S2SV_blank>decryption<S2SV_blank>context:<S2SV_blank>%s" , error ) ; quic_packet -> decryption . error = wmem_strdup ( wmem_file_scope ( ) , error ) ; } } if ( conn ) { cipher = ! quic_packet -> from_server ? & conn -> client_handshake_cipher : & conn -> server_handshake_cipher ; } # endif pkn_len = dissect_quic_packet_number ( tvb , pinfo , quic_tree , offset , conn , quic_packet , cipher , GCRY_CIPHER_AES128 , & pkn ) ; if ( pkn_len == 0 ) { return offset ; } offset += pkn_len ; col_append_fstr ( pinfo -> cinfo , COL_INFO , ",<S2SV_blank>PKN:<S2SV_blank>%" G_GINT64_MODIFIER "u" , pkn ) ; switch ( long_packet_type ) { case QUIC_LPT_INITIAL : offset = dissect_quic_initial ( tvb , pinfo , quic_tree , offset , conn , quic_packet , pkn_len ) ; break ; case QUIC_LPT_HANDSHAKE : offset = dissect_quic_handshake ( tvb , pinfo , quic_tree , offset , conn , quic_packet , pkn_len ) ; break ; case QUIC_LPT_RETRY : offset = dissect_quic_retry ( tvb , pinfo , quic_tree , offset , conn , quic_packet , pkn_len ) ; break ; default : proto_tree_add_item ( quic_tree , hf_quic_protected_payload , tvb , offset , - 1 , ENC_NA ) ; offset += tvb_reported_length_remaining ( tvb , offset ) ; break ; } return offset ; }
static guint32 dissect_quic_packet_number ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , guint offset , quic_info_data_t * quic_info , quic_packet_info_t * quic_packet , quic_cipher * cipher , int pn_cipher_algo , guint64 * pkn_out ) { proto_item * ti ; guint pkn_len ; guint64 pkn ; if ( quic_info && is_quic_draft_max ( quic_info -> version , 11 ) ) { guint8 packet_type = tvb_get_guint8 ( tvb , 0 ) ; if ( ( packet_type & 0x80 ) != 0 ) { pkn_len = 4 ; } else { pkn_len = get_len_packet_number ( packet_type ) ; } proto_tree_add_item_ret_uint64 ( tree , hf_quic_packet_number , tvb , offset , pkn_len , ENC_BIG_ENDIAN , & pkn ) ; } else { if ( ! PINFO_FD_VISITED ( pinfo ) ) { pkn_len = quic_decrypt_packet_number ( tvb , offset , cipher , pn_cipher_algo , & pkn ) ; quic_packet -> pkn_len = pkn_len ; } else { pkn_len = quic_packet -> pkn_len ; pkn = quic_packet -> packet_number & ( ( 1UL << ( 8 * pkn_len ) ) - 1 ) ; } if ( ! pkn_len ) { expert_add_info_format ( pinfo , tree , & ei_quic_decryption_failed , "Failed<S2SV_blank>to<S2SV_blank>decrypt<S2SV_blank>packet<S2SV_blank>number" ) ; return 0 ; } proto_tree_add_uint64 ( tree , hf_quic_packet_number , tvb , offset , pkn_len , pkn ) ; } if ( ! quic_info ) { * pkn_out = pkn ; return pkn_len ; } if ( ! PINFO_FD_VISITED ( pinfo ) ) { if ( quic_packet -> from_server ) { pkn = quic_pkt_adjust_pkt_num ( quic_info -> max_server_pkn , pkn , 8 * pkn_len ) ; quic_info -> max_server_pkn = pkn ; } else { pkn = quic_pkt_adjust_pkt_num ( quic_info -> max_client_pkn , pkn , 8 * pkn_len ) ; quic_info -> max_client_pkn = pkn ; } quic_packet -> packet_number = pkn ; } else { pkn = quic_packet -> packet_number ; } ti = proto_tree_add_uint64 ( tree , hf_quic_packet_number_full , tvb , offset , pkn_len , pkn ) ; PROTO_ITEM_SET_GENERATED ( ti ) ; * pkn_out = pkn ; return pkn_len ; }
static int dissect_quic_short_header ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * quic_tree , quic_packet_info_t * quic_packet ) { guint offset = 0 ; quic_cid_t dcid = { . len = 0 } ; guint32 pkn_len ; guint64 pkn ; proto_item * ti ; gboolean key_phase = FALSE ; quic_cipher * cipher = NULL ; quic_info_data_t * conn = quic_packet -> conn ; proto_tree_add_item_ret_boolean ( quic_tree , hf_quic_short_kp_flag , tvb , offset , 1 , ENC_NA , & key_phase ) ; proto_tree_add_item ( quic_tree , hf_quic_short_packet_type , tvb , offset , 1 , ENC_NA ) ; if ( conn ) { dcid . len = quic_packet -> from_server ? conn -> client_cids . data . len : conn -> server_cids . data . len ; } offset += 1 ; if ( dcid . len > 0 ) { proto_tree_add_item ( quic_tree , hf_quic_dcid , tvb , offset , dcid . len , ENC_NA ) ; tvb_memcpy ( tvb , dcid . cid , offset , dcid . len ) ; offset += dcid . len ; } # ifdef HAVE_LIBGCRYPT_AEAD if ( ! PINFO_FD_VISITED ( pinfo ) && conn ) { pkn = 0 ; cipher = quic_get_pp_cipher ( pinfo , key_phase , pkn , conn , quic_packet -> from_server ) ; } # endif pkn_len = dissect_quic_packet_number ( tvb , pinfo , quic_tree , offset , conn , quic_packet , cipher , conn ? conn -> pn_cipher_algo : 0 , & pkn ) ; if ( pkn_len == 0 ) { return offset ; } offset += pkn_len ; col_clear ( pinfo -> cinfo , COL_INFO ) ; col_append_fstr ( pinfo -> cinfo , COL_INFO , "Protected<S2SV_blank>Payload<S2SV_blank>(KP%u),<S2SV_blank>PKN:<S2SV_blank>%" G_GINT64_MODIFIER "u" , key_phase , pkn ) ; if ( dcid . len > 0 ) { col_append_fstr ( pinfo -> cinfo , COL_INFO , ",<S2SV_blank>DCID=%s" , cid_to_string ( & dcid ) ) ; } ti = proto_tree_add_item ( quic_tree , hf_quic_protected_payload , tvb , offset , - 1 , ENC_NA ) ; if ( conn ) { quic_process_payload ( tvb , pinfo , quic_tree , ti , offset , conn , quic_packet , cipher , pkn_len ) ; } offset += tvb_reported_length_remaining ( tvb , offset ) ; return offset ; }
static void quic_add_connection_info ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , quic_packet_info_t * quic_packet ) { proto_tree * ctree ; proto_item * pi ; quic_info_data_t * conn = quic_packet -> conn ; ctree = proto_tree_add_subtree ( tree , tvb , 0 , 0 , ett_quic_connection_info , NULL , "QUIC<S2SV_blank>Connection<S2SV_blank>information" ) ; if ( ! conn ) { expert_add_info ( pinfo , ctree , & ei_quic_connection_unknown ) ; return ; } pi = proto_tree_add_uint ( ctree , hf_quic_connection_number , tvb , 0 , 0 , conn -> number ) ; PROTO_ITEM_SET_GENERATED ( pi ) ; # if 0 proto_tree_add_debug_text ( ctree , "Client<S2SV_blank>CID:<S2SV_blank>%s" , cid_to_string ( & conn -> client_cids . data ) ) ; proto_tree_add_debug_text ( ctree , "Server<S2SV_blank>CID:<S2SV_blank>%s" , cid_to_string ( & conn -> server_cids . data ) ) ; proto_tree_add_debug_text ( ctree , "InitialCID:<S2SV_blank>%s" , cid_to_string ( & conn -> client_dcid_initial ) ) ; # endif }
int netmap_bwrap_notify ( struct netmap_kring * kring , int flags ) { struct netmap_adapter * na = kring -> na ; struct netmap_bwrap_adapter * bna = na -> na_private ; struct netmap_adapter * hwna = bna -> hwna ; u_int ring_n = kring -> ring_id ; u_int lim = kring -> nkr_num_slots - 1 ; struct netmap_kring * hw_kring ; int error ; ND ( "%s:<S2SV_blank>na<S2SV_blank>%s<S2SV_blank>hwna<S2SV_blank>%s" , ( kring ? kring -> name : "NULL!" ) , ( na ? na -> name : "NULL!" ) , ( hwna ? hwna -> name : "NULL!" ) ) ; hw_kring = hwna -> tx_rings [ ring_n ] ; if ( nm_kr_tryget ( hw_kring , 0 , NULL ) ) { return ENXIO ; } netmap_vp_rxsync ( kring , flags ) ; ND ( "%s[%d]<S2SV_blank>PRE<S2SV_blank>rx(c%3d<S2SV_blank>t%3d<S2SV_blank>l%3d)<S2SV_blank>ring(h%3d<S2SV_blank>c%3d<S2SV_blank>t%3d)<S2SV_blank>tx(c%3d<S2SV_blank>ht%3d<S2SV_blank>t%3d)" , na -> name , ring_n , kring -> nr_hwcur , kring -> nr_hwtail , kring -> nkr_hwlease , ring -> head , ring -> cur , ring -> tail , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail , hw_ring -> rtail ) ; hw_kring -> rhead = hw_kring -> rcur = kring -> nr_hwtail ; error = hw_kring -> nm_sync ( hw_kring , flags ) ; if ( error ) goto put_out ; kring -> rhead = kring -> rcur = nm_next ( hw_kring -> nr_hwtail , lim ) ; netmap_vp_rxsync ( kring , flags ) ; ND ( "%s[%d]<S2SV_blank>PST<S2SV_blank>rx(c%3d<S2SV_blank>t%3d<S2SV_blank>l%3d)<S2SV_blank>ring(h%3d<S2SV_blank>c%3d<S2SV_blank>t%3d)<S2SV_blank>tx(c%3d<S2SV_blank>ht%3d<S2SV_blank>t%3d)" , na -> name , ring_n , kring -> nr_hwcur , kring -> nr_hwtail , kring -> nkr_hwlease , ring -> head , ring -> cur , ring -> tail , hw_kring -> nr_hwcur , hw_kring -> nr_hwtail , hw_kring -> rtail ) ; put_out : nm_kr_put ( hw_kring ) ; return error ? error : NM_IRQ_COMPLETED ; }
int ipmi_register_smi ( const struct ipmi_smi_handlers * handlers , void * send_info , struct device * si_dev , unsigned char slave_addr ) { int i , j ; int rv ; struct ipmi_smi * intf , * tintf ; struct list_head * link ; struct ipmi_device_id id ; if ( ! initialized ) { rv = ipmi_init_msghandler ( ) ; if ( rv ) return rv ; if ( ! initialized ) return - ENODEV ; } intf = kzalloc ( sizeof ( * intf ) , GFP_KERNEL ) ; if ( ! intf ) return - ENOMEM ; rv = init_srcu_struct ( & intf -> users_srcu ) ; if ( rv ) { kfree ( intf ) ; return rv ; } intf -> bmc = & intf -> tmp_bmc ; INIT_LIST_HEAD ( & intf -> bmc -> intfs ) ; mutex_init ( & intf -> bmc -> dyn_mutex ) ; INIT_LIST_HEAD ( & intf -> bmc_link ) ; mutex_init ( & intf -> bmc_reg_mutex ) ; intf -> intf_num = - 1 ; kref_init ( & intf -> refcount ) ; INIT_WORK ( & intf -> bmc_reg_work , redo_bmc_reg ) ; intf -> si_dev = si_dev ; for ( j = 0 ; j < IPMI_MAX_CHANNELS ; j ++ ) { intf -> addrinfo [ j ] . address = IPMI_BMC_SLAVE_ADDR ; intf -> addrinfo [ j ] . lun = 2 ; } if ( slave_addr != 0 ) intf -> addrinfo [ 0 ] . address = slave_addr ; INIT_LIST_HEAD ( & intf -> users ) ; intf -> handlers = handlers ; intf -> send_info = send_info ; spin_lock_init ( & intf -> seq_lock ) ; for ( j = 0 ; j < IPMI_IPMB_NUM_SEQ ; j ++ ) { intf -> seq_table [ j ] . inuse = 0 ; intf -> seq_table [ j ] . seqid = 0 ; } intf -> curr_seq = 0 ; spin_lock_init ( & intf -> waiting_rcv_msgs_lock ) ; INIT_LIST_HEAD ( & intf -> waiting_rcv_msgs ) ; tasklet_init ( & intf -> recv_tasklet , smi_recv_tasklet , ( unsigned long ) intf ) ; atomic_set ( & intf -> watchdog_pretimeouts_to_deliver , 0 ) ; spin_lock_init ( & intf -> xmit_msgs_lock ) ; INIT_LIST_HEAD ( & intf -> xmit_msgs ) ; INIT_LIST_HEAD ( & intf -> hp_xmit_msgs ) ; spin_lock_init ( & intf -> events_lock ) ; atomic_set ( & intf -> event_waiters , 0 ) ; intf -> ticks_to_req_ev = IPMI_REQUEST_EV_TIME ; INIT_LIST_HEAD ( & intf -> waiting_events ) ; intf -> waiting_events_count = 0 ; mutex_init ( & intf -> cmd_rcvrs_mutex ) ; spin_lock_init ( & intf -> maintenance_mode_lock ) ; INIT_LIST_HEAD ( & intf -> cmd_rcvrs ) ; init_waitqueue_head ( & intf -> waitq ) ; for ( i = 0 ; i < IPMI_NUM_STATS ; i ++ ) atomic_set ( & intf -> stats [ i ] , 0 ) ; mutex_lock ( & ipmi_interfaces_mutex ) ; i = 0 ; link = & ipmi_interfaces ; list_for_each_entry_rcu ( tintf , & ipmi_interfaces , link ) { if ( tintf -> intf_num != i ) { link = & tintf -> link ; break ; } i ++ ; } if ( i == 0 ) list_add_rcu ( & intf -> link , & ipmi_interfaces ) ; else list_add_tail_rcu ( & intf -> link , link ) ; rv = handlers -> start_processing ( send_info , intf ) ; if ( rv ) goto out ; rv = __bmc_get_device_id ( intf , NULL , & id , NULL , NULL , i ) ; if ( rv ) { dev_err ( si_dev , "Unable<S2SV_blank>to<S2SV_blank>get<S2SV_blank>the<S2SV_blank>device<S2SV_blank>id:<S2SV_blank>%d\\n" , rv ) ; goto out ; } mutex_lock ( & intf -> bmc_reg_mutex ) ; rv = __scan_channels ( intf , & id ) ; mutex_unlock ( & intf -> bmc_reg_mutex ) ; out : if ( rv ) { ipmi_bmc_unregister ( intf ) ; list_del_rcu ( & intf -> link ) ; mutex_unlock ( & ipmi_interfaces_mutex ) ; synchronize_srcu ( & ipmi_interfaces_srcu ) ; cleanup_srcu_struct ( & intf -> users_srcu ) ; kref_put ( & intf -> refcount , intf_free ) ; } else { smp_wmb ( ) ; intf -> intf_num = i ; mutex_unlock ( & ipmi_interfaces_mutex ) ; call_smi_watchers ( i , intf -> si_dev ) ; } return rv ; }
void ipmi_unregister_smi ( struct ipmi_smi * intf ) { struct ipmi_smi_watcher * w ; int intf_num = intf -> intf_num , index ; mutex_lock ( & ipmi_interfaces_mutex ) ; intf -> intf_num = - 1 ; intf -> in_shutdown = true ; list_del_rcu ( & intf -> link ) ; mutex_unlock ( & ipmi_interfaces_mutex ) ; synchronize_srcu ( & ipmi_interfaces_srcu ) ; mutex_lock ( & smi_watchers_mutex ) ; list_for_each_entry ( w , & smi_watchers , link ) w -> smi_gone ( intf_num ) ; mutex_unlock ( & smi_watchers_mutex ) ; index = srcu_read_lock ( & intf -> users_srcu ) ; while ( ! list_empty ( & intf -> users ) ) { struct ipmi_user * user = container_of ( list_next_rcu ( & intf -> users ) , struct ipmi_user , link ) ; _ipmi_destroy_user ( user ) ; } srcu_read_unlock ( & intf -> users_srcu , index ) ; intf -> handlers -> shutdown ( intf -> send_info ) ; cleanup_smi_msgs ( intf ) ; ipmi_bmc_unregister ( intf ) ; cleanup_srcu_struct ( & intf -> users_srcu ) ; kref_put ( & intf -> refcount , intf_free ) ; }
static void shutdown_ssif ( void * send_info ) { struct ssif_info * ssif_info = send_info ; device_remove_group ( & ssif_info -> client -> dev , & ipmi_ssif_dev_attr_group ) ; dev_set_drvdata ( & ssif_info -> client -> dev , NULL ) ; while ( ssif_info -> ssif_state != SSIF_NORMAL ) schedule_timeout ( 1 ) ; ssif_info -> stopping = true ; del_timer_sync ( & ssif_info -> retry_timer ) ; if ( ssif_info -> thread ) { complete ( & ssif_info -> wake_thread ) ; kthread_stop ( ssif_info -> thread ) ; } kfree ( ssif_info ) ; }
static int ssif_remove ( struct i2c_client * client ) { struct ssif_info * ssif_info = i2c_get_clientdata ( client ) ; struct ipmi_smi * intf ; struct ssif_addr_info * addr_info ; if ( ! ssif_info ) return 0 ; intf = ssif_info -> intf ; ssif_info -> intf = NULL ; ipmi_unregister_smi ( intf ) ; list_for_each_entry ( addr_info , & ssif_infos , link ) { if ( addr_info -> client == client ) { addr_info -> client = NULL ; break ; } } return 0 ; }
static ssize_t keychord_write ( struct file * file , const char __user * buffer , size_t count , loff_t * ppos ) { struct keychord_device * kdev = file -> private_data ; struct input_keychord * keychords = 0 ; struct input_keychord * keychord , * next , * end ; int ret , i , key ; unsigned long flags ; if ( count < sizeof ( struct input_keychord ) ) return - EINVAL ; keychords = kzalloc ( count , GFP_KERNEL ) ; if ( ! keychords ) return - ENOMEM ; if ( copy_from_user ( keychords , buffer , count ) ) { kfree ( keychords ) ; return - EFAULT ; } if ( kdev -> registered ) { input_unregister_handler ( & kdev -> input_handler ) ; kdev -> registered = 0 ; } spin_lock_irqsave ( & kdev -> lock , flags ) ; kfree ( kdev -> keychords ) ; kdev -> keychords = 0 ; kdev -> keychord_count = 0 ; kdev -> key_down = 0 ; memset ( kdev -> keybit , 0 , sizeof ( kdev -> keybit ) ) ; memset ( kdev -> keystate , 0 , sizeof ( kdev -> keystate ) ) ; kdev -> head = kdev -> tail = 0 ; keychord = keychords ; end = ( struct input_keychord * ) ( ( char * ) keychord + count ) ; while ( keychord < end ) { next = NEXT_KEYCHORD ( keychord ) ; if ( keychord -> count <= 0 || next > end ) { pr_err ( "keychord:<S2SV_blank>invalid<S2SV_blank>keycode<S2SV_blank>count<S2SV_blank>%d\\n" , keychord -> count ) ; goto err_unlock_return ; } if ( keychord -> version != KEYCHORD_VERSION ) { pr_err ( "keychord:<S2SV_blank>unsupported<S2SV_blank>version<S2SV_blank>%d\\n" , keychord -> version ) ; goto err_unlock_return ; } for ( i = 0 ; i < keychord -> count ; i ++ ) { key = keychord -> keycodes [ i ] ; if ( key < 0 || key >= KEY_CNT ) { pr_err ( "keychord:<S2SV_blank>keycode<S2SV_blank>%d<S2SV_blank>out<S2SV_blank>of<S2SV_blank>range\\n" , key ) ; goto err_unlock_return ; } __set_bit ( key , kdev -> keybit ) ; } kdev -> keychord_count ++ ; keychord = next ; } kdev -> keychords = keychords ; spin_unlock_irqrestore ( & kdev -> lock , flags ) ; ret = input_register_handler ( & kdev -> input_handler ) ; if ( ret ) { kfree ( keychords ) ; kdev -> keychords = 0 ; return ret ; } kdev -> registered = 1 ; return count ; err_unlock_return : spin_unlock_irqrestore ( & kdev -> lock , flags ) ; kfree ( keychords ) ; return - EINVAL ; }
void snd_seq_fifo_cell_putback ( struct snd_seq_fifo * f , struct snd_seq_event_cell * cell ) { unsigned long flags ; if ( cell ) { spin_lock_irqsave ( & f -> lock , flags ) ; cell -> next = f -> head ; f -> head = cell ; f -> cells ++ ; spin_unlock_irqrestore ( & f -> lock , flags ) ; } }
int snd_seq_fifo_event_in ( struct snd_seq_fifo * f , struct snd_seq_event * event ) { struct snd_seq_event_cell * cell ; unsigned long flags ; int err ; if ( snd_BUG_ON ( ! f ) ) return - EINVAL ; snd_use_lock_use ( & f -> use_lock ) ; err = snd_seq_event_dup ( f -> pool , event , & cell , 1 , NULL ) ; if ( err < 0 ) { if ( ( err == - ENOMEM ) || ( err == - EAGAIN ) ) atomic_inc ( & f -> overflow ) ; snd_use_lock_free ( & f -> use_lock ) ; return err ; } spin_lock_irqsave ( & f -> lock , flags ) ; if ( f -> tail != NULL ) f -> tail -> next = cell ; f -> tail = cell ; if ( f -> head == NULL ) f -> head = cell ; f -> cells ++ ; spin_unlock_irqrestore ( & f -> lock , flags ) ; if ( waitqueue_active ( & f -> input_sleep ) ) wake_up ( & f -> input_sleep ) ; snd_use_lock_free ( & f -> use_lock ) ; return 0 ; }
void keyboard_slave_loop ( void ) { matrix_init ( ) ; # ifdef RGBLIGHT_ENABLE rgblight_init ( ) ; # endif while ( 1 ) { matrix_slave_scan ( ) ; # ifdef BACKLIGHT_ENABLE if ( BACKLIT_DIRTY ) { backlight_set ( i2c_slave_buffer [ I2C_BACKLIT_START ] ) ; BACKLIT_DIRTY = false ; } # endif # ifdef RGBLIGHT_ENABLE if ( RGB_DIRTY ) { cli ( ) ; uint32_t dword ; uint8_t * dword_dat = ( uint8_t * ) ( & dword ) ; for ( int i = 0 ; i < 4 ; i ++ ) { dword_dat [ i ] = i2c_slave_buffer [ I2C_RGB_START + i ] ; } rgblight_update_dword ( dword ) ; RGB_DIRTY = false ; sei ( ) ; } # endif } }
static unsigned long ondemand_readahead ( struct address_space * mapping , struct file_ra_state * ra , struct file * filp , bool hit_readahead_marker , pgoff_t offset , unsigned long req_size ) { struct backing_dev_info * bdi = inode_to_bdi ( mapping -> host ) ; unsigned long max_pages = ra -> ra_pages ; pgoff_t prev_offset ; if ( req_size > max_pages && bdi -> io_pages > max_pages ) max_pages = min ( req_size , bdi -> io_pages ) ; if ( ! offset ) goto initial_readahead ; if ( ( offset == ( ra -> start + ra -> size - ra -> async_size ) || offset == ( ra -> start + ra -> size ) ) ) { ra -> start += ra -> size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( hit_readahead_marker ) { pgoff_t start ; rcu_read_lock ( ) ; start = page_cache_next_hole ( mapping , offset + 1 , max_pages ) ; rcu_read_unlock ( ) ; if ( ! start || start - offset > max_pages ) return 0 ; ra -> start = start ; ra -> size = start - offset ; ra -> size += req_size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( req_size > max_pages ) goto initial_readahead ; prev_offset = ( unsigned long long ) ra -> prev_pos >> PAGE_SHIFT ; if ( offset - prev_offset <= 1UL ) goto initial_readahead ; if ( try_context_readahead ( mapping , ra , offset , req_size , max_pages ) ) goto readit ; return __do_page_cache_readahead ( mapping , filp , offset , req_size , 0 ) ; initial_readahead : ra -> start = offset ; ra -> size = get_init_ra_size ( req_size , max_pages ) ; ra -> async_size = ra -> size > req_size ? ra -> size - req_size : ra -> size ; readit : if ( offset == ra -> start && ra -> size == ra -> async_size ) { ra -> async_size = get_next_ra_size ( ra , max_pages ) ; ra -> size += ra -> async_size ; } return ra_submit ( ra , mapping , filp ) ; }
Type * checkExprTypeEnum ( Expr * expr , CheckerContext * ctx , Package * pkg ) { ASSERT ( expr -> kind == ExprKind_TypeEnum ) ; Expr_TypeEnum enm = expr -> TypeEnum ; b32 hasMinMax = false ; u64 maxValue ; Type * backingType = NULL ; if ( enm . explicitType ) { Type * type = checkExpr ( enm . explicitType , ctx , pkg ) ; if ( ctx -> mode == ExprMode_Unresolved ) goto unresolved ; if ( ctx -> mode != ExprMode_Invalid ) { expectType ( pkg , type , ctx , enm . explicitType -> start ) ; if ( IsInteger ( type ) ) { maxValue = MaxValueForIntOrPointerType ( type ) ; hasMinMax = true ; backingType = type ; } else { ReportError ( pkg , TypeMismatchError , enm . explicitType -> start , "Enum<S2SV_blank>backing<S2SV_blank>type<S2SV_blank>must<S2SV_blank>be<S2SV_blank>an<S2SV_blank>integer.<S2SV_blank>Got:<S2SV_blank>%s" , DescribeType ( type ) ) ; } } } DynamicArray ( EnumField ) fields = NULL ; ArrayFit ( fields , ArrayLen ( enm . items ) ) ; u64 currentValue = 0 ; u64 largestValue = 0 ; For ( enm . items ) { EnumItem item = enm . items [ i ] ; if ( item . init ) { CheckerContext itemCtx = { . scope = ctx -> scope , . desiredType = backingType } ; Type * type = checkExpr ( item . init , & itemCtx , pkg ) ; if ( itemCtx . mode == ExprMode_Unresolved ) goto unresolved ; if ( ! IsConstant ( & itemCtx ) ) { ReportError ( pkg , TODOError , item . init -> start , "Enum<S2SV_blank>cases<S2SV_blank>must<S2SV_blank>be<S2SV_blank>a<S2SV_blank>constant<S2SV_blank>value" ) ; continue ; } if ( backingType && ! coerceType ( item . init , ctx , & type , backingType , pkg ) ) { continue ; } u64 val = itemCtx . val . u64 ; currentValue = val ; largestValue = MAX ( largestValue , val ) ; } if ( hasMinMax && currentValue > maxValue ) { ReportError ( pkg , IntOverflowError , item . init -> start , "Enum<S2SV_blank>case<S2SV_blank>is<S2SV_blank>will<S2SV_blank>overflow<S2SV_blank>backing<S2SV_blank>type" ) ; continue ; } ArrayPush ( fields , ( EnumField ) { . name = item . name , . val = currentValue } ) ; currentValue ++ ; } backingType = backingType ? backingType : SmallestIntTypeForPositiveValue ( largestValue ) ; Type * type = NewTypeEnum ( TypeFlag_None , backingType , fields ) ; storeInfoBasicExpr ( pkg , expr , type , ctx ) ; ctx -> mode = ExprMode_Type ; return type ; unresolved : ctx -> mode = ExprMode_Unresolved ; return NULL ; }
void checkStmtSwitch ( Stmt * stmt , CheckerContext * ctx , Package * pkg ) { CheckerContext switchCtx = { . scope = pushScope ( pkg , ctx -> scope ) , . swtch = stmt , . nextCase = NULL , . loop = ctx -> loop , . flags = ctx -> flags & ~ CheckerContextFlag_Constant & ~ CheckerContextFlag_LoopClosest , } ; Type * switchType = BoolType ; if ( stmt -> Switch . match ) { switchType = checkExpr ( stmt -> Switch . match , & switchCtx , pkg ) ; if ( ! isNumericOrPointer ( switchType ) && ! isBoolean ( switchType ) ) { ReportError ( pkg , CannotSwitchError , stmt -> Switch . match -> start , "Cannot<S2SV_blank>switch<S2SV_blank>on<S2SV_blank>value<S2SV_blank>of<S2SV_blank>type<S2SV_blank>%s" , DescribeType ( switchType ) ) ; } } Symbol * breakTarget = declareLabelSymbol ( pkg , switchCtx . scope , "$break" ) ; storeInfoSwitch ( pkg , stmt , breakTarget ) ; ForEachWithIndex ( stmt -> Switch . cases , i , Stmt * , switchCase ) { ForEach ( switchCase -> SwitchCase . matches , Expr * ) { Type * type = checkExpr ( it , & switchCtx , pkg ) ; if ( ! coerceType ( it , & switchCtx , & type , switchType , pkg ) ) { ReportError ( pkg , TypeMismatchError , it -> start , "Cannot<S2SV_blank>convert<S2SV_blank>%s<S2SV_blank>to<S2SV_blank>type<S2SV_blank>%s" , DescribeType ( type ) , DescribeType ( switchType ) ) ; } } if ( ! switchCase -> SwitchCase . matches && i + 1 != ArrayLen ( stmt -> Switch . cases ) ) { ReportError ( pkg , DefaultSwitchCaseNotLastError , switchCase -> start , "The<S2SV_blank>default<S2SV_blank>switch<S2SV_blank>case<S2SV_blank>must<S2SV_blank>be<S2SV_blank>the<S2SV_blank>final<S2SV_blank>case" ) ; } CheckerContext caseCtx = { . scope = pushScope ( pkg , switchCtx . scope ) , . swtch = stmt , . desiredType = ctx -> desiredType , . nextCase = NULL , . loop = switchCtx . loop , . flags = switchCtx . flags & ~ CheckerContextFlag_Constant , } ; if ( i + 1 < ArrayLen ( stmt -> Switch . cases ) ) { CheckerInfo_Case * nextCase = & GetStmtInfo ( pkg , stmt -> Switch . cases [ i + 1 ] ) -> Case ; nextCase -> fallthroughTarget = declareLabelSymbol ( pkg , caseCtx . scope , "$fallthrough" ) ; caseCtx . nextCase = stmt -> Switch . cases [ i + 1 ] ; } ForEach ( switchCase -> SwitchCase . block -> stmts , Stmt * ) { checkStmt ( it , & caseCtx , pkg ) ; } } }
Conversion conversion ( Type * type , Type * target ) { Conversion result = 0 ; if ( type -> kind == target -> kind ) { result |= ConversionKind_Same ; switch ( type -> kind ) { case TypeKind_Float : result |= ConversionFlag_Float ; if ( type -> Width < target -> Width ) result |= ConversionFlag_Extend ; return result ; case TypeKind_Int : if ( type -> Width < target -> Width ) result |= ConversionFlag_Extend ; if ( IsSigned ( type ) ) result |= ConversionFlag_Signed ; return result ; default : return result ; } } if ( type -> kind == TypeKind_Tuple && ArrayLen ( type -> Tuple . types ) == 1 ) { return conversion ( type -> Tuple . types [ 0 ] , target ) ; } if ( isBoolean ( target ) ) { result |= ConversionKind_Bool ; return result ; } if ( IsInteger ( type ) && IsFloat ( target ) ) { result |= ConversionKind_ItoF ; if ( IsSigned ( type ) ) result |= ConversionFlag_Signed ; return result ; } if ( type -> kind == TypeKind_Enum && IsInteger ( target ) ) { return ConversionKind_None ; } if ( IsFloat ( type ) && IsInteger ( target ) ) { result |= ConversionKind_FtoI & ConversionFlag_Float ; if ( IsSigned ( type ) ) result |= ConversionFlag_Signed ; return result ; } if ( isPointer ( type ) && IsInteger ( target ) ) { result |= ConversionKind_PtoI ; return result ; } if ( IsInteger ( target ) && isPointer ( type ) ) { result |= ConversionKind_ItoP ; return result ; } PANIC ( "Unhandled<S2SV_blank>or<S2SV_blank>prohibited<S2SV_blank>conversion" ) ; return ConversionKind_None ; }
void cgenDecl ( HeaderContext * ctx , DynamicArray ( Expr_Ident * ) names , Type * type , b32 isConst ) { ForEach ( names , Expr_Ident * ) { switch ( type -> kind ) { case TypeKind_Function : cgenFuncPrototype ( & ctx -> functions , it -> name , type ) ; break ; case TypeKind_Struct : { if ( type -> Symbol -> backendUserdata != HEAD_GENERATED ) { ArrayPrintf ( ctx -> primitiveDecls , "typedef<S2SV_blank>" ) ; cgenType ( & ctx -> primitiveDecls , it -> name , type ) ; ArrayPrintf ( ctx -> primitiveDecls , "<S2SV_blank>%s;\\n" , it -> name ) ; type -> Symbol -> backendUserdata = HEAD_GENERATED ; } ArrayPrintf ( ctx -> complexDecls , "struct<S2SV_blank>%s<S2SV_blank>{\\n" , it -> name ) ; ForEach ( type -> Struct . members , TypeField * ) { ArrayPrintf ( ctx -> complexDecls , "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>" ) ; cgenType ( & ctx -> complexDecls , it -> name , it -> type ) ; ArrayPrintf ( ctx -> complexDecls , ";\\n" ) ; } ArrayPrintf ( ctx -> complexDecls , "};\\n" ) ; } break ; default : { String typeStr = NULL ; cgenType ( & typeStr , it -> name , type ) ; const char * qualifiers = isConst ? "extern<S2SV_blank>const" : "extern" ; ArrayPrintf ( ctx -> primitiveDecls , "%s<S2SV_blank>%s;\\n" , qualifiers , typeStr ) ; } } } }
void cgenType ( String * buffer , const char * name , Type * type ) { b32 appendName = name != NULL ; switch ( type -> kind ) { case TypeKind_Int : ArrayPrintf ( * buffer , "Kai%s%d" , type -> Flags & TypeFlag_Signed ? "I" : "U" , type -> Width ) ; break ; case TypeKind_Float : ArrayPrintf ( * buffer , "KaiF%d" , type -> Width ) ; break ; case TypeKind_Pointer : { String pointee = NULL ; cgenType ( & pointee , NULL , type -> Pointer . pointeeType ) ; ArrayPrintf ( * buffer , "%s*" , pointee ) ; ArrayFree ( pointee ) ; } break ; case TypeKind_Struct : { appendName = false ; ArrayPrintf ( * buffer , "struct<S2SV_blank>%s" , name ? name : type -> Symbol -> name ) ; } break ; case TypeKind_Array : { appendName = false ; String elementType = NULL ; cgenType ( & elementType , NULL , type -> Array . elementType ) ; ArrayPrintf ( * buffer , "%s<S2SV_blank>%s[%lu]" , elementType , name , type -> Array . length ) ; ArrayFree ( elementType ) ; } break ; default : if ( type == VoidType ) { ArrayPrintf ( * buffer , "void" ) ; } else { ArrayPrintf ( * buffer , "type" ) ; } } if ( appendName ) { ArrayPrintf ( * buffer , "<S2SV_blank>%s" , name ) ; } }
const char * DescribeType ( Type * type ) { if ( ! type ) return DescribeTypeKind ( TypeKind_Invalid ) ; if ( type -> Symbol ) { return type -> Symbol -> name ; } return DescribeTypeKind ( type -> kind ) ; }
static ssize_t aod_show ( struct device * dev , struct device_attribute * attr , char * buf ) { struct drm_connector * connector = to_drm_connector ( dev ) ; int ret = 0 ; int aod_mode = 0 ; aod_mode = dsi_display_get_aod_mode ( connector ) ; ret = scnprintf ( buf , PAGE_SIZE , "AOD<S2SV_blank>mode<S2SV_blank>=<S2SV_blank>%d\\n" "0--AOD<S2SV_blank>off\\n" "1--AOD(10nit-alpm)\\n" "2--AOD(50nit-alpm)\\n" "3--AOD(10nit-hlpm)\\n" "4--AOD(50nit-hlpm)\\n" , aod_mode ) ; return ret ; }
static ssize_t aod_store ( struct device * dev , struct device_attribute * attr , const char * buf , size_t count ) { struct drm_connector * connector = to_drm_connector ( dev ) ; int ret = 0 ; int aod_mode = 0 ; ret = kstrtoint ( buf , 10 , & aod_mode ) ; if ( ret ) { pr_err ( "kstrtoint<S2SV_blank>failed.<S2SV_blank>ret=%d\\n" , ret ) ; return ret ; } ret = dsi_display_set_aod_mode ( connector , aod_mode ) ; if ( ret ) pr_err ( "set<S2SV_blank>AOD<S2SV_blank>mode(%d)<S2SV_blank>fail\\n" , aod_mode ) ; return count ; }
int dsi_display_set_power ( struct drm_connector * connector , int power_mode , void * disp ) { struct dsi_display * display = disp ; int rc = 0 ; struct msm_drm_notifier notifier_data ; int blank ; int aod_mode = 0 ; if ( ! display || ! display -> panel ) { pr_err ( "invalid<S2SV_blank>display/panel\\n" ) ; return - EINVAL ; } switch ( power_mode ) { case SDE_MODE_DPMS_LP1 : printk ( KERN_ERR "SDE_MODE_DPMS_LP1\\n" ) ; rc = dsi_panel_set_lp1 ( display -> panel ) ; aod_mode = display -> panel -> aod_mode ; printk ( KERN_ERR "When<S2SV_blank>on<S2SV_blank>doze<S2SV_blank>state<S2SV_blank>AOD_MODE<S2SV_blank>=<S2SV_blank>%d\\n" , aod_mode ) ; if ( aod_mode != 0 ) { dsi_panel_set_aod_mode ( display -> panel , aod_mode ) ; } break ; case SDE_MODE_DPMS_LP2 : printk ( KERN_ERR "SDE_MODE_DPMS_LP2\\n" ) ; rc = dsi_panel_set_lp2 ( display -> panel ) ; break ; default : printk ( KERN_ERR "SDE_MODE_DPMS<S2SV_blank>default\\n" ) ; rc = dsi_panel_set_nolp ( display -> panel ) ; if ( ( power_mode == SDE_MODE_DPMS_ON ) && display -> panel -> aod_status ) { aod_mode = 0 ; printk ( KERN_ERR "Turn<S2SV_blank>off<S2SV_blank>AOD<S2SV_blank>MODE<S2SV_blank>aod_mode<S2SV_blank>=<S2SV_blank>%d\\n" , aod_mode ) ; dsi_panel_set_aod_mode ( display -> panel , aod_mode ) ; } else if ( ( power_mode == SDE_MODE_DPMS_OFF ) && display -> panel -> aod_status ) { display -> panel -> aod_status = 0 ; display -> panel -> aod_curr_mode = 0 ; } break ; } if ( power_mode == SDE_MODE_DPMS_ON ) { blank = MSM_DRM_BLANK_UNBLANK_CUST ; notifier_data . data = & blank ; notifier_data . id = connector_state_crtc_index ; msm_drm_notifier_call_chain ( MSM_DRM_EARLY_EVENT_BLANK , & notifier_data ) ; } else if ( power_mode == SDE_MODE_DPMS_LP1 ) { blank = MSM_DRM_BLANK_NORMAL ; notifier_data . data = & blank ; notifier_data . id = connector_state_crtc_index ; msm_drm_notifier_call_chain ( MSM_DRM_EARLY_EVENT_BLANK , & notifier_data ) ; } else if ( power_mode == SDE_MODE_DPMS_OFF ) { blank = MSM_DRM_BLANK_POWERDOWN_CUST ; notifier_data . data = & blank ; notifier_data . id = connector_state_crtc_index ; msm_drm_notifier_call_chain ( MSM_DRM_EARLY_EVENT_BLANK , & notifier_data ) ; } return rc ; }
static unsigned long read_swap_header ( struct swap_info_struct * p , union swap_header * swap_header , struct inode * inode ) { int i ; unsigned long maxpages ; unsigned long swapfilepages ; if ( memcmp ( "SWAPSPACE2" , swap_header -> magic . magic , 10 ) ) { printk ( KERN_ERR "Unable<S2SV_blank>to<S2SV_blank>find<S2SV_blank>swap-space<S2SV_blank>signature\\n" ) ; return 0 ; } if ( swab32 ( swap_header -> info . version ) == 1 ) { swab32s ( & swap_header -> info . version ) ; swab32s ( & swap_header -> info . last_page ) ; swab32s ( & swap_header -> info . nr_badpages ) ; for ( i = 0 ; i < swap_header -> info . nr_badpages ; i ++ ) swab32s ( & swap_header -> info . badpages [ i ] ) ; } if ( swap_header -> info . version != 1 ) { printk ( KERN_WARNING "Unable<S2SV_blank>to<S2SV_blank>handle<S2SV_blank>swap<S2SV_blank>header<S2SV_blank>version<S2SV_blank>%d\\n" , swap_header -> info . version ) ; return 0 ; } p -> lowest_bit = 1 ; p -> cluster_next = 1 ; p -> cluster_nr = 0 ; maxpages = swp_offset ( pte_to_swp_entry ( swp_entry_to_pte ( swp_entry ( 0 , ~ 0UL ) ) ) ) + 1 ; if ( maxpages > swap_header -> info . last_page ) { maxpages = swap_header -> info . last_page + 1 ; if ( ( unsigned int ) maxpages == 0 ) maxpages = UINT_MAX ; } p -> highest_bit = maxpages - 1 ; if ( ! maxpages ) return 0 ; swapfilepages = i_size_read ( inode ) >> PAGE_SHIFT ; if ( swapfilepages && maxpages > swapfilepages ) { printk ( KERN_WARNING "Swap<S2SV_blank>area<S2SV_blank>shorter<S2SV_blank>than<S2SV_blank>signature<S2SV_blank>indicates\\n" ) ; return 0 ; } if ( swap_header -> info . nr_badpages && S_ISREG ( inode -> i_mode ) ) return 0 ; if ( swap_header -> info . nr_badpages > MAX_SWAP_BADPAGES ) return 0 ; return maxpages ; }
MVMString * MVM_string_utf16_decode ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes ) { # ifdef MVM_BIGENDIAN int mode = UTF16_DECODE_BIG_ENDIAN ; # else int mode = UTF16_DECODE_LITTLE_ENDIAN ; # endif if ( 2 <= bytes ) { if ( is_little_endian ( utf16_chars ) ) { mode = UTF16_DECODE_LITTLE_ENDIAN ; utf16_chars += 2 ; bytes -= 2 ; } else if ( is_big_endian ( utf16_chars ) ) { mode = UTF16_DECODE_BIG_ENDIAN ; utf16_chars += 2 ; bytes -= 2 ; } } return MVM_string_utf16_decode_main ( tc , result_type , utf16_chars , bytes , mode ) ; }
static MVMString * MVM_string_utf16_decode_main ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes , int endianess ) { MVMString * result = ( MVMString * ) REPR ( result_type ) -> allocate ( tc , STABLE ( result_type ) ) ; size_t str_pos = 0 ; MVMuint8 * utf16 = ( MVMuint8 * ) utf16_chars ; MVMuint8 * utf16_end = NULL ; int low , high ; MVMNormalizer norm ; MVMint32 ready ; switch ( endianess ) { case UTF16_DECODE_BIG_ENDIAN : low = 1 ; high = 0 ; break ; case UTF16_DECODE_LITTLE_ENDIAN : low = 0 ; high = 1 ; break ; default : MVM_exception_throw_adhoc ( tc , "Unknown<S2SV_blank>mode<S2SV_blank>set<S2SV_blank>in<S2SV_blank>utf16<S2SV_blank>decode.<S2SV_blank>This<S2SV_blank>should<S2SV_blank>never<S2SV_blank>happen." ) ; } if ( bytes % 2 ) { MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>odd<S2SV_blank>number<S2SV_blank>of<S2SV_blank>bytes" ) ; } utf16_end = utf16 + bytes ; result -> body . storage . blob_32 = MVM_malloc ( sizeof ( MVMGrapheme32 ) * bytes / 2 ) ; MVM_unicode_normalizer_init ( tc , & norm , MVM_NORMALIZE_NFG ) ; for ( ; utf16 < utf16_end ; utf16 += 2 ) { MVMuint32 value = ( utf16 [ high ] << 8 ) + utf16 [ low ] ; MVMuint32 value2 ; MVMGrapheme32 g ; if ( ( value & 0xFC00 ) == 0xDC00 ) { MVM_unicode_normalizer_cleanup ( tc , & norm ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>unexpected<S2SV_blank>low<S2SV_blank>surrogate" ) ; } if ( ( value & 0xFC00 ) == 0xD800 ) { utf16 += 2 ; if ( utf16 == utf16_end ) { MVM_unicode_normalizer_cleanup ( tc , & norm ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value2 = ( utf16 [ high ] << 8 ) + utf16 [ low ] ; if ( ( value2 & 0xFC00 ) != 0xDC00 ) { MVM_unicode_normalizer_cleanup ( tc , & norm ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value = 0x10000 + ( ( value & 0x3FF ) << 10 ) + ( value2 & 0x3FF ) ; } ready = MVM_unicode_normalizer_process_codepoint_to_grapheme ( tc , & norm , value , & g ) ; if ( ready ) { result -> body . storage . blob_32 [ str_pos ++ ] = g ; while ( -- ready > 0 ) result -> body . storage . blob_32 [ str_pos ++ ] = MVM_unicode_normalizer_get_grapheme ( tc , & norm ) ; } } MVM_unicode_normalizer_eof ( tc , & norm ) ; ready = MVM_unicode_normalizer_available ( tc , & norm ) ; while ( ready -- ) result -> body . storage . blob_32 [ str_pos ++ ] = MVM_unicode_normalizer_get_grapheme ( tc , & norm ) ; MVM_unicode_normalizer_cleanup ( tc , & norm ) ; result -> body . storage_type = MVM_STRING_GRAPHEME_32 ; result -> body . num_graphs = str_pos ; return result ; }
MVMuint32 MVM_string_utf16_decodestream ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { return MVM_string_utf16_decodestream_main ( tc , ds , stopper_chars , seps , UTF16_DECODE_AUTO_ENDIAN ) ; }
MVMuint32 MVM_string_utf16_decodestream_main ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps , int endianess ) { MVMint32 count = 0 , total = 0 ; MVMint32 bufsize ; MVMGrapheme32 * buffer ; MVMDecodeStreamBytes * cur_bytes ; MVMDecodeStreamBytes * last_accept_bytes = ds -> bytes_head ; MVMint32 last_accept_pos , last_was_cr ; MVMuint32 reached_stopper ; # ifdef MVM_BIGENDIAN int low = 1 ; int high = 0 ; # else int low = 0 ; int high = 1 ; # endif if ( ! ds -> bytes_head ) return 0 ; last_accept_pos = ds -> bytes_head_pos ; if ( stopper_chars && * stopper_chars == 0 ) return 1 ; bufsize = ds -> result_size_guess ; buffer = MVM_malloc ( bufsize * sizeof ( MVMGrapheme32 ) ) ; cur_bytes = ds -> bytes_head ; last_was_cr = 0 ; reached_stopper = 0 ; while ( cur_bytes ) { MVMint32 pos = cur_bytes == ds -> bytes_head ? ds -> bytes_head_pos : 0 ; MVMuint8 * bytes = ( unsigned char * ) cur_bytes -> bytes ; if ( ds -> abs_byte_pos == 0 && pos + 1 < cur_bytes -> length ) { if ( is_little_endian ( bytes + pos ) ) { low = 0 ; high = 1 ; last_accept_pos = pos ; pos += 2 ; } else if ( is_big_endian ( bytes + pos ) ) { low = 1 ; high = 0 ; last_accept_pos = pos ; pos += 2 ; } } for ( ; pos + 1 < cur_bytes -> length ; pos += 2 ) { MVMuint32 value = ( bytes [ pos + high ] << 8 ) + bytes [ pos + low ] ; MVMuint32 value2 ; MVMGrapheme32 g ; if ( ( value & 0xFC00 ) == 0xDC00 ) { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>unexpected<S2SV_blank>low<S2SV_blank>surrogate" ) ; } if ( ( value & 0xFC00 ) == 0xD800 ) { pos += 2 ; if ( pos + 1 >= cur_bytes -> length ) { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value2 = ( bytes [ pos + high ] << 8 ) + bytes [ pos + low ] ; if ( ( value2 & 0xFC00 ) != 0xDC00 ) { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value = 0x10000 + ( ( value & 0x3FF ) << 10 ) + ( value2 & 0x3FF ) ; } if ( count == bufsize ) { MVM_string_decodestream_add_chars ( tc , ds , buffer , bufsize ) ; buffer = MVM_malloc ( bufsize * sizeof ( MVMGrapheme32 ) ) ; count = 0 ; } buffer [ count ++ ] = value ; last_accept_bytes = cur_bytes ; last_accept_pos = pos ; total ++ ; if ( MVM_string_decode_stream_maybe_sep ( tc , seps , value ) || stopper_chars && * stopper_chars == total ) { reached_stopper = 1 ; goto done ; } } cur_bytes = cur_bytes -> next ; } done : if ( count ) { MVM_string_decodestream_add_chars ( tc , ds , buffer , count ) ; } else { MVM_free ( buffer ) ; } MVM_string_decodestream_discard_to ( tc , ds , last_accept_bytes , last_accept_pos + 1 ) ; return reached_stopper ; }
MVMString * MVM_string_utf16be_decode ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main ( tc , result_type , utf16_chars , bytes , UTF16_DECODE_BIG_ENDIAN ) ; }
MVMuint32 MVM_string_utf16be_decodestream ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { return MVM_string_utf16_decodestream_main ( tc , ds , stopper_chars , seps , UTF16_DECODE_BIG_ENDIAN ) ; }
MVMString * MVM_string_utf16le_decode ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main ( tc , result_type , utf16_chars , bytes , UTF16_DECODE_LITTLE_ENDIAN ) ; }
MVMuint32 MVM_string_utf16le_decodestream ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { return MVM_string_utf16_decodestream_main ( tc , ds , stopper_chars , seps , UTF16_DECODE_LITTLE_ENDIAN ) ; }
static unsigned long ondemand_readahead ( struct address_space * mapping , struct file_ra_state * ra , struct file * filp , bool hit_readahead_marker , pgoff_t offset , unsigned long req_size ) { struct backing_dev_info * bdi = inode_to_bdi ( mapping -> host ) ; unsigned long max_pages = ra -> ra_pages ; pgoff_t prev_offset ; if ( req_size > max_pages && bdi -> io_pages > max_pages ) max_pages = min ( req_size , bdi -> io_pages ) ; if ( ! offset ) goto initial_readahead ; if ( ( offset == ( ra -> start + ra -> size - ra -> async_size ) || offset == ( ra -> start + ra -> size ) ) ) { ra -> start += ra -> size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( hit_readahead_marker ) { pgoff_t start ; rcu_read_lock ( ) ; start = page_cache_next_hole ( mapping , offset + 1 , max_pages ) ; rcu_read_unlock ( ) ; if ( ! start || start - offset > max_pages ) return 0 ; ra -> start = start ; ra -> size = start - offset ; ra -> size += req_size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( req_size > max_pages ) goto initial_readahead ; prev_offset = ( unsigned long long ) ra -> prev_pos >> PAGE_SHIFT ; if ( offset - prev_offset <= 1UL ) goto initial_readahead ; if ( try_context_readahead ( mapping , ra , offset , req_size , max_pages ) ) goto readit ; return __do_page_cache_readahead ( mapping , filp , offset , req_size , 0 ) ; initial_readahead : ra -> start = offset ; ra -> size = get_init_ra_size ( req_size , max_pages ) ; ra -> async_size = ra -> size > req_size ? ra -> size - req_size : ra -> size ; readit : if ( offset == ra -> start && ra -> size == ra -> async_size ) { ra -> async_size = get_next_ra_size ( ra , max_pages ) ; ra -> size += ra -> async_size ; } return ra_submit ( ra , mapping , filp ) ; }
void keyboard_slave_loop ( void ) { matrix_init ( ) ; # ifdef RGBLIGHT_ENABLE rgblight_init ( ) ; # endif while ( 1 ) { matrix_slave_scan ( ) ; # ifdef BACKLIGHT_ENABLE if ( BACKLIT_DIRTY ) { backlight_set ( i2c_slave_buffer [ I2C_BACKLIT_START ] ) ; BACKLIT_DIRTY = false ; } # endif # ifdef RGBLIGHT_ENABLE if ( RGB_DIRTY ) { cli ( ) ; uint32_t dword ; uint8_t * dword_dat = ( uint8_t * ) ( & dword ) ; for ( int i = 0 ; i < 4 ; i ++ ) { dword_dat [ i ] = i2c_slave_buffer [ I2C_RGB_START + i ] ; } rgblight_update_dword ( dword ) ; RGB_DIRTY = false ; sei ( ) ; } # endif } }
MVMString * MVM_string_utf16_decode ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes ) { # ifdef MVM_BIGENDIAN int mode = UTF16_DECODE_BIG_ENDIAN ; # else int mode = UTF16_DECODE_LITTLE_ENDIAN ; # endif if ( 2 <= bytes ) { if ( is_little_endian ( utf16_chars ) ) { mode = UTF16_DECODE_LITTLE_ENDIAN ; utf16_chars += 2 ; bytes -= 2 ; } else if ( is_big_endian ( utf16_chars ) ) { mode = UTF16_DECODE_BIG_ENDIAN ; utf16_chars += 2 ; bytes -= 2 ; } } return MVM_string_utf16_decode_main ( tc , result_type , utf16_chars , bytes , mode ) ; }
static MVMString * MVM_string_utf16_decode_main ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes , int endianess ) { MVMString * result = ( MVMString * ) REPR ( result_type ) -> allocate ( tc , STABLE ( result_type ) ) ; size_t str_pos = 0 ; MVMuint8 * utf16 = ( MVMuint8 * ) utf16_chars ; MVMuint8 * utf16_end = NULL ; int low , high ; MVMNormalizer norm ; MVMint32 ready ; switch ( endianess ) { case UTF16_DECODE_BIG_ENDIAN : low = 1 ; high = 0 ; break ; case UTF16_DECODE_LITTLE_ENDIAN : low = 0 ; high = 1 ; break ; default : MVM_exception_throw_adhoc ( tc , "Unknown<S2SV_blank>mode<S2SV_blank>set<S2SV_blank>in<S2SV_blank>utf16<S2SV_blank>decode.<S2SV_blank>This<S2SV_blank>should<S2SV_blank>never<S2SV_blank>happen." ) ; } if ( bytes % 2 ) { MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>odd<S2SV_blank>number<S2SV_blank>of<S2SV_blank>bytes" ) ; } utf16_end = utf16 + bytes ; result -> body . storage . blob_32 = MVM_malloc ( sizeof ( MVMGrapheme32 ) * bytes / 2 ) ; MVM_unicode_normalizer_init ( tc , & norm , MVM_NORMALIZE_NFG ) ; for ( ; utf16 < utf16_end ; utf16 += 2 ) { MVMuint32 value = ( utf16 [ high ] << 8 ) + utf16 [ low ] ; MVMuint32 value2 ; MVMGrapheme32 g ; if ( ( value & 0xFC00 ) == 0xDC00 ) { MVM_unicode_normalizer_cleanup ( tc , & norm ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>unexpected<S2SV_blank>low<S2SV_blank>surrogate" ) ; } if ( ( value & 0xFC00 ) == 0xD800 ) { utf16 += 2 ; if ( utf16 == utf16_end ) { MVM_unicode_normalizer_cleanup ( tc , & norm ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value2 = ( utf16 [ high ] << 8 ) + utf16 [ low ] ; if ( ( value2 & 0xFC00 ) != 0xDC00 ) { MVM_unicode_normalizer_cleanup ( tc , & norm ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value = 0x10000 + ( ( value & 0x3FF ) << 10 ) + ( value2 & 0x3FF ) ; } ready = MVM_unicode_normalizer_process_codepoint_to_grapheme ( tc , & norm , value , & g ) ; if ( ready ) { result -> body . storage . blob_32 [ str_pos ++ ] = g ; while ( -- ready > 0 ) result -> body . storage . blob_32 [ str_pos ++ ] = MVM_unicode_normalizer_get_grapheme ( tc , & norm ) ; } } MVM_unicode_normalizer_eof ( tc , & norm ) ; ready = MVM_unicode_normalizer_available ( tc , & norm ) ; while ( ready -- ) result -> body . storage . blob_32 [ str_pos ++ ] = MVM_unicode_normalizer_get_grapheme ( tc , & norm ) ; MVM_unicode_normalizer_cleanup ( tc , & norm ) ; result -> body . storage_type = MVM_STRING_GRAPHEME_32 ; result -> body . num_graphs = str_pos ; return result ; }
MVMuint32 MVM_string_utf16_decodestream ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { return MVM_string_utf16_decodestream_main ( tc , ds , stopper_chars , seps , UTF16_DECODE_AUTO_ENDIAN ) ; }
MVMuint32 MVM_string_utf16_decodestream_main ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps , int endianess ) { MVMint32 count = 0 , total = 0 ; MVMint32 bufsize ; MVMGrapheme32 * buffer ; MVMDecodeStreamBytes * cur_bytes ; MVMDecodeStreamBytes * last_accept_bytes = ds -> bytes_head ; MVMint32 last_accept_pos , last_was_cr ; MVMuint32 reached_stopper ; # ifdef MVM_BIGENDIAN int low = 1 ; int high = 0 ; # else int low = 0 ; int high = 1 ; # endif if ( ! ds -> bytes_head ) return 0 ; last_accept_pos = ds -> bytes_head_pos ; if ( stopper_chars && * stopper_chars == 0 ) return 1 ; bufsize = ds -> result_size_guess ; buffer = MVM_malloc ( bufsize * sizeof ( MVMGrapheme32 ) ) ; cur_bytes = ds -> bytes_head ; last_was_cr = 0 ; reached_stopper = 0 ; while ( cur_bytes ) { MVMint32 pos = cur_bytes == ds -> bytes_head ? ds -> bytes_head_pos : 0 ; MVMuint8 * bytes = ( unsigned char * ) cur_bytes -> bytes ; if ( ds -> abs_byte_pos == 0 && pos + 1 < cur_bytes -> length ) { if ( is_little_endian ( bytes + pos ) ) { low = 0 ; high = 1 ; last_accept_pos = pos ; pos += 2 ; } else if ( is_big_endian ( bytes + pos ) ) { low = 1 ; high = 0 ; last_accept_pos = pos ; pos += 2 ; } } for ( ; pos + 1 < cur_bytes -> length ; pos += 2 ) { MVMuint32 value = ( bytes [ pos + high ] << 8 ) + bytes [ pos + low ] ; MVMuint32 value2 ; MVMGrapheme32 g ; if ( ( value & 0xFC00 ) == 0xDC00 ) { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>unexpected<S2SV_blank>low<S2SV_blank>surrogate" ) ; } if ( ( value & 0xFC00 ) == 0xD800 ) { pos += 2 ; if ( pos + 1 >= cur_bytes -> length ) { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value2 = ( bytes [ pos + high ] << 8 ) + bytes [ pos + low ] ; if ( ( value2 & 0xFC00 ) != 0xDC00 ) { MVM_free ( buffer ) ; MVM_exception_throw_adhoc ( tc , "Malformed<S2SV_blank>UTF-16;<S2SV_blank>incomplete<S2SV_blank>surrogate<S2SV_blank>pair" ) ; } value = 0x10000 + ( ( value & 0x3FF ) << 10 ) + ( value2 & 0x3FF ) ; } if ( count == bufsize ) { MVM_string_decodestream_add_chars ( tc , ds , buffer , bufsize ) ; buffer = MVM_malloc ( bufsize * sizeof ( MVMGrapheme32 ) ) ; count = 0 ; } buffer [ count ++ ] = value ; last_accept_bytes = cur_bytes ; last_accept_pos = pos ; total ++ ; if ( MVM_string_decode_stream_maybe_sep ( tc , seps , value ) || stopper_chars && * stopper_chars == total ) { reached_stopper = 1 ; goto done ; } } cur_bytes = cur_bytes -> next ; } done : if ( count ) { MVM_string_decodestream_add_chars ( tc , ds , buffer , count ) ; } else { MVM_free ( buffer ) ; } MVM_string_decodestream_discard_to ( tc , ds , last_accept_bytes , last_accept_pos + 1 ) ; return reached_stopper ; }
MVMString * MVM_string_utf16be_decode ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main ( tc , result_type , utf16_chars , bytes , UTF16_DECODE_BIG_ENDIAN ) ; }
MVMuint32 MVM_string_utf16be_decodestream ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { return MVM_string_utf16_decodestream_main ( tc , ds , stopper_chars , seps , UTF16_DECODE_BIG_ENDIAN ) ; }
MVMString * MVM_string_utf16le_decode ( MVMThreadContext * tc , const MVMObject * result_type , char * utf16_chars , size_t bytes ) { return MVM_string_utf16_decode_main ( tc , result_type , utf16_chars , bytes , UTF16_DECODE_LITTLE_ENDIAN ) ; }
MVMuint32 MVM_string_utf16le_decodestream ( MVMThreadContext * tc , MVMDecodeStream * ds , const MVMint32 * stopper_chars , MVMDecodeStreamSeparators * seps ) { return MVM_string_utf16_decodestream_main ( tc , ds , stopper_chars , seps , UTF16_DECODE_LITTLE_ENDIAN ) ; }
sexp * r_new_condition ( sexp * subclass , sexp * msg , sexp * call , sexp * data ) { if ( msg == r_null ) { msg = r_shared_empty_chr ; } else if ( ! r_is_scalar_character ( msg ) ) { r_abort ( "Condition<S2SV_blank>message<S2SV_blank>must<S2SV_blank>be<S2SV_blank>a<S2SV_blank>string" ) ; } r_ssize_t n_data = r_length ( data ) ; sexp * cnd = KEEP ( r_new_vector ( VECSXP , n_data + 2 ) ) ; r_list_poke ( cnd , 0 , msg ) ; r_list_poke ( cnd , 1 , call ) ; r_vec_poke_n ( cnd , 2 , data , 0 , r_length ( cnd ) - 2 ) ; r_poke_names ( cnd , KEEP ( new_condition_names ( data ) ) ) ; r_poke_class ( cnd , KEEP ( chr_append ( subclass , r_string ( "condition" ) ) ) ) ; FREE ( 3 ) ; return cnd ; }
static void dump_header ( struct oom_control * oc , struct task_struct * p ) { pr_warn ( "%s<S2SV_blank>invoked<S2SV_blank>oom-killer:<S2SV_blank>gfp_mask=%#x(%pGg),<S2SV_blank>order=%d,<S2SV_blank>" "oom_score_adj=%hd\\n" , current -> comm , oc -> gfp_mask , & oc -> gfp_mask , oc -> order , current -> signal -> oom_score_adj ) ; if ( ! IS_ENABLED ( CONFIG_COMPACTION ) && oc -> order ) pr_warn ( "COMPACTION<S2SV_blank>is<S2SV_blank>disabled!!!\\n" ) ; cpuset_print_current_mems_allowed ( ) ; dump_stack ( ) ; if ( oc -> memcg ) mem_cgroup_print_oom_info ( oc -> memcg , p ) ; else show_mem ( SHOW_MEM_FILTER_NODES ) ; if ( sysctl_oom_dump_tasks ) dump_tasks ( oc -> memcg , oc -> nodemask ) ; }
void snd_hda_bus_reset_codecs ( struct hda_bus * bus ) { struct hda_codec * codec ; list_for_each_codec ( codec , bus ) { cancel_delayed_work_sync ( & codec -> jackpoll_work ) ; # ifdef CONFIG_PM if ( hda_codec_is_power_on ( codec ) ) { hda_call_codec_suspend ( codec ) ; hda_call_codec_resume ( codec ) ; } # endif } }
static unsigned long ondemand_readahead ( struct address_space * mapping , struct file_ra_state * ra , struct file * filp , bool hit_readahead_marker , pgoff_t offset , unsigned long req_size ) { struct backing_dev_info * bdi = inode_to_bdi ( mapping -> host ) ; unsigned long max_pages = ra -> ra_pages ; pgoff_t prev_offset ; if ( req_size > max_pages && bdi -> io_pages > max_pages ) max_pages = min ( req_size , bdi -> io_pages ) ; if ( ! offset ) goto initial_readahead ; if ( ( offset == ( ra -> start + ra -> size - ra -> async_size ) || offset == ( ra -> start + ra -> size ) ) ) { ra -> start += ra -> size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( hit_readahead_marker ) { pgoff_t start ; rcu_read_lock ( ) ; start = page_cache_next_hole ( mapping , offset + 1 , max_pages ) ; rcu_read_unlock ( ) ; if ( ! start || start - offset > max_pages ) return 0 ; ra -> start = start ; ra -> size = start - offset ; ra -> size += req_size ; ra -> size = get_next_ra_size ( ra , max_pages ) ; ra -> async_size = ra -> size ; goto readit ; } if ( req_size > max_pages ) goto initial_readahead ; prev_offset = ( unsigned long long ) ra -> prev_pos >> PAGE_SHIFT ; if ( offset - prev_offset <= 1UL ) goto initial_readahead ; if ( try_context_readahead ( mapping , ra , offset , req_size , max_pages ) ) goto readit ; return __do_page_cache_readahead ( mapping , filp , offset , req_size , 0 ) ; initial_readahead : ra -> start = offset ; ra -> size = get_init_ra_size ( req_size , max_pages ) ; ra -> async_size = ra -> size > req_size ? ra -> size - req_size : ra -> size ; readit : if ( offset == ra -> start && ra -> size == ra -> async_size ) { ra -> async_size = get_next_ra_size ( ra , max_pages ) ; ra -> size += ra -> async_size ; } return ra_submit ( ra , mapping , filp ) ; }
static void msm_vfe40_process_error_status ( struct vfe_device * vfe_dev ) { uint32_t halt_mask ; uint32_t error_status1 = vfe_dev -> error_info . error_mask1 ; struct msm_isp_event_data error_event ; if ( error_status1 & ( 1 << 0 ) ) { pr_err ( "%s:<S2SV_blank>camif<S2SV_blank>error<S2SV_blank>status:<S2SV_blank>0x%x\\n" , __func__ , vfe_dev -> error_info . camif_status ) ; error_event . frame_id = vfe_dev -> axi_data . src_info [ VFE_PIX_0 ] . frame_id ; msm_isp_send_event ( vfe_dev , ISP_EVENT_ERROR , & error_event ) ; halt_mask = msm_camera_io_r ( vfe_dev -> vfe_base + 0x2C ) ; halt_mask &= ~ ( 1 << 8 ) ; msm_camera_io_w_mb ( halt_mask , vfe_dev -> vfe_base + 0x2C ) ; msm_camera_io_w_mb ( 0x1 , vfe_dev -> vfe_base + 0x2C0 ) ; } if ( error_status1 & ( 1 << 1 ) ) pr_err ( "%s:<S2SV_blank>stats<S2SV_blank>bhist<S2SV_blank>overwrite\\n" , __func__ ) ; if ( error_status1 & ( 1 << 2 ) ) pr_err ( "%s:<S2SV_blank>stats<S2SV_blank>cs<S2SV_blank>overwrite\\n" , __func__ ) ; if ( error_status1 & ( 1 << 3 ) ) pr_err ( "%s:<S2SV_blank>stats<S2SV_blank>ihist<S2SV_blank>overwrite\\n" , __func__ ) ; if ( error_status1 & ( 1 << 4 ) ) pr_err ( "%s:<S2SV_blank>realign<S2SV_blank>buf<S2SV_blank>y<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 5 ) ) pr_err ( "%s:<S2SV_blank>realign<S2SV_blank>buf<S2SV_blank>cb<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 6 ) ) pr_err ( "%s:<S2SV_blank>realign<S2SV_blank>buf<S2SV_blank>cr<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 7 ) ) { pr_err ( "%s:<S2SV_blank>violation\\n" , __func__ ) ; msm_vfe40_process_violation_status ( vfe_dev ) ; } if ( error_status1 & ( 1 << 9 ) ) pr_err ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>0<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 10 ) ) pr_err ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>1<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 11 ) ) pr_err ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>2<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 12 ) ) pr_err ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>3<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 13 ) ) pr_err ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>4<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 14 ) ) pr_err ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>5<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 15 ) ) pr_err ( "%s:<S2SV_blank>image<S2SV_blank>master<S2SV_blank>6<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 16 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>be<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 17 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>bg<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 18 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>bf<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 19 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>awb<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 20 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>rs<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 21 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>cs<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 22 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>ihist<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; if ( error_status1 & ( 1 << 23 ) ) pr_err ( "%s:<S2SV_blank>status<S2SV_blank>skin<S2SV_blank>bhist<S2SV_blank>bus<S2SV_blank>overflow\\n" , __func__ ) ; }
static int parse_options ( struct super_block * sb , char * options , int silent , int * debug , struct sdcardfs_vfsmount_options * vfsopts , struct sdcardfs_mount_options * opts ) { char * p ; substring_t args [ MAX_OPT_ARGS ] ; int option ; opts -> fs_low_uid = AID_MEDIA_RW ; opts -> fs_low_gid = AID_MEDIA_RW ; vfsopts -> mask = 0 ; opts -> multiuser = false ; opts -> fs_user_id = 0 ; vfsopts -> gid = 0 ; opts -> reserved_mb = 0 ; opts -> gid_derivation = false ; vfsopts -> default_normal = false ; * debug = 0 ; if ( ! options ) return 0 ; while ( ( p = strsep ( & options , "," ) ) != NULL ) { int token ; if ( ! * p ) continue ; token = match_token ( p , sdcardfs_tokens , args ) ; switch ( token ) { case Opt_debug : * debug = 1 ; break ; case Opt_fsuid : if ( match_int ( & args [ 0 ] , & option ) ) return 0 ; opts -> fs_low_uid = option ; break ; case Opt_fsgid : if ( match_int ( & args [ 0 ] , & option ) ) return 0 ; opts -> fs_low_gid = option ; break ; case Opt_gid : if ( match_int ( & args [ 0 ] , & option ) ) return 0 ; vfsopts -> gid = option ; break ; case Opt_userid : if ( match_int ( & args [ 0 ] , & option ) ) return 0 ; opts -> fs_user_id = option ; break ; case Opt_mask : if ( match_int ( & args [ 0 ] , & option ) ) return 0 ; vfsopts -> mask = option ; break ; case Opt_multiuser : opts -> multiuser = true ; break ; case Opt_reserved_mb : if ( match_int ( & args [ 0 ] , & option ) ) return 0 ; opts -> reserved_mb = option ; break ; case Opt_gid_derivation : opts -> gid_derivation = true ; break ; case Opt_default_normal : vfsopts -> default_normal = true ; default : if ( ! silent ) pr_err ( "Unrecognized<S2SV_blank>mount<S2SV_blank>option<S2SV_blank>\\"%s\\"<S2SV_blank>or<S2SV_blank>missing<S2SV_blank>value" , p ) ; return - EINVAL ; } } if ( * debug ) { pr_info ( "sdcardfs<S2SV_blank>:<S2SV_blank>options<S2SV_blank>-<S2SV_blank>debug:%d\\n" , * debug ) ; pr_info ( "sdcardfs<S2SV_blank>:<S2SV_blank>options<S2SV_blank>-<S2SV_blank>uid:%d\\n" , opts -> fs_low_uid ) ; pr_info ( "sdcardfs<S2SV_blank>:<S2SV_blank>options<S2SV_blank>-<S2SV_blank>gid:%d\\n" , opts -> fs_low_gid ) ; } return 0 ; }
static u32 make_rpcs ( struct drm_i915_private * dev_priv ) { u32 rpcs = 0 ; if ( INTEL_GEN ( dev_priv ) < 9 ) return 0 ; if ( INTEL_INFO ( dev_priv ) -> sseu . has_slice_pg ) { rpcs |= GEN8_RPCS_S_CNT_ENABLE ; rpcs |= hweight8 ( INTEL_INFO ( dev_priv ) -> sseu . slice_mask ) << GEN8_RPCS_S_CNT_SHIFT ; rpcs |= GEN8_RPCS_ENABLE ; } if ( INTEL_INFO ( dev_priv ) -> sseu . has_subslice_pg ) { rpcs |= GEN8_RPCS_SS_CNT_ENABLE ; rpcs |= hweight8 ( INTEL_INFO ( dev_priv ) -> sseu . subslice_mask [ 0 ] ) << GEN8_RPCS_SS_CNT_SHIFT ; rpcs |= GEN8_RPCS_ENABLE ; } if ( INTEL_INFO ( dev_priv ) -> sseu . has_eu_pg ) { rpcs |= INTEL_INFO ( dev_priv ) -> sseu . eu_per_subslice << GEN8_RPCS_EU_MIN_SHIFT ; rpcs |= INTEL_INFO ( dev_priv ) -> sseu . eu_per_subslice << GEN8_RPCS_EU_MAX_SHIFT ; rpcs |= GEN8_RPCS_ENABLE ; } return rpcs ; }
AWS_TEST_CASE ( test_hash_table_hash_clear_allows_cleanup , s_test_hash_table_hash_clear_allows_cleanup_fn ) static int s_test_hash_table_hash_clear_allows_cleanup_fn ( struct aws_allocator * allocator , void * ctx ) { ( void ) ctx ; struct aws_hash_table hash_table ; int err_code = aws_hash_table_init ( & hash_table , allocator , 10 , aws_hash_c_string , aws_c_string_eq , s_destroy_key_fn , s_destroy_value_fn ) ; ASSERT_SUCCESS ( err_code , "Hash<S2SV_blank>Map<S2SV_blank>init<S2SV_blank>should<S2SV_blank>have<S2SV_blank>succeeded." ) ; s_reset_destroy_ck ( ) ; err_code = aws_hash_table_create ( & hash_table , ( void * ) TEST_STR_1 , NULL , NULL ) ; ASSERT_SUCCESS ( err_code , "Hash<S2SV_blank>Map<S2SV_blank>put<S2SV_blank>should<S2SV_blank>have<S2SV_blank>succeeded." ) ; err_code = aws_hash_table_create ( & hash_table , ( void * ) TEST_STR_2 , NULL , NULL ) ; ASSERT_SUCCESS ( err_code , "Hash<S2SV_blank>Map<S2SV_blank>put<S2SV_blank>should<S2SV_blank>have<S2SV_blank>succeeded." ) ; aws_hash_table_clear ( & hash_table ) ; ASSERT_INT_EQUALS ( 2 , s_key_removal_counter , "Clear<S2SV_blank>should<S2SV_blank>destroy<S2SV_blank>all<S2SV_blank>keys" ) ; ASSERT_INT_EQUALS ( 2 , s_value_removal_counter , "Clear<S2SV_blank>should<S2SV_blank>destroy<S2SV_blank>all<S2SV_blank>values" ) ; struct aws_hash_element * pElem ; err_code = aws_hash_table_find ( & hash_table , ( void * ) TEST_STR_1 , & pElem ) ; ASSERT_SUCCESS ( err_code , "Find<S2SV_blank>should<S2SV_blank>still<S2SV_blank>succeed<S2SV_blank>after<S2SV_blank>clear" ) ; ASSERT_NULL ( pElem , "Element<S2SV_blank>should<S2SV_blank>not<S2SV_blank>be<S2SV_blank>found" ) ; s_reset_destroy_ck ( ) ; err_code = aws_hash_table_create ( & hash_table , ( void * ) TEST_STR_1 , NULL , NULL ) ; ASSERT_SUCCESS ( err_code , "Hash<S2SV_blank>Map<S2SV_blank>put<S2SV_blank>should<S2SV_blank>have<S2SV_blank>succeeded." ) ; err_code = aws_hash_table_create ( & hash_table , ( void * ) TEST_STR_2 , NULL , NULL ) ; ASSERT_SUCCESS ( err_code , "Hash<S2SV_blank>Map<S2SV_blank>put<S2SV_blank>should<S2SV_blank>have<S2SV_blank>succeeded." ) ; aws_hash_table_clean_up ( & hash_table ) ; ASSERT_INT_EQUALS ( 2 , s_key_removal_counter , "Cleanup<S2SV_blank>should<S2SV_blank>destroy<S2SV_blank>all<S2SV_blank>keys" ) ; ASSERT_INT_EQUALS ( 2 , s_value_removal_counter , "Cleanup<S2SV_blank>should<S2SV_blank>destroy<S2SV_blank>all<S2SV_blank>values" ) ; return 0 ; }
void snd_hda_bus_reset_codecs ( struct hda_bus * bus ) { struct hda_codec * codec ; list_for_each_codec ( codec , bus ) { cancel_delayed_work_sync ( & codec -> jackpoll_work ) ; # ifdef CONFIG_PM if ( hda_codec_is_power_on ( codec ) ) { hda_call_codec_suspend ( codec ) ; hda_call_codec_resume ( codec ) ; } # endif } }
static int ina2xx_buffer_disable ( struct iio_dev * indio_dev ) { struct ina2xx_chip_info * chip = iio_priv ( indio_dev ) ; if ( chip -> task ) { kthread_stop ( chip -> task ) ; chip -> task = NULL ; } return 0 ; }
static int ina2xx_buffer_enable ( struct iio_dev * indio_dev ) { struct ina2xx_chip_info * chip = iio_priv ( indio_dev ) ; unsigned int sampling_us = SAMPLING_PERIOD ( chip ) ; dev_dbg ( & indio_dev -> dev , "Enabling<S2SV_blank>buffer<S2SV_blank>w/<S2SV_blank>scan_mask<S2SV_blank>%02x,<S2SV_blank>freq<S2SV_blank>=<S2SV_blank>%d,<S2SV_blank>avg<S2SV_blank>=%u\\n" , ( unsigned int ) ( * indio_dev -> active_scan_mask ) , 1000000 / sampling_us , chip -> avg ) ; dev_dbg ( & indio_dev -> dev , "Expected<S2SV_blank>work<S2SV_blank>period:<S2SV_blank>%u<S2SV_blank>us\\n" , sampling_us ) ; dev_dbg ( & indio_dev -> dev , "Async<S2SV_blank>readout<S2SV_blank>mode:<S2SV_blank>%d\\n" , chip -> allow_async_readout ) ; chip -> task = kthread_run ( ina2xx_capture_thread , ( void * ) indio_dev , "%s:%d-%uus" , indio_dev -> name , indio_dev -> id , sampling_us ) ; return PTR_ERR_OR_ZERO ( chip -> task ) ; }
void xaddCommand ( client * c ) { streamID id ; int id_given = 0 ; long long maxlen = 0 ; int approx_maxlen = 0 ; int maxlen_arg_idx = 0 ; int i = 2 ; for ( ; i < c -> argc ; i ++ ) { int moreargs = ( c -> argc - 1 ) - i ; char * opt = c -> argv [ i ] -> ptr ; if ( opt [ 0 ] == '*' && opt [ 1 ] == '\\0' ) { break ; } else if ( ! strcasecmp ( opt , "maxlen" ) && moreargs ) { char * next = c -> argv [ i + 1 ] -> ptr ; if ( moreargs >= 2 && next [ 0 ] == '~' && next [ 1 ] == '\\0' ) { approx_maxlen = 1 ; i ++ ; } if ( getLongLongFromObjectOrReply ( c , c -> argv [ i + 1 ] , & maxlen , NULL ) != C_OK ) return ; i ++ ; maxlen_arg_idx = i ; } else { if ( streamParseIDOrReply ( NULL , c -> argv [ i ] , & id , 0 ) == C_OK ) { id_given = 1 ; break ; } else { addReply ( c , shared . syntaxerr ) ; return ; } } } int field_pos = i + 1 ; if ( ( c -> argc - field_pos ) < 2 || ( c -> argc - field_pos % 2 ) == 1 ) { addReplyError ( c , "wrong<S2SV_blank>number<S2SV_blank>of<S2SV_blank>arguments<S2SV_blank>for<S2SV_blank>XADD" ) ; return ; } robj * o ; stream * s ; if ( ( o = streamTypeLookupWriteOrCreate ( c , c -> argv [ 1 ] ) ) == NULL ) return ; s = o -> ptr ; if ( streamAppendItem ( s , c -> argv + field_pos , ( c -> argc - field_pos ) / 2 , & id , id_given ? & id : NULL ) == C_ERR ) { addReplyError ( c , "The<S2SV_blank>ID<S2SV_blank>specified<S2SV_blank>in<S2SV_blank>XADD<S2SV_blank>is<S2SV_blank>equal<S2SV_blank>or<S2SV_blank>smaller<S2SV_blank>than<S2SV_blank>the<S2SV_blank>" "target<S2SV_blank>stream<S2SV_blank>top<S2SV_blank>item" ) ; return ; } addReplyStreamID ( c , & id ) ; signalModifiedKey ( c -> db , c -> argv [ 1 ] ) ; notifyKeyspaceEvent ( NOTIFY_STREAM , "xadd" , c -> argv [ 1 ] , c -> db -> id ) ; server . dirty ++ ; if ( maxlen ) { if ( ! streamTrimByLength ( s , maxlen , approx_maxlen ) ) { robj * zeroobj = createStringObjectFromLongLong ( 0 ) ; rewriteClientCommandArgument ( c , maxlen_arg_idx , zeroobj ) ; decrRefCount ( zeroobj ) ; } else { notifyKeyspaceEvent ( NOTIFY_STREAM , "xtrim" , c -> argv [ 1 ] , c -> db -> id ) ; } } robj * idarg = createObjectFromStreamID ( & id ) ; rewriteClientCommandArgument ( c , i , idarg ) ; decrRefCount ( idarg ) ; if ( server . blocked_clients_by_type [ BLOCKED_STREAM ] ) signalKeyAsReady ( c -> db , c -> argv [ 1 ] ) ; }
static int f2fs_fill_super ( struct super_block * sb , void * data , int silent ) { struct f2fs_sb_info * sbi ; struct f2fs_super_block * raw_super ; struct inode * root ; int err ; bool retry = true , need_fsck = false ; char * options = NULL ; int recovery , i , valid_super_block ; struct curseg_info * seg_i ; try_onemore : err = - EINVAL ; raw_super = NULL ; valid_super_block = - 1 ; recovery = 0 ; sbi = kzalloc ( sizeof ( struct f2fs_sb_info ) , GFP_KERNEL ) ; if ( ! sbi ) return - ENOMEM ; sbi -> sb = sb ; sbi -> s_chksum_driver = crypto_alloc_shash ( "crc32" , 0 , 0 ) ; if ( IS_ERR ( sbi -> s_chksum_driver ) ) { f2fs_msg ( sb , KERN_ERR , "Cannot<S2SV_blank>load<S2SV_blank>crc32<S2SV_blank>driver." ) ; err = PTR_ERR ( sbi -> s_chksum_driver ) ; sbi -> s_chksum_driver = NULL ; goto free_sbi ; } if ( unlikely ( ! sb_set_blocksize ( sb , F2FS_BLKSIZE ) ) ) { f2fs_msg ( sb , KERN_ERR , "unable<S2SV_blank>to<S2SV_blank>set<S2SV_blank>blocksize" ) ; goto free_sbi ; } err = read_raw_super_block ( sbi , & raw_super , & valid_super_block , & recovery ) ; if ( err ) goto free_sbi ; sb -> s_fs_info = sbi ; sbi -> raw_super = raw_super ; if ( f2fs_sb_has_inode_chksum ( sb ) ) sbi -> s_chksum_seed = f2fs_chksum ( sbi , ~ 0 , raw_super -> uuid , sizeof ( raw_super -> uuid ) ) ; # ifndef CONFIG_BLK_DEV_ZONED if ( f2fs_sb_has_blkzoned ( sb ) ) { f2fs_msg ( sb , KERN_ERR , "Zoned<S2SV_blank>block<S2SV_blank>device<S2SV_blank>support<S2SV_blank>is<S2SV_blank>not<S2SV_blank>enabled\\n" ) ; err = - EOPNOTSUPP ; goto free_sb_buf ; } # endif default_options ( sbi ) ; options = kstrdup ( ( const char * ) data , GFP_KERNEL ) ; if ( data && ! options ) { err = - ENOMEM ; goto free_sb_buf ; } err = parse_options ( sb , options ) ; if ( err ) goto free_options ; sbi -> max_file_blocks = max_file_blocks ( ) ; sb -> s_maxbytes = sbi -> max_file_blocks << le32_to_cpu ( raw_super -> log_blocksize ) ; sb -> s_max_links = F2FS_LINK_MAX ; get_random_bytes ( & sbi -> s_next_generation , sizeof ( u32 ) ) ; # ifdef CONFIG_QUOTA sb -> dq_op = & f2fs_quota_operations ; if ( f2fs_sb_has_quota_ino ( sb ) ) sb -> s_qcop = & dquot_quotactl_sysfile_ops ; else sb -> s_qcop = & f2fs_quotactl_ops ; sb -> s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ ; if ( f2fs_sb_has_quota_ino ( sbi -> sb ) ) { for ( i = 0 ; i < MAXQUOTAS ; i ++ ) { if ( f2fs_qf_ino ( sbi -> sb , i ) ) sbi -> nquota_files ++ ; } } # endif sb -> s_op = & f2fs_sops ; # ifdef CONFIG_F2FS_FS_ENCRYPTION sb -> s_cop = & f2fs_cryptops ; # endif sb -> s_xattr = f2fs_xattr_handlers ; sb -> s_export_op = & f2fs_export_ops ; sb -> s_magic = F2FS_SUPER_MAGIC ; sb -> s_time_gran = 1 ; sb -> s_flags = ( sb -> s_flags & ~ MS_POSIXACL ) | ( test_opt ( sbi , POSIX_ACL ) ? MS_POSIXACL : 0 ) ; memcpy ( & sb -> s_uuid , raw_super -> uuid , sizeof ( raw_super -> uuid ) ) ; sb -> s_iflags |= SB_I_CGROUPWB ; sbi -> valid_super_block = valid_super_block ; mutex_init ( & sbi -> gc_mutex ) ; mutex_init ( & sbi -> cp_mutex ) ; init_rwsem ( & sbi -> node_write ) ; init_rwsem ( & sbi -> node_change ) ; set_sbi_flag ( sbi , SBI_POR_DOING ) ; spin_lock_init ( & sbi -> stat_lock ) ; spin_lock_init ( & sbi -> iostat_lock ) ; sbi -> iostat_enable = false ; for ( i = 0 ; i < NR_PAGE_TYPE ; i ++ ) { int n = ( i == META ) ? 1 : NR_TEMP_TYPE ; int j ; sbi -> write_io [ i ] = f2fs_kmalloc ( sbi , array_size ( n , sizeof ( struct f2fs_bio_info ) ) , GFP_KERNEL ) ; if ( ! sbi -> write_io [ i ] ) { err = - ENOMEM ; goto free_options ; } for ( j = HOT ; j < n ; j ++ ) { init_rwsem ( & sbi -> write_io [ i ] [ j ] . io_rwsem ) ; sbi -> write_io [ i ] [ j ] . sbi = sbi ; sbi -> write_io [ i ] [ j ] . bio = NULL ; spin_lock_init ( & sbi -> write_io [ i ] [ j ] . io_lock ) ; INIT_LIST_HEAD ( & sbi -> write_io [ i ] [ j ] . io_list ) ; } } init_rwsem ( & sbi -> cp_rwsem ) ; init_waitqueue_head ( & sbi -> cp_wait ) ; init_sb_info ( sbi ) ; err = init_percpu_info ( sbi ) ; if ( err ) goto free_bio_info ; if ( F2FS_IO_SIZE ( sbi ) > 1 ) { sbi -> write_io_dummy = mempool_create_page_pool ( 2 * ( F2FS_IO_SIZE ( sbi ) - 1 ) , 0 ) ; if ( ! sbi -> write_io_dummy ) { err = - ENOMEM ; goto free_percpu ; } } sbi -> meta_inode = f2fs_iget ( sb , F2FS_META_INO ( sbi ) ) ; if ( IS_ERR ( sbi -> meta_inode ) ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>F2FS<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>inode" ) ; err = PTR_ERR ( sbi -> meta_inode ) ; goto free_io_dummy ; } err = f2fs_get_valid_checkpoint ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>get<S2SV_blank>valid<S2SV_blank>F2FS<S2SV_blank>checkpoint" ) ; goto free_meta_inode ; } err = f2fs_scan_devices ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>find<S2SV_blank>devices" ) ; goto free_devices ; } sbi -> total_valid_node_count = le32_to_cpu ( sbi -> ckpt -> valid_node_count ) ; percpu_counter_set ( & sbi -> total_valid_inode_count , le32_to_cpu ( sbi -> ckpt -> valid_inode_count ) ) ; sbi -> user_block_count = le64_to_cpu ( sbi -> ckpt -> user_block_count ) ; sbi -> total_valid_block_count = le64_to_cpu ( sbi -> ckpt -> valid_block_count ) ; sbi -> last_valid_block_count = sbi -> total_valid_block_count ; sbi -> reserved_blocks = 0 ; sbi -> current_reserved_blocks = 0 ; limit_reserve_root ( sbi ) ; for ( i = 0 ; i < NR_INODE_TYPE ; i ++ ) { INIT_LIST_HEAD ( & sbi -> inode_list [ i ] ) ; spin_lock_init ( & sbi -> inode_lock [ i ] ) ; } f2fs_init_extent_cache_info ( sbi ) ; f2fs_init_ino_entry_info ( sbi ) ; err = f2fs_build_segment_manager ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>initialize<S2SV_blank>F2FS<S2SV_blank>segment<S2SV_blank>manager" ) ; goto free_sm ; } err = f2fs_build_node_manager ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>initialize<S2SV_blank>F2FS<S2SV_blank>node<S2SV_blank>manager" ) ; goto free_nm ; } if ( sb -> s_bdev -> bd_part ) sbi -> sectors_written_start = ( u64 ) part_stat_read ( sb -> s_bdev -> bd_part , sectors [ 1 ] ) ; seg_i = CURSEG_I ( sbi , CURSEG_HOT_NODE ) ; if ( __exist_node_summaries ( sbi ) ) sbi -> kbytes_written = le64_to_cpu ( seg_i -> journal -> info . kbytes_written ) ; f2fs_build_gc_manager ( sbi ) ; sbi -> node_inode = f2fs_iget ( sb , F2FS_NODE_INO ( sbi ) ) ; if ( IS_ERR ( sbi -> node_inode ) ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>node<S2SV_blank>inode" ) ; err = PTR_ERR ( sbi -> node_inode ) ; goto free_nm ; } err = f2fs_build_stats ( sbi ) ; if ( err ) goto free_node_inode ; root = f2fs_iget ( sb , F2FS_ROOT_INO ( sbi ) ) ; if ( IS_ERR ( root ) ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>root<S2SV_blank>inode" ) ; err = PTR_ERR ( root ) ; goto free_stats ; } if ( ! S_ISDIR ( root -> i_mode ) || ! root -> i_blocks || ! root -> i_size ) { iput ( root ) ; err = - EINVAL ; goto free_node_inode ; } sb -> s_root = d_make_root ( root ) ; if ( ! sb -> s_root ) { err = - ENOMEM ; goto free_root_inode ; } err = f2fs_register_sysfs ( sbi ) ; if ( err ) goto free_root_inode ; # ifdef CONFIG_QUOTA if ( f2fs_sb_has_quota_ino ( sb ) && ! f2fs_readonly ( sb ) ) { err = f2fs_enable_quotas ( sb ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Cannot<S2SV_blank>turn<S2SV_blank>on<S2SV_blank>quotas:<S2SV_blank>error<S2SV_blank>%d" , err ) ; goto free_sysfs ; } } # endif err = f2fs_recover_orphan_inodes ( sbi ) ; if ( err ) goto free_meta ; if ( ! test_opt ( sbi , DISABLE_ROLL_FORWARD ) ) { if ( bdev_read_only ( sb -> s_bdev ) && ! is_set_ckpt_flags ( sbi , CP_UMOUNT_FLAG ) ) { err = - EROFS ; goto free_meta ; } if ( need_fsck ) set_sbi_flag ( sbi , SBI_NEED_FSCK ) ; if ( ! retry ) goto skip_recovery ; err = f2fs_recover_fsync_data ( sbi , false ) ; if ( err < 0 ) { need_fsck = true ; f2fs_msg ( sb , KERN_ERR , "Cannot<S2SV_blank>recover<S2SV_blank>all<S2SV_blank>fsync<S2SV_blank>data<S2SV_blank>errno=%d" , err ) ; goto free_meta ; } } else { err = f2fs_recover_fsync_data ( sbi , true ) ; if ( ! f2fs_readonly ( sb ) && err > 0 ) { err = - EINVAL ; f2fs_msg ( sb , KERN_ERR , "Need<S2SV_blank>to<S2SV_blank>recover<S2SV_blank>fsync<S2SV_blank>data" ) ; goto free_meta ; } } skip_recovery : clear_sbi_flag ( sbi , SBI_POR_DOING ) ; if ( test_opt ( sbi , BG_GC ) && ! f2fs_readonly ( sb ) ) { err = f2fs_start_gc_thread ( sbi ) ; if ( err ) goto free_meta ; } kfree ( options ) ; if ( recovery ) { err = f2fs_commit_super ( sbi , true ) ; f2fs_msg ( sb , KERN_INFO , "Try<S2SV_blank>to<S2SV_blank>recover<S2SV_blank>%dth<S2SV_blank>superblock,<S2SV_blank>ret:<S2SV_blank>%d" , sbi -> valid_super_block ? 1 : 2 , err ) ; } f2fs_join_shrinker ( sbi ) ; f2fs_tuning_parameters ( sbi ) ; f2fs_msg ( sbi -> sb , KERN_NOTICE , "Mounted<S2SV_blank>with<S2SV_blank>checkpoint<S2SV_blank>version<S2SV_blank>=<S2SV_blank>%llx" , cur_cp_version ( F2FS_CKPT ( sbi ) ) ) ; f2fs_update_time ( sbi , CP_TIME ) ; f2fs_update_time ( sbi , REQ_TIME ) ; return 0 ; free_meta : # ifdef CONFIG_QUOTA if ( f2fs_sb_has_quota_ino ( sb ) && ! f2fs_readonly ( sb ) ) f2fs_quota_off_umount ( sbi -> sb ) ; # endif f2fs_sync_inode_meta ( sbi ) ; truncate_inode_pages_final ( META_MAPPING ( sbi ) ) ; # ifdef CONFIG_QUOTA free_sysfs : # endif f2fs_unregister_sysfs ( sbi ) ; free_root_inode : dput ( sb -> s_root ) ; sb -> s_root = NULL ; free_stats : f2fs_destroy_stats ( sbi ) ; free_node_inode : f2fs_release_ino_entry ( sbi , true ) ; truncate_inode_pages_final ( NODE_MAPPING ( sbi ) ) ; iput ( sbi -> node_inode ) ; free_nm : f2fs_destroy_node_manager ( sbi ) ; free_sm : f2fs_destroy_segment_manager ( sbi ) ; free_devices : destroy_device_list ( sbi ) ; kfree ( sbi -> ckpt ) ; free_meta_inode : make_bad_inode ( sbi -> meta_inode ) ; iput ( sbi -> meta_inode ) ; free_io_dummy : mempool_destroy ( sbi -> write_io_dummy ) ; free_percpu : destroy_percpu_info ( sbi ) ; free_bio_info : for ( i = 0 ; i < NR_PAGE_TYPE ; i ++ ) kfree ( sbi -> write_io [ i ] ) ; free_options : # ifdef CONFIG_QUOTA for ( i = 0 ; i < MAXQUOTAS ; i ++ ) kfree ( F2FS_OPTION ( sbi ) . s_qf_names [ i ] ) ; # endif kfree ( options ) ; free_sb_buf : kfree ( raw_super ) ; free_sbi : if ( sbi -> s_chksum_driver ) crypto_free_shash ( sbi -> s_chksum_driver ) ; kfree ( sbi ) ; if ( retry ) { retry = false ; shrink_dcache_sb ( sb ) ; goto try_onemore ; } return err ; }
char * JSONArrayStringToDelimitedString ( const char * json , char delim ) { if ( NULL == json ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } cJSON * cj = stringToJson ( json ) ; if ( cj == NULL ) { return NULL ; } char * str = JSONArrayToDelimitedString ( cj , delim ) ; secFreeJson ( cj ) ; return str ; }
list_t * JSONArrayStringToList ( const char * json ) { if ( NULL == json ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } cJSON * cj = stringToJson ( json ) ; if ( cj == NULL ) { return NULL ; } list_t * l = JSONArrayToList ( cj ) ; secFreeJson ( cj ) ; return l ; }
char * JSONArrayToDelimitedString ( const cJSON * cjson , char delim ) { if ( NULL == cjson ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } list_t * list = JSONArrayToList ( cjson ) ; char * str = listToDelimitedString ( list , delim ) ; list_destroy ( list ) ; return str ; }
list_t * JSONArrayToList ( const cJSON * cjson ) { if ( NULL == cjson ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } if ( ! cJSON_IsArray ( cjson ) ) { oidc_errno = OIDC_EJSONARR ; return NULL ; } int j ; list_t * l = list_new ( ) ; l -> free = secFree ; l -> match = ( int ( * ) ( void * , void * ) ) & strequal ; for ( j = 0 ; j < cJSON_GetArraySize ( cjson ) ; j ++ ) { list_rpush ( l , list_node_new ( oidc_strcopy ( getJSONItemValue ( cJSON_GetArrayItem ( cjson , j ) ) ) ) ) ; } return l ; }
static int alloc_lookup_fw_priv ( const char * fw_name , struct firmware_cache * fwc , struct fw_priv * * fw_priv , void * dbuf , size_t size , enum fw_opt opt_flags ) { struct fw_priv * tmp ; spin_lock ( & fwc -> lock ) ; if ( ! ( opt_flags & FW_OPT_NOCACHE ) ) { tmp = __lookup_fw_priv ( fw_name ) ; if ( tmp ) { kref_get ( & tmp -> ref ) ; spin_unlock ( & fwc -> lock ) ; * fw_priv = tmp ; pr_debug ( "batched<S2SV_blank>request<S2SV_blank>-<S2SV_blank>sharing<S2SV_blank>the<S2SV_blank>same<S2SV_blank>struct<S2SV_blank>fw_priv<S2SV_blank>and<S2SV_blank>lookup<S2SV_blank>for<S2SV_blank>multiple<S2SV_blank>requests\\n" ) ; return 1 ; } } tmp = __allocate_fw_priv ( fw_name , fwc , dbuf , size ) ; if ( tmp && ! ( opt_flags & FW_OPT_NOCACHE ) ) list_add ( & tmp -> list , & fwc -> head ) ; spin_unlock ( & fwc -> lock ) ; * fw_priv = tmp ; return tmp ? 0 : - ENOMEM ; }
IDATA J9VMDllMain ( J9JavaVM * vm , IDATA stage , void * reserved ) { IDATA returnVal = J9VMDLLMAIN_OK ; UDATA rc = 0 ; PORT_ACCESS_FROM_JAVAVM ( vm ) ; if ( vm -> sharedCacheAPI == NULL ) { IDATA index ; U_64 runtimeFlags = getDefaultRuntimeFlags ( ) ; runtimeFlags |= ( ( j9shr_isPlatformDefaultPersistent ( vm ) == TRUE ) ? J9SHR_RUNTIMEFLAG_ENABLE_PERSISTENT_CACHE : 0 ) ; vm -> sharedCacheAPI = ( J9SharedCacheAPI * ) j9mem_allocate_memory ( sizeof ( J9SharedCacheAPI ) , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI == NULL ) { return J9VMDLLMAIN_FAILED ; } memset ( vm -> sharedCacheAPI , 0 , sizeof ( J9SharedCacheAPI ) ) ; vm -> sharedCacheAPI -> softMaxBytes = ( U_32 ) - 1 ; vm -> sharedCacheAPI -> minAOT = - 1 ; vm -> sharedCacheAPI -> maxAOT = - 1 ; vm -> sharedCacheAPI -> minJIT = - 1 ; vm -> sharedCacheAPI -> maxJIT = - 1 ; if ( ( index = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ) >= 0 ) { char optionsBuffer [ SHR_SUBOPT_BUFLEN ] ; char * optionsBufferPtr = ( char * ) optionsBuffer ; IDATA parseRc = OPTION_OK ; vm -> sharedCacheAPI -> xShareClassesPresent = TRUE ; parseRc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , SHR_SUBOPT_BUFLEN ) ; if ( OPTION_OK == parseRc ) { UDATA verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; UDATA printStatsOptions = PRINTSTATS_SHOW_NONE ; UDATA storageKeyTesting = 0 ; char * cacheName = CACHE_ROOT_PREFIX ; char * modContext = NULL ; char * expireTime = NULL ; char * ctrlDirName = NULL ; char * cacheDirPermStr = NULL ; char * methodSpecs = NULL ; # if ! defined ( WIN32 ) && ! defined ( WIN64 ) char defaultCacheDir [ J9SH_MAXPATH ] ; # endif IDATA argIndex1 = - 1 ; IDATA argIndex2 = - 1 ; BOOLEAN matchedOneSpecialOptions ; UDATA bufSize = SHR_SUBOPT_BUFLEN ; do { matchedOneSpecialOptions = FALSE ; if ( ( strcmp ( optionsBufferPtr , OPTION_RESET ) == 0 ) && ( optionsBufferPtr [ strlen ( OPTION_RESET ) + 1 ] == 0 ) ) { if ( ( index = FIND_NEXT_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL , index ) ) >= 0 ) { UDATA resetLen = strlen ( OPTION_RESET ) ; optionsBufferPtr += resetLen + 1 ; bufSize -= resetLen + 1 ; rc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , bufSize ) ; matchedOneSpecialOptions = TRUE ; if ( OPTION_OK != rc ) { if ( OPTION_OVERFLOW == rc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } } if ( ( strcmp ( optionsBufferPtr , OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) == 0 ) && ( optionsBufferPtr [ strlen ( OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) + 1 ] == 0 ) ) { if ( ( index = FIND_NEXT_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL , index ) ) >= 0 ) { UDATA disableCorruptedCacheLen = strlen ( OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) ; optionsBufferPtr += disableCorruptedCacheLen + 1 ; bufSize -= disableCorruptedCacheLen + 1 ; rc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , bufSize ) ; matchedOneSpecialOptions = TRUE ; if ( OPTION_OK != rc ) { if ( OPTION_OVERFLOW == rc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } } } while ( matchedOneSpecialOptions ) ; optionsBufferPtr = optionsBuffer ; argIndex1 = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , VMOPT_XXSHARECLASSESENABLEBCI , NULL ) ; argIndex2 = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , VMOPT_XXSHARECLASSESDISABLEBCI , NULL ) ; if ( argIndex1 > argIndex2 ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_BCI ; } else if ( argIndex2 > argIndex1 ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_DISABLE_BCI ; } vm -> sharedCacheAPI -> parseResult = parseArgs ( vm , optionsBufferPtr , & runtimeFlags , & verboseFlags , & cacheName , & modContext , & expireTime , & ctrlDirName , & cacheDirPermStr , & methodSpecs , & printStatsOptions , & storageKeyTesting ) ; if ( ( RESULT_PARSE_FAILED == vm -> sharedCacheAPI -> parseResult ) ) { return J9VMDLLMAIN_FAILED ; } if ( cacheName != NULL ) { vm -> sharedCacheAPI -> cacheName = ( char * ) j9mem_allocate_memory ( strlen ( cacheName ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> cacheName == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> cacheName , cacheName , strlen ( cacheName ) + 1 ) ; } if ( ctrlDirName != NULL ) { vm -> sharedCacheAPI -> ctrlDirName = ( char * ) j9mem_allocate_memory ( strlen ( ctrlDirName ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> ctrlDirName == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> ctrlDirName , ctrlDirName , strlen ( ctrlDirName ) + 1 ) ; } if ( modContext != NULL ) { vm -> sharedCacheAPI -> modContext = ( char * ) j9mem_allocate_memory ( strlen ( modContext ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> modContext == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> modContext , modContext , strlen ( modContext ) + 1 ) ; } if ( expireTime != NULL ) { vm -> sharedCacheAPI -> expireTime = ( char * ) j9mem_allocate_memory ( strlen ( expireTime ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> expireTime == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> expireTime , expireTime , strlen ( expireTime ) + 1 ) ; } if ( NULL != methodSpecs ) { vm -> sharedCacheAPI -> methodSpecs = ( char * ) j9mem_allocate_memory ( strlen ( methodSpecs ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( NULL == vm -> sharedCacheAPI -> methodSpecs ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> methodSpecs , methodSpecs , strlen ( methodSpecs ) + 1 ) ; } # if ! defined ( WIN32 ) && ! defined ( WIN64 ) rc = j9shmem_getDir ( NULL , J9SHMEM_GETDIR_APPEND_BASEDIR , defaultCacheDir , J9SH_MAXPATH ) ; if ( - 1 == rc ) { SHRCLSSUP_ERR_TRACE ( verboseFlags , J9NLS_SHRC_SHRCLSSUP_FAILURE_GET_DEFAULT_DIR_FAILED ) ; Trc_SHR_Assert_ShouldNeverHappen ( ) ; return J9VMDLLMAIN_FAILED ; } if ( ( NULL != ctrlDirName ) && ( 0 != ( strcmp ( defaultCacheDir , ctrlDirName ) ) ) ) { vm -> sharedCacheAPI -> cacheDirPerm = convertPermToDecimal ( vm , cacheDirPermStr ) ; if ( ( UDATA ) - 1 == vm -> sharedCacheAPI -> cacheDirPerm ) { return J9VMDLLMAIN_FAILED ; } } else { vm -> sharedCacheAPI -> cacheDirPerm = J9SH_DIRPERM_ABSENT ; } # else vm -> sharedCacheAPI -> cacheDirPerm = J9SH_DIRPERM_ABSENT ; # endif if ( runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_PERSISTENT_CACHE ) { vm -> sharedCacheAPI -> cacheType = J9PORT_SHR_CACHE_TYPE_PERSISTENT ; } else { vm -> sharedCacheAPI -> cacheType = J9PORT_SHR_CACHE_TYPE_NONPERSISTENT ; } vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags ; vm -> sharedCacheAPI -> verboseFlags = verboseFlags ; vm -> sharedCacheAPI -> printStatsOptions = printStatsOptions ; vm -> sharedCacheAPI -> storageKeyTesting = storageKeyTesting ; } else { if ( OPTION_OVERFLOW == parseRc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } else { vm -> sharedCacheAPI -> xShareClassesPresent = FALSE ; vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags ; vm -> sharedCacheAPI -> verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; } } switch ( stage ) { case DLL_LOAD_TABLE_FINALIZED : { IDATA index ; if ( ( index = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ) >= 0 ) { char optionsBuffer [ SHR_SUBOPT_BUFLEN ] ; char * optionsBufferPtr = ( char * ) optionsBuffer ; if ( GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , SHR_SUBOPT_BUFLEN ) == OPTION_OK ) { while ( * optionsBufferPtr ) { if ( try_scan ( & optionsBufferPtr , OPT_NONE ) ) { J9VMDllLoadInfo * loadInfo = FIND_DLL_TABLE_ENTRY ( THIS_DLL_NAME ) ; if ( loadInfo ) { loadInfo -> loadFlags |= FORCE_UNLOAD ; } break ; } optionsBufferPtr += strlen ( optionsBufferPtr ) + 1 ; } } } break ; } case ALL_VM_ARGS_CONSUMED : FIND_AND_CONSUME_ARG ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ; vm -> sharedClassConfig = NULL ; break ; case JIT_INITIALIZED : { UDATA loadFlags = 0 ; UDATA nonfatal = 0 ; UT_MODULE_LOADED ( J9_UTINTERFACE_FROM_VM ( vm ) ) ; Trc_SHR_VMInitStages_Event1 ( vm -> mainThread ) ; vm -> sharedCacheAPI -> iterateSharedCaches = j9shr_iterateSharedCaches ; vm -> sharedCacheAPI -> destroySharedCache = j9shr_destroySharedCache ; if ( ( vm -> sharedCacheAPI -> xShareClassesPresent == TRUE ) && ( vm -> sharedCacheAPI -> parseResult != RESULT_DO_UTILITIES ) ) { if ( ( rc = j9shr_init ( vm , loadFlags , & nonfatal ) ) != J9VMDLLMAIN_OK ) { if ( nonfatal ) { return J9VMDLLMAIN_OK ; } else { return rc ; } } vm -> systemClassLoader -> flags |= J9CLASSLOADER_SHARED_CLASSES_ENABLED ; if ( FIND_ARG_IN_VMARGS ( EXACT_MATCH , VMOPT_XNOLINENUMBERS , NULL ) < 0 ) { vm -> requiredDebugAttributes |= J9VM_DEBUG_ATTRIBUTE_RECORD_ALL ; } } break ; } case ALL_LIBRARIES_LOADED : { if ( ( vm -> sharedCacheAPI -> xShareClassesPresent == TRUE ) && ( vm -> sharedCacheAPI -> parseResult != RESULT_DO_UTILITIES ) ) { if ( 0 != initZipLibrary ( vm -> portLibrary , vm -> j2seRootDirectory ) ) { returnVal = J9VMDLLMAIN_FAILED ; } } break ; } case ABOUT_TO_BOOTSTRAP : { break ; } case LIBRARIES_ONUNLOAD : case JVM_EXIT_STAGE : j9shr_guaranteed_exit ( vm , FALSE ) ; break ; case HEAP_STRUCTURES_FREED : if ( vm != NULL ) { j9shr_shutdown ( vm ) ; } break ; default : break ; } return returnVal ; }
static void virtDBusConnectFree ( virtDBusConnect * connect ) { if ( connect -> connection ) virtDBusConnectClose ( connect , TRUE ) ; g_free ( connect -> domainPath ) ; g_free ( connect -> interfacePath ) ; g_free ( connect -> networkPath ) ; g_free ( connect -> nodeDevPath ) ; g_free ( connect -> nwfilterPath ) ; g_free ( connect -> secretPath ) ; g_free ( connect -> storagePoolPath ) ; g_free ( connect -> storageVolPath ) ; g_free ( connect ) ; }
static void virtDBusNetworkDHCPLeaseListFree ( virNetworkDHCPLeasePtr * leases ) { for ( gint i = 0 ; leases [ i ] != NULL ; i ++ ) virNetworkDHCPLeaseFree ( leases [ i ] ) ; g_free ( leases ) ; }
char * JSONArrayStringToDelimitedString ( const char * json , char delim ) { if ( NULL == json ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } cJSON * cj = stringToJson ( json ) ; if ( cj == NULL ) { return NULL ; } char * str = JSONArrayToDelimitedString ( cj , delim ) ; secFreeJson ( cj ) ; return str ; }
list_t * JSONArrayStringToList ( const char * json ) { if ( NULL == json ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } cJSON * cj = stringToJson ( json ) ; if ( cj == NULL ) { return NULL ; } list_t * l = JSONArrayToList ( cj ) ; secFreeJson ( cj ) ; return l ; }
char * JSONArrayToDelimitedString ( const cJSON * cjson , char delim ) { if ( NULL == cjson ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } list_t * list = JSONArrayToList ( cjson ) ; char * str = listToDelimitedString ( list , delim ) ; list_destroy ( list ) ; return str ; }
list_t * JSONArrayToList ( const cJSON * cjson ) { if ( NULL == cjson ) { oidc_setArgNullFuncError ( __func__ ) ; return NULL ; } if ( ! cJSON_IsArray ( cjson ) ) { oidc_errno = OIDC_EJSONARR ; return NULL ; } int j ; list_t * l = list_new ( ) ; l -> free = secFree ; l -> match = ( int ( * ) ( void * , void * ) ) & strequal ; for ( j = 0 ; j < cJSON_GetArraySize ( cjson ) ; j ++ ) { list_rpush ( l , list_node_new ( oidc_strcopy ( getJSONItemValue ( cJSON_GetArrayItem ( cjson , j ) ) ) ) ) ; } return l ; }
IDATA J9VMDllMain ( J9JavaVM * vm , IDATA stage , void * reserved ) { IDATA returnVal = J9VMDLLMAIN_OK ; UDATA rc = 0 ; PORT_ACCESS_FROM_JAVAVM ( vm ) ; if ( vm -> sharedCacheAPI == NULL ) { IDATA index ; U_64 runtimeFlags = getDefaultRuntimeFlags ( ) ; runtimeFlags |= ( ( j9shr_isPlatformDefaultPersistent ( vm ) == TRUE ) ? J9SHR_RUNTIMEFLAG_ENABLE_PERSISTENT_CACHE : 0 ) ; vm -> sharedCacheAPI = ( J9SharedCacheAPI * ) j9mem_allocate_memory ( sizeof ( J9SharedCacheAPI ) , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI == NULL ) { return J9VMDLLMAIN_FAILED ; } memset ( vm -> sharedCacheAPI , 0 , sizeof ( J9SharedCacheAPI ) ) ; vm -> sharedCacheAPI -> softMaxBytes = ( U_32 ) - 1 ; vm -> sharedCacheAPI -> minAOT = - 1 ; vm -> sharedCacheAPI -> maxAOT = - 1 ; vm -> sharedCacheAPI -> minJIT = - 1 ; vm -> sharedCacheAPI -> maxJIT = - 1 ; if ( ( index = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ) >= 0 ) { char optionsBuffer [ SHR_SUBOPT_BUFLEN ] ; char * optionsBufferPtr = ( char * ) optionsBuffer ; IDATA parseRc = OPTION_OK ; vm -> sharedCacheAPI -> xShareClassesPresent = TRUE ; parseRc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , SHR_SUBOPT_BUFLEN ) ; if ( OPTION_OK == parseRc ) { UDATA verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; UDATA printStatsOptions = PRINTSTATS_SHOW_NONE ; UDATA storageKeyTesting = 0 ; char * cacheName = CACHE_ROOT_PREFIX ; char * modContext = NULL ; char * expireTime = NULL ; char * ctrlDirName = NULL ; char * cacheDirPermStr = NULL ; char * methodSpecs = NULL ; # if ! defined ( WIN32 ) && ! defined ( WIN64 ) char defaultCacheDir [ J9SH_MAXPATH ] ; # endif IDATA argIndex1 = - 1 ; IDATA argIndex2 = - 1 ; BOOLEAN matchedOneSpecialOptions ; UDATA bufSize = SHR_SUBOPT_BUFLEN ; do { matchedOneSpecialOptions = FALSE ; if ( ( strcmp ( optionsBufferPtr , OPTION_RESET ) == 0 ) && ( optionsBufferPtr [ strlen ( OPTION_RESET ) + 1 ] == 0 ) ) { if ( ( index = FIND_NEXT_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL , index ) ) >= 0 ) { UDATA resetLen = strlen ( OPTION_RESET ) ; optionsBufferPtr += resetLen + 1 ; bufSize -= resetLen + 1 ; rc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , bufSize ) ; matchedOneSpecialOptions = TRUE ; if ( OPTION_OK != rc ) { if ( OPTION_OVERFLOW == rc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } } if ( ( strcmp ( optionsBufferPtr , OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) == 0 ) && ( optionsBufferPtr [ strlen ( OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) + 1 ] == 0 ) ) { if ( ( index = FIND_NEXT_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL , index ) ) >= 0 ) { UDATA disableCorruptedCacheLen = strlen ( OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) ; optionsBufferPtr += disableCorruptedCacheLen + 1 ; bufSize -= disableCorruptedCacheLen + 1 ; rc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , bufSize ) ; matchedOneSpecialOptions = TRUE ; if ( OPTION_OK != rc ) { if ( OPTION_OVERFLOW == rc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } } } while ( matchedOneSpecialOptions ) ; optionsBufferPtr = optionsBuffer ; argIndex1 = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , VMOPT_XXSHARECLASSESENABLEBCI , NULL ) ; argIndex2 = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , VMOPT_XXSHARECLASSESDISABLEBCI , NULL ) ; if ( argIndex1 > argIndex2 ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_BCI ; } else if ( argIndex2 > argIndex1 ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_DISABLE_BCI ; } vm -> sharedCacheAPI -> parseResult = parseArgs ( vm , optionsBufferPtr , & runtimeFlags , & verboseFlags , & cacheName , & modContext , & expireTime , & ctrlDirName , & cacheDirPermStr , & methodSpecs , & printStatsOptions , & storageKeyTesting ) ; if ( ( RESULT_PARSE_FAILED == vm -> sharedCacheAPI -> parseResult ) ) { return J9VMDLLMAIN_FAILED ; } if ( cacheName != NULL ) { vm -> sharedCacheAPI -> cacheName = ( char * ) j9mem_allocate_memory ( strlen ( cacheName ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> cacheName == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> cacheName , cacheName , strlen ( cacheName ) + 1 ) ; } if ( ctrlDirName != NULL ) { vm -> sharedCacheAPI -> ctrlDirName = ( char * ) j9mem_allocate_memory ( strlen ( ctrlDirName ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> ctrlDirName == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> ctrlDirName , ctrlDirName , strlen ( ctrlDirName ) + 1 ) ; } if ( modContext != NULL ) { vm -> sharedCacheAPI -> modContext = ( char * ) j9mem_allocate_memory ( strlen ( modContext ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> modContext == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> modContext , modContext , strlen ( modContext ) + 1 ) ; } if ( expireTime != NULL ) { vm -> sharedCacheAPI -> expireTime = ( char * ) j9mem_allocate_memory ( strlen ( expireTime ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> expireTime == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> expireTime , expireTime , strlen ( expireTime ) + 1 ) ; } if ( NULL != methodSpecs ) { vm -> sharedCacheAPI -> methodSpecs = ( char * ) j9mem_allocate_memory ( strlen ( methodSpecs ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( NULL == vm -> sharedCacheAPI -> methodSpecs ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> methodSpecs , methodSpecs , strlen ( methodSpecs ) + 1 ) ; } # if ! defined ( WIN32 ) && ! defined ( WIN64 ) rc = j9shmem_getDir ( NULL , J9SHMEM_GETDIR_APPEND_BASEDIR , defaultCacheDir , J9SH_MAXPATH ) ; if ( - 1 == rc ) { SHRCLSSUP_ERR_TRACE ( verboseFlags , J9NLS_SHRC_SHRCLSSUP_FAILURE_GET_DEFAULT_DIR_FAILED ) ; Trc_SHR_Assert_ShouldNeverHappen ( ) ; return J9VMDLLMAIN_FAILED ; } if ( ( NULL != ctrlDirName ) && ( 0 != ( strcmp ( defaultCacheDir , ctrlDirName ) ) ) ) { vm -> sharedCacheAPI -> cacheDirPerm = convertPermToDecimal ( vm , cacheDirPermStr ) ; if ( ( UDATA ) - 1 == vm -> sharedCacheAPI -> cacheDirPerm ) { return J9VMDLLMAIN_FAILED ; } } else { vm -> sharedCacheAPI -> cacheDirPerm = J9SH_DIRPERM_ABSENT ; } # else vm -> sharedCacheAPI -> cacheDirPerm = J9SH_DIRPERM_ABSENT ; # endif if ( runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_PERSISTENT_CACHE ) { vm -> sharedCacheAPI -> cacheType = J9PORT_SHR_CACHE_TYPE_PERSISTENT ; } else { vm -> sharedCacheAPI -> cacheType = J9PORT_SHR_CACHE_TYPE_NONPERSISTENT ; } vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags ; vm -> sharedCacheAPI -> verboseFlags = verboseFlags ; vm -> sharedCacheAPI -> printStatsOptions = printStatsOptions ; vm -> sharedCacheAPI -> storageKeyTesting = storageKeyTesting ; } else { if ( OPTION_OVERFLOW == parseRc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } else { vm -> sharedCacheAPI -> xShareClassesPresent = FALSE ; vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags ; vm -> sharedCacheAPI -> verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; } } switch ( stage ) { case DLL_LOAD_TABLE_FINALIZED : { IDATA index ; if ( ( index = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ) >= 0 ) { char optionsBuffer [ SHR_SUBOPT_BUFLEN ] ; char * optionsBufferPtr = ( char * ) optionsBuffer ; if ( GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , SHR_SUBOPT_BUFLEN ) == OPTION_OK ) { while ( * optionsBufferPtr ) { if ( try_scan ( & optionsBufferPtr , OPT_NONE ) ) { J9VMDllLoadInfo * loadInfo = FIND_DLL_TABLE_ENTRY ( THIS_DLL_NAME ) ; if ( loadInfo ) { loadInfo -> loadFlags |= FORCE_UNLOAD ; } break ; } optionsBufferPtr += strlen ( optionsBufferPtr ) + 1 ; } } } break ; } case ALL_VM_ARGS_CONSUMED : FIND_AND_CONSUME_ARG ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ; vm -> sharedClassConfig = NULL ; break ; case JIT_INITIALIZED : { UDATA loadFlags = 0 ; UDATA nonfatal = 0 ; UT_MODULE_LOADED ( J9_UTINTERFACE_FROM_VM ( vm ) ) ; Trc_SHR_VMInitStages_Event1 ( vm -> mainThread ) ; vm -> sharedCacheAPI -> iterateSharedCaches = j9shr_iterateSharedCaches ; vm -> sharedCacheAPI -> destroySharedCache = j9shr_destroySharedCache ; if ( ( vm -> sharedCacheAPI -> xShareClassesPresent == TRUE ) && ( vm -> sharedCacheAPI -> parseResult != RESULT_DO_UTILITIES ) ) { if ( ( rc = j9shr_init ( vm , loadFlags , & nonfatal ) ) != J9VMDLLMAIN_OK ) { if ( nonfatal ) { return J9VMDLLMAIN_OK ; } else { return rc ; } } vm -> systemClassLoader -> flags |= J9CLASSLOADER_SHARED_CLASSES_ENABLED ; if ( FIND_ARG_IN_VMARGS ( EXACT_MATCH , VMOPT_XNOLINENUMBERS , NULL ) < 0 ) { vm -> requiredDebugAttributes |= J9VM_DEBUG_ATTRIBUTE_RECORD_ALL ; } } break ; } case ALL_LIBRARIES_LOADED : { if ( ( vm -> sharedCacheAPI -> xShareClassesPresent == TRUE ) && ( vm -> sharedCacheAPI -> parseResult != RESULT_DO_UTILITIES ) ) { if ( 0 != initZipLibrary ( vm -> portLibrary , vm -> j2seRootDirectory ) ) { returnVal = J9VMDLLMAIN_FAILED ; } } break ; } case ABOUT_TO_BOOTSTRAP : { break ; } case LIBRARIES_ONUNLOAD : case JVM_EXIT_STAGE : j9shr_guaranteed_exit ( vm , FALSE ) ; break ; case HEAP_STRUCTURES_FREED : if ( vm != NULL ) { j9shr_shutdown ( vm ) ; } break ; default : break ; } return returnVal ; }
static int f2fs_readdir ( struct file * file , void * dirent , filldir_t filldir ) { unsigned long pos = file -> f_pos ; unsigned int bit_pos = 0 ; struct inode * inode = file_inode ( file ) ; unsigned long npages = dir_blocks ( inode ) ; struct f2fs_dentry_block * dentry_blk = NULL ; struct page * dentry_page = NULL ; struct file_ra_state * ra = & file -> f_ra ; struct f2fs_dentry_ptr d ; struct f2fs_str fstr = FSTR_INIT ( NULL , 0 ) ; unsigned int n = 0 ; int err = 0 ; if ( f2fs_encrypted_inode ( inode ) ) { err = f2fs_get_encryption_info ( inode ) ; if ( err ) return err ; err = f2fs_fname_crypto_alloc_buffer ( inode , F2FS_NAME_LEN , & fstr ) ; if ( err < 0 ) return err ; } if ( f2fs_has_inline_dentry ( inode ) ) { err = f2fs_read_inline_dir ( file , dirent , filldir , & fstr ) ; goto out ; } bit_pos = ( pos % NR_DENTRY_IN_BLOCK ) ; n = ( pos / NR_DENTRY_IN_BLOCK ) ; if ( npages - n > 1 && ! ra_has_index ( ra , n ) ) page_cache_sync_readahead ( inode -> i_mapping , ra , file , n , min ( npages - n , ( pgoff_t ) MAX_DIR_RA_PAGES ) ) ; for ( ; n < npages ; n ++ ) { dentry_page = get_lock_data_page ( inode , n , false ) ; if ( IS_ERR ( dentry_page ) ) continue ; dentry_blk = kmap ( dentry_page ) ; make_dentry_ptr ( inode , & d , ( void * ) dentry_blk , 1 ) ; if ( f2fs_fill_dentries ( file , dirent , filldir , & d , n , bit_pos , & fstr ) ) goto stop ; bit_pos = 0 ; file -> f_pos = ( n + 1 ) * NR_DENTRY_IN_BLOCK ; kunmap ( dentry_page ) ; f2fs_put_page ( dentry_page , 1 ) ; dentry_page = NULL ; } stop : if ( dentry_page && ! IS_ERR ( dentry_page ) ) { kunmap ( dentry_page ) ; f2fs_put_page ( dentry_page , 1 ) ; } out : f2fs_fname_crypto_free_buffer ( & fstr ) ; return err ; }
char * elasticsearch_dumpQuery ( ZDBIndexDescriptor * indexDescriptor , char * userQuery ) { StringInfo query ; StringInfo endpoint = makeStringInfo ( ) ; StringInfo response ; bool useInvisibilityMap = strstr ( userQuery , "#expand" ) != NULL || indexDescriptor -> options != NULL ; appendStringInfo ( endpoint , "%s%s/_zdbquery" , indexDescriptor -> url , indexDescriptor -> fullyQualifiedName ) ; if ( indexDescriptor -> searchPreference != NULL ) appendStringInfo ( endpoint , "?preference=%s" , indexDescriptor -> searchPreference ) ; query = buildQuery ( indexDescriptor , & userQuery , 1 , useInvisibilityMap ) ; response = rest_call ( "POST" , endpoint -> data , query , indexDescriptor -> compressionLevel ) ; freeStringInfo ( query ) ; freeStringInfo ( endpoint ) ; return response -> data ; }
ZDBSearchResponse * elasticsearch_searchIndex ( ZDBIndexDescriptor * indexDescriptor , char * * queries , int nqueries , uint64 * nhits , bool wantScores , bool needSort ) { StringInfo query ; StringInfo endpoint = makeStringInfo ( ) ; StringInfo response ; ZDBSearchResponse * hits ; ZDBScore max_score ; bool useInvisibilityMap = strstr ( queries [ 0 ] , "#expand" ) != NULL || indexDescriptor -> options != NULL ; int expected_bytes_len ; appendStringInfo ( endpoint , "%s%s/_pgtid?scores=%s&sort=%s" , indexDescriptor -> url , indexDescriptor -> fullyQualifiedName , wantScores ? "true" : "false" , needSort ? "true" : "false" ) ; if ( indexDescriptor -> searchPreference != NULL ) appendStringInfo ( endpoint , "&preference=%s" , indexDescriptor -> searchPreference ) ; query = buildQuery ( indexDescriptor , queries , nqueries , useInvisibilityMap ) ; response = rest_call ( "POST" , endpoint -> data , query , indexDescriptor -> compressionLevel ) ; if ( response -> data [ 0 ] != '\\0' ) elog ( ERROR , "%s" , response -> data ) ; if ( response -> len < 1 + sizeof ( uint64 ) + ( wantScores ? sizeof ( float4 ) : 0 ) ) elog ( ERROR , "Elasticsearch<S2SV_blank>didn\'t<S2SV_blank>return<S2SV_blank>enough<S2SV_blank>header<S2SV_blank>data" ) ; memcpy ( nhits , response -> data + 1 , sizeof ( uint64 ) ) ; if ( wantScores ) { memcpy ( & max_score , response -> data + 1 + sizeof ( uint64 ) , sizeof ( float4 ) ) ; } else { memset ( & max_score , 0 , sizeof ( ZDBScore ) ) ; } expected_bytes_len = 1 + sizeof ( uint64 ) + ( wantScores ? sizeof ( float4 ) : 0 ) + ( * nhits * ( sizeof ( BlockNumber ) + sizeof ( OffsetNumber ) + ( wantScores ? sizeof ( float4 ) : 0 ) ) ) ; if ( response -> len != expected_bytes_len ) elog ( ERROR , "Elasticsearch<S2SV_blank>says<S2SV_blank>there\'s<S2SV_blank>%ld<S2SV_blank>hits,<S2SV_blank>but<S2SV_blank>didn\'t<S2SV_blank>return<S2SV_blank>the<S2SV_blank>correct<S2SV_blank>number<S2SV_blank>of<S2SV_blank>bytes,<S2SV_blank>expected=%d,<S2SV_blank>received=%d" , * nhits , expected_bytes_len , response -> len ) ; hits = palloc ( sizeof ( ZDBSearchResponse ) ) ; hits -> httpResponse = response ; hits -> hits = ( response -> data + 1 + sizeof ( uint64 ) + ( wantScores ? sizeof ( float4 ) : 0 ) ) ; hits -> total_hits = * nhits ; hits -> max_score = max_score . fscore ; freeStringInfo ( endpoint ) ; freeStringInfo ( query ) ; return hits ; }
UINT8 rfc_parse_data ( tRFC_MCB * p_mcb , MX_FRAME * p_frame , BT_HDR * p_buf ) { UINT8 ead , eal , fcs ; UINT8 * p_data = ( UINT8 * ) ( p_buf + 1 ) + p_buf -> offset ; UINT8 * p_start = p_data ; UINT16 len ; if ( p_buf -> len < RFCOMM_CTRL_FRAME_LEN ) { RFCOMM_TRACE_ERROR1 ( "Bad<S2SV_blank>Length1:<S2SV_blank>%d" , p_buf -> len ) ; return ( RFC_EVENT_BAD_FRAME ) ; } RFCOMM_PARSE_CTRL_FIELD ( ead , p_frame -> cr , p_frame -> dlci , p_data ) ; if ( ! ead ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>Address(EA<S2SV_blank>must<S2SV_blank>be<S2SV_blank>1)" ) ; return ( RFC_EVENT_BAD_FRAME ) ; } RFCOMM_PARSE_TYPE_FIELD ( p_frame -> type , p_frame -> pf , p_data ) ; RFCOMM_PARSE_LEN_FIELD ( eal , len , p_data ) ; p_buf -> len -= ( 3 + ! ead + ! eal + 1 ) ; p_buf -> offset += ( 3 + ! ead + ! eal ) ; if ( ( p_mcb -> flow == PORT_FC_CREDIT ) && ( p_frame -> type == RFCOMM_UIH ) && ( p_frame -> dlci != RFCOMM_MX_DLCI ) && ( p_frame -> pf == 1 ) ) { p_frame -> credit = * p_data ++ ; p_buf -> len -- ; p_buf -> offset ++ ; } else p_frame -> credit = 0 ; if ( p_buf -> len != len ) { RFCOMM_TRACE_ERROR2 ( "Bad<S2SV_blank>Length2<S2SV_blank>%d<S2SV_blank>%d" , p_buf -> len , len ) ; return ( RFC_EVENT_BAD_FRAME ) ; } fcs = * ( p_data + len ) ; switch ( p_frame -> type ) { case RFCOMM_SABME : if ( RFCOMM_FRAME_IS_RSP ( p_mcb -> is_initiator , p_frame -> cr ) || ! p_frame -> pf || len || ! RFCOMM_VALID_DLCI ( p_frame -> dlci ) || ! rfc_check_fcs ( RFCOMM_CTRL_FRAME_LEN , p_start , fcs ) ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>SABME" ) ; return ( RFC_EVENT_BAD_FRAME ) ; } else return ( RFC_EVENT_SABME ) ; case RFCOMM_UA : if ( RFCOMM_FRAME_IS_CMD ( p_mcb -> is_initiator , p_frame -> cr ) || ! p_frame -> pf || len || ! RFCOMM_VALID_DLCI ( p_frame -> dlci ) || ! rfc_check_fcs ( RFCOMM_CTRL_FRAME_LEN , p_start , fcs ) ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>UA" ) ; return ( RFC_EVENT_BAD_FRAME ) ; } else return ( RFC_EVENT_UA ) ; case RFCOMM_DM : if ( RFCOMM_FRAME_IS_CMD ( p_mcb -> is_initiator , p_frame -> cr ) || len || ! RFCOMM_VALID_DLCI ( p_frame -> dlci ) || ! rfc_check_fcs ( RFCOMM_CTRL_FRAME_LEN , p_start , fcs ) ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>DM" ) ; return ( RFC_EVENT_BAD_FRAME ) ; } else return ( RFC_EVENT_DM ) ; case RFCOMM_DISC : if ( RFCOMM_FRAME_IS_RSP ( p_mcb -> is_initiator , p_frame -> cr ) || ! p_frame -> pf || len || ! RFCOMM_VALID_DLCI ( p_frame -> dlci ) || ! rfc_check_fcs ( RFCOMM_CTRL_FRAME_LEN , p_start , fcs ) ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>DISC" ) ; return ( RFC_EVENT_BAD_FRAME ) ; } else return ( RFC_EVENT_DISC ) ; case RFCOMM_UIH : if ( ! RFCOMM_VALID_DLCI ( p_frame -> dlci ) ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>UIH<S2SV_blank>-<S2SV_blank>invalid<S2SV_blank>DLCI" ) ; return ( RFC_EVENT_BAD_FRAME ) ; } else if ( ! rfc_check_fcs ( 2 , p_start , fcs ) ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>UIH<S2SV_blank>-<S2SV_blank>FCS" ) ; return ( RFC_EVENT_BAD_FRAME ) ; } else if ( RFCOMM_FRAME_IS_RSP ( p_mcb -> is_initiator , p_frame -> cr ) ) { RFCOMM_TRACE_ERROR0 ( "Bad<S2SV_blank>UIH<S2SV_blank>-<S2SV_blank>response" ) ; return ( RFC_EVENT_UIH ) ; } else return ( RFC_EVENT_UIH ) ; } return ( RFC_EVENT_BAD_FRAME ) ; }
uint32_t layer_state_set_user ( uint32_t state ) { switch ( biton32 ( state ) ) { case QWERTY : rgblight_mode ( 9 ) ; break ; case COLEMAK : rgblight_mode ( 27 ) ; break ; case DVORAK : rgblight_mode ( 28 ) ; break ; case NAV_CLUSTER : rgblight_mode ( 29 ) ; break ; case MOUSE : rgblight_mode ( 30 ) ; break ; case GAMING : rgblight_mode ( 26 ) ; break ; case SQLMACROS : rgblight_mode ( 1 ) ; rgblight_setrgb ( 0x00 , 0xFF , 0x80 ) ; break ; case SQLNAMES : rgblight_mode ( 1 ) ; rgblight_setrgb ( 0x80 , 0xFF , 0x00 ) ; break ; case FN_LAYER : rgblight_mode ( 1 ) ; rgblight_setrgb ( 0x00 , 0x80 , 0xFF ) ; break ; case LAYER_SEL : rgblight_mode ( 1 ) ; rgblight_setrgb ( 0xFF , 0x00 , 0xFF ) ; break ; } return state ; }
u_int ieee802_15_4_if_print ( netdissect_options * ndo , const struct pcap_pkthdr * h , const u_char * p ) { u_int caplen = h -> caplen ; u_int hdrlen ; uint16_t fc ; uint8_t seq ; uint16_t panid = 0 ; if ( caplen < 3 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return caplen ; } hdrlen = 3 ; fc = EXTRACT_LE_16BITS ( p ) ; seq = EXTRACT_LE_8BITS ( p + 2 ) ; p += 3 ; caplen -= 3 ; ND_PRINT ( ( ndo , "IEEE<S2SV_blank>802.15.4<S2SV_blank>%s<S2SV_blank>packet<S2SV_blank>" , ftypes [ FC_FRAME_TYPE ( fc ) ] ) ) ; if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "seq<S2SV_blank>%02x<S2SV_blank>" , seq ) ) ; switch ( FC_DEST_ADDRESSING_MODE ( fc ) ) { case FC_ADDRESSING_MODE_NONE : if ( fc & FC_PAN_ID_COMPRESSION ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "none<S2SV_blank>" ) ) ; break ; case FC_ADDRESSING_MODE_RESERVED : if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "reserved<S2SV_blank>destination<S2SV_blank>addressing<S2SV_blank>mode" ) ) ; return hdrlen ; case FC_ADDRESSING_MODE_SHORT : if ( caplen < 2 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } panid = EXTRACT_LE_16BITS ( p ) ; p += 2 ; caplen -= 2 ; hdrlen += 2 ; if ( caplen < 2 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "%04x:%04x<S2SV_blank>" , panid , EXTRACT_LE_16BITS ( p + 2 ) ) ) ; p += 2 ; caplen -= 2 ; hdrlen += 2 ; break ; case FC_ADDRESSING_MODE_LONG : if ( caplen < 2 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } panid = EXTRACT_LE_16BITS ( p ) ; p += 2 ; caplen -= 2 ; hdrlen += 2 ; if ( caplen < 8 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "%04x:%s<S2SV_blank>" , panid , le64addr_string ( ndo , p ) ) ) ; p += 8 ; caplen -= 8 ; hdrlen += 8 ; break ; } if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "<<S2SV_blank>" ) ) ; switch ( FC_SRC_ADDRESSING_MODE ( fc ) ) { case FC_ADDRESSING_MODE_NONE : if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "none<S2SV_blank>" ) ) ; break ; case FC_ADDRESSING_MODE_RESERVED : if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "reserved<S2SV_blank>source<S2SV_blank>addressing<S2SV_blank>mode" ) ) ; return 0 ; case FC_ADDRESSING_MODE_SHORT : if ( ! ( fc & FC_PAN_ID_COMPRESSION ) ) { if ( caplen < 2 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } panid = EXTRACT_LE_16BITS ( p ) ; p += 2 ; caplen -= 2 ; hdrlen += 2 ; } if ( caplen < 2 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "%04x:%04x<S2SV_blank>" , panid , EXTRACT_LE_16BITS ( p ) ) ) ; p += 2 ; caplen -= 2 ; hdrlen += 2 ; break ; case FC_ADDRESSING_MODE_LONG : if ( ! ( fc & FC_PAN_ID_COMPRESSION ) ) { if ( caplen < 2 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } panid = EXTRACT_LE_16BITS ( p ) ; p += 2 ; caplen -= 2 ; hdrlen += 2 ; } if ( caplen < 8 ) { ND_PRINT ( ( ndo , "[|802.15.4]" ) ) ; return hdrlen ; } if ( ndo -> ndo_vflag ) ND_PRINT ( ( ndo , "%04x:%s<S2SV_blank>" , panid , le64addr_string ( ndo , p ) ) ) ; p += 8 ; caplen -= 8 ; hdrlen += 8 ; break ; } if ( ! ndo -> ndo_suppress_default_print ) ND_DEFAULTPRINT ( p , caplen ) ; return hdrlen ; }
static int ina2xx_buffer_disable ( struct iio_dev * indio_dev ) { struct ina2xx_chip_info * chip = iio_priv ( indio_dev ) ; if ( chip -> task ) { kthread_stop ( chip -> task ) ; chip -> task = NULL ; } return 0 ; }
static int ina2xx_buffer_enable ( struct iio_dev * indio_dev ) { struct ina2xx_chip_info * chip = iio_priv ( indio_dev ) ; unsigned int sampling_us = SAMPLING_PERIOD ( chip ) ; dev_dbg ( & indio_dev -> dev , "Enabling<S2SV_blank>buffer<S2SV_blank>w/<S2SV_blank>scan_mask<S2SV_blank>%02x,<S2SV_blank>freq<S2SV_blank>=<S2SV_blank>%d,<S2SV_blank>avg<S2SV_blank>=%u\\n" , ( unsigned int ) ( * indio_dev -> active_scan_mask ) , 1000000 / sampling_us , chip -> avg ) ; dev_dbg ( & indio_dev -> dev , "Expected<S2SV_blank>work<S2SV_blank>period:<S2SV_blank>%u<S2SV_blank>us\\n" , sampling_us ) ; dev_dbg ( & indio_dev -> dev , "Async<S2SV_blank>readout<S2SV_blank>mode:<S2SV_blank>%d\\n" , chip -> allow_async_readout ) ; chip -> task = kthread_run ( ina2xx_capture_thread , ( void * ) indio_dev , "%s:%d-%uus" , indio_dev -> name , indio_dev -> id , sampling_us ) ; return PTR_ERR_OR_ZERO ( chip -> task ) ; }
int ext4_resize_fs ( struct super_block * sb , ext4_fsblk_t n_blocks_count ) { struct ext4_new_flex_group_data * flex_gd = NULL ; struct ext4_sb_info * sbi = EXT4_SB ( sb ) ; struct ext4_super_block * es = sbi -> s_es ; struct buffer_head * bh ; struct inode * resize_inode = NULL ; ext4_grpblk_t add , offset ; unsigned long n_desc_blocks ; unsigned long o_desc_blocks ; ext4_group_t o_group ; ext4_group_t n_group ; ext4_fsblk_t o_blocks_count ; ext4_fsblk_t n_blocks_count_retry = 0 ; unsigned long last_update_time = 0 ; int err = 0 , flexbg_size = 1 << sbi -> s_log_groups_per_flex ; int meta_bg ; bh = sb_bread ( sb , n_blocks_count - 1 ) ; if ( ! bh ) { ext4_warning ( sb , "can\'t<S2SV_blank>read<S2SV_blank>last<S2SV_blank>block,<S2SV_blank>resize<S2SV_blank>aborted" ) ; return - ENOSPC ; } brelse ( bh ) ; retry : o_blocks_count = ext4_blocks_count ( es ) ; ext4_msg ( sb , KERN_INFO , "resizing<S2SV_blank>filesystem<S2SV_blank>from<S2SV_blank>%llu<S2SV_blank>" "to<S2SV_blank>%llu<S2SV_blank>blocks" , o_blocks_count , n_blocks_count ) ; if ( n_blocks_count < o_blocks_count ) { ext4_warning ( sb , "can\'t<S2SV_blank>shrink<S2SV_blank>FS<S2SV_blank>-<S2SV_blank>resize<S2SV_blank>aborted" ) ; return - EINVAL ; } if ( n_blocks_count == o_blocks_count ) return 0 ; n_group = ext4_get_group_number ( sb , n_blocks_count - 1 ) ; if ( n_group >= ( 0xFFFFFFFFUL / EXT4_INODES_PER_GROUP ( sb ) ) ) { ext4_warning ( sb , "resize<S2SV_blank>would<S2SV_blank>cause<S2SV_blank>inodes_count<S2SV_blank>overflow" ) ; return - EINVAL ; } ext4_get_group_no_and_offset ( sb , o_blocks_count - 1 , & o_group , & offset ) ; n_desc_blocks = num_desc_blocks ( sb , n_group + 1 ) ; o_desc_blocks = num_desc_blocks ( sb , sbi -> s_groups_count ) ; meta_bg = EXT4_HAS_INCOMPAT_FEATURE ( sb , EXT4_FEATURE_INCOMPAT_META_BG ) ; if ( EXT4_HAS_COMPAT_FEATURE ( sb , EXT4_FEATURE_COMPAT_RESIZE_INODE ) ) { if ( meta_bg ) { ext4_error ( sb , "resize_inode<S2SV_blank>and<S2SV_blank>meta_bg<S2SV_blank>enabled<S2SV_blank>" "simultaneously" ) ; return - EINVAL ; } if ( n_desc_blocks > o_desc_blocks + le16_to_cpu ( es -> s_reserved_gdt_blocks ) ) { n_blocks_count_retry = n_blocks_count ; n_desc_blocks = o_desc_blocks + le16_to_cpu ( es -> s_reserved_gdt_blocks ) ; n_group = n_desc_blocks * EXT4_DESC_PER_BLOCK ( sb ) ; n_blocks_count = ( ext4_fsblk_t ) n_group * EXT4_BLOCKS_PER_GROUP ( sb ) ; n_group -- ; } if ( ! resize_inode ) resize_inode = ext4_iget ( sb , EXT4_RESIZE_INO ) ; if ( IS_ERR ( resize_inode ) ) { ext4_warning ( sb , "Error<S2SV_blank>opening<S2SV_blank>resize<S2SV_blank>inode" ) ; return PTR_ERR ( resize_inode ) ; } } if ( ( ! resize_inode && ! meta_bg ) || n_blocks_count == o_blocks_count ) { err = ext4_convert_meta_bg ( sb , resize_inode ) ; if ( err ) goto out ; if ( resize_inode ) { iput ( resize_inode ) ; resize_inode = NULL ; } if ( n_blocks_count_retry ) { n_blocks_count = n_blocks_count_retry ; n_blocks_count_retry = 0 ; goto retry ; } } if ( n_group == o_group ) add = n_blocks_count - o_blocks_count ; else add = EXT4_BLOCKS_PER_GROUP ( sb ) - ( offset + 1 ) ; if ( add > 0 ) { err = ext4_group_extend_no_check ( sb , o_blocks_count , add ) ; if ( err ) goto out ; } if ( ext4_blocks_count ( es ) == n_blocks_count ) goto out ; err = ext4_alloc_flex_bg_array ( sb , n_group + 1 ) ; if ( err ) return err ; err = ext4_mb_alloc_groupinfo ( sb , n_group + 1 ) ; if ( err ) goto out ; flex_gd = alloc_flex_gd ( flexbg_size ) ; if ( flex_gd == NULL ) { err = - ENOMEM ; goto out ; } while ( ext4_setup_next_flex_gd ( sb , flex_gd , n_blocks_count , flexbg_size ) ) { if ( jiffies - last_update_time > HZ * 10 ) { if ( last_update_time ) ext4_msg ( sb , KERN_INFO , "resized<S2SV_blank>to<S2SV_blank>%llu<S2SV_blank>blocks" , ext4_blocks_count ( es ) ) ; last_update_time = jiffies ; } if ( ext4_alloc_group_tables ( sb , flex_gd , flexbg_size ) != 0 ) break ; err = ext4_flex_group_add ( sb , resize_inode , flex_gd ) ; if ( unlikely ( err ) ) break ; } if ( ! err && n_blocks_count_retry ) { n_blocks_count = n_blocks_count_retry ; n_blocks_count_retry = 0 ; free_flex_gd ( flex_gd ) ; flex_gd = NULL ; goto retry ; } out : if ( flex_gd ) free_flex_gd ( flex_gd ) ; if ( resize_inode != NULL ) iput ( resize_inode ) ; ext4_msg ( sb , KERN_INFO , "resized<S2SV_blank>filesystem<S2SV_blank>to<S2SV_blank>%llu" , n_blocks_count ) ; return err ; }
void keyboard_slave_loop ( void ) { matrix_init ( ) ; # ifdef RGBLIGHT_ENABLE rgblight_init ( ) ; # endif while ( 1 ) { matrix_slave_scan ( ) ; # ifdef BACKLIGHT_ENABLE if ( BACKLIT_DIRTY ) { backlight_set ( i2c_slave_buffer [ I2C_BACKLIT_START ] ) ; BACKLIT_DIRTY = false ; } # endif # ifdef RGBLIGHT_ENABLE if ( RGB_DIRTY ) { cli ( ) ; uint32_t dword ; uint8_t * dword_dat = ( uint8_t * ) ( & dword ) ; for ( int i = 0 ; i < 4 ; i ++ ) { dword_dat [ i ] = i2c_slave_buffer [ I2C_RGB_START + i ] ; } rgblight_update_dword ( dword ) ; RGB_DIRTY = false ; sei ( ) ; } # endif } }
static int ina2xx_buffer_disable ( struct iio_dev * indio_dev ) { struct ina2xx_chip_info * chip = iio_priv ( indio_dev ) ; if ( chip -> task ) { kthread_stop ( chip -> task ) ; chip -> task = NULL ; } return 0 ; }
static int ina2xx_buffer_enable ( struct iio_dev * indio_dev ) { struct ina2xx_chip_info * chip = iio_priv ( indio_dev ) ; unsigned int sampling_us = SAMPLING_PERIOD ( chip ) ; dev_dbg ( & indio_dev -> dev , "Enabling<S2SV_blank>buffer<S2SV_blank>w/<S2SV_blank>scan_mask<S2SV_blank>%02x,<S2SV_blank>freq<S2SV_blank>=<S2SV_blank>%d,<S2SV_blank>avg<S2SV_blank>=%u\\n" , ( unsigned int ) ( * indio_dev -> active_scan_mask ) , 1000000 / sampling_us , chip -> avg ) ; dev_dbg ( & indio_dev -> dev , "Expected<S2SV_blank>work<S2SV_blank>period:<S2SV_blank>%u<S2SV_blank>us\\n" , sampling_us ) ; dev_dbg ( & indio_dev -> dev , "Async<S2SV_blank>readout<S2SV_blank>mode:<S2SV_blank>%d\\n" , chip -> allow_async_readout ) ; chip -> task = kthread_run ( ina2xx_capture_thread , ( void * ) indio_dev , "%s:%d-%uus" , indio_dev -> name , indio_dev -> id , sampling_us ) ; return PTR_ERR_OR_ZERO ( chip -> task ) ; }
static int f2fs_fill_super ( struct super_block * sb , void * data , int silent ) { struct f2fs_sb_info * sbi ; struct f2fs_super_block * raw_super ; struct inode * root ; int err ; bool retry = true , need_fsck = false ; char * options = NULL ; int recovery , i , valid_super_block ; struct curseg_info * seg_i ; try_onemore : err = - EINVAL ; raw_super = NULL ; valid_super_block = - 1 ; recovery = 0 ; sbi = kzalloc ( sizeof ( struct f2fs_sb_info ) , GFP_KERNEL ) ; if ( ! sbi ) return - ENOMEM ; sbi -> sb = sb ; sbi -> s_chksum_driver = crypto_alloc_shash ( "crc32" , 0 , 0 ) ; if ( IS_ERR ( sbi -> s_chksum_driver ) ) { f2fs_msg ( sb , KERN_ERR , "Cannot<S2SV_blank>load<S2SV_blank>crc32<S2SV_blank>driver." ) ; err = PTR_ERR ( sbi -> s_chksum_driver ) ; sbi -> s_chksum_driver = NULL ; goto free_sbi ; } if ( unlikely ( ! sb_set_blocksize ( sb , F2FS_BLKSIZE ) ) ) { f2fs_msg ( sb , KERN_ERR , "unable<S2SV_blank>to<S2SV_blank>set<S2SV_blank>blocksize" ) ; goto free_sbi ; } err = read_raw_super_block ( sbi , & raw_super , & valid_super_block , & recovery ) ; if ( err ) goto free_sbi ; sb -> s_fs_info = sbi ; sbi -> raw_super = raw_super ; if ( f2fs_sb_has_inode_chksum ( sb ) ) sbi -> s_chksum_seed = f2fs_chksum ( sbi , ~ 0 , raw_super -> uuid , sizeof ( raw_super -> uuid ) ) ; # ifndef CONFIG_BLK_DEV_ZONED if ( f2fs_sb_has_blkzoned ( sb ) ) { f2fs_msg ( sb , KERN_ERR , "Zoned<S2SV_blank>block<S2SV_blank>device<S2SV_blank>support<S2SV_blank>is<S2SV_blank>not<S2SV_blank>enabled\\n" ) ; err = - EOPNOTSUPP ; goto free_sb_buf ; } # endif default_options ( sbi ) ; options = kstrdup ( ( const char * ) data , GFP_KERNEL ) ; if ( data && ! options ) { err = - ENOMEM ; goto free_sb_buf ; } err = parse_options ( sb , options ) ; if ( err ) goto free_options ; sbi -> max_file_blocks = max_file_blocks ( ) ; sb -> s_maxbytes = sbi -> max_file_blocks << le32_to_cpu ( raw_super -> log_blocksize ) ; sb -> s_max_links = F2FS_LINK_MAX ; get_random_bytes ( & sbi -> s_next_generation , sizeof ( u32 ) ) ; # ifdef CONFIG_QUOTA sb -> dq_op = & f2fs_quota_operations ; if ( f2fs_sb_has_quota_ino ( sb ) ) sb -> s_qcop = & dquot_quotactl_sysfile_ops ; else sb -> s_qcop = & f2fs_quotactl_ops ; sb -> s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ ; if ( f2fs_sb_has_quota_ino ( sbi -> sb ) ) { for ( i = 0 ; i < MAXQUOTAS ; i ++ ) { if ( f2fs_qf_ino ( sbi -> sb , i ) ) sbi -> nquota_files ++ ; } } # endif sb -> s_op = & f2fs_sops ; # ifdef CONFIG_F2FS_FS_ENCRYPTION sb -> s_cop = & f2fs_cryptops ; # endif sb -> s_xattr = f2fs_xattr_handlers ; sb -> s_export_op = & f2fs_export_ops ; sb -> s_magic = F2FS_SUPER_MAGIC ; sb -> s_time_gran = 1 ; sb -> s_flags = ( sb -> s_flags & ~ MS_POSIXACL ) | ( test_opt ( sbi , POSIX_ACL ) ? MS_POSIXACL : 0 ) ; memcpy ( & sb -> s_uuid , raw_super -> uuid , sizeof ( raw_super -> uuid ) ) ; sb -> s_iflags |= SB_I_CGROUPWB ; sbi -> valid_super_block = valid_super_block ; mutex_init ( & sbi -> gc_mutex ) ; mutex_init ( & sbi -> cp_mutex ) ; init_rwsem ( & sbi -> node_write ) ; init_rwsem ( & sbi -> node_change ) ; set_sbi_flag ( sbi , SBI_POR_DOING ) ; spin_lock_init ( & sbi -> stat_lock ) ; spin_lock_init ( & sbi -> iostat_lock ) ; sbi -> iostat_enable = false ; for ( i = 0 ; i < NR_PAGE_TYPE ; i ++ ) { int n = ( i == META ) ? 1 : NR_TEMP_TYPE ; int j ; sbi -> write_io [ i ] = f2fs_kmalloc ( sbi , array_size ( n , sizeof ( struct f2fs_bio_info ) ) , GFP_KERNEL ) ; if ( ! sbi -> write_io [ i ] ) { err = - ENOMEM ; goto free_options ; } for ( j = HOT ; j < n ; j ++ ) { init_rwsem ( & sbi -> write_io [ i ] [ j ] . io_rwsem ) ; sbi -> write_io [ i ] [ j ] . sbi = sbi ; sbi -> write_io [ i ] [ j ] . bio = NULL ; spin_lock_init ( & sbi -> write_io [ i ] [ j ] . io_lock ) ; INIT_LIST_HEAD ( & sbi -> write_io [ i ] [ j ] . io_list ) ; } } init_rwsem ( & sbi -> cp_rwsem ) ; init_waitqueue_head ( & sbi -> cp_wait ) ; init_sb_info ( sbi ) ; err = init_percpu_info ( sbi ) ; if ( err ) goto free_bio_info ; if ( F2FS_IO_SIZE ( sbi ) > 1 ) { sbi -> write_io_dummy = mempool_create_page_pool ( 2 * ( F2FS_IO_SIZE ( sbi ) - 1 ) , 0 ) ; if ( ! sbi -> write_io_dummy ) { err = - ENOMEM ; goto free_percpu ; } } sbi -> meta_inode = f2fs_iget ( sb , F2FS_META_INO ( sbi ) ) ; if ( IS_ERR ( sbi -> meta_inode ) ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>F2FS<S2SV_blank>meta<S2SV_blank>data<S2SV_blank>inode" ) ; err = PTR_ERR ( sbi -> meta_inode ) ; goto free_io_dummy ; } err = f2fs_get_valid_checkpoint ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>get<S2SV_blank>valid<S2SV_blank>F2FS<S2SV_blank>checkpoint" ) ; goto free_meta_inode ; } err = f2fs_scan_devices ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>find<S2SV_blank>devices" ) ; goto free_devices ; } sbi -> total_valid_node_count = le32_to_cpu ( sbi -> ckpt -> valid_node_count ) ; percpu_counter_set ( & sbi -> total_valid_inode_count , le32_to_cpu ( sbi -> ckpt -> valid_inode_count ) ) ; sbi -> user_block_count = le64_to_cpu ( sbi -> ckpt -> user_block_count ) ; sbi -> total_valid_block_count = le64_to_cpu ( sbi -> ckpt -> valid_block_count ) ; sbi -> last_valid_block_count = sbi -> total_valid_block_count ; sbi -> reserved_blocks = 0 ; sbi -> current_reserved_blocks = 0 ; limit_reserve_root ( sbi ) ; for ( i = 0 ; i < NR_INODE_TYPE ; i ++ ) { INIT_LIST_HEAD ( & sbi -> inode_list [ i ] ) ; spin_lock_init ( & sbi -> inode_lock [ i ] ) ; } f2fs_init_extent_cache_info ( sbi ) ; f2fs_init_ino_entry_info ( sbi ) ; err = f2fs_build_segment_manager ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>initialize<S2SV_blank>F2FS<S2SV_blank>segment<S2SV_blank>manager" ) ; goto free_sm ; } err = f2fs_build_node_manager ( sbi ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>initialize<S2SV_blank>F2FS<S2SV_blank>node<S2SV_blank>manager" ) ; goto free_nm ; } if ( sb -> s_bdev -> bd_part ) sbi -> sectors_written_start = ( u64 ) part_stat_read ( sb -> s_bdev -> bd_part , sectors [ 1 ] ) ; seg_i = CURSEG_I ( sbi , CURSEG_HOT_NODE ) ; if ( __exist_node_summaries ( sbi ) ) sbi -> kbytes_written = le64_to_cpu ( seg_i -> journal -> info . kbytes_written ) ; f2fs_build_gc_manager ( sbi ) ; sbi -> node_inode = f2fs_iget ( sb , F2FS_NODE_INO ( sbi ) ) ; if ( IS_ERR ( sbi -> node_inode ) ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>node<S2SV_blank>inode" ) ; err = PTR_ERR ( sbi -> node_inode ) ; goto free_nm ; } err = f2fs_build_stats ( sbi ) ; if ( err ) goto free_node_inode ; root = f2fs_iget ( sb , F2FS_ROOT_INO ( sbi ) ) ; if ( IS_ERR ( root ) ) { f2fs_msg ( sb , KERN_ERR , "Failed<S2SV_blank>to<S2SV_blank>read<S2SV_blank>root<S2SV_blank>inode" ) ; err = PTR_ERR ( root ) ; goto free_stats ; } if ( ! S_ISDIR ( root -> i_mode ) || ! root -> i_blocks || ! root -> i_size ) { iput ( root ) ; err = - EINVAL ; goto free_node_inode ; } sb -> s_root = d_make_root ( root ) ; if ( ! sb -> s_root ) { err = - ENOMEM ; goto free_root_inode ; } err = f2fs_register_sysfs ( sbi ) ; if ( err ) goto free_root_inode ; # ifdef CONFIG_QUOTA if ( f2fs_sb_has_quota_ino ( sb ) && ! f2fs_readonly ( sb ) ) { err = f2fs_enable_quotas ( sb ) ; if ( err ) { f2fs_msg ( sb , KERN_ERR , "Cannot<S2SV_blank>turn<S2SV_blank>on<S2SV_blank>quotas:<S2SV_blank>error<S2SV_blank>%d" , err ) ; goto free_sysfs ; } } # endif err = f2fs_recover_orphan_inodes ( sbi ) ; if ( err ) goto free_meta ; if ( ! test_opt ( sbi , DISABLE_ROLL_FORWARD ) ) { if ( bdev_read_only ( sb -> s_bdev ) && ! is_set_ckpt_flags ( sbi , CP_UMOUNT_FLAG ) ) { err = - EROFS ; goto free_meta ; } if ( need_fsck ) set_sbi_flag ( sbi , SBI_NEED_FSCK ) ; if ( ! retry ) goto skip_recovery ; err = f2fs_recover_fsync_data ( sbi , false ) ; if ( err < 0 ) { need_fsck = true ; f2fs_msg ( sb , KERN_ERR , "Cannot<S2SV_blank>recover<S2SV_blank>all<S2SV_blank>fsync<S2SV_blank>data<S2SV_blank>errno=%d" , err ) ; goto free_meta ; } } else { err = f2fs_recover_fsync_data ( sbi , true ) ; if ( ! f2fs_readonly ( sb ) && err > 0 ) { err = - EINVAL ; f2fs_msg ( sb , KERN_ERR , "Need<S2SV_blank>to<S2SV_blank>recover<S2SV_blank>fsync<S2SV_blank>data" ) ; goto free_meta ; } } skip_recovery : clear_sbi_flag ( sbi , SBI_POR_DOING ) ; if ( test_opt ( sbi , BG_GC ) && ! f2fs_readonly ( sb ) ) { err = f2fs_start_gc_thread ( sbi ) ; if ( err ) goto free_meta ; } kfree ( options ) ; if ( recovery ) { err = f2fs_commit_super ( sbi , true ) ; f2fs_msg ( sb , KERN_INFO , "Try<S2SV_blank>to<S2SV_blank>recover<S2SV_blank>%dth<S2SV_blank>superblock,<S2SV_blank>ret:<S2SV_blank>%d" , sbi -> valid_super_block ? 1 : 2 , err ) ; } f2fs_join_shrinker ( sbi ) ; f2fs_tuning_parameters ( sbi ) ; f2fs_msg ( sbi -> sb , KERN_NOTICE , "Mounted<S2SV_blank>with<S2SV_blank>checkpoint<S2SV_blank>version<S2SV_blank>=<S2SV_blank>%llx" , cur_cp_version ( F2FS_CKPT ( sbi ) ) ) ; f2fs_update_time ( sbi , CP_TIME ) ; f2fs_update_time ( sbi , REQ_TIME ) ; return 0 ; free_meta : # ifdef CONFIG_QUOTA if ( f2fs_sb_has_quota_ino ( sb ) && ! f2fs_readonly ( sb ) ) f2fs_quota_off_umount ( sbi -> sb ) ; # endif f2fs_sync_inode_meta ( sbi ) ; truncate_inode_pages_final ( META_MAPPING ( sbi ) ) ; # ifdef CONFIG_QUOTA free_sysfs : # endif f2fs_unregister_sysfs ( sbi ) ; free_root_inode : dput ( sb -> s_root ) ; sb -> s_root = NULL ; free_stats : f2fs_destroy_stats ( sbi ) ; free_node_inode : f2fs_release_ino_entry ( sbi , true ) ; truncate_inode_pages_final ( NODE_MAPPING ( sbi ) ) ; iput ( sbi -> node_inode ) ; free_nm : f2fs_destroy_node_manager ( sbi ) ; free_sm : f2fs_destroy_segment_manager ( sbi ) ; free_devices : destroy_device_list ( sbi ) ; kfree ( sbi -> ckpt ) ; free_meta_inode : make_bad_inode ( sbi -> meta_inode ) ; iput ( sbi -> meta_inode ) ; free_io_dummy : mempool_destroy ( sbi -> write_io_dummy ) ; free_percpu : destroy_percpu_info ( sbi ) ; free_bio_info : for ( i = 0 ; i < NR_PAGE_TYPE ; i ++ ) kfree ( sbi -> write_io [ i ] ) ; free_options : # ifdef CONFIG_QUOTA for ( i = 0 ; i < MAXQUOTAS ; i ++ ) kfree ( F2FS_OPTION ( sbi ) . s_qf_names [ i ] ) ; # endif kfree ( options ) ; free_sb_buf : kfree ( raw_super ) ; free_sbi : if ( sbi -> s_chksum_driver ) crypto_free_shash ( sbi -> s_chksum_driver ) ; kfree ( sbi ) ; if ( retry ) { retry = false ; shrink_dcache_sb ( sb ) ; goto try_onemore ; } return err ; }
IDATA J9VMDllMain ( J9JavaVM * vm , IDATA stage , void * reserved ) { IDATA returnVal = J9VMDLLMAIN_OK ; UDATA rc = 0 ; PORT_ACCESS_FROM_JAVAVM ( vm ) ; if ( vm -> sharedCacheAPI == NULL ) { IDATA index ; U_64 runtimeFlags = getDefaultRuntimeFlags ( ) ; runtimeFlags |= ( ( j9shr_isPlatformDefaultPersistent ( vm ) == TRUE ) ? J9SHR_RUNTIMEFLAG_ENABLE_PERSISTENT_CACHE : 0 ) ; vm -> sharedCacheAPI = ( J9SharedCacheAPI * ) j9mem_allocate_memory ( sizeof ( J9SharedCacheAPI ) , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI == NULL ) { return J9VMDLLMAIN_FAILED ; } memset ( vm -> sharedCacheAPI , 0 , sizeof ( J9SharedCacheAPI ) ) ; vm -> sharedCacheAPI -> softMaxBytes = ( U_32 ) - 1 ; vm -> sharedCacheAPI -> minAOT = - 1 ; vm -> sharedCacheAPI -> maxAOT = - 1 ; vm -> sharedCacheAPI -> minJIT = - 1 ; vm -> sharedCacheAPI -> maxJIT = - 1 ; if ( ( index = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ) >= 0 ) { char optionsBuffer [ SHR_SUBOPT_BUFLEN ] ; char * optionsBufferPtr = ( char * ) optionsBuffer ; IDATA parseRc = OPTION_OK ; vm -> sharedCacheAPI -> xShareClassesPresent = TRUE ; parseRc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , SHR_SUBOPT_BUFLEN ) ; if ( OPTION_OK == parseRc ) { UDATA verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; UDATA printStatsOptions = PRINTSTATS_SHOW_NONE ; UDATA storageKeyTesting = 0 ; char * cacheName = CACHE_ROOT_PREFIX ; char * modContext = NULL ; char * expireTime = NULL ; char * ctrlDirName = NULL ; char * cacheDirPermStr = NULL ; char * methodSpecs = NULL ; # if ! defined ( WIN32 ) && ! defined ( WIN64 ) char defaultCacheDir [ J9SH_MAXPATH ] ; # endif IDATA argIndex1 = - 1 ; IDATA argIndex2 = - 1 ; BOOLEAN matchedOneSpecialOptions ; UDATA bufSize = SHR_SUBOPT_BUFLEN ; do { matchedOneSpecialOptions = FALSE ; if ( ( strcmp ( optionsBufferPtr , OPTION_RESET ) == 0 ) && ( optionsBufferPtr [ strlen ( OPTION_RESET ) + 1 ] == 0 ) ) { if ( ( index = FIND_NEXT_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL , index ) ) >= 0 ) { UDATA resetLen = strlen ( OPTION_RESET ) ; optionsBufferPtr += resetLen + 1 ; bufSize -= resetLen + 1 ; rc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , bufSize ) ; matchedOneSpecialOptions = TRUE ; if ( OPTION_OK != rc ) { if ( OPTION_OVERFLOW == rc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } } if ( ( strcmp ( optionsBufferPtr , OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) == 0 ) && ( optionsBufferPtr [ strlen ( OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) + 1 ] == 0 ) ) { if ( ( index = FIND_NEXT_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL , index ) ) >= 0 ) { UDATA disableCorruptedCacheLen = strlen ( OPTION_DISABLE_CORRUPT_CACHE_DUMPS ) ; optionsBufferPtr += disableCorruptedCacheLen + 1 ; bufSize -= disableCorruptedCacheLen + 1 ; rc = GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , bufSize ) ; matchedOneSpecialOptions = TRUE ; if ( OPTION_OK != rc ) { if ( OPTION_OVERFLOW == rc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } } } while ( matchedOneSpecialOptions ) ; optionsBufferPtr = optionsBuffer ; argIndex1 = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , VMOPT_XXSHARECLASSESENABLEBCI , NULL ) ; argIndex2 = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , VMOPT_XXSHARECLASSESDISABLEBCI , NULL ) ; if ( argIndex1 > argIndex2 ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_ENABLE_BCI ; } else if ( argIndex2 > argIndex1 ) { runtimeFlags |= J9SHR_RUNTIMEFLAG_DISABLE_BCI ; } vm -> sharedCacheAPI -> parseResult = parseArgs ( vm , optionsBufferPtr , & runtimeFlags , & verboseFlags , & cacheName , & modContext , & expireTime , & ctrlDirName , & cacheDirPermStr , & methodSpecs , & printStatsOptions , & storageKeyTesting ) ; if ( ( RESULT_PARSE_FAILED == vm -> sharedCacheAPI -> parseResult ) ) { return J9VMDLLMAIN_FAILED ; } if ( cacheName != NULL ) { vm -> sharedCacheAPI -> cacheName = ( char * ) j9mem_allocate_memory ( strlen ( cacheName ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> cacheName == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> cacheName , cacheName , strlen ( cacheName ) + 1 ) ; } if ( ctrlDirName != NULL ) { vm -> sharedCacheAPI -> ctrlDirName = ( char * ) j9mem_allocate_memory ( strlen ( ctrlDirName ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> ctrlDirName == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> ctrlDirName , ctrlDirName , strlen ( ctrlDirName ) + 1 ) ; } if ( modContext != NULL ) { vm -> sharedCacheAPI -> modContext = ( char * ) j9mem_allocate_memory ( strlen ( modContext ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> modContext == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> modContext , modContext , strlen ( modContext ) + 1 ) ; } if ( expireTime != NULL ) { vm -> sharedCacheAPI -> expireTime = ( char * ) j9mem_allocate_memory ( strlen ( expireTime ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( vm -> sharedCacheAPI -> expireTime == NULL ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> expireTime , expireTime , strlen ( expireTime ) + 1 ) ; } if ( NULL != methodSpecs ) { vm -> sharedCacheAPI -> methodSpecs = ( char * ) j9mem_allocate_memory ( strlen ( methodSpecs ) + 1 , J9MEM_CATEGORY_CLASSES ) ; if ( NULL == vm -> sharedCacheAPI -> methodSpecs ) { return J9VMDLLMAIN_FAILED ; } memcpy ( vm -> sharedCacheAPI -> methodSpecs , methodSpecs , strlen ( methodSpecs ) + 1 ) ; } # if ! defined ( WIN32 ) && ! defined ( WIN64 ) rc = j9shmem_getDir ( NULL , J9SHMEM_GETDIR_APPEND_BASEDIR , defaultCacheDir , J9SH_MAXPATH ) ; if ( - 1 == rc ) { SHRCLSSUP_ERR_TRACE ( verboseFlags , J9NLS_SHRC_SHRCLSSUP_FAILURE_GET_DEFAULT_DIR_FAILED ) ; Trc_SHR_Assert_ShouldNeverHappen ( ) ; return J9VMDLLMAIN_FAILED ; } if ( ( NULL != ctrlDirName ) && ( 0 != ( strcmp ( defaultCacheDir , ctrlDirName ) ) ) ) { vm -> sharedCacheAPI -> cacheDirPerm = convertPermToDecimal ( vm , cacheDirPermStr ) ; if ( ( UDATA ) - 1 == vm -> sharedCacheAPI -> cacheDirPerm ) { return J9VMDLLMAIN_FAILED ; } } else { vm -> sharedCacheAPI -> cacheDirPerm = J9SH_DIRPERM_ABSENT ; } # else vm -> sharedCacheAPI -> cacheDirPerm = J9SH_DIRPERM_ABSENT ; # endif if ( runtimeFlags & J9SHR_RUNTIMEFLAG_ENABLE_PERSISTENT_CACHE ) { vm -> sharedCacheAPI -> cacheType = J9PORT_SHR_CACHE_TYPE_PERSISTENT ; } else { vm -> sharedCacheAPI -> cacheType = J9PORT_SHR_CACHE_TYPE_NONPERSISTENT ; } vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags ; vm -> sharedCacheAPI -> verboseFlags = verboseFlags ; vm -> sharedCacheAPI -> printStatsOptions = printStatsOptions ; vm -> sharedCacheAPI -> storageKeyTesting = storageKeyTesting ; } else { if ( OPTION_OVERFLOW == parseRc ) { SHRCLSSUP_ERR_TRACE1 ( J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT , J9NLS_SHRC_SHRCLSSUP_FAILURE_OPTION_BUFFER_OVERFLOW , SHR_SUBOPT_BUFLEN ) ; } return J9VMDLLMAIN_FAILED ; } } else { vm -> sharedCacheAPI -> xShareClassesPresent = FALSE ; vm -> sharedCacheAPI -> runtimeFlags = runtimeFlags ; vm -> sharedCacheAPI -> verboseFlags = J9SHR_VERBOSEFLAG_ENABLE_VERBOSE_DEFAULT ; } } switch ( stage ) { case DLL_LOAD_TABLE_FINALIZED : { IDATA index ; if ( ( index = FIND_ARG_IN_VMARGS ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ) >= 0 ) { char optionsBuffer [ SHR_SUBOPT_BUFLEN ] ; char * optionsBufferPtr = ( char * ) optionsBuffer ; if ( GET_OPTION_VALUES ( index , ':' , ',' , & optionsBufferPtr , SHR_SUBOPT_BUFLEN ) == OPTION_OK ) { while ( * optionsBufferPtr ) { if ( try_scan ( & optionsBufferPtr , OPT_NONE ) ) { J9VMDllLoadInfo * loadInfo = FIND_DLL_TABLE_ENTRY ( THIS_DLL_NAME ) ; if ( loadInfo ) { loadInfo -> loadFlags |= FORCE_UNLOAD ; } break ; } optionsBufferPtr += strlen ( optionsBufferPtr ) + 1 ; } } } break ; } case ALL_VM_ARGS_CONSUMED : FIND_AND_CONSUME_ARG ( OPTIONAL_LIST_MATCH , OPT_XSHARECLASSES , NULL ) ; vm -> sharedClassConfig = NULL ; break ; case JIT_INITIALIZED : { UDATA loadFlags = 0 ; UDATA nonfatal = 0 ; UT_MODULE_LOADED ( J9_UTINTERFACE_FROM_VM ( vm ) ) ; Trc_SHR_VMInitStages_Event1 ( vm -> mainThread ) ; vm -> sharedCacheAPI -> iterateSharedCaches = j9shr_iterateSharedCaches ; vm -> sharedCacheAPI -> destroySharedCache = j9shr_destroySharedCache ; if ( ( vm -> sharedCacheAPI -> xShareClassesPresent == TRUE ) && ( vm -> sharedCacheAPI -> parseResult != RESULT_DO_UTILITIES ) ) { if ( ( rc = j9shr_init ( vm , loadFlags , & nonfatal ) ) != J9VMDLLMAIN_OK ) { if ( nonfatal ) { return J9VMDLLMAIN_OK ; } else { return rc ; } } vm -> systemClassLoader -> flags |= J9CLASSLOADER_SHARED_CLASSES_ENABLED ; if ( FIND_ARG_IN_VMARGS ( EXACT_MATCH , VMOPT_XNOLINENUMBERS , NULL ) < 0 ) { vm -> requiredDebugAttributes |= J9VM_DEBUG_ATTRIBUTE_RECORD_ALL ; } } break ; } case ALL_LIBRARIES_LOADED : { if ( ( vm -> sharedCacheAPI -> xShareClassesPresent == TRUE ) && ( vm -> sharedCacheAPI -> parseResult != RESULT_DO_UTILITIES ) ) { if ( 0 != initZipLibrary ( vm -> portLibrary , vm -> j2seRootDirectory ) ) { returnVal = J9VMDLLMAIN_FAILED ; } } break ; } case ABOUT_TO_BOOTSTRAP : { break ; } case LIBRARIES_ONUNLOAD : case JVM_EXIT_STAGE : j9shr_guaranteed_exit ( vm , FALSE ) ; break ; case HEAP_STRUCTURES_FREED : if ( vm != NULL ) { j9shr_shutdown ( vm ) ; } break ; default : break ; } return returnVal ; }
